{
  "papers": [
    {
      "paper_code": "ACL_23_P_866",
      "abstract": "The ability of commonsense reasoning (CR) decides whether a neural machine translation (NMT) model can move beyond pattern recognition. Despite the rapid advancement of NMT and the use of pretraining to enhance NMT models, research on CR in NMT is still in its infancy, leaving much to be explored in terms of effectively training NMT models with high CR abilities and devising accurate automatic evaluation metrics. This paper presents a comprehensive study aimed at expanding the understanding of CR in NMT. For the training, we confirm the effectiveness of incorporating pretrained knowledge into NMT models and subsequently utilizing these models as robust testbeds for investigating CR in NMT. For the evaluation, we propose a novel entity-aware evaluation method that takes into account both the NMT candidate and important entities in the candidate, which is more aligned with human judgement. Based on the strong testbed and evaluation methods, we identify challenges in training NMT models with high CR abilities and suggest directions for further unlabeled data utilization and model design. We hope that our methods and findings will contribute to advancing the research of CR in NMT.",
      "events": [
        {
          "Background/Introduction": "",
          "Text": "The ability of commonsense reasoning (CR) decides whether a neural machine translation (NMT) model can move beyond pattern recognition. Despite the rapid advancement of NMT and the use of pretraining to enhance NMT models, research on CR in NMT is still in its infancy, leaving much to be explored in terms of effectively training NMT models with high CR abilities and devising accurate automatic evaluation metrics.",
          "Main Action": "Despite the rapid advancement of NMT and the use of pretraining to enhance NMT models",
          "Arguments": {
            "Agent": [
              "researchers"
            ],
            "Object": {
              "Primary Object": [
                "Neural Machine Translation (NMT) models"
              ],
              "Secondary Object": [
                "<NONE>"
              ]
            },
            "Context": [
              "Commonsense Reasoning (CR)"
            ],
            "Purpose": [
              "effectively training NMT models with high CR abilities and devising accurate automatic evaluation metrics"
            ],
            "Method": [
              "pretraining"
            ],
            "Results": [
              "current state of research leaves much to be explored"
            ],
            "Analysis": [
              "previous studies have focused more on syntax rather than semantics"
            ],
            "Challenge": [
              "much to be explored in terms of effectively training NMT models"
            ],
            "Ethical": [
              "<NONE>"
            ],
            "Implications": [
              "significant improvements in NMT systems"
            ],
            "Contradictions": [
              "<NONE>"
            ]
          }
        },
        {
          "Methods/Approach": "",
          "Text": "This paper presents a comprehensive study aimed at expanding the understanding of CR in NMT. For the training, we confirm the effectiveness of incorporating pretrained knowledge into NMT models and subsequently utilizing these models as robust testbeds for investigating CR in NMT. For the evaluation, we propose a novel entity-aware evaluation method that takes into account both the NMT candidate and important entities in the candidate, which is more aligned with human judgement.",
          "Main Action": "propose a novel entity-aware evaluation method",
          "Arguments": {
            "Agent": [
              "we"
            ],
            "Object": {
              "Primary Object": [
                "NMT candidate"
              ],
              "Secondary Object": [
                "important entities in the candidate"
              ]
            },
            "Context": [
              "expanding understanding of CR in NMT"
            ],
            "Purpose": [
              "investigating CR in NMT"
            ],
            "Method": [
              "proposing a novel entity-aware evaluation method"
            ],
            "Results": [
              "aligning more closely with human judgement"
            ],
            "Analysis": [
              "<NONE>"
            ],
            "Challenge": [
              "<NONE>"
            ],
            "Ethical": [
              "<NONE>"
            ],
            "Implications": [
              "improving evaluation methods for natural language processing tasks involving machine translation"
            ],
            "Contradictions": [
              "<NONE>"
            ]
          }
        },
        {
          "Results/Findings": "",
          "Text": "Based on the strong testbed and evaluation methods, we identify challenges in training NMT models with high CR abilities and suggest directions for further unlabeled data utilization and model design.",
          "Main Action": "We identify challenges",
          "Arguments": {
            "Agent": [
              "<NONE>"
            ],
            "Object": {
              "Primary Object": [
                "NMT models"
              ],
              "Secondary Object": [
                "Model design"
              ]
            },
            "Context": [
              "Strong testbed and evaluation methods"
            ],
            "Purpose": [
              "To identify challenges in training NMT models"
            ],
            "Method": [
              "Strong testbed and evaluation methods"
            ],
            "Results": [
              "Challenges in training NMT models with high CR abilities"
            ],
            "Analysis": [
              "Directions for further unlabeled data utilization and model design"
            ],
            "Challenge": [
              "Training NMT models with high CR abilities"
            ],
            "Ethical": [
              "<NONE>"
            ],
            "Implications": [
              "Future applications through improved model designs"
            ],
            "Contradictions": [
              "<NONE>"
            ]
          }
        },
        {
          "Conclusions/Implications": "",
          "Text": "We hope that our methods and findings will contribute to advancing the research of CR in NMT.",
          "Main Action": "contribute",
          "Arguments": {
            "Agent": [
              "we"
            ],
            "Object": {
              "Primary Object": [
                "advancing the research of CR in NMT"
              ],
              "Secondary Object": [
                "<NONE>"
              ]
            },
            "Context": [
              "<NONE>"
            ],
            "Purpose": [
              "to advance the research of CR in NMT"
            ],
            "Method": [
              "our methods"
            ],
            "Results": [
              "our findings"
            ],
            "Analysis": [
              "<NONE>"
            ],
            "Challenge": [
              "<NONE>"
            ],
            "Ethical": [
              "<NONE>"
            ],
            "Implications": [
              "<NONE>"
            ],
            "Contradictions": [
              "<NONE>"
            ]
          }
        }
      ]
    },
    {
      "paper_code": "ACL_23_P_377",
      "abstract": "A series of datasets and models have been proposed for summaries generated for well-formatted documents such as news articles. Dialogue summaries, however, have been under explored. In this paper, we present the first dataset with fine-grained factual error annotations named DIASUMFACT. We define fine-grained factual error detection as a sentence-level multi-label classification problem, and weevaluate two state-of-the-art (SOTA) models on our dataset. Both models yield sub-optimal results, with a macro-averaged F1 score of around 0.25 over 6 error classes. We further propose an unsupervised model ENDERANKER via candidate ranking using pretrained encoder-decoder models. Our model performs on par with the SOTA models while requiring fewer resources. These observations confirm the challenges in detecting factual errors from dialogue summaries, which call for further studies, for which our dataset and results offer a solid foundation.",
      "events": [
        {
          "Background/Introduction": "",
          "Text": "A series of datasets and models have been proposed for summaries generated for well-formatted documents such as news articles. Dialogue summaries, however, have been under explored.",
          "Main Action": "datasets and models have been proposed",
          "Arguments": {
            "Agent": [
              "<NONE>"
            ],
            "Object": {
              "Primary Object": [
                "summaries",
                "well-formatted documents such as news articles"
              ],
              "Secondary Object": [
                "dialogue summaries"
              ]
            },
            "Context": [
              "<NONE>"
            ],
            "Purpose": [
              "<NONE>"
            ],
            "Method": [
              "<NONE>"
            ],
            "Results": [
              "<NONE>"
            ],
            "Analysis": [
              "<NONE>"
            ],
            "Challenge": [
              "under explored"
            ],
            "Ethical": [
              "<NONE>"
            ],
            "Implications": [
              "more research needed"
            ],
            "Contradictions": [
              "<NONE>"
            ]
          }
        },
        {
          "Methods/Approach": "",
          "Text": "In this paper, we present the first dataset with fine-grained factual error annotations named DIASUMFACT. We define fine-grained factual error detection as a sentence-level multi-label classification problem, and weevaluate two state-of-the-art (SOTA) models on our dataset. Both models yield sub-optimal results, with a macro-averaged F1 score of around 0.25 over 6 error classes. We further propose an unsupervised model ENDERANKER via candidate ranking using pretrained encoder-decoder models.",
          "Main Action": "Present",
          "Arguments": {
            "Agent": [
              "We"
            ],
            "Object": {
              "Primary Object": [
                "DIASUMFACT"
              ],
              "Secondary Object": [
                "<NONE>"
              ]
            },
            "Context": [
              "fine-grained factual error detection",
              "sentence-level multi-label classification problem"
            ],
            "Purpose": [
              "Evaluate two state-of-the-art models on our dataset"
            ],
            "Method": [
              "state-of-the-art (SOTA) models",
              "macro-averaged F1 score"
            ],
            "Results": [
              "sub-optimal results",
              "F1 score of around 0.25 over 6 error classes"
            ],
            "Analysis": [
              "<NONE>"
            ],
            "Challenge": [
              "<NONE>"
            ],
            "Ethical": [
              "<NONE>"
            ],
            "Implications": [
              "<NONE>"
            ],
            "Contradictions": [
              "<NONE>"
            ]
          }
        },
        {
          "Results/Findings": "",
          "Text": "Our model performs on par with the SOTA models while requiring fewer resources. These observations confirm the challenges in detecting factual errors from dialogue summaries, which call for further studies, for which our dataset and results offer a solid foundation.",
          "Main Action": "These observations",
          "Arguments": {
            "Agent": [
              "<NONE>"
            ],
            "Object": {
              "Primary Object": [
                "detecting factual errors from dialogue summaries"
              ],
              "Secondary Object": [
                "<NONE>"
              ]
            },
            "Context": [
              "challenges in detecting factual errors from dialogue summaries"
            ],
            "Purpose": [
              "further studies"
            ],
            "Method": [
              "dataset",
              "results"
            ],
            "Results": [
              "performing on par with the SOTA models while requiring fewer resources"
            ],
            "Analysis": [
              "<NONE>"
            ],
            "Challenge": [
              "challenges in detecting factual errors from dialogue summaries"
            ],
            "Ethical": [
              "<NONE>"
            ],
            "Implications": [
              "offering a solid foundation"
            ],
            "Contradictions": [
              "<NONE>"
            ]
          }
        }
      ]
    }
  ]
}