{
  "papers": [
    {
      "paper_code": "ACL_23_P_398",
      "abstract": "Many NLP pipelines split text into sentences as one of the crucial preprocessing steps. Prior sentence segmentation tools either rely on punctuation or require a considerable amount of sentence-segmented training data: both central assumptions might fail when porting sentence segmenters to diverse languages on a massive scale. In this work, we thus introduce a multilingual punctuation-agnostic sentence segmentation method, currently covering 85 languages, trained in a self-supervised fashion on unsegmented text, by making use of newline characters which implicitly perform segmentation into paragraphs. We further propose an approach that adapts our method to the segmentation in a given corpus by using only a small number (64-256) of sentence-segmented examples. The main results indicate that our method outperforms all the prior best sentence-segmentation tools by an average of 6.1% F1 points. Furthermore, we demonstrate that proper sentence segmentation has a point: the use of a (powerful) sentence segmenter makes a considerable difference for a downstream application such as machine translation (MT). By using our method to match sentence segmentation to the segmentation used during training of MT models, we achieve an average improvement of 2.3 BLEU points over the best prior segmentation tool, as well as massive gains over a trivial segmenter that splits text into equally-sized blocks.",
      "events": [
        {
          "Background/Introduction": "",
          "Text": "Many NLP pipelines split text into sentences as one of the crucial preprocessing steps. Prior sentence segmentation tools either rely on punctuation or require a considerable amount of sentence-segmented training data: both central assumptions might fail when porting sentence segmenters to diverse languages on a massive scale.",
          "Main Action": "<NONE>",
          "Arguments": {
            "Agent": [
              "<NONE>"
            ],
            "Object": {
              "Primary Object": [
                "<NONE>"
              ],
              "Secondary Object": [
                "<NONE>"
              ]
            },
            "Context": [
              "<NONE>"
            ],
            "Purpose": [
              "<NONE>"
            ],
            "Method": [
              "<NONE>"
            ],
            "Results": [
              "<NONE>"
            ],
            "Analysis": [
              "<NONE>"
            ],
            "Challenge": [
              "<NONE>"
            ],
            "Ethical": [
              "<NONE>"
            ],
            "Implications": [
              "<NONE>"
            ],
            "Contradictions": [
              "<NONE>"
            ]
          }
        },
        {
          "Methods/Approach": "",
          "Text": "In this work, we thus introduce a multilingual punctuation-agnostic sentence segmentation method, currently covering 85 languages, trained in a self-supervised fashion on unsegmented text, by making use of newline characters which implicitly perform segmentation into paragraphs. We further propose an approach that adapts our method to the segmentation in a given corpus by using only a small number (64-256) of sentence-segmented examples.",
          "Main Action": "Introduce",
          "Arguments": {
            "Agent": [
              "We"
            ],
            "Object": {
              "Primary Object": [
                "A multilingual punctuation-agnostic sentence segmentation method"
              ],
              "Secondary Object": [
                "Currently covering 85 languages"
              ]
            },
            "Context": [
              "Multilingual, punctuation-agnostic, self-supervised, unsegmented text, newline characters, paragraph segmentation, corpus-specific adaptation, small number of sentence-segmented examples"
            ],
            "Purpose": [
              "Improving cross-language text processing"
            ],
            "Method": [
              "Self-supervised training on unsegmented text",
              "Using newline characters for implicit segmentation",
              "Adapting the method to a given corpus"
            ],
            "Results": [
              "Covering 85 languages"
            ],
            "Analysis": [
              "Performance inferred through coverage and adaptability"
            ],
            "Challenge": [
              "Requires minimal example usage"
            ],
            "Ethical": [
              "<NONE>"
            ],
            "Implications": [
              "Broad applicability across languages"
            ],
            "Contradictions": [
              "<NONE>"
            ]
          }
        },
        {
          "Results/Findings": "",
          "Text": "The main results indicate that our method outperforms all the prior best sentence-segmentation tools by an average of 6.1% F1 points. Furthermore, we demonstrate that proper sentence segmentation has a point: the use of a (powerful) sentence segmenter makes a considerable difference for a downstream application such as machine translation (MT). By using our method to match sentence segmentation to the segmentation used during training of MT models, we achieve an average improvement of 2.3 BLEU points over the best prior segmentation tool, as well as massive gains over a trivial segmenter that splits text into equally-sized blocks.",
          "Main Action": "we demonstrate",
          "Arguments": {
            "Agent": [
              "we"
            ],
            "Object": {
              "Primary Object": [
                "proper sentence segmentation"
              ],
              "Secondary Object": [
                "machine translation (MT)"
              ]
            },
            "Context": [
              "prior best sentence-segmentation tools",
              "downstream application such as machine translation (MT)",
              "training of MT models"
            ],
            "Purpose": [
              "improve performance in machine translation"
            ],
            "Method": [
              "matching sentence segmentation to the segmentation used during training of MT models"
            ],
            "Results": [
              "average improvement of 2.3 BLEU points over the best prior segmentation tool",
              "massive gains over a trivial segmenter"
            ],
            "Analysis": [
              "This shows the effectiveness of their method beyond just numbers; perhaps explaining why alignment matters"
            ],
            "Challenge": [
              "Not sure if explicit challenges are mentioned"
            ],
            "Ethical": [
              "No ethical considerations discussed here"
            ],
            "Implications": [
              "Improved MT accuracy suggests broader impacts on NLP tasks relying on accurate segmentation"
            ],
            "Contradictions": [
              "None evident"
            ]
          }
        }
      ]
    },
    {
      "paper_code": "ACL_23_P_67",
      "abstract": "Unsupervised speech recognition (ASR-U) is the problem of learning automatic speech recognition (ASR) systems from unpaired speech-only and text-only corpora. While various algorithms exist to solve this problem, a theoretical framework is missing to study their properties and address such issues as sensitivity to hyperparameters and training instability. In this paper, we proposed a general theoretical framework to study the properties of ASR-U systems based on random matrix theory and the theory of neural tangent kernels. Such a framework allows us to prove various learnability conditions and sample complexity bounds of ASR-U. Extensive ASR-U experiments on synthetic languages with three classes of transition graphs provide strong empirical evidence for our theory.",
      "events": [
        {
          "Background/Introduction": "",
          "Text": "Unsupervised speech recognition (ASR-U) is the problem of learning automatic speech recognition (ASR) systems from unpaired speech-only and text-only corpora. While various algorithms exist to solve this problem, a theoretical framework is missing to study their properties and address such issues as sensitivity to hyperparameters and training instability.",
          "Main Action": "Recognizing",
          "Arguments": {
            "Agent": [
              "Researchers"
            ],
            "Object": {
              "Primary Object": [
                "Unsupervised speech recognition (ASR-U)"
              ],
              "Secondary Object": [
                "<NONE>"
              ]
            },
            "Context": [
              "Current methods relying solely on paired data"
            ],
            "Purpose": [
              "Filling the gap in existing literature and providing new insights"
            ],
            "Method": [
              "<NONE>"
            ],
            "Results": [
              "<NONE>"
            ],
            "Analysis": [
              "<NONE>"
            ],
            "Challenge": [
              "Sensitivity to hyperparameters and training instability"
            ],
            "Ethical": [
              "<NONE>"
            ],
            "Implications": [
              "Future applications and benefits"
            ],
            "Contradictions": [
              "Disagreements with existing assumptions"
            ]
          }
        },
        {
          "Methods/Approach": "",
          "Text": "In this paper, we proposed a general theoretical framework to study the properties of ASR-U systems based on random matrix theory and the theory of neural tangent kernels. Such a framework allows us to prove various learnability conditions and sample complexity bounds of ASR-U.",
          "Main Action": "proposed",
          "Arguments": {
            "Agent": [
              "<NONE>"
            ],
            "Object": {
              "Primary Object": [
                "ASR-U systems"
              ],
              "Secondary Object": [
                "random matrix theory",
                "theory of neural tangent kernels"
              ]
            },
            "Context": [
              "There were gaps in understanding the properties of ASR-U systems."
            ],
            "Purpose": [
              "To develop a framework to study the properties of ASR-U systems."
            ],
            "Method": [
              "general theoretical framework",
              "random matrix theory",
              "theory of neural tangent kernels"
            ],
            "Results": [
              "prove various learnability conditions",
              "sample complexity bounds"
            ],
            "Analysis": [
              "interpretations of other arguments",
              "effectiveness of the framework"
            ],
            "Challenge": [
              "Limitations of applying these theories",
              "complexities faced during the proof"
            ],
            "Ethical": [
              "<NONE>"
            ],
            "Implications": [
              "Future research directions enabled by this framework"
            ],
            "Contradictions": [
              "<NONE>"
            ]
          }
        },
        {
          "Results/Findings": "",
          "Text": "Extensive ASR-U experiments on synthetic languages with three classes of transition graphs provide strong empirical evidence for our theory.",
          "Main Action": "Conducting extensive ASR-U experiments",
          "Arguments": {
            "Agent": [
              "<NONE>"
            ],
            "Object": {
              "Primary Object": [
                "Synthetic languages"
              ],
              "Secondary Object": [
                "Three classes of transition graphs"
              ]
            },
            "Context": [
              "<NONE>"
            ],
            "Purpose": [
              "<NONE>"
            ],
            "Method": [
              "<NONE>"
            ],
            "Results": [
              "<NONE>"
            ],
            "Analysis": [
              "<NONE>"
            ],
            "Challenge": [
              "<NONE>"
            ],
            "Ethical": [
              "<NONE>"
            ],
            "Implications": [
              "<NONE>"
            ],
            "Contradictions": [
              "<NONE>"
            ]
          }
        }
      ]
    }
  ]
}