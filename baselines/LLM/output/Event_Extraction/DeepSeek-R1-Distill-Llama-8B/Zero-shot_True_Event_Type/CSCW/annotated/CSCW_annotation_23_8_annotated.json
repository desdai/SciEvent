{
  "papers": [
    {
      "paper_code": "cscw_23_P_267",
      "abstract": "Past work has explored various ways for online platforms to leverage crowd wisdom for misinformation detection and moderation. Yet, platforms often relegate governance to their communities, and limited research has been done from the perspective of these communities and their moderators. How is misinformation currently moderated in online communities that are heavily self-governed? What role does the crowd play in this process, and how can this process be improved? In this study, we answer these questions through semi-structured interviews with Reddit moderators. We focus on a case study of COVID-19 misinformation. First, our analysis identifies a general moderation workflow model encompassing various processes participants use for handling COVID-19 misinformation. Further, we show that the moderation workflow revolves around three elements: content facticity, user intent, and perceived harm. Next, our interviews reveal that Reddit moderators rely on two types of crowd wisdom for misinformation detection. Almost all participants are heavily reliant on reports from crowds of ordinary users to identify potential misinformation. A second crowd--participants' own moderation teams and expert moderators of other communities--provide support when participants encounter difficult, ambiguous cases. Finally, we use design probes to better understand how different types of crowd signals---from ordinary users and moderators---readily available on Reddit can assist moderators with identifying misinformation. We observe that nearly half of all participants preferred these cues over labels from expert fact-checkers because these cues can help them discern user intent. Additionally, a quarter of the participants distrust professional fact-checkers, raising important concerns about misinformation moderation.",
      "events": [
        {
          "Background/Introduction": "",
          "Text": "Past work has explored various ways for online platforms to leverage crowd wisdom for misinformation detection and moderation. Yet, platforms often relegate governance to their communities, and limited research has been done from the perspective of these communities and their moderators. How is misinformation currently moderated in online communities that are heavily self-governed? What role does the crowd play in this process, and how can this process be improved?",
          "Main Action": "Past work has explored",
          "Arguments": {
            "Agent": [
              "Past work"
            ],
            "Object": {
              "Primary Object": [
                "Various ways for online platforms to leverage crowd wisdom for misinformation detection and moderation"
              ],
              "Secondary Object": [
                "<NONE>"
              ]
            },
            "Context": [
              "Online platforms",
              "Misinformation detection and moderation"
            ],
            "Purpose": [
              "To explore ways for online platforms to leverage crowd wisdom for misinformation detection and moderation"
            ],
            "Method": [
              "<NONE>"
            ],
            "Results": [
              "<NONE>"
            ],
            "Analysis": [
              "<NONE>"
            ],
            "Challenge": [
              "<NONE>"
            ],
            "Ethical": [
              "<NONE>"
            ],
            "Implications": [
              "<NONE>"
            ],
            "Contradictions": [
              "<NONE>"
            ]
          }
        },
        {
          "Methods/Approach": "",
          "Text": "In this study, we answer these questions through semi-structured interviews with Reddit moderators. We focus on a case study of COVID-19 misinformation. First, our analysis identifies a general moderation workflow model encompassing various processes participants use for handling COVID-19 misinformation. Further, we show that the moderation workflow revolves around three elements: content facticity, user intent, and perceived harm.",
          "Main Action": "Conducting semi-structured interviews",
          "Arguments": {
            "Agent": [
              "We"
            ],
            "Object": {
              "Primary Object": [
                "Reddit moderators"
              ],
              "Secondary Object": [
                "<NONE>"
              ]
            },
            "Context": [
              "COVID-19 misinformation"
            ],
            "Purpose": [
              "Understanding how Reddit moderators handle COVID-19 misinformation"
            ],
            "Method": [
              "Semi-structured interviews",
              "General moderation workflow model",
              "Content facticity",
              "User intent",
              "Perceived harm"
            ],
            "Results": [
              "Three elements: content facticity, user intent, and perceived harm"
            ],
            "Analysis": [
              "Importance of each element in moderation"
            ],
            "Challenge": [
              "Limitations of sample size or depth of interviews"
            ],
            "Ethical": [
              "Ensuring anonymity of participants"
            ],
            "Implications": [
              "Contributing to understanding online misinformation management"
            ],
            "Contradictions": [
              "Prior research may have overlooked aspects of moderation"
            ]
          }
        },
        {
          "Results/Findings": "",
          "Text": "Next, our interviews reveal that Reddit moderators rely on two types of crowd wisdom for misinformation detection. Almost all participants are heavily reliant on reports from crowds of ordinary users to identify potential misinformation. A second crowd--participants' own moderation teams and expert moderators of other communities--provide support when participants encounter difficult, ambiguous cases. Finally, we use design probes to better understand how different types of crowd signals---from ordinary users and moderators---readily available on Reddit can assist moderators with identifying misinformation. We observe that nearly half of all participants preferred these cues over labels from expert fact-checkers because these cues can help them discern user intent. Additionally, a quarter of the participants distrust professional fact-checkers, raising important concerns about misinformation moderation.",
          "Main Action": "we observe that nearly half of all participants preferred these cues over labels from expert fact-checkers",
          "Arguments": {
            "Agent": [
              "We"
            ],
            "Object": {
              "Primary Object": [
                "Reddit moderators"
              ],
              "Secondary Object": [
                "expert fact-checkers"
              ]
            },
            "Context": [
              "Almost all participants are heavily reliant on reports from crowds of ordinary users to identify potential misinformation.",
              "A second crowd--participants' own moderation teams and expert moderators of other communities--provide support when participants encounter difficult, ambiguous cases.",
              "we use design probes to better understand how different types of crowd signals---from ordinary users and moderators---readily available on Reddit can assist moderators with identifying misinformation."
            ],
            "Purpose": [
              "<NONE>"
            ],
            "Method": [
              "<NONE>"
            ],
            "Results": [
              "<NONE>"
            ],
            "Analysis": [
              "<NONE>"
            ],
            "Challenge": [
              "<NONE>"
            ],
            "Ethical": [
              "<NONE>"
            ],
            "Implications": [
              "<NONE>"
            ],
            "Contradictions": [
              "<NONE>"
            ]
          }
        }
      ]
    },
    {
      "paper_code": "cscw_23_P_206",
      "abstract": "Traditional wall-sized displays mostly only support side-by-side co-located collaboration, while transparent displays naturally support face-to-face interaction. Many previous works assume transparent displays support collaboration. Yet it is unknown how exactly its afforded face-to-face interaction can support loose or close collaboration, especially compared to the side-by-side configuration offered by traditional large displays. In this paper, we used an established experimental task that operationalizes different collaboration coupling and layout locality, to compare pairs of participants collaborating side-by-side versus face-to-face in each collaborative situation. We compared quantitative measures and collected interview and observation data to further illustrate and explain our observed user behavior patterns. The results showed that the unique face-to-face collaboration brought by transparent display can result in more efficient task performance, different territorial behavior, and both positive and negative collaborative factors. Our findings provided empirical understanding about the collaborative experience supported by wall-sized transparent displays and shed light on its future design.",
      "events": [
        {
          "Background/Introduction": "",
          "Text": "Traditional wall-sized displays mostly only support side-by-side co-located collaboration, while transparent displays naturally support face-to-face interaction. Many previous works assume transparent displays support collaboration. Yet it is unknown how exactly its afforded face-to-face interaction can support loose or close collaboration, especially compared to the side-by-side configuration offered by traditional large displays.",
          "Main Action": "<NONE>",
          "Arguments": {
            "Agent": [
              "<NONE>"
            ],
            "Object": {
              "Primary Object": [
                "<NONE>"
              ],
              "Secondary Object": [
                "<NONE>"
              ]
            },
            "Context": [
              "transparent displays naturally support face-to-face interaction",
              "traditional wall-sized displays mostly only support side-by-side co-located collaboration"
            ],
            "Purpose": [
              "it is unknown how exactly its afforded face-to-face interaction can support loose or close collaboration",
              "compared to the side-by-side configuration offered by traditional large displays"
            ],
            "Method": [
              "<NONE>"
            ],
            "Results": [
              "<NONE>"
            ],
            "Analysis": [
              "Many previous works assume transparent displays support collaboration"
            ],
            "Challenge": [
              "<NONE>"
            ],
            "Ethical": [
              "<NONE>"
            ],
            "Implications": [
              "<NONE>"
            ],
            "Contradictions": [
              "<NONE>"
            ]
          }
        },
        {
          "Methods/Approach": "",
          "Text": "In this paper, we used an established experimental task that operationalizes different collaboration coupling and layout locality, to compare pairs of participants collaborating side-by-side versus face-to-face in each collaborative situation. We compared quantitative measures and collected interview and observation data to further illustrate and explain our observed user behavior patterns.",
          "Main Action": "We used an established experimental task",
          "Arguments": {
            "Agent": [
              "we"
            ],
            "Object": {
              "Primary Object": [
                "an established experimental task"
              ],
              "Secondary Object": [
                "<NONE>"
              ]
            },
            "Context": [
              "to compare pairs of participants collaborating side-by-side versus face-to-face in each collaborative situation"
            ],
            "Purpose": [
              "to compare pairs of participants collaborating side-by-side versus face-to-face in each collaborative situation"
            ],
            "Method": [
              "We compared quantitative measures and collected interview and observation data"
            ],
            "Results": [
              "further illustrate and explain our observed user behavior patterns"
            ],
            "Analysis": [
              "<NONE>"
            ],
            "Challenge": [
              "<NONE>"
            ],
            "Ethical": [
              "<NONE>"
            ],
            "Implications": [
              "understanding the effects of collaboration style on user behavior and possibly informing design decisions in group environments"
            ],
            "Contradictions": [
              "<NONE>"
            ]
          }
        },
        {
          "Results/Findings": "",
          "Text": "The results showed that the unique face-to-face collaboration brought by transparent display can result in more efficient task performance, different territorial behavior, and both positive and negative collaborative factors.",
          "Main Action": "showed",
          "Arguments": {
            "Agent": [
              "<NONE>"
            ],
            "Object": {
              "Primary Object": [
                "task performance"
              ],
              "Secondary Object": [
                "collaborative factors"
              ]
            },
            "Context": [
              "face-to-face collaboration",
              "transparent display"
            ],
            "Purpose": [
              "understanding how these interactions affect efficiency and dynamics during tasks"
            ],
            "Method": [
              "transparent display"
            ],
            "Results": [
              "improved task performance",
              "different territorial behavior",
              "both positive and negative collaborative factors"
            ],
            "Analysis": [
              "<NONE>"
            ],
            "Challenge": [
              "<NONE>"
            ],
            "Ethical": [
              "<NONE>"
            ],
            "Implications": [
              "potential for future applications in team settings"
            ],
            "Contradictions": [
              "<NONE>"
            ]
          }
        },
        {
          "Conclusions/Implications": "",
          "Text": "Our findings provided empirical understanding about the collaborative experience supported by wall-sized transparent displays and shed light on its future design.",
          "Main Action": "shed light",
          "Arguments": {
            "Agent": [
              "findings"
            ],
            "Object": {
              "Primary Object": [
                "its future design"
              ],
              "Secondary Object": [
                "<NONE>"
              ]
            },
            "Context": [
              "collaborative experience supported by wall-sized transparent displays"
            ],
            "Purpose": [
              "<NONE>"
            ],
            "Method": [
              "<NONE>"
            ],
            "Results": [
              "our findings"
            ],
            "Analysis": [
              "<NONE>"
            ],
            "Challenge": [
              "<NONE>"
            ],
            "Ethical": [
              "<NONE>"
            ],
            "Implications": [
              "sheltering light on its future design"
            ],
            "Contradictions": [
              "<NONE>"
            ]
          }
        }
      ]
    }
  ]
}