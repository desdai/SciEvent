{
  "papers": [
    {
      "paper_code": "ACL_23_P_22",
      "abstract": "Classic approaches to content moderation typically apply a rule-based heuristic approach to flag content. While rules are easily customizable and intuitive for humans to interpret, they are inherently fragile and lack the flexibility or robustness needed to moderate the vast amount of undesirable content found online today. Recent advances in deep learning have demonstrated the promise of using highly effective deep neural models to overcome these challenges. However, despite the improved performance, these data-driven models lack transparency and explainability, often leading to mistrust from everyday users and a lack of adoption by many platforms. In this paper, we present Rule By Example (RBE): a novel exemplar-based contrastive learning approach for learning from logical rules for the task of textual content moderation. RBE is capable of providing rule-grounded predictions, allowing for more explainable and customizable predictions compared to typical deep learning-based approaches. We demonstrate that our approach is capable of learning rich rule embedding representations using only a few data examples. Experimental results on 3 popular hate speech classification datasets show that RBE is able to outperform state-of-the-art deep learning classifiers as well as the use of rules in both supervised and unsupervised settings while providing explainable model predictions via rule-grounding.",
      "events": [
        {
          "Background/Introduction": "",
          "Text": "Classic approaches to content moderation typically apply a rule-based heuristic approach to flag content. While rules are easily customizable and intuitive for humans to interpret, they are inherently fragile and lack the flexibility or robustness needed to moderate the vast amount of undesirable content found online today. Recent advances in deep learning have demonstrated the promise of using highly effective deep neural models to overcome these challenges. However, despite the improved performance, these data-driven models lack transparency and explainability, often leading to mistrust from everyday users and a lack of adoption by many platforms.",
          "Main Action": "Highlighting the limitations of contemporary content moderation methods",
          "Arguments": {
            "Agent": [
              "<NONE>"
            ],
            "Object": {
              "Primary Object": [
                "Deep learning models"
              ],
              "Secondary Object": [
                "Content moderation"
              ]
            },
            "Context": [
              "Traditional rule-based approaches and increasing digital content volume"
            ],
            "Purpose": [
              "Improving content moderation efficiency and reliability"
            ],
            "Method": [
              "Rule-based heuristics",
              "Deep learning models"
            ],
            "Results": [
              "Improved performance over traditional methods"
            ],
            "Analysis": [
              "Lack of transparency in AI models"
            ],
            "Challenge": [
              "Mistrust among users due to opacity"
            ],
            "Ethical": [
              "Potential impact on platform reputation and user trust"
            ],
            "Implications": [
              "Need for more transparent algorithms in future research"
            ],
            "Contradictions": [
              "Trade-off between computational power and interpretability"
            ]
          }
        },
        {
          "Methods/Approach": "",
          "Text": "In this paper, we present Rule By Example (RBE): a novel exemplar-based contrastive learning approach for learning from logical rules for the task of textual content moderation. RBE is capable of providing rule-grounded predictions, allowing for more explainable and customizable predictions compared to typical deep learning-based approaches.",
          "Main Action": "present",
          "Arguments": {
            "Agent": [
              "we"
            ],
            "Object": {
              "Primary Object": [
                "Rule By Example (RBE)"
              ],
              "Secondary Object": [
                "<NONE>"
              ]
            },
            "Context": [
              "textual content moderation",
              "logical rules",
              "deep learning-based approaches"
            ],
            "Purpose": [
              "more explainable and customizable predictions"
            ],
            "Method": [
              "exemplar-based contrastive learning approach",
              "learning from logical rules"
            ],
            "Results": [
              "rule-grounded predictions"
            ],
            "Analysis": [
              "<NONE>"
            ],
            "Challenge": [
              "<NONE>"
            ],
            "Ethical": [
              "<NONE>"
            ],
            "Implications": [
              "improving over existing methods"
            ],
            "Contradictions": [
              "<NONE>"
            ]
          }
        },
        {
          "Results/Findings": "",
          "Text": "We demonstrate that our approach is capable of learning rich rule embedding representations using only a few data examples. Experimental results on 3 popular hate speech classification datasets show that RBE is able to outperform state-of-the-art deep learning classifiers as well as the use of rules in both supervised and unsupervised settings while providing explainable model predictions via rule-grounding.",
          "Main Action": "demonstrate",
          "Arguments": {
            "Agent": [
              "our approach"
            ],
            "Object": {
              "Primary Object": [
                "rule embedding representations"
              ],
              "Secondary Object": [
                "<NONE>"
              ]
            },
            "Context": [
              "<NONE>"
            ],
            "Purpose": [
              "evaluate the effectiveness of Rule-Based Embedding"
            ],
            "Method": [
              "testing Rule-Based Embedding on three hate speech datasets"
            ],
            "Results": [
              "experimental results on 3 popular hate speech classification datasets show that RBE is able to outperform state-of-the-art deep learning classifiers"
            ],
            "Analysis": [
              "<NONE>"
            ],
            "Challenge": [
              "<NONE>"
            ],
            "Ethical": [
              "<NONE>"
            ],
            "Implications": [
              "advancements in model interpretability and efficient training with limited data"
            ],
            "Contradictions": [
              "<NONE>"
            ]
          }
        }
      ]
    },
    {
      "paper_code": "ACL_23_P_219",
      "abstract": "Monolingual word alignment is crucial to model semantic interactions between sentences. In particular, null alignment, a phenomenon in which words have no corresponding counterparts, is pervasive and critical in handling semantically divergent sentences. Identification of null alignment is useful on its own to reason about the semantic similarity of sentences by indicating there exists information inequality. To achieve unbalanced word alignment that values both alignment and null alignment, this study shows that the family of optimal transport (OT), i.e., balanced, partial, and unbalanced OT, are natural and powerful approaches even without tailor-made techniques. Our extensive experiments covering unsupervised and supervised settings indicate that our generic OT-based alignment methods are competitive against the state-of-the-arts specially designed for word alignment, remarkably on challenging datasets with high null alignment frequencies.",
      "events": [
        {
          "Background/Introduction": "",
          "Text": "Monolingual word alignment is crucial to model semantic interactions between sentences. In particular, null alignment, a phenomenon in which words have no corresponding counterparts, is pervasive and critical in handling semantically divergent sentences. Identification of null alignment is useful on its own to reason about the semantic similarity of sentences by indicating there exists information inequality.",
          "Main Action": "Identification of null alignment",
          "Arguments": {
            "Agent": [
              "<NONE>"
            ],
            "Object": {
              "Primary Object": [
                "Null alignment"
              ],
              "Secondary Object": [
                "<NONE>"
              ]
            },
            "Context": [
              "This indicates there exists information inequality"
            ],
            "Purpose": [
              "To improve handling of semantically divergent sentences"
            ],
            "Method": [
              "<NONE>"
            ],
            "Results": [
              "Null alignment is pervasive and critical",
              "Handling semantically divergent sentences"
            ],
            "Analysis": [
              "By indicating there exists information inequality"
            ],
            "Challenge": [
              "<NONE>"
            ],
            "Ethical": [
              "<NONE>"
            ],
            "Implications": [
              "Enhancing Natural Language Processing models"
            ],
            "Contradictions": [
              "<NONE>"
            ]
          }
        },
        {
          "Methods/Approach": "ERROR",
          "Text": "To achieve unbalanced word alignment that values both alignment and null alignment, this study shows that the family of optimal transport (OT), i.e., balanced, partial, and unbalanced OT, are natural and powerful approaches even without tailor-made techniques.",
          "Main Action": "ERROR",
          "Arguments": {
            "Agent": [
              "ERROR"
            ],
            "Object": {
              "Primary Object": [
                "ERROR"
              ],
              "Secondary Object": [
                "ERROR"
              ]
            },
            "Context": [
              "ERROR"
            ],
            "Purpose": [
              "ERROR"
            ],
            "Method": [
              "ERROR"
            ],
            "Results": [
              "ERROR"
            ],
            "Analysis": [
              "ERROR"
            ],
            "Challenge": [
              "ERROR"
            ],
            "Ethical": [
              "ERROR"
            ],
            "Implications": [
              "ERROR"
            ],
            "Contradictions": [
              "ERROR"
            ]
          },
          "Error_Type": "NO_JSON_FOUND"
        },
        {
          "Results/Findings": "",
          "Text": "Our extensive experiments covering unsupervised and supervised settings indicate that our generic OT-based alignment methods are competitive against the state-of-the-arts specially designed for word alignment, remarkably on challenging datasets with high null alignment frequencies.",
          "Main Action": "extensive experiments",
          "Arguments": {
            "Agent": [
              "Our"
            ],
            "Object": {
              "Primary Object": [
                "generic OT-based alignment methods"
              ],
              "Secondary Object": [
                "<NONE>"
              ]
            },
            "Context": [
              "unsupervised and supervised settings"
            ],
            "Purpose": [
              "to evaluate and demonstrate the effectiveness of their alignment methods compared to current best practices"
            ],
            "Method": [
              "OT-based alignment methods"
            ],
            "Results": [
              "are competitive against the state-of-the-arts...on challenging datasets with high null alignment frequencies"
            ],
            "Analysis": [
              "<NONE>"
            ],
            "Challenge": [
              "challenging datasets with high null alignment frequencies"
            ],
            "Ethical": [
              "<NONE>"
            ],
            "Implications": [
              "may lead to better word alignment technologies or inspire new approaches in NLP"
            ],
            "Contradictions": [
              "<NONE>"
            ]
          }
        }
      ]
    }
  ]
}