{
  "papers": [
    {
      "paper_code": "ACL_23_P_03",
      "abstract": "While the problem of hallucinations in neural machine translation has long been recognized, so far the progress on its alleviation is very little. Indeed, recently it turned out that without artificially encouraging models to hallucinate, previously existing methods fall short and even the standard sequence log-probability is more informative. It means that internal characteristics of the model can give much more information than we expect, and before using external models and measures, we first need to ask: how far can we go if we use nothing but the translation model itself? We propose to use a method that evaluates the percentage of the source contribution to a generated translation. Intuitively, hallucinations are translations “detached” from the source, hence they can be identified by low source contribution. This method improves detection accuracy for the most severe hallucinations by a factor of 2 and is able to alleviate hallucinations at test time on par with the previous best approach that relies on external models. Next, if we move away from internal model characteristics and allow external tools, we show that using sentence similarity from cross-lingual embeddings further improves these results.",
      "events": [
        {
          "Background/Introduction": "",
          "Text": "While the problem of hallucinations in neural machine translation has long been recognized, so far the progress on its alleviation is very little. Indeed, recently it turned out that without artificially encouraging models to hallucinate, previously existing methods fall short and even the standard sequence log-probability is more informative. It means that internal characteristics of the model can give much more information than we expect, and before using external models and measures, we first need to ask: how far can we go if we use nothing but the translation model itself?",
          "Main Action": "have been extensively studied",
          "Arguments": {
            "Agent": [
              "hallucinations in neural machine translation"
            ],
            "Object": {
              "Primary Object": [
                "the problem"
              ],
              "Secondary Object": [
                "<NONE>"
              ]
            },
            "Context": [
              "graph data structures play a central role in computing de novo genome assembly",
              "Most long-read assemblers use Myers's string graph model to sparsify overlap graphs",
              "Graph sparsification improves assembly contiguity by removing spurious and redundant connections",
              "a graph model must be coverage-preserving",
              "for diploid genomes, polyploid genomes, and metagenomes"
            ],
            "Purpose": [
              "<NONE>"
            ],
            "Method": [
              "<NONE>"
            ],
            "Results": [
              "<NONE>"
            ],
            "Analysis": [
              "<NONE>"
            ],
            "Challenge": [
              "a graph model must be coverage-preserving",
              "a risk of losing haplotype-specific information"
            ],
            "Ethical": [
              "<NONE>"
            ],
            "Implications": [
              "<NONE>"
            ],
            "Contradictions": [
              "<NONE>"
            ]
          }
        },
        {
          "Methods/Approach": "",
          "Text": "We propose to use a method that evaluates the percentage of the source contribution to a generated translation. Intuitively, hallucinations are translations “detached” from the source, hence they can be identified by low source contribution.",
          "Main Action": "evaluate",
          "Arguments": {
            "Agent": [
              "the percentage of the source contribution to a generated translation"
            ],
            "Object": {
              "Primary Object": [
                "hallucinations"
              ],
              "Secondary Object": [
                "<NONE>"
              ]
            },
            "Context": [
              "intuitively, hallucinations are translations 'detached' from the source, hence they can be identified by low source contribution"
            ],
            "Purpose": [
              "<NONE>"
            ],
            "Method": [
              "<NONE>"
            ],
            "Results": [
              "as in human SLA, language family distance predicts more negative transfer"
            ],
            "Analysis": [
              "<NONE>"
            ],
            "Challenge": [
              "negative transfer",
              "risk of losing haplotype-specific information"
            ],
            "Ethical": [
              "<NONE>"
            ],
            "Implications": [
              "<NONE>"
            ],
            "Contradictions": [
              "<NONE>"
            ]
          }
        },
        {
          "Results/Findings": "",
          "Text": "This method improves detection accuracy for the most severe hallucinations by a factor of 2 and is able to alleviate hallucinations at test time on par with the previous best approach that relies on external models. Next, if we move away from internal model characteristics and allow external tools, we show that using sentence similarity from cross-lingual embeddings further improves these results.",
          "Main Action": "improves detection accuracy for the most severe hallucinations by a factor of 2",
          "Arguments": {
            "Agent": [
              "this method"
            ],
            "Object": {
              "Primary Object": [
                "detection accuracy for the most severe hallucinations"
              ],
              "Secondary Object": [
                "<NONE>"
              ]
            },
            "Context": [
              "next, if we move away from internal model characteristics and allow external tools, we show that using sentence similarity from cross-lingual embeddings further improves these results."
            ],
            "Purpose": [
              "<NONE>"
            ],
            "Method": [
              "<NONE>"
            ],
            "Results": [
              "<NONE>"
            ],
            "Analysis": [
              "<NONE>"
            ],
            "Challenge": [
              "<NONE>"
            ],
            "Ethical": [
              "<NONE>"
            ],
            "Implications": [
              "<NONE>"
            ],
            "Contradictions": [
              "<NONE>"
            ]
          }
        }
      ]
    },
    {
      "paper_code": "ACL_23_P_809",
      "abstract": "The wide accessibility of social media has provided linguistically under-represented communities with an extraordinary opportunity to create content in their native languages. This, however, comes with certain challenges in script normalization, particularly where the speakers of a language in a bilingual community rely on another script or orthography to write their native language. This paper addresses the problem of script normalization for several such languages that are mainly written in a Perso-Arabic script. Using synthetic data with various levels of noise and a transformer-based model, we demonstrate that the problem can be effectively remediated. We conduct a small-scale evaluation of real data as well. Our experiments indicate that script normalization is also beneficial to improve the performance of downstream tasks such as machine translation and language identification.",
      "events": [
        {
          "Background/Introduction": "",
          "Text": "The wide accessibility of social media has provided linguistically under-represented communities with an extraordinary opportunity to create content in their native languages. This, however, comes with certain challenges in script normalization, particularly where the speakers of a language in a bilingual community rely on another script or orthography to write their native language.",
          "Main Action": "provided",
          "Arguments": {
            "Agent": [
              "linguistically under-represented communities"
            ],
            "Object": {
              "Primary Object": [
                "content in their native languages"
              ],
              "Secondary Object": [
                "<NONE>"
              ]
            },
            "Context": [
              "accessibility of social media"
            ],
            "Purpose": [
              "<NONE>"
            ],
            "Method": [
              "<NONE>"
            ],
            "Results": [
              "<NONE>"
            ],
            "Analysis": [
              "<NONE>"
            ],
            "Challenge": [
              "normalization",
              "script normalization",
              "understandable script or orthography"
            ],
            "Ethical": [
              "<NONE>"
            ],
            "Implications": [
              "opportunity",
              "extraordinary opportunity",
              "create content",
              "express themselves freely"
            ],
            "Contradictions": [
              "<NONE>"
            ]
          }
        },
        {
          "Methods/Approach": "",
          "Text": "This paper addresses the problem of script normalization for several such languages that are mainly written in a Perso-Arabic script. Using synthetic data with various levels of noise and a transformer-based model, we demonstrate that the problem can be effectively remediated. We conduct a small-scale evaluation of real data as well.",
          "Main Action": "<NONE>",
          "Arguments": {
            "Agent": [
              "<NONE>"
            ],
            "Object": {
              "Primary Object": [
                "<NONE>"
              ],
              "Secondary Object": [
                "<NONE>"
              ]
            },
            "Context": [
              "Using synthetic data with various levels of noise and a transformer-based model",
              "we demonstrate that the problem can be effectively remediated",
              "Additionally, we evaluate real data as well"
            ],
            "Purpose": [
              "<NONE>"
            ],
            "Method": [
              "synthetic data with various levels of noise",
              "transformer-based model"
            ],
            "Results": [
              "problem can be effectively remediated",
              "evaluation of real data confirms effectiveness"
            ],
            "Analysis": [
              "<NONE>"
            ],
            "Challenge": [
              "remediating the problem requires careful consideration of noise levels and model performance trade-offs"
            ],
            "Ethical": [
              "<NONE>"
            ],
            "Implications": [
              "<NONE>"
            ],
            "Contradictions": [
              "<NONE>"
            ]
          }
        },
        {
          "Results/Findings": "",
          "Text": "Our experiments indicate that script normalization is also beneficial to improve the performance of downstream tasks such as machine translation and language identification.",
          "Main Action": "experiments indicate",
          "Arguments": {
            "Agent": [
              "Our experiments"
            ],
            "Object": {
              "Primary Object": [
                "script normalization is also beneficial to improve the performance of downstream tasks"
              ],
              "Secondary Object": [
                "<NONE>"
              ]
            },
            "Context": [
              "effects of such transfer can be positive (facilitating acquisition) or negative (impeding acquisition)",
              "language family distance predicts more negative transfer"
            ],
            "Purpose": [
              "<NONE>"
            ],
            "Method": [
              "<NONE>"
            ],
            "Results": [
              "<NONE>"
            ],
            "Analysis": [
              "<NONE>"
            ],
            "Challenge": [
              "<NONE>"
            ],
            "Ethical": [
              "<NONE>"
            ],
            "Implications": [
              "<NONE>"
            ],
            "Contradictions": [
              "<NONE>"
            ]
          }
        }
      ]
    }
  ]
}