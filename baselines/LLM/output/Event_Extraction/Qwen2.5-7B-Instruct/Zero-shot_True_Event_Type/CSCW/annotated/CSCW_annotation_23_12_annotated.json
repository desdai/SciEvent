{
  "papers": [
    {
      "paper_code": "cscw_23_P_57",
      "abstract": "Sexist content is widespread on social media and can reduce women's psychological well-being and their willingness to participate in online discourse, making it a societal issue. To counter these effects, social media platforms employ moderators. To date, little is known about the effectiveness of different forms of moderation in creating a safe space and their acceptance, in particular from the perspective of women as members of the targeted group and users in general (rather than perpetrators). In this research, we propose that some common forms of moderation can be systematized along two facets of visibility, namely visibility of sexist content and of counterspeech. In an online experiment (N = 839), we manipulated these two facets and tested how they shaped social norms, feelings of safety, and intent to participate, as well as fairness, trustworthiness, and efficacy evaluations. In line with our predictions, deletion of sexist content - i.e., its invisibility - and (public) counterspeech - i.e., its visibility - against visible sexist content contributed to creating a safe space. Looking at the underlying psychological mechanism, we found that these effects were largely driven by changes in what was perceived normative in the presented context. Interestingly, deletion of sexist content was judged as less fair than counterspeech against visible sexist content. Our research contributes to a growing body of literature that highlights the importance of norms in creating safer online environments and provides practical implications for moderators for selecting actions that can be effective and accepted.",
      "events": [
        {
          "Background/Introduction": "",
          "Text": "Sexist content is widespread on social media and can reduce women's psychological well-being and their willingness to participate in online discourse, making it a societal issue. To counter these effects, social media platforms employ moderators. To date, little is known about the effectiveness of different forms of moderation in creating a safe space and their acceptance, in particular from the perspective of women as members of the targeted group and users in general (rather than perpetrators).",
          "Main Action": "<NONE>",
          "Arguments": {
            "Agent": [
              "little is known"
            ],
            "Object": {
              "Primary Object": [
                "effectiveness of different forms of moderation",
                "acceptance"
              ],
              "Secondary Object": [
                "social media platforms",
                "women as members of the targeted group and users in general"
              ]
            },
            "Context": [
              "sexist content is widespread on social media and can reduce women's psychological well-being and their willingness to participate in online discourse, making it a societal issue"
            ],
            "Purpose": [
              "To counter these effects"
            ],
            "Method": [
              "<NONE>"
            ],
            "Results": [
              "<NONE>"
            ],
            "Analysis": [
              "<NONE>"
            ],
            "Challenge": [
              "<NONE>"
            ],
            "Ethical": [
              "<NONE>"
            ],
            "Implications": [
              "in particular from the perspective of women as members of the targeted group and users in general (rather than perpetrators)"
            ],
            "Contradictions": [
              "<NONE>"
            ]
          }
        },
        {
          "Methods/Approach": "",
          "Text": "In this research, we propose that some common forms of moderation can be systematized along two facets of visibility, namely visibility of sexist content and of counterspeech. In an online experiment (N = 839), we manipulated these two facets and tested how they shaped social norms, feelings of safety, and intent to participate, as well as fairness, trustworthiness, and efficacy evaluations.",
          "Main Action": "<NONE>",
          "Arguments": {
            "Agent": [
              "we"
            ],
            "Object": {
              "Primary Object": [
                "some common forms of moderation",
                "two facets of visibility"
              ],
              "Secondary Object": [
                "<NONE>"
              ]
            },
            "Context": [
              "In this research"
            ],
            "Purpose": [
              "to test how they shaped social norms, feelings of safety, and intent to participate, as well as fairness, trustworthiness, and efficacy evaluations"
            ],
            "Method": [
              "manipulated these two facets and conducted an online experiment"
            ],
            "Results": [
              "not explicitly mentioned but implied through testing conditions"
            ],
            "Analysis": [
              "how they shaped...intent to participate, as well as fairness, trustworthiness, and efficacy evaluations"
            ],
            "Challenge": [
              "<NONE>"
            ],
            "Ethical": [
              "<NONE>"
            ],
            "Implications": [
              "<NONE>"
            ],
            "Contradictions": [
              "<NONE>"
            ]
          }
        },
        {
          "Results/Findings": "",
          "Text": "In line with our predictions, deletion of sexist content - i.e., its invisibility - and (public) counterspeech - i.e., its visibility - against visible sexist content contributed to creating a safe space. Looking at the underlying psychological mechanism, we found that these effects were largely driven by changes in what was perceived normative in the presented context. Interestingly, deletion of sexist content was judged as less fair than counterspeech against visible sexist content.",
          "Main Action": "<NONE>",
          "Arguments": {
            "Agent": [
              "we"
            ],
            "Object": {
              "Primary Object": [
                "deletion of sexist content",
                "(public) counterspeech against visible sexist content"
              ],
              "Secondary Object": [
                "creating a safe space",
                "changes in what was perceived normative in the presented context"
              ]
            },
            "Context": [
              "Looking at the underlying psychological mechanism"
            ],
            "Purpose": [
              "contributed to creating a safe space",
              "were largely driven by changes in what was perceived normative in the presented context"
            ],
            "Method": [
              "["
            ],
            "Results": [
              "deletion of sexist content was judged as less fair than counterspeech against visible sexist content"
            ],
            "Analysis": [
              "these effects were largely driven by changes in what was perceived normative in the presented context"
            ],
            "Challenge": [
              "<NONE>"
            ],
            "Ethical": [
              "<NONE>"
            ],
            "Implications": [
              "what is the broader significance or potential for future applications/research"
            ],
            "Contradictions": [
              "<NONE>"
            ]
          }
        },
        {
          "Conclusions/Implications": "",
          "Text": "Our research contributes to a growing body of literature that highlights the importance of norms in creating safer online environments and provides practical implications for moderators for selecting actions that can be effective and accepted.",
          "Main Action": "<NONE>",
          "Arguments": {
            "Agent": [
              "our research"
            ],
            "Object": {
              "Primary Object": [
                "a growing body of literature"
              ],
              "Secondary Object": [
                "moderators"
              ]
            },
            "Context": [
              "highlights the importance of norms in creating safer online environments"
            ],
            "Purpose": [
              "provides practical implications for moderators for selecting actions that can be effective and accepted"
            ],
            "Method": [
              "<NONE>"
            ],
            "Results": [
              "<NONE>"
            ],
            "Analysis": [
              "<NONE>"
            ],
            "Challenge": [
              "<NONE>"
            ],
            "Ethical": [
              "<NONE>"
            ],
            "Implications": [
              "broad significance or potential for future applications/research"
            ],
            "Contradictions": [
              "<NONE>"
            ]
          }
        }
      ]
    },
    {
      "paper_code": "cscw_23_P_249",
      "abstract": "News sharing has become prevalent on many social media platforms. Users are not only exposed to news shared by others, but also actively share information with a diverse set of motivations. In this work, we propose five news sharing motivations based on the intrinsic and extrinsic factors found in prior literature. Through an online experiment, we further examine how a host of factors, including motivations, influence participants' decision to share news online. We then prompt participants to switch their original decision for extra compensation, observing how different news types, motivational and demographic factors may affect the switch. Our analysis suggests that sharing decisions can be reversed when a strong external stimulus (higher bonus) is presented. Further, there are motivational factors that independently influence participants' reversal decisions. Finally, using our work as an empirical basis, we propose designs for future new sharing systems.",
      "events": [
        {
          "Background/Introduction": "",
          "Text": "News sharing has become prevalent on many social media platforms. Users are not only exposed to news shared by others, but also actively share information with a diverse set of motivations.",
          "Main Action": "<NONE>",
          "Arguments": {
            "Agent": [
              "Users"
            ],
            "Object": {
              "Primary Object": [
                "news shared by others",
                "information"
              ],
              "Secondary Object": [
                "a diverse set of motivations"
              ]
            },
            "Context": [
              "on many social media platforms"
            ],
            "Purpose": [
              "<NONE>"
            ],
            "Method": [
              "<NONE>"
            ],
            "Results": [
              "<NONE>"
            ],
            "Analysis": [
              "<NONE>"
            ],
            "Challenge": [
              "<NONE>"
            ],
            "Ethical": [
              "<NONE>"
            ],
            "Implications": [
              "<NONE>"
            ],
            "Contradictions": [
              "<NONE>"
            ]
          }
        },
        {
          "Methods/Approach": "",
          "Text": "In this work, we propose five news sharing motivations based on the intrinsic and extrinsic factors found in prior literature. Through an online experiment, we further examine how a host of factors, including motivations, influence participants' decision to share news online. We then prompt participants to switch their original decision for extra compensation, observing how different news types, motivational and demographic factors may affect the switch.",
          "Main Action": "propose",
          "Arguments": {
            "Agent": [
              "we"
            ],
            "Object": {
              "Primary Object": [
                "five news sharing motivations"
              ],
              "Secondary Object": [
                "intrinsic and extrinsic factors"
              ]
            },
            "Context": [
              "based on the intrinsic and extrinsic factors found in prior literature"
            ],
            "Purpose": [
              "further examine how a host of factors, including motivations, influence participants' decision to share news online"
            ],
            "Method": [
              "an online experiment"
            ],
            "Results": [
              "prompt participants to switch their original decision for extra compensation, observing how different news types, motivational and demographic factors may affect the switch"
            ],
            "Analysis": [
              "<NONE>"
            ],
            "Challenge": [
              "<NONE>"
            ],
            "Ethical": [
              "<NONE>"
            ],
            "Implications": [
              "<NONE>"
            ],
            "Contradictions": [
              "<NONE>"
            ]
          }
        },
        {
          "Results/Findings": "",
          "Text": "Our analysis suggests that sharing decisions can be reversed when a strong external stimulus (higher bonus) is presented. Further, there are motivational factors that independently influence participants' reversal decisions.",
          "Main Action": "<NONE>",
          "Arguments": {
            "Agent": [
              "There are motivational factors"
            ],
            "Object": {
              "Primary Object": [
                "participants' reversal decisions"
              ],
              "Secondary Object": [
                "a strong external stimulus (higher bonus)"
              ]
            },
            "Context": [
              "<NONE>"
            ],
            "Purpose": [
              "<NONE>"
            ],
            "Method": [
              "<NONE>"
            ],
            "Results": [
              "sharing decisions can be reversed",
              "motivational factors that independently influence"
            ],
            "Analysis": [
              "<NONE>"
            ],
            "Challenge": [
              "<NONE>"
            ],
            "Ethical": [
              "<NONE>"
            ],
            "Implications": [
              "<NONE>"
            ],
            "Contradictions": [
              "<NONE>"
            ]
          }
        },
        {
          "Conclusions/Implications": "",
          "Text": "Finally, using our work as an empirical basis, we propose designs for future new sharing systems.",
          "Main Action": "propose",
          "Arguments": {
            "Agent": [
              "we"
            ],
            "Object": {
              "Primary Object": [
                "designs"
              ],
              "Secondary Object": [
                "future new sharing systems"
              ]
            },
            "Context": [
              "using our work as an empirical basis"
            ],
            "Purpose": [
              "<NONE>"
            ],
            "Method": [
              "<NONE>"
            ],
            "Results": [
              "<NONE>"
            ],
            "Analysis": [
              "<NONE>"
            ],
            "Challenge": [
              "<NONE>"
            ],
            "Ethical": [
              "<NONE>"
            ],
            "Implications": [
              "broader significance or potential for future applications/research"
            ],
            "Contradictions": [
              "<NONE>"
            ]
          }
        }
      ]
    }
  ]
}