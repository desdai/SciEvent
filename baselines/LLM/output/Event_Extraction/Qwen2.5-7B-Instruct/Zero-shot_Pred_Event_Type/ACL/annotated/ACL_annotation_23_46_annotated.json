{
  "papers": [
    {
      "paper_code": "ACL_23_P_359",
      "abstract": "Social biases and stereotypes are embedded in our culture in part through their presence in our stories, as evidenced by the rich history of humanities and social science literature analyzing such biases in children's stories. Because these analyses are often conducted manually and at a small scale, such investigations can benefit from the use of more recent natural language processing (NLP) methods that examine social bias in models and data corpora. Our work joins this interdisciplinary effort and makes a unique contribution by taking into account the event narrative structures when analyzing the social bias of stories. We propose a computational pipeline that automatically extracts a story’s temporal narrative verb-based event chain for each of its characters as well as character attributes such as gender. We also present a verb-based event annotation scheme that can facilitate bias analysis by including categories such as those that align with traditional stereotypes. Through a case study analyzing gender bias in fairy tales, we demonstrate that our framework can reveal bias in not only the unigram verb-based events in which female and male characters participate but also in the temporal narrative order of such event participation.",
      "events": [
        {
          "Background/Introduction": "",
          "Text": "Social biases and stereotypes are embedded in our culture in part through their presence in our stories, as evidenced by the rich history of humanities and social science literature analyzing such biases in children's stories. Because these analyses are often conducted manually and at a small scale, such investigations can benefit from the use of more recent natural language processing (NLP) methods that examine social bias in models and data corpora.",
          "Main Action": "<NONE>",
          "Arguments": {
            "Agent": [
              "Because these analyses are often conducted manually and at a small scale"
            ],
            "Object": {
              "Primary Object": [
                "such investigations"
              ],
              "Secondary Object": [
                "natural language processing (NLP) methods"
              ]
            },
            "Context": [
              "Social biases and stereotypes are embedded in our culture in part through their presence in our stories",
              "analyses are often conducted manually and at a small scale"
            ],
            "Purpose": [
              "can benefit from the use of more recent natural language processing (NLP) methods that examine social bias in models and data corpora"
            ],
            "Method": [
              "use of more recent natural language processing (NLP) methods"
            ],
            "Results": [
              "<NONE>"
            ],
            "Analysis": [
              "<NONE>"
            ],
            "Challenge": [
              "<NONE>"
            ],
            "Ethical": [
              "<NONE>"
            ],
            "Implications": [
              "<NONE>"
            ],
            "Contradictions": [
              "<NONE>"
            ]
          }
        },
        {
          "Methods/Approach": "",
          "Text": "Our work joins this interdisciplinary effort and makes a unique contribution by taking into account the event narrative structures when analyzing the social bias of stories. We propose a computational pipeline that automatically extracts a story’s temporal narrative verb-based event chain for each of its characters as well as character attributes such as gender. We also present a verb-based event annotation scheme that can facilitate bias analysis by including categories such as those that align with traditional stereotypes.",
          "Main Action": "makes",
          "Arguments": {
            "Agent": [
              "our work"
            ],
            "Object": {
              "Primary Object": [
                "a unique contribution"
              ],
              "Secondary Object": [
                "by taking into account the event narrative structures when analyzing the social bias of stories"
              ]
            },
            "Context": [
              "This work joins this interdisciplinary effort"
            ],
            "Purpose": [
              "to analyze the social bias of stories"
            ],
            "Method": [
              "proposes a computational pipeline that automatically extracts a story's temporal narrative verb-based event chain for each of its characters as well as character attributes such as gender; presents a verb-based event annotation scheme that includes categories aligned with traditional stereotypes"
            ],
            "Results": [
              "none specified here but implied through proposed methods"
            ],
            "Analysis": [
              "none specified here but implied through proposed methods"
            ],
            "Challenge": [
              "none mentioned"
            ],
            "Ethical": [
              "none mentioned"
            ],
            "Implications": [
              "can facilitate bias analysis"
            ],
            "Contradictions": [
              "none mentioned"
            ]
          }
        },
        {
          "Results/Findings": "",
          "Text": "Through a case study analyzing gender bias in fairy tales, we demonstrate that our framework can reveal bias in not only the unigram verb-based events in which female and male characters participate but also in the temporal narrative order of such event participation.",
          "Main Action": "demonstrate",
          "Arguments": {
            "Agent": [
              "our framework"
            ],
            "Object": {
              "Primary Object": [
                "bias in not only the unigram verb-based events in which female and male characters participate but also in the temporal narrative order of such event participation"
              ],
              "Secondary Object": [
                "gender bias in fairy tales"
              ]
            },
            "Context": [
              "case study analyzing gender bias in fairy tales"
            ],
            "Purpose": [
              "reveal bias"
            ],
            "Method": [
              "framework"
            ],
            "Results": [
              "<NONE>"
            ],
            "Analysis": [
              "notable finding about revealing bias in both types of events mentioned"
            ],
            "Challenge": [
              "none explicit"
            ],
            "Ethical": [
              "none explicit"
            ],
            "Implications": [
              "broader significance for understanding and addressing biases in storytelling"
            ],
            "Contradictions": [
              "none explicit"
            ]
          }
        }
      ]
    },
    {
      "paper_code": "ACL_23_P_900",
      "abstract": "Current image generation models struggle to reliably produce well-formed visual text. In this paper, we investigate a key contributing factor: popular text-to-image models lack character-level input features, making it much harder to predict a word’s visual makeup as a series of glyphs. To quantify this effect, we conduct a series of experiments comparing character-aware vs. character-blind text encoders. In the text-only domain, we find that character-aware models provide large gains on a novel spelling task (WikiSpell). Applying our learnings to the visual domain, we train a suite of image generation models, and show that character-aware variants outperform their character-blind counterparts across a range of novel text rendering tasks (our DrawText benchmark). Our models set a much higher state-of-the-art on visual spelling, with 30+ point accuracy gains over competitors on rare words, despite training on far fewer examples.",
      "events": [
        {
          "Background/Introduction": "",
          "Text": "Current image generation models struggle to reliably produce well-formed visual text. In this paper, we investigate a key contributing factor: popular text-to-image models lack character-level input features, making it much harder to predict a word’s visual makeup as a series of glyphs.",
          "Main Action": "<NONE>",
          "Arguments": {
            "Agent": [
              "popular text-to-image models"
            ],
            "Object": {
              "Primary Object": [
                "character-level input features"
              ],
              "Secondary Object": [
                "word's visual makeup"
              ]
            },
            "Context": [
              "Current image generation models struggle to reliably produce well-formed visual text.",
              "In this paper, we investigate a key contributing factor:"
            ],
            "Purpose": [
              "to make it easier to predict a word’s visual makeup as a series of glyphs"
            ],
            "Method": [
              "<NONE>"
            ],
            "Results": [
              "<NONE>"
            ],
            "Analysis": [
              "<NONE>"
            ],
            "Challenge": [
              "lack of character-level input features makes it much harder to predict a word’s visual makeup as a series of glyphs"
            ],
            "Ethical": [
              "<NONE>"
            ],
            "Implications": [
              "<NONE>"
            ],
            "Contradictions": [
              "<NONE>"
            ]
          }
        },
        {
          "Methods/Approach": "",
          "Text": "To quantify this effect, we conduct a series of experiments comparing character-aware vs. character-blind text encoders. In the text-only domain, we find that character-aware models provide large gains on a novel spelling task (WikiSpell). Applying our learnings to the visual domain, we train a suite of image generation models, and show that character-aware variants outperform their character-blind counterparts across a range of novel text rendering tasks (our DrawText benchmark).",
          "Main Action": "conduct",
          "Arguments": {
            "Agent": [
              "we"
            ],
            "Object": {
              "Primary Object": [
                "a series of experiments"
              ],
              "Secondary Object": [
                "character-aware vs. character-blind text encoders"
              ]
            },
            "Context": [
              "to quantify this effect"
            ],
            "Purpose": [
              "none explicitly stated but implied through experimentation"
            ],
            "Method": [
              "comparing character-aware vs. character-blind text encoders"
            ],
            "Results": [
              "find that character-aware models provide large gains on a novel spelling task (WikiSpell)",
              "show that character-aware variants outperform their character-blind counterparts across a range of novel text rendering tasks (our DrawText benchmark)"
            ],
            "Analysis": [
              "none explicitly stated"
            ],
            "Challenge": [
              "none explicitly stated"
            ],
            "Ethical": [
              "none explicitly stated"
            ],
            "Implications": [
              "applying our learnings to the visual domain; training a suite of image generation models; showing performance improvements in various benchmarks"
            ],
            "Contradictions": [
              "<NONE>"
            ]
          }
        },
        {
          "Results/Findings": "",
          "Text": "Our models set a much higher state-of-the-art on visual spelling, with 30+ point accuracy gains over competitors on rare words, despite training on far fewer examples.",
          "Main Action": "<NONE>",
          "Arguments": {
            "Agent": [
              "Our models"
            ],
            "Object": {
              "Primary Object": [
                "state-of-the-art"
              ],
              "Secondary Object": [
                "rare words"
              ]
            },
            "Context": [
              "visual spelling",
              "training on far fewer examples"
            ],
            "Purpose": [
              "set a new benchmark"
            ],
            "Method": [
              "models"
            ],
            "Results": [
              "30+ point accuracy gains over competitors"
            ],
            "Analysis": [
              "<NONE>"
            ],
            "Challenge": [
              "<NONE>"
            ],
            "Ethical": [
              "<NONE>"
            ],
            "Implications": [
              "<NONE>"
            ],
            "Contradictions": [
              "<NONE>"
            ]
          }
        }
      ]
    }
  ]
}