{
  "papers": [
    {
      "paper_code": "cscw_23_P_57",
      "abstract": "Sexist content is widespread on social media and can reduce women's psychological well-being and their willingness to participate in online discourse, making it a societal issue. To counter these effects, social media platforms employ moderators. To date, little is known about the effectiveness of different forms of moderation in creating a safe space and their acceptance, in particular from the perspective of women as members of the targeted group and users in general (rather than perpetrators). In this research, we propose that some common forms of moderation can be systematized along two facets of visibility, namely visibility of sexist content and of counterspeech. In an online experiment (N = 839), we manipulated these two facets and tested how they shaped social norms, feelings of safety, and intent to participate, as well as fairness, trustworthiness, and efficacy evaluations. In line with our predictions, deletion of sexist content - i.e., its invisibility - and (public) counterspeech - i.e., its visibility - against visible sexist content contributed to creating a safe space. Looking at the underlying psychological mechanism, we found that these effects were largely driven by changes in what was perceived normative in the presented context. Interestingly, deletion of sexist content was judged as less fair than counterspeech against visible sexist content. Our research contributes to a growing body of literature that highlights the importance of norms in creating safer online environments and provides practical implications for moderators for selecting actions that can be effective and accepted.",
      "events": [
        {
          "Background/Introduction": "",
          "Text": "Sexist content is widespread on social media and can reduce women's psychological well-being and their willingness to participate in online discourse, making it a societal issue. To counter these effects, social media platforms employ moderators. To date, little is known about the effectiveness of different forms of moderation in creating a safe space and their acceptance, in particular from the perspective of women as members of the targeted group and users in general (rather than perpetrators).",
          "Main Action": "<NONE>",
          "Arguments": {
            "Agent": [
              "little is known"
            ],
            "Object": {
              "Primary Object": [
                "effectiveness of different forms of moderation",
                "acceptance"
              ],
              "Secondary Object": [
                "from the perspective of women as members of the targeted group and users in general"
              ]
            },
            "Context": [
              "sexist content is widespread on social media",
              "can reduce women's psychological well-being and their willingness to participate in online discourse"
            ],
            "Purpose": [
              "To counter these effects"
            ],
            "Method": [
              "employing moderators"
            ],
            "Results": [
              "<NONE>"
            ],
            "Analysis": [
              "<NONE>"
            ],
            "Challenge": [
              "<NONE>"
            ],
            "Ethical": [
              "<NONE>"
            ],
            "Implications": [
              "making it a societal issue"
            ],
            "Contradictions": [
              "<NONE>"
            ]
          }
        },
        {
          "Methods/Approach": "",
          "Text": "In this research, we propose that some common forms of moderation can be systematized along two facets of visibility, namely visibility of sexist content and of counterspeech. In an online experiment (N = 839), we manipulated these two facets and tested how they shaped social norms, feelings of safety, and intent to participate, as well as fairness, trustworthiness, and efficacy evaluations.",
          "Main Action": "<NONE>",
          "Arguments": {
            "Agent": [
              "we"
            ],
            "Object": {
              "Primary Object": [
                "some common forms of moderation",
                "two facets of visibility"
              ],
              "Secondary Object": [
                "social norms",
                "feelings of safety",
                "intent to participate",
                "fairness",
                "trustworthiness",
                "efficacy evaluations"
              ]
            },
            "Context": [
              "online experiment (N = 839)",
              "manipulated these two facets"
            ],
            "Purpose": [
              "tested how they shaped..."
            ],
            "Method": [
              "manipulate these two facets and test their effects"
            ],
            "Results": [
              "not specified but implied through testing process"
            ],
            "Analysis": [
              "how they shaped social norms, feelings of safety, and intent to participate, as well as fairness, trustworthiness, and efficacy evaluations"
            ],
            "Challenge": [
              "<NONE>"
            ],
            "Ethical": [
              "<NONE>"
            ],
            "Implications": [
              "importance, impact, applications, or future work"
            ],
            "Contradictions": [
              "<NONE>"
            ]
          }
        },
        {
          "Results/Findings": "",
          "Text": "In line with our predictions, deletion of sexist content - i.e., its invisibility - and (public) counterspeech - i.e., its visibility - against visible sexist content contributed to creating a safe space. Looking at the underlying psychological mechanism, we found that these effects were largely driven by changes in what was perceived normative in the presented context. Interestingly, deletion of sexist content was judged as less fair than counterspeech against visible sexist content.",
          "Main Action": "<NONE>",
          "Arguments": {
            "Agent": [
              "we"
            ],
            "Object": {
              "Primary Object": [
                "deletion of sexist content",
                "(public) counterspeech against visible sexist content"
              ],
              "Secondary Object": [
                "creating a safe space"
              ]
            },
            "Context": [
              "in line with our predictions",
              "looking at the underlying psychological mechanism"
            ],
            "Purpose": [
              "contributed to creating a safe space"
            ],
            "Method": [
              "changes in what was perceived normative in the presented context"
            ],
            "Results": [
              "these effects were largely driven by changes in what was perceived normative in the presented context"
            ],
            "Analysis": [
              "deletion of sexist content was judged as less fair than counterspeech against visible sexist content"
            ],
            "Challenge": [
              "<NONE>"
            ],
            "Ethical": [
              "<NONE>"
            ],
            "Implications": [
              "<NONE>"
            ],
            "Contradictions": [
              "<NONE>"
            ]
          }
        },
        {
          "Conclusions/Implications": "",
          "Text": "Our research contributes to a growing body of literature that highlights the importance of norms in creating safer online environments and provides practical implications for moderators for selecting actions that can be effective and accepted.",
          "Main Action": "<NONE>",
          "Arguments": {
            "Agent": [
              "Our research"
            ],
            "Object": {
              "Primary Object": [
                "a growing body of literature"
              ],
              "Secondary Object": [
                "moderators"
              ]
            },
            "Context": [
              "highlights the importance of norms",
              "creating safer online environments"
            ],
            "Purpose": [
              "provides practical implications"
            ],
            "Method": [
              "<NONE>"
            ],
            "Results": [
              "<NONE>"
            ],
            "Analysis": [
              "selecting actions that can be effective and accepted"
            ],
            "Challenge": [
              "<NONE>"
            ],
            "Ethical": [
              "<NONE>"
            ],
            "Implications": [
              "importance, impact, applications, or future work"
            ],
            "Contradictions": [
              "<NONE>"
            ]
          }
        }
      ]
    },
    {
      "paper_code": "cscw_23_P_249",
      "abstract": "News sharing has become prevalent on many social media platforms. Users are not only exposed to news shared by others, but also actively share information with a diverse set of motivations. In this work, we propose five news sharing motivations based on the intrinsic and extrinsic factors found in prior literature. Through an online experiment, we further examine how a host of factors, including motivations, influence participants' decision to share news online. We then prompt participants to switch their original decision for extra compensation, observing how different news types, motivational and demographic factors may affect the switch. Our analysis suggests that sharing decisions can be reversed when a strong external stimulus (higher bonus) is presented. Further, there are motivational factors that independently influence participants' reversal decisions. Finally, using our work as an empirical basis, we propose designs for future new sharing systems.",
      "events": [
        {
          "Background/Introduction": "",
          "Text": "News sharing has become prevalent on many social media platforms. Users are not only exposed to news shared by others, but also actively share information with a diverse set of motivations.",
          "Main Action": "<NONE>",
          "Arguments": {
            "Agent": [
              "Users"
            ],
            "Object": {
              "Primary Object": [
                "news shared by others",
                "information"
              ],
              "Secondary Object": [
                "a diverse set of motivations"
              ]
            },
            "Context": [
              "on many social media platforms"
            ],
            "Purpose": [
              "<NONE>"
            ],
            "Method": [
              "<NONE>"
            ],
            "Results": [
              "<NONE>"
            ],
            "Analysis": [
              "<NONE>"
            ],
            "Challenge": [
              "<NONE>"
            ],
            "Ethical": [
              "<NONE>"
            ],
            "Implications": [
              "<NONE>"
            ],
            "Contradictions": [
              "<NONE>"
            ]
          }
        },
        {
          "Methods/Approach": "",
          "Text": "In this work, we propose five news sharing motivations based on the intrinsic and extrinsic factors found in prior literature. Through an online experiment, we further examine how a host of factors, including motivations, influence participants' decision to share news online. We then prompt participants to switch their original decision for extra compensation, observing how different news types, motivational and demographic factors may affect the switch.",
          "Main Action": "<NONE>",
          "Arguments": {
            "Agent": [
              "we"
            ],
            "Object": {
              "Primary Object": [
                "five news sharing motivations",
                "participants"
              ],
              "Secondary Object": [
                "online experiment",
                "different news types",
                "motivational and demographic factors"
              ]
            },
            "Context": [
              "based on the intrinsic and extrinsic factors found in prior literature",
              "We then prompt participants to switch their original decision for extra compensation"
            ],
            "Purpose": [
              "to examine how a host of factors, including motivations, influence participants' decision to share news online"
            ],
            "Method": [
              "an online experiment"
            ],
            "Results": [
              "observing how different news types, motivational and demographic factors may affect the switch"
            ],
            "Analysis": [
              "<NONE>"
            ],
            "Challenge": [
              "<NONE>"
            ],
            "Ethical": [
              "<NONE>"
            ],
            "Implications": [
              "<NONE>"
            ],
            "Contradictions": [
              "<NONE>"
            ]
          }
        },
        {
          "Results/Findings": "",
          "Text": "Our analysis suggests that sharing decisions can be reversed when a strong external stimulus (higher bonus) is presented. Further, there are motivational factors that independently influence participants' reversal decisions.",
          "Main Action": "<NONE>",
          "Arguments": {
            "Agent": [
              "There are motivational factors"
            ],
            "Object": {
              "Primary Object": [
                "participants' reversal decisions"
              ],
              "Secondary Object": [
                "a strong external stimulus (higher bonus)"
              ]
            },
            "Context": [
              "Our analysis suggests that sharing decisions can be reversed"
            ],
            "Purpose": [
              "<NONE>"
            ],
            "Method": [
              "<NONE>"
            ],
            "Results": [
              "<NONE>"
            ],
            "Analysis": [
              "further, there are motivational factors that independently influence participants' reversal decisions"
            ],
            "Challenge": [
              "<NONE>"
            ],
            "Ethical": [
              "<NONE>"
            ],
            "Implications": [
              "<NONE>"
            ],
            "Contradictions": [
              "<NONE>"
            ]
          }
        },
        {
          "Conclusions/Implications": "",
          "Text": "Finally, using our work as an empirical basis, we propose designs for future new sharing systems.",
          "Main Action": "propose",
          "Arguments": {
            "Agent": [
              "we"
            ],
            "Object": {
              "Primary Object": [
                "designs"
              ],
              "Secondary Object": [
                "future new sharing systems"
              ]
            },
            "Context": [
              "using our work as an empirical basis"
            ],
            "Purpose": [
              "as an empirical basis"
            ],
            "Method": [
              "<NONE>"
            ],
            "Results": [
              "<NONE>"
            ],
            "Analysis": [
              "<NONE>"
            ],
            "Challenge": [
              "<NONE>"
            ],
            "Ethical": [
              "<NONE>"
            ],
            "Implications": [
              "for future applications/research"
            ],
            "Contradictions": [
              "<NONE>"
            ]
          }
        }
      ]
    }
  ]
}