{
  "papers": [
    {
      "paper_code": "cscw_23_P_109",
      "abstract": "Prior work has identified a resilient phenomenon that threatens the performance of human-AI decision-making teams: overreliance, when people agree with an AI, even when it is incorrect. Surprisingly, overreliance does not reduce when the AI produces explanations for its predictions, compared to only providing predictions. Some have argued that overreliance results from cognitive biases or uncalibrated trust, attributing overreliance to an inevitability of human cognition. By contrast, our paper argues that people strategically choose whether or not to engage with an AI explanation, demonstrating empirically that there are scenarios where AI explanations reduce overreliance. To achieve this, we formalize this strategic choice in a cost-benefit framework, where the costs and benefits of engaging with the task are weighed against the costs and benefits of relying on the AI. We manipulate the costs and benefits in a maze task, where participants collaborate with a simulated AI to find the exit of a maze. Through 5 studies (N = 731), we find that costs such as task difficulty (Study 1), explanation difficulty (Study 2, 3), and benefits such as monetary compensation (Study 4) affect overreliance. Finally, Study 5 adapts the Cognitive Effort Discounting paradigm to quantify the utility of different explanations, providing further support for our framework. Our results suggest that some of the null effects found in literature could be due in part to the explanation not sufficiently reducing the costs of verifying the AI's prediction.",
      "events": [
        {
          "Background/Introduction": "",
          "Text": "Prior work has identified a resilient phenomenon that threatens the performance of human-AI decision-making teams: overreliance, when people agree with an AI, even when it is incorrect. Surprisingly, overreliance does not reduce when the AI produces explanations for its predictions, compared to only providing predictions. Some have argued that overreliance results from cognitive biases or uncalibrated trust, attributing overreliance to an inevitability of human cognition. By contrast, our paper argues that people strategically choose whether or not to engage with an AI explanation, demonstrating empirically that there are scenarios where AI explanations reduce overreliance.",
          "Main Action": "<NONE>",
          "Arguments": {
            "Agent": [
              "our paper"
            ],
            "Object": {
              "Primary Object": [
                "people's strategic choice about engaging with AI explanation"
              ],
              "Secondary Object": [
                "AI explanation"
              ]
            },
            "Context": [
              "prior work has identified a resilient phenomenon",
              "overreliance occurs despite AI producing explanations"
            ],
            "Purpose": [
              "demonstrate empirically that AI explanations do not always reduce overreliance"
            ],
            "Method": [
              "empirical demonstration"
            ],
            "Results": [
              "there are scenarios where AI explanations reduce overreliance"
            ],
            "Analysis": [
              "some argue overreliance comes from cognitive biases; we challenge this view"
            ],
            "Challenge": [
              "none specified in the given text"
            ],
            "Ethical": [
              "none specified in the given text"
            ],
            "Implications": [
              "broader understanding of how humans interact with AI systems and strategies to mitigate overreliance"
            ],
            "Contradictions": [
              "contrary to some views, people may selectively engage with AI explanations based on their needs"
            ]
          }
        },
        {
          "Methods/Approach": "",
          "Text": "To achieve this, we formalize this strategic choice in a cost-benefit framework, where the costs and benefits of engaging with the task are weighed against the costs and benefits of relying on the AI. We manipulate the costs and benefits in a maze task, where participants collaborate with a simulated AI to find the exit of a maze.",
          "Main Action": "<FORMALIZE STRATEGIC CHOICE>",
          "Arguments": {
            "Agent": [
              "we"
            ],
            "Object": {
              "Primary Object": [
                "cost-benefit framework"
              ],
              "Secondary Object": [
                "tasks",
                "participants",
                "simulated AI"
              ]
            },
            "Context": [
              "engaging with the task",
              "relying on the AI"
            ],
            "Purpose": [
              "weighing costs and benefits"
            ],
            "Method": [
              "manipulate costs and benefits in a maze task"
            ],
            "Results": [
              "<NONE>"
            ],
            "Analysis": [
              "<NONE>"
            ],
            "Challenge": [
              "<NONE>"
            ],
            "Ethical": [
              "<NONE>"
            ],
            "Implications": [
              "<NONE>"
            ],
            "Contradictions": [
              "<NONE>"
            ]
          }
        },
        {
          "Results/Findings": "",
          "Text": "Through 5 studies (N = 731), we find that costs such as task difficulty (Study 1), explanation difficulty (Study 2, 3), and benefits such as monetary compensation (Study 4) affect overreliance. Finally, Study 5 adapts the Cognitive Effort Discounting paradigm to quantify the utility of different explanations, providing further support for our framework.",
          "Main Action": "find",
          "Arguments": {
            "Agent": [
              "we"
            ],
            "Object": {
              "Primary Object": [
                "costs such as task difficulty",
                "explanation difficulty",
                "benefits such as monetary compensation",
                "utility of different explanations"
              ],
              "Secondary Object": [
                "overreliance",
                "Cognitive Effort Discounting paradigm"
              ]
            },
            "Context": [
              "through 5 studies (N = 731)",
              "adapt the Cognitive Effort Discounting paradigm to quantify the utility of different explanations"
            ],
            "Purpose": [
              "provide further support for our framework"
            ],
            "Method": [
              "conduct Studies 1 through 5"
            ],
            "Results": [
              "find that costs...affect overreliance",
              "quantify the utility of different explanations, providing further support for our framework"
            ],
            "Analysis": [
              "<NONE>"
            ],
            "Challenge": [
              "<NONE>"
            ],
            "Ethical": [
              "<NONE>"
            ],
            "Implications": [
              "support for our framework"
            ],
            "Contradictions": [
              "<NONE>"
            ]
          }
        },
        {
          "Conclusions/Implications": "",
          "Text": "Our results suggest that some of the null effects found in literature could be due in part to the explanation not sufficiently reducing the costs of verifying the AI's prediction.",
          "Main Action": "<SUGGESTED TRIGGER PHRASE HERE>",
          "Arguments": {
            "Agent": [
              "our results"
            ],
            "Object": {
              "Primary Object": [
                "some of the null effects found in literature"
              ],
              "Secondary Object": [
                "the explanation"
              ]
            },
            "Context": [
              "could be due in part to the explanation not sufficiently reducing the costs of verifying the AI's prediction"
            ],
            "Purpose": [
              "<NONE>"
            ],
            "Method": [
              "<NONE>"
            ],
            "Results": [
              "suggest that...could be due in part to the explanation not sufficiently reducing the costs of verifying the AI's prediction"
            ],
            "Analysis": [
              "<NONE>"
            ],
            "Challenge": [
              "<NONE>"
            ],
            "Ethical": [
              "<NONE>"
            ],
            "Implications": [
              "<NONE>"
            ],
            "Contradictions": [
              "<NONE>"
            ]
          }
        }
      ]
    },
    {
      "paper_code": "cscw_23_P_142",
      "abstract": "For peer production communities to be sustainable, they must attract and retain new contributors. Studies have identified social and technical barriers to entry and discovered some potential solutions, but these solutions have typically focused on a single highly successful community, the English Wikipedia, been tested in isolation, and rarely evaluated through controlled experiments. We propose the Newcomer Homepage, a central place where newcomers can learn how peer production works and find opportunities to contribute, as a solution for attracting and retaining newcomers. The homepage was built upon existing research and designed in collaboration with partner communities. Through a large-scale controlled experiment spanning 27 non-English Wikipedia wikis, we evaluate the homepage and find modest gains, and that having a positive effect on the newcomer experience depends on the newcomer's context. We discuss how this impacts interventions that aim to improve the newcomer experience in peer production communities.",
      "events": [
        {
          "Background/Introduction": "",
          "Text": "For peer production communities to be sustainable, they must attract and retain new contributors. Studies have identified social and technical barriers to entry and discovered some potential solutions, but these solutions have typically focused on a single highly successful community, the English Wikipedia, been tested in isolation, and rarely evaluated through controlled experiments.",
          "Main Action": "<NONE>",
          "Arguments": {
            "Agent": [
              "Studies"
            ],
            "Object": {
              "Primary Object": [
                "social and technical barriers to entry",
                "some potential solutions"
              ],
              "Secondary Object": [
                "a single highly successful community, the English Wikipedia",
                "been tested in isolation",
                "rarely evaluated through controlled experiments"
              ]
            },
            "Context": [
              "peer production communities to be sustainable",
              "studies have identified..."
            ],
            "Purpose": [
              "to understand factors affecting sustainability and find possible solutions"
            ],
            "Method": [
              "identified",
              "discovered",
              "focused on",
              "tested in isolation",
              "evaluated through controlled experiments"
            ],
            "Results": [
              "["
            ],
            "Analysis": [
              "["
            ],
            "Challenge": [
              "["
            ],
            "Ethical": [
              "["
            ],
            "Implications": [
              "["
            ],
            "Contradictions": [
              "[\"these solutions have typically focused on a single highly successful community\"]"
            ]
          }
        },
        {
          "Methods/Approach": "",
          "Text": "We propose the Newcomer Homepage, a central place where newcomers can learn how peer production works and find opportunities to contribute, as a solution for attracting and retaining newcomers. The homepage was built upon existing research and designed in collaboration with partner communities.",
          "Main Action": "propose",
          "Arguments": {
            "Agent": [
              "we"
            ],
            "Object": {
              "Primary Object": [
                "Newcomer Homepage"
              ],
              "Secondary Object": [
                "a central place where newcomers can learn how peer production works and find opportunities to contribute"
              ]
            },
            "Context": [
              "existing research",
              "collaboration with partner communities"
            ],
            "Purpose": [
              "attracting and retaining newcomers"
            ],
            "Method": [
              "built upon existing research",
              "designed in collaboration with partner communities"
            ],
            "Results": [
              "<NONE>"
            ],
            "Analysis": [
              "<NONE>"
            ],
            "Challenge": [
              "<NONE>"
            ],
            "Ethical": [
              "<NONE>"
            ],
            "Implications": [
              "<NONE>"
            ],
            "Contradictions": [
              "<NONE>"
            ]
          }
        },
        {
          "Results/Findings": "",
          "Text": "Through a large-scale controlled experiment spanning 27 non-English Wikipedia wikis, we evaluate the homepage and find modest gains, and that having a positive effect on the newcomer experience depends on the newcomer's context.",
          "Main Action": "evaluate",
          "Arguments": {
            "Agent": [
              "we"
            ],
            "Object": {
              "Primary Object": [
                "homepage"
              ],
              "Secondary Object": [
                "non-English Wikipedia wikis"
              ]
            },
            "Context": [
              "a large-scale controlled experiment spanning 27 non-English Wikipedia wikis"
            ],
            "Purpose": [
              "to find modest gains, and that having a positive effect on the newcomer experience depends on the newcomer's context"
            ],
            "Method": [
              "a large-scale controlled experiment"
            ],
            "Results": [
              "modest gains",
              "having a positive effect on the newcomer experience depends on the newcomer's context"
            ],
            "Analysis": [
              "finds"
            ],
            "Challenge": [
              "<NONE>"
            ],
            "Ethical": [
              "<NONE>"
            ],
            "Implications": [
              "<NONE>"
            ],
            "Contradictions": [
              "<NONE>"
            ]
          }
        },
        {
          "Conclusions/Implications": "",
          "Text": "We discuss how this impacts interventions that aim to improve the newcomer experience in peer production communities.",
          "Main Action": "<NONE>",
          "Arguments": {
            "Agent": [
              "we"
            ],
            "Object": {
              "Primary Object": [
                "interventions"
              ],
              "Secondary Object": [
                "aim to improve",
                "newcomer experience",
                "peer production communities"
              ]
            },
            "Context": [
              "how this impacts"
            ],
            "Purpose": [
              "improve the newcomer experience"
            ],
            "Method": [
              "discuss"
            ],
            "Results": [
              "<NONE>"
            ],
            "Analysis": [
              "<NONE>"
            ],
            "Challenge": [
              "<NONE>"
            ],
            "Ethical": [
              "<NONE>"
            ],
            "Implications": [
              "impacts interventions"
            ],
            "Contradictions": [
              "<NONE>"
            ]
          }
        }
      ]
    }
  ]
}