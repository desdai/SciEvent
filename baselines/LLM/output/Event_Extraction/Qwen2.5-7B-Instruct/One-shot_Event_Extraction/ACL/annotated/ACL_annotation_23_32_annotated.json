{
  "papers": [
    {
      "paper_code": "ACL_23_P_634",
      "abstract": "Many text generation applications require the generated text to be factually consistent with input information. Automatic evaluation of factual consistency is challenging. Previous work has developed various metrics that often depend on specific functions, such as natural language inference (NLI) or question answering (QA), trained on limited data. Those metrics thus can hardly assess diverse factual inconsistencies (e.g., contradictions, hallucinations) that occur in varying inputs/outputs (e.g., sentences, documents) from different tasks. In this paper, we propose AlignScore, a new holistic metric that applies to a variety of factual inconsistency scenarios as above. AlignScore is based on a general function of information alignment between two arbitrary text pieces. Crucially, we develop a unified training framework of the alignment function by integrating a large diversity of data sources, resulting in 4.7M training examples from 7 well-established tasks (NLI, QA, paraphrasing, fact verification, information retrieval, semantic similarity, and summarization). We conduct extensive experiments on large-scale benchmarks including 22 evaluation datasets, where 19 of the datasets were never seen in the alignment training. AlignScore achieves substantial improvement over a wide range of previous metrics. Moreover, AlignScore (355M parameters) matches or even outperforms metrics based on ChatGPT and GPT-4 that are orders of magnitude larger.",
      "events": [
        {
          "Background/Introduction": "",
          "Text": "Many text generation applications require the generated text to be factually consistent with input information. Automatic evaluation of factual consistency is challenging. Previous work has developed various metrics that often depend on specific functions, such as natural language inference (NLI) or question answering (QA), trained on limited data. Those metrics thus can hardly assess diverse factual inconsistencies (e.g., contradictions, hallucinations) that occur in varying inputs/outputs (e.g., sentences, documents) from different tasks.",
          "Main Action": "require",
          "Arguments": {
            "Agent": [
              "many text generation applications"
            ],
            "Object": {
              "Primary Object": [
                "generated text to be factually consistent with input information"
              ],
              "Secondary Object": [
                "automatic evaluation of factual consistency"
              ]
            },
            "Context": [
              "Automatic evaluation of factual consistency is challenging"
            ],
            "Purpose": [
              "<NONE>"
            ],
            "Method": [
              "developed various metrics that often depend on specific functions, such as natural language inference (NLI) or question answering (QA), trained on limited data"
            ],
            "Results": [
              "those metrics thus can hardly assess diverse factual inconsistencies (e.g., contradictions, hallucinations) that occur in varying inputs/outputs (e.g., sentences, documents) from different tasks"
            ],
            "Analysis": [
              "<NONE>"
            ],
            "Challenge": [
              "<NONE>"
            ],
            "Ethical": [
              "<NONE>"
            ],
            "Implications": [
              "<NONE>"
            ],
            "Contradictions": [
              "<NONE>"
            ]
          }
        },
        {
          "Methods/Approach": "",
          "Text": "In this paper, we propose AlignScore, a new holistic metric that applies to a variety of factual inconsistency scenarios as above. AlignScore is based on a general function of information alignment between two arbitrary text pieces. Crucially, we develop a unified training framework of the alignment function by integrating a large diversity of data sources, resulting in 4.7M training examples from 7 well-established tasks (NLI, QA, paraphrasing, fact verification, information retrieval, semantic similarity, and summarization).",
          "Main Action": "propose",
          "Arguments": {
            "Agent": [
              "we"
            ],
            "Object": {
              "Primary Object": [
                "AlignScore"
              ],
              "Secondary Object": [
                "holistic metric"
              ]
            },
            "Context": [
              "a new holistic metric that applies to a variety of factual inconsistency scenarios as above"
            ],
            "Purpose": [
              "<NONE>"
            ],
            "Method": [
              "based on a general function of information alignment between two arbitrary text pieces; develops a unified training framework of the alignment function by integrating a large diversity of data sources"
            ],
            "Results": [
              "resulting in 4.7M training examples from 7 well-established tasks (NLI, QA, paraphrasing, fact verification, information retrieval, semantic similarity, and summarization)"
            ],
            "Analysis": [
              "<NONE>"
            ],
            "Challenge": [
              "<NONE>"
            ],
            "Ethical": [
              "<NONE>"
            ],
            "Implications": [
              "<NONE>"
            ],
            "Contradictions": [
              "<NONE>"
            ]
          }
        },
        {
          "Results/Findings": "",
          "Text": "We conduct extensive experiments on large-scale benchmarks including 22 evaluation datasets, where 19 of the datasets were never seen in the alignment training. AlignScore achieves substantial improvement over a wide range of previous metrics. Moreover, AlignScore (355M parameters) matches or even outperforms metrics based on ChatGPT and GPT-4 that are orders of magnitude larger.",
          "Main Action": "conduct",
          "Arguments": {
            "Agent": [
              "we"
            ],
            "Object": {
              "Primary Object": [
                "extensive experiments"
              ],
              "Secondary Object": [
                "large-scale benchmarks including 22 evaluation datasets"
              ]
            },
            "Context": [
              "where 19 of the datasets were never seen in the alignment training"
            ],
            "Purpose": [
              "<NONE>"
            ],
            "Method": [
              "<NONE>"
            ],
            "Results": [
              "AlignScore achieves substantial improvement over a wide range of previous metrics"
            ],
            "Analysis": [
              "matches or even outperforms metrics based on ChatGPT and GPT-4 that are orders of magnitude larger"
            ],
            "Challenge": [
              "<NONE>"
            ],
            "Ethical": [
              "<NONE>"
            ],
            "Implications": [
              "<NONE>"
            ],
            "Contradictions": [
              "<NONE>"
            ]
          }
        }
      ]
    },
    {
      "paper_code": "ACL_23_P_859",
      "abstract": "Large language models (LLMs) that have been trained on multilingual but not parallel text exhibit a remarkable ability to translate between languages. We probe this ability in an in-depth study of the pathways language model (PaLM), which has demonstrated the strongest machine translation (MT) performance among similarly-trained LLMs to date. We investigate various strategies for choosing translation examples for few-shot prompting, concluding that example quality is the most important factor. Using optimized prompts, we revisit previous assessments of PaLM’s MT capabilities with more recent test sets, modern MT metrics, and human evaluation, and find that its performance, while impressive, still lags that of state-of-the-art supervised systems. We conclude by providing an analysis of PaLM’s MT output which reveals some interesting properties and prospects for future work.",
      "events": [
        {
          "Background/Introduction": "",
          "Text": "Large language models (LLMs) that have been trained on multilingual but not parallel text exhibit a remarkable ability to translate between languages.",
          "Main Action": "exhibit",
          "Arguments": {
            "Agent": [
              "Large language models (LLMs)"
            ],
            "Object": {
              "Primary Object": [
                "remarkable ability to translate between languages"
              ],
              "Secondary Object": [
                "<NONE>"
              ]
            },
            "Context": [
              "that have been trained on multilingual but not parallel text"
            ],
            "Purpose": [
              "<NONE>"
            ],
            "Method": [
              "<NONE>"
            ],
            "Results": [
              "<NONE>"
            ],
            "Analysis": [
              "<NONE>"
            ],
            "Challenge": [
              "<NONE>"
            ],
            "Ethical": [
              "<NONE>"
            ],
            "Implications": [
              "<NONE>"
            ],
            "Contradictions": [
              "<NONE>"
            ]
          }
        },
        {
          "Methods/Approach": "",
          "Text": "We probe this ability in an in-depth study of the pathways language model (PaLM), which has demonstrated the strongest machine translation (MT) performance among similarly-trained LLMs to date. We investigate various strategies for choosing translation examples for few-shot prompting, concluding that example quality is the most important factor. Using optimized prompts, we revisit previous assessments of PaLM’s MT capabilities with more recent test sets, modern MT metrics, and human evaluation, and find that its performance, while impressive, still lags that of state-of-the-art supervised systems.",
          "Main Action": "probe",
          "Arguments": {
            "Agent": [
              "we"
            ],
            "Object": {
              "Primary Object": [
                "this ability"
              ],
              "Secondary Object": [
                "in an in-depth study of the pathways language model (PaLM)"
              ]
            },
            "Context": [
              "which has demonstrated the strongest machine translation (MT) performance among similarly-trained LLMs to date"
            ],
            "Purpose": [
              "investigate various strategies for choosing translation examples for few-shot prompting"
            ],
            "Method": [
              "Using optimized prompts, we revisit previous assessments of PaLM’s MT capabilities with more recent test sets, modern MT metrics, and human evaluation"
            ],
            "Results": [
              "find that its performance, while impressive, still lags that of state-of-the-art supervised systems"
            ],
            "Analysis": [
              "concluding that example quality is the most important factor"
            ],
            "Challenge": [
              "<NONE>"
            ],
            "Ethical": [
              "<NONE>"
            ],
            "Implications": [
              "<NONE>"
            ],
            "Contradictions": [
              "<NONE>"
            ]
          }
        },
        {
          "Conclusions/Implications": "",
          "Text": "We conclude by providing an analysis of PaLM’s MT output which reveals some interesting properties and prospects for future work.",
          "Main Action": "providing an analysis",
          "Arguments": {
            "Agent": [
              "we"
            ],
            "Object": {
              "Primary Object": [
                "PaLM’s MT output"
              ],
              "Secondary Object": [
                "interesting properties and prospects for future work"
              ]
            },
            "Context": [
              "<NONE>"
            ],
            "Purpose": [
              "<NONE>"
            ],
            "Method": [
              "<NONE>"
            ],
            "Results": [
              "reveals some interesting properties and prospects for future work"
            ],
            "Analysis": [
              "an analysis of PaLM’s MT output"
            ],
            "Challenge": [
              "<NONE>"
            ],
            "Ethical": [
              "<NONE>"
            ],
            "Implications": [
              "provides insights into PaLM’s capabilities and directions for subsequent studies"
            ],
            "Contradictions": [
              "<NONE>"
            ]
          }
        }
      ]
    }
  ]
}