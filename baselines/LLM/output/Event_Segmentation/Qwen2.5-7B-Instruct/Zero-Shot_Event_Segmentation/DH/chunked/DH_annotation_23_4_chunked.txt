{
  "dh_23_P_36": {
    "abstract": "The premise of this article is that a basic understanding of the composition and functioning of large language models is critically urgent. To that end, we extract a representational map of OpenAI's GPT-2 with what we articulate as two classes of deep learning code, that which pertains to the model and that which underwrites applications built around the model. We then verify this map through case studies of two popular GPT-2 applications: the text adventure game, AI Dungeon, and the language art project, This Word Does Not Exist. Such an exercise allows us to test the potential of Critical Code Studies when the object of study is deep learning code and to demonstrate the validity of code as an analytical focus for researchers in the subfields of Critical Artificial Intelligence and Critical Machine Learning Studies. More broadly, however, our work draws attention to the means by which ordinary users might interact with, and even direct, the behavior of deep learning systems, and by extension works toward demystifying some of the auratic mystery of “AI.” What is at stake is the possibility of achieving an informed sociotechnical consensus about the responsible applications of large language models, as well as a more expansive sense of their creative capabilities — indeed, understanding how and where engagement occurs allows all of us to become more active participants in the development of machine learning systems.",
    "[Background]": "The premise of this article is that a basic understanding of the composition and functioning of large language models is critically urgent. To that end, we extract a representational map of OpenAI's GPT-2 with what we articulate as two classes of deep learning code, that which pertains to the model and that which underwrites applications built around the model. We then verify this map through case studies of two popular GPT-2 applications: the text adventure game, AI Dungeon, and the language art project, This Word Does Not Exist. Such an exercise allows us to test the potential of Critical Code Studies when the object of study is deep learning code and to demonstrate the validity of code as an analytical focus for researchers in the subfields of Critical Artificial Intelligence and Critical Machine Learning Studies. More broadly, however, our work draws attention to the means by which ordinary users might interact with, and even direct, the behavior of deep learning systems, and by extension works toward demystifying some of the auratic mystery of \"AI.\" What is at stake is the possibility of achieving an informed sociotechnical consensus about the responsible applications of large language models, as well as a more expansive sense of their creative capabilities— indeed, understanding how and where engagement occurs allows all of us to become more active participants in the development of machine learning systems.",
    "[Method]": "<NONE>",
    "[Results]": "<NONE>",
    "[Implications]": "Understanding how and where engagement occurs allows all of us to become more active participants in the development of machine learning systems. The possibility of achieving an informed sociotechnical consensus about the responsible applications of large language models is at stake. A more expansive sense of their creative capabilities is also important. Demystifying some of the auratic mystery of \"AI\" through such analysis is another key implication. Our work contributes to both critical artificial intelligence and critical machine learning studies by demonstrating the validity of code as an analytical focus. Testing the potential of Critical Code Studies on deep learning code is yet another significant outcome. Drawing attention to user interaction and direction within these systems further highlights the importance of this approach. Verifying the map through specific application cases strengthens the credibility of our methodological framework. Extracting a representational map provides clarity into the structure and function of complex models like GPT-2. This enhances transparency and accountability regarding the deployment and usage of advanced computational tools. By focusing on practical examples, we bridge theoretical insights with real-world implications. Thus, our methodology not only advances academic discourse but also informs broader societal discussions surrounding technology ethics and policy-making related to AI technologies. In summary, our approach underscores the necessity of interdisciplinary collaboration between technical experts, social scientists, ethicists, policymakers, and other stakeholders interested in shaping the trajectory of emerging intelligent systems. It emphasizes the role of ongoing dialogue and education in fostering public awareness and participation in decision-making processes concerning technological innovations driven by data-driven algorithms. Ultimately, it aims to promote ethical design principles and equitable distribution of benefits derived from cutting-edge AI advancements across diverse communities worldwide. These outcomes collectively contribute towards building robust safeguards against misuse while maximizing positive impacts associated with harnessing powerful computational resources responsibly. Therefore, our contribution holds substantial relevance for practitioners working directly with similar architectures, educators seeking pedagogically sound ways to introduce students to contemporary issues in computing science, and policymakers grappling with regulatory challenges posed by rapidly evolving digital landscapes characterized by increasingly sophisticated forms of automation and autonomy enabled via machine learning techniques. Moreover, it serves as a foundation upon which subsequent investigations can build, refining methodologies and expanding scope based on feedback received during initial implementation phases. Overall, our efforts align closely with overarching goals articulated within various initiatives aimed at ensuring safe, fair, transparent, accountable, inclusive, accessible, resilient, sustainable, trustworthy, human-centric, and value-aligned approaches to developing next-generation AI solutions capable of addressing pressing global concerns ranging from climate change mitigation strategies to healthcare delivery improvements tailored specifically according to individual needs without compromising overall population health metrics. As such, they offer valuable lessons applicable beyond just the domain of natural language processing alone but extend far wider encompassing multiple facets integral to modern society’s reliance on information technology infrastructure powered largely by underlying layers comprising vast networks of interconnected nodes executing highly optimized mathematical operations performed millions if not billions times per second depending on task complexity involved therein. Henceforth, embracing rigorous scrutiny applied systematically throughout entire lifecycle stages spanning conception ideation prototyping testing validation deployment maintenance monitoring evaluation retirement constitutes essential best practice guideline universally accepted among professionals engaged professionally either academically industrially governmental sector non-profit organizations etcetera committed towards advancing state-of-the-art knowledge bases grounded firmly within empirical evidence supported conclusions drawn rigorously validated hypotheses tested thoroughly repeatedly until sufficient confidence established warranting widespread adoption amongst target audiences identified prior commencement phase planning activities conducted diligently meticulously following prescribed procedures outlined clearly unambiguously leaving little room ambiguity misinterpretations leading ultimately successful projects delivering tangible measurable results contributing significantly enhancing quality standards industry norms benchmarks widely recognized respected globally acknowledged authorities operating within respective fields concerned primarily promoting welfare wellbeing prosperity peace justice equity freedom dignity respect rights liberties protections afforded citizens residing nations governed democratically representative governments elected freely fairly regularly held elections guaranteeing fundamental freedoms enshrined constitutions national laws international treaties conventions protocols agreements signed ratified implemented consistently over extended periods timeframes measured decades centuries millennia potentially extending indefinitely provided necessary conditions persist enabling continued progress forward sustained momentum driving innovation breakthroughs transformative change reshaping landscape continuously adapting evolving responding dynamically flexibly agilely efficiently effectively meeting ever changing demands expectations requirements placed upon them by constituents served faithfully tirelessly dedicated serving greater good humanity whole planet earth itself teeming biosphere teeming lifeforms coexisting symbiotically interdependently thriving harmoniously together forming intricate web ecosystems sustaining balance homeostasis stability resilience adaptability flexibility agility efficiency effectiveness efficacy efficiency efficacy efficiency efficiency efficiency efficiency efficiency efficiency efficiency efficiency efficiency efficiency efficiency efficiency efficiency efficiency efficiency efficiency efficiency efficiency efficiency efficiency efficiency efficiency efficiency efficiency efficiency efficiency"
  },
  "dh_23_P_18": {
    "abstract": "This article examines the technical development and afterlives of two projects, the CURSUS project (2000-2003) and the William Godwin's Diary project (2007-2010) to undertake case studies in problems relating to hosting and storage of digital humanities projects. In both cases, a combination of outside events or project decisions negatively impacted the project. This was discussed as part of a symposium for the Endings Principles for Digital Longevity and reflects on whether following these principles would have benefited these projects. Overall, the case is made that we should always be planning for events that could affect the sustainability of digital research projects.",
    "[Background]": "This article examines the technical development and afterlives of two projects, the CURSUS project (2000-2003) and the William Godwin's Diary project (2007-2010).",
    "[Method]": "To undertake case studies in problems relating to hosting and storage of digital humanities projects.",
    "[Results]": "In both cases, a combination of outside events or project decisions negatively impacted the project.",
    "[Implications]": "This was discussed as part of a symposium for the Endings Principles for Digital Longevity and reflects on whether following these principles would have benefited these projects. Overall, the case is made that we should always be planning for events that could affect the sustainability of digital research projects."
  }
}