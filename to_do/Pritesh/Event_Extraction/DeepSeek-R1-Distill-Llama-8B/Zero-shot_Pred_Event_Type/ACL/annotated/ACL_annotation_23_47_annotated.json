{
  "papers": [
    {
      "paper_code": "ACL_23_P_183",
      "abstract": "The potential choices for news article headlines are enormous, and finding the right balance between conveying the essential message and capturing the reader’s attention is key to effective headlining. However, presenting the same news headline to all readers is a suboptimal strategy, because it does not take into account the different preferences and interests of diverse readers, who may be confused about why a particular article has been recommended to them and do not see a clear connection between their interests and the recommended article. In this paper, we present a novel framework that addresses these challenges by incorporating user profiling to generate personalized headlines, and a combination of automated and human evaluation methods to determine user preference for personalized headlines. Our framework utilizes a learnable relevance function to assign personalized signature phrases to users based on their reading histories, which are then used to personalize headline generation. Through extensive evaluation, we demonstrate the effectiveness of our proposed framework in generating personalized headlines that meet the needs of a diverse audience. Our framework has the potential to improve the efficacy of news recommendations and facilitate creation of personalized content.",
      "events": [
        {
          "Background/Introduction": "",
          "Text": "The potential choices for news article headlines are enormous, and finding the right balance between conveying the essential message and capturing the reader’s attention is key to effective headlining. However, presenting the same news headline to all readers is a suboptimal strategy, because it does not take into account the different preferences and interests of diverse readers, who may be confused about why a particular article has been recommended to them and do not see a clear connection between their interests and the recommended article.",
          "Main Action": "Presenting the same news headline to all readers",
          "Arguments": {
            "Agent": [
              "Presenting the same news headline to all readers"
            ],
            "Object": {
              "Primary Object": [
                "diverse readers"
              ],
              "Secondary Object": [
                "confusion"
              ]
            },
            "Context": [
              "news article",
              "recommendation system"
            ],
            "Purpose": [
              "enhancing user experience"
            ],
            "Method": [
              "considering different preferences",
              "tailoring content"
            ],
            "Results": [
              "confusion among readers"
            ],
            "Analysis": [
              "<NONE>"
            ],
            "Challenge": [
              "suboptimal strategy"
            ],
            "Ethical": [
              "<NONE>"
            ],
            "Implications": [
              "importance of personalization"
            ],
            "Contradictions": [
              "<NONE>"
            ]
          }
        },
        {
          "Methods/Approach": "",
          "Text": "In this paper, we present a novel framework that addresses these challenges by incorporating user profiling to generate personalized headlines, and a combination of automated and human evaluation methods to determine user preference for personalized headlines. Our framework utilizes a learnable relevance function to assign personalized signature phrases to users based on their reading histories, which are then used to personalize headline generation.",
          "Main Action": "present",
          "Arguments": {
            "Agent": [
              "we"
            ],
            "Object": {
              "Primary Object": [
                "a novel framework"
              ],
              "Secondary Object": [
                "<NONE>"
              ]
            },
            "Context": [
              "addressing these challenges"
            ],
            "Purpose": [
              "to address these challenges"
            ],
            "Method": [
              "incorporating user profiling",
              "automated and human evaluation methods",
              "learnable relevance function"
            ],
            "Results": [
              "<NONE>"
            ],
            "Analysis": [
              "<NONE>"
            ],
            "Challenge": [
              "these challenges"
            ],
            "Ethical": [
              "<NONE>"
            ],
            "Implications": [
              "improving personalization, enhancing user experience"
            ],
            "Contradictions": [
              "<NONE>"
            ]
          }
        },
        {
          "Results/Findings": "",
          "Text": "Through extensive evaluation, we demonstrate the effectiveness of our proposed framework in generating personalized headlines that meet the needs of a diverse audience.",
          "Main Action": "Through extensive evaluation, we demonstrate the effectiveness of our proposed framework in generating personalized headlines that meet the needs of a diverse audience.",
          "Arguments": {
            "Agent": [
              "We"
            ],
            "Object": {
              "Primary Object": [
                "our proposed framework"
              ],
              "Secondary Object": [
                "personalized headlines"
              ]
            },
            "Context": [
              "<NONE>"
            ],
            "Purpose": [
              "To evaluate and demonstrate the effectiveness of our proposed framework in generating personalized headlines that meet the needs of a diverse audience."
            ],
            "Method": [
              "Extensive evaluation"
            ],
            "Results": [
              "We demonstrated the effectiveness of our proposed framework in generating personalized headlines that meet the needs of a diverse audience."
            ],
            "Analysis": [
              "<NONE>"
            ],
            "Challenge": [
              "<NONE>"
            ],
            "Ethical": [
              "<NONE>"
            ],
            "Implications": [
              "This demonstrates that our framework effectively generates personalized headlines suitable for diverse audiences, highlighting its value in improving content relevance and engagement."
            ],
            "Contradictions": [
              "<NONE>"
            ]
          }
        },
        {
          "Conclusions/Implications": "",
          "Text": "Our framework has the potential to improve the efficacy of news recommendations and facilitate creation of personalized content.",
          "Main Action": "has the potential to improve",
          "Arguments": {
            "Agent": [
              "our framework"
            ],
            "Object": {
              "Primary Object": [
                "news recommendations"
              ],
              "Secondary Object": [
                "creation of personalized content"
              ]
            },
            "Context": [
              "<NONE>"
            ],
            "Purpose": [
              "<NONE>"
            ],
            "Method": [
              "<NONE>"
            ],
            "Results": [
              "<NONE>"
            ],
            "Analysis": [
              "<NONE>"
            ],
            "Challenge": [
              "<NONE>"
            ],
            "Ethical": [
              "<NONE>"
            ],
            "Implications": [
              "<NONE>"
            ],
            "Contradictions": [
              "<NONE>"
            ]
          }
        }
      ]
    },
    {
      "paper_code": "ACL_23_P_386",
      "abstract": "Fact-checking real-world claims often requires collecting multiple pieces of evidence and applying complex multi-step reasoning. In this paper, we present Program-Guided Fact-Checking (ProgramFC), a novel fact-checking model that decomposes complex claims into simpler sub-tasks that can be solved using a shared library of specialized functions. We first leverage the in-context learning ability of large language models to generate reasoning programs to guide the verification process. Afterward, we execute the program by delegating each sub-task to the corresponding sub-task handler. This process makes our model both explanatory and data-efficient, providing clear explanations of its reasoning process and requiring minimal training data. We evaluate ProgramFC on two challenging fact-checking datasets and show that it outperforms seven fact-checking baselines across different settings of evidence availability, with explicit output programs that benefit human debugging.",
      "events": [
        {
          "Background/Introduction": "",
          "Text": "Fact-checking real-world claims often requires collecting multiple pieces of evidence and applying complex multi-step reasoning.",
          "Main Action": "requires",
          "Arguments": {
            "Agent": [
              "<NONE>"
            ],
            "Object": {
              "Primary Object": [
                "collecting multiple pieces of evidence"
              ],
              "Secondary Object": [
                "applying complex multi-step reasoning"
              ]
            },
            "Context": [
              "<NONE>"
            ],
            "Purpose": [
              "Ensuring accurate verification of claims"
            ],
            "Method": [
              "Collecting evidence and applying multi-step reasoning"
            ],
            "Results": [
              "<NONE>"
            ],
            "Analysis": [
              "<NONE>"
            ],
            "Challenge": [
              "Complexity of the process"
            ],
            "Ethical": [
              "<NONE>"
            ],
            "Implications": [
              "Broader societal impacts like informed decision-making"
            ],
            "Contradictions": [
              "<NONE>"
            ]
          }
        },
        {
          "Methods/Approach": "",
          "Text": "In this paper, we present Program-Guided Fact-Checking (ProgramFC), a novel fact-checking model that decomposes complex claims into simpler sub-tasks that can be solved using a shared library of specialized functions. We first leverage the in-context learning ability of large language models to generate reasoning programs to guide the verification process. Afterward, we execute the program by delegating each sub-task to the corresponding sub-task handler. This process makes our model both explanatory and data-efficient, providing clear explanations of its reasoning process and requiring minimal training data.",
          "Main Action": "We create and execute reasoning programs",
          "Arguments": {
            "Agent": [
              "they"
            ],
            "Object": {
              "Primary Object": [
                "ProgramFC"
              ],
              "Secondary Object": [
                "<NONE>"
              ]
            },
            "Context": [
              "verifying complex claims accurately",
              "motivation behind developing such a model"
            ],
            "Purpose": [
              "improving accuracy and efficiency in fact-checking processes"
            ],
            "Method": [
              "leverage the in-context learning ability of large language models",
              "shared library of specialized functions"
            ],
            "Results": [
              "explanatory",
              "data-efficient"
            ],
            "Analysis": [
              "makes our model both explanatory and data-efficient"
            ],
            "Challenge": [
              "<NONE>"
            ],
            "Ethical": [
              "<NONE>"
            ],
            "Implications": [
              "automated fact-checkers can handle diverse domains more effectively"
            ],
            "Contradictions": [
              "<NONE>"
            ]
          }
        },
        {
          "Results/Findings": "",
          "Text": "We evaluate ProgramFC on two challenging fact-checking datasets and show that it outperforms seven fact-checking baselines across different settings of evidence availability, with explicit output programs that benefit human debugging.",
          "Main Action": "Evaluate ProgramFC",
          "Arguments": {
            "Agent": [
              "We"
            ],
            "Object": {
              "Primary Object": [
                "ProgramFC"
              ],
              "Secondary Object": [
                "<NONE>"
              ]
            },
            "Context": [
              "two challenging fact-checking datasets",
              "different settings of evidence availability"
            ],
            "Purpose": [
              "to assess the performance of ProgramFC compared to seven fact-checking baselines"
            ],
            "Method": [
              "testing on specific datasets",
              "comparing results against established baselines",
              "explicit output programs that benefit human debugging"
            ],
            "Results": [
              "outperforms seven fact-checking baselines across different settings of evidence availability"
            ],
            "Analysis": [
              "<NONE>"
            ],
            "Challenge": [
              "complexity implied by 'challenging datasets'"
            ],
            "Ethical": [
              "<NONE>"
            ],
            "Implications": [
              "advancements in automatic fact-checking technologies"
            ],
            "Contradictions": [
              "<NONE>"
            ]
          }
        }
      ]
    }
  ]
}