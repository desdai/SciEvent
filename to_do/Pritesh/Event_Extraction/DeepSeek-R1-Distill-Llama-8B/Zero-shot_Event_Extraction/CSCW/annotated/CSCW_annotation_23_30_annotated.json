{
  "papers": [
    {
      "paper_code": "cscw_23_P_257",
      "abstract": "AI explanations are often mentioned as a way to improve human-AI decision-making, but empirical studies have not found consistent evidence of explanations' effectiveness and, on the contrary, suggest that they can increase overreliance when the AI system is wrong. While many factors may affect reliance on AI support, one important factor is how decision-makers reconcile their own intuition — beliefs or heuristics, based on prior knowledge, experience, or pattern recognition, used to make judgments — with the information provided by the AI system to determine when to override AI predictions. We conduct a think-aloud, mixed-methods study with two explanation types (feature- and example-based) for two prediction tasks to explore how decision-makers' intuition affects their use of AI predictions and explanations, and ultimately their choice of when to rely on AI. Our results identify three types of intuition involved in reasoning about AI predictions and explanations: intuition about the task outcome, features, and AI limitations. Building on these, we summarize three observed pathways for decision-makers to apply their own intuition and override AI predictions. We use these pathways to explain why (1) the feature-based explanations we used did not improve participants' decision outcomes and increased their overreliance on AI, and (2) the example-based explanations we used improved decision-makers' performance over feature-based explanations and helped achieve complementary human-AI performance. Overall, our work identifies directions for further development of AI decision-support systems and explanation methods that help decision-makers effectively apply their intuition to achieve appropriate reliance on AI.",
      "events": [
        {
          "Background/Introduction": "",
          "Text": "AI explanations are often mentioned as a way to improve human-AI decision-making, but empirical studies have not found consistent evidence of explanations' effectiveness and, on the contrary, suggest that they can increase overreliance when the AI system is wrong. While many factors may affect reliance on AI support, one important factor is how decision-makers reconcile their own intuition — beliefs or heuristics, based on prior knowledge, experience, or pattern recognition, used to make judgments — with the information provided by the AI system to determine when to override AI predictions.",
          "Main Action": "reconcile",
          "Arguments": {
            "Agent": [
              "decision-makers"
            ],
            "Object": {
              "Primary Object": [
                "their own intuition"
              ],
              "Secondary Object": [
                "the information provided by the AI system"
              ]
            },
            "Context": [
              "human-AI decision-making"
            ],
            "Purpose": [
              "exploring the limitations of relying on explanations"
            ],
            "Method": [
              "empirical studies"
            ],
            "Results": [
              "empirical studies have not found consistent evidence",
              "increased overreliance when the AI system is wrong"
            ],
            "Analysis": [
              "suggesting that they can increase overreliance"
            ],
            "Challenge": [
              "mixed results from empirical studies"
            ],
            "Ethical": [
              "<NONE>"
            ],
            "Implications": [
              "current strategies focusing solely on providing explanations might not be sufficient"
            ],
            "Contradictions": [
              "while explanations were thought to help"
            ]
          }
        },
        {
          "Methods/Approach": "",
          "Text": "We conduct a think-aloud, mixed-methods study with two explanation types (feature- and example-based) for two prediction tasks to explore how decision-makers' intuition affects their use of AI predictions and explanations, and ultimately their choice of when to rely on AI.",
          "Main Action": "conduct a think-aloud, mixed-methods study",
          "Arguments": {
            "Agent": [
              "we"
            ],
            "Object": {
              "Primary Object": [
                "a think-aloud, mixed-methods study"
              ],
              "Secondary Object": [
                "two explanation types (feature- and example-based)",
                "two prediction tasks"
              ]
            },
            "Context": [
              "how decision-makers' intuition affects their use of AI predictions and explanations"
            ],
            "Purpose": [
              "to explore how decision-makers' intuition affects their use of AI predictions and explanations, and ultimately their choice of when to rely on AI"
            ],
            "Method": [
              "mixed-methods study",
              "qualitative (think-aloud) and quantitative methods"
            ],
            "Results": [
              "understanding the relationship between intuition and reliance on AI"
            ],
            "Analysis": [
              "interpretations of other arguments",
              "why certain factors matter more than others"
            ],
            "Challenge": [
              "small sample size",
              "difficulty in capturing all aspects of decision-making",
              "complexity of integrating different methods"
            ],
            "Ethical": [
              "bias in AI models affecting decision-making",
              "privacy concerns regarding data collection"
            ],
            "Implications": [
              "improving AI design",
              "user trust",
              "better integration into decision-making processes"
            ],
            "Contradictions": [
              "<NONE>"
            ]
          }
        },
        {
          "Results/Findings": "",
          "Text": "Our results identify three types of intuition involved in reasoning about AI predictions and explanations: intuition about the task outcome, features, and AI limitations. Building on these, we summarize three observed pathways for decision-makers to apply their own intuition and override AI predictions. We use these pathways to explain why (1) the feature-based explanations we used did not improve participants' decision outcomes and increased their overreliance on AI, and (2) the example-based explanations we used improved decision-makers' performance over feature-based explanations and helped achieve complementary human-AI performance.",
          "Main Action": "We summarize",
          "Arguments": {
            "Agent": [
              "we"
            ],
            "Object": {
              "Primary Object": [
                "three observed pathways"
              ],
              "Secondary Object": [
                "decision-makers"
              ]
            },
            "Context": [
              "reasoning about AI predictions and explanations",
              "intuition about the task outcome",
              "features, and AI limitations"
            ],
            "Purpose": [
              "to allow decision-makers to apply their own intuition and override AI predictions"
            ],
            "Method": [
              "using these pathways to explain why"
            ],
            "Results": [
              "the feature-based explanations we used did not improve participants' decision outcomes and increased their overreliance on AI",
              "and (2) the example-based explanations we used improved decision-makers' performance over feature-based explanations and helped achieve complementary human-AI performance"
            ],
            "Analysis": [
              "<NONE>"
            ],
            "Challenge": [
              "<NONE>"
            ],
            "Ethical": [
              "<NONE>"
            ],
            "Implications": [
              "understanding how different explanation styles influence trust and reliance between humans and AI systems"
            ],
            "Contradictions": [
              "<NONE>"
            ]
          }
        },
        {
          "Conclusions/Implications": "",
          "Text": "Overall, our work identifies directions for further development of AI decision-support systems and explanation methods that help decision-makers effectively apply their intuition to achieve appropriate reliance on AI.",
          "Main Action": "<NONE>",
          "Arguments": {
            "Agent": [
              "<NONE>"
            ],
            "Object": {
              "Primary Object": [
                "<NONE>"
              ],
              "Secondary Object": [
                "<NONE>"
              ]
            },
            "Context": [
              "<NONE>"
            ],
            "Purpose": [
              "<NONE>"
            ],
            "Method": [
              "<NONE>"
            ],
            "Results": [
              "<NONE>"
            ],
            "Analysis": [
              "<NONE>"
            ],
            "Challenge": [
              "<NONE>"
            ],
            "Ethical": [
              "<NONE>"
            ],
            "Implications": [
              "<NONE>"
            ],
            "Contradictions": [
              "<NONE>"
            ]
          }
        }
      ]
    },
    {
      "paper_code": "cscw_23_P_182",
      "abstract": "With the shift to hybrid meetings in work spaces, there is an increasing need to create a more inclusive hybrid meeting experience where people meeting together in a room interact with those joining remotely. This paper describes a design exploration, implementation, and evaluation of Perspectives, a novel hybrid meeting system that aimed to create an inclusive and equitable space for hybrid meetings. Perspectives digitally composites everyone into a virtual room so that each person has a unique but spatially consistent viewpoint into the meeting. The user study compared Perspectives with three commercially available UX designs for hybrid meetings: Gallery, Together Mode, and Front Row. Results from this study revealed key benefits of Perspectives, including supporting natural interactions, creating a strong sense of co-presence, and reducing cognitive load. Results from the study also helped iterate on the design principles of Perspectives, which offer important insights on supporting hybrid meetings.",
      "events": [
        {
          "Background/Introduction": "",
          "Text": "With the shift to hybrid meetings in work spaces, there is an increasing need to create a more inclusive hybrid meeting experience where people meeting together in a room interact with those joining remotely.",
          "Main Action": "<NONE>",
          "Arguments": {
            "Agent": [
              "<NONE>"
            ],
            "Object": {
              "Primary Object": [
                "<NONE>"
              ],
              "Secondary Object": [
                "<NONE>"
              ]
            },
            "Context": [
              "<NONE>"
            ],
            "Purpose": [
              "<NONE>"
            ],
            "Method": [
              "<NONE>"
            ],
            "Results": [
              "<NONE>"
            ],
            "Analysis": [
              "<NONE>"
            ],
            "Challenge": [
              "<NONE>"
            ],
            "Ethical": [
              "<NONE>"
            ],
            "Implications": [
              "<NONE>"
            ],
            "Contradictions": [
              "<NONE>"
            ]
          }
        },
        {
          "Methods/Approach": "",
          "Text": "This paper describes a design exploration, implementation, and evaluation of Perspectives, a novel hybrid meeting system that aimed to create an inclusive and equitable space for hybrid meetings. Perspectives digitally composites everyone into a virtual room so that each person has a unique but spatially consistent viewpoint into the meeting. The user study compared Perspectives with three commercially available UX designs for hybrid meetings: Gallery, Together Mode, and Front Row.",
          "Main Action": "digitally composites",
          "Arguments": {
            "Agent": [
              "Perspectives"
            ],
            "Object": {
              "Primary Object": [
                "everyone"
              ],
              "Secondary Object": [
                "virtual room"
              ]
            },
            "Context": [
              "hybrid meetings"
            ],
            "Purpose": [
              "create an inclusive and equitable space"
            ],
            "Method": [
              "digital composites"
            ],
            "Results": [
              "user study compared Perspectives with three commercially available UX designs for hybrid meetings: Gallery, Together Mode, and Front Row"
            ],
            "Analysis": [
              "interpretations or explanations of other arguments"
            ],
            "Challenge": [
              "constraints or weaknesses of the event"
            ],
            "Ethical": [
              "ethical concerns, justifications or implications of the event"
            ],
            "Implications": [
              "broader significance or potential for future applications/research"
            ],
            "Contradictions": [
              "disagreements with existing knowledge"
            ]
          }
        },
        {
          "Results/Findings": "",
          "Text": "Results from this study revealed key benefits of Perspectives, including supporting natural interactions, creating a strong sense of co-presence, and reducing cognitive load. Results from the study also helped iterate on the design principles of Perspectives, which offer important insights on supporting hybrid meetings.",
          "Main Action": "<NONE>",
          "Arguments": {
            "Agent": [
              "<NONE>"
            ],
            "Object": {
              "Primary Object": [
                "<NONE>"
              ],
              "Secondary Object": [
                "<NONE>"
              ]
            },
            "Context": [
              "<NONE>"
            ],
            "Purpose": [
              "<NONE>"
            ],
            "Method": [
              "<NONE>"
            ],
            "Results": [
              "<NONE>"
            ],
            "Analysis": [
              "<NONE>"
            ],
            "Challenge": [
              "<NONE>"
            ],
            "Ethical": [
              "<NONE>"
            ],
            "Implications": [
              "<NONE>"
            ],
            "Contradictions": [
              "<NONE>"
            ]
          }
        }
      ]
    }
  ]
}