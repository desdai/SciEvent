{
  "papers": [
    {
      "paper_code": "ACL_23_P_634",
      "abstract": "Many text generation applications require the generated text to be factually consistent with input information. Automatic evaluation of factual consistency is challenging. Previous work has developed various metrics that often depend on specific functions, such as natural language inference (NLI) or question answering (QA), trained on limited data. Those metrics thus can hardly assess diverse factual inconsistencies (e.g., contradictions, hallucinations) that occur in varying inputs/outputs (e.g., sentences, documents) from different tasks. In this paper, we propose AlignScore, a new holistic metric that applies to a variety of factual inconsistency scenarios as above. AlignScore is based on a general function of information alignment between two arbitrary text pieces. Crucially, we develop a unified training framework of the alignment function by integrating a large diversity of data sources, resulting in 4.7M training examples from 7 well-established tasks (NLI, QA, paraphrasing, fact verification, information retrieval, semantic similarity, and summarization). We conduct extensive experiments on large-scale benchmarks including 22 evaluation datasets, where 19 of the datasets were never seen in the alignment training. AlignScore achieves substantial improvement over a wide range of previous metrics. Moreover, AlignScore (355M parameters) matches or even outperforms metrics based on ChatGPT and GPT-4 that are orders of magnitude larger.",
      "events": [
        {
          "Background/Introduction": "",
          "Text": "Many text generation applications require the generated text to be factually consistent with input information. Automatic evaluation of factual consistency is challenging. Previous work has developed various metrics that often depend on specific functions, such as natural language inference (NLI) or question answering (QA), trained on limited data. Those metrics thus can hardly assess diverse factual inconsistencies (e.g., contradictions, hallucinations) that occur in varying inputs/outputs (e.g., sentences, documents) from different tasks.",
          "Main Action": "<NONE>",
          "Arguments": {
            "Agent": [
              "Previous work"
            ],
            "Object": {
              "Primary Object": [
                "various metrics"
              ],
              "Secondary Object": [
                "limited data",
                "diverse factual inconsistencies"
              ]
            },
            "Context": [
              "Automatic evaluation of factual consistency is challenging",
              "Those metrics thus can hardly assess"
            ],
            "Purpose": [
              "assess diverse factual inconsistencies"
            ],
            "Method": [
              "developed various metrics based on NLI or QA"
            ],
            "Results": [
              "<NONE>"
            ],
            "Analysis": [
              "<NONE>"
            ],
            "Challenge": [
              "challenging automatic evaluation of factual consistency",
              "can hardly assess diverse factual inconsistencies"
            ],
            "Ethical": [
              "<NONE>"
            ],
            "Implications": [
              "<NONE>"
            ],
            "Contradictions": [
              "<NONE>"
            ]
          }
        },
        {
          "Methods/Approach": "",
          "Text": "In this paper, we propose AlignScore, a new holistic metric that applies to a variety of factual inconsistency scenarios as above. AlignScore is based on a general function of information alignment between two arbitrary text pieces. Crucially, we develop a unified training framework of the alignment function by integrating a large diversity of data sources, resulting in 4.7M training examples from 7 well-established tasks (NLI, QA, paraphrasing, fact verification, information retrieval, semantic similarity, and summarization).",
          "Main Action": "<NONE>",
          "Arguments": {
            "Agent": [
              "we"
            ],
            "Object": {
              "Primary Object": [
                "AlignScore",
                "a unified training framework of the alignment function"
              ],
              "Secondary Object": [
                "4.7M training examples from 7 well-established tasks"
              ]
            },
            "Context": [
              "In this paper"
            ],
            "Purpose": [
              "to apply to a variety of factual inconsistency scenarios",
              "developing a unified training framework"
            ],
            "Method": [
              "integrating a large diversity of data sources"
            ],
            "Results": [
              "resulting in 4.7M training examples from 7 well-established tasks"
            ],
            "Analysis": [
              "<NONE>"
            ],
            "Challenge": [
              "<NONE>"
            ],
            "Ethical": [
              "<NONE>"
            ],
            "Implications": [
              "<NONE>"
            ],
            "Contradictions": [
              "<NONE>"
            ]
          }
        },
        {
          "Results/Findings": "",
          "Text": "We conduct extensive experiments on large-scale benchmarks including 22 evaluation datasets, where 19 of the datasets were never seen in the alignment training. AlignScore achieves substantial improvement over a wide range of previous metrics. Moreover, AlignScore (355M parameters) matches or even outperforms metrics based on ChatGPT and GPT-4 that are orders of magnitude larger.",
          "Main Action": "<NONE>",
          "Arguments": {
            "Agent": [
              "AlignScore"
            ],
            "Object": {
              "Primary Object": [
                "achieves substantial improvement"
              ],
              "Secondary Object": [
                "previous metrics",
                "metrics based on ChatGPT and GPT-4"
              ]
            },
            "Context": [
              "extensive experiments on large-scale benchmarks",
              "including 22 evaluation datasets, where 19 of the datasets were never seen in the alignment training"
            ],
            "Purpose": [
              "improvement over a wide range of previous metrics"
            ],
            "Method": [
              "conducted extensive experiments"
            ],
            "Results": [
              "substantial improvement over a wide range of previous metrics",
              "matches or even outperforms metrics based on ChatGPT and GPT-4 that are orders of magnitude larger"
            ],
            "Analysis": [
              "none detected"
            ],
            "Challenge": [
              "none detected"
            ],
            "Ethical": [
              "none detected"
            ],
            "Implications": [
              "broad significance or potential for future applications/research"
            ],
            "Contradictions": [
              "none detected"
            ]
          }
        }
      ]
    },
    {
      "paper_code": "ACL_23_P_859",
      "abstract": "Large language models (LLMs) that have been trained on multilingual but not parallel text exhibit a remarkable ability to translate between languages. We probe this ability in an in-depth study of the pathways language model (PaLM), which has demonstrated the strongest machine translation (MT) performance among similarly-trained LLMs to date. We investigate various strategies for choosing translation examples for few-shot prompting, concluding that example quality is the most important factor. Using optimized prompts, we revisit previous assessments of PaLM’s MT capabilities with more recent test sets, modern MT metrics, and human evaluation, and find that its performance, while impressive, still lags that of state-of-the-art supervised systems. We conclude by providing an analysis of PaLM’s MT output which reveals some interesting properties and prospects for future work.",
      "events": [
        {
          "Background/Introduction": "",
          "Text": "Large language models (LLMs) that have been trained on multilingual but not parallel text exhibit a remarkable ability to translate between languages.",
          "Main Action": "<NONE>",
          "Arguments": {
            "Agent": [
              "Large language models"
            ],
            "Object": {
              "Primary Object": [
                "exhibit a remarkable ability"
              ],
              "Secondary Object": [
                "to translate between languages"
              ]
            },
            "Context": [
              "that have been trained on multilingual but not parallel text"
            ],
            "Purpose": [
              "<NONE>"
            ],
            "Method": [
              "<NONE>"
            ],
            "Results": [
              "exhibit a remarkable ability to translate between languages"
            ],
            "Analysis": [
              "<NONE>"
            ],
            "Challenge": [
              "<NONE>"
            ],
            "Ethical": [
              "<NONE>"
            ],
            "Implications": [
              "<NONE>"
            ],
            "Contradictions": [
              "<NONE>"
            ]
          }
        },
        {
          "Methods/Approach": "",
          "Text": "We probe this ability in an in-depth study of the pathways language model (PaLM), which has demonstrated the strongest machine translation (MT) performance among similarly-trained LLMs to date. We investigate various strategies for choosing translation examples for few-shot prompting, concluding that example quality is the most important factor. Using optimized prompts, we revisit previous assessments of PaLM’s MT capabilities with more recent test sets, modern MT metrics, and human evaluation, and find that its performance, while impressive, still lags that of state-of-the-art supervised systems.",
          "Main Action": "<NONE>",
          "Arguments": {
            "Agent": [
              "we"
            ],
            "Object": {
              "Primary Object": [
                "an in-depth study of the pathways language model (PaLM)",
                "various strategies for choosing translation examples for few-shot prompting",
                "optimized prompts",
                "previous assessments of PaLM's MT capabilities",
                "more recent test sets",
                "modern MT metrics",
                "human evaluation"
              ],
              "Secondary Object": [
                "state-of-the-art supervised systems"
              ]
            },
            "Context": [
              "in an in-depth study of the pathways language model (PaLM)",
              "which has demonstrated the strongest machine translation (MT) performance among similarly-trained LLMs to date",
              "using optimized prompts",
              "with more recent test sets, modern MT metrics, and human evaluation"
            ],
            "Purpose": [
              "investigate various strategies for choosing translation examples for few-shot prompting",
              "revisit previous assessments of PaLM’s MT capabilities",
              "find that its performance, while impressive, still lags that of state-of-the-art supervised systems"
            ],
            "Method": [
              "investigate various strategies for choosing translation examples for few-shot prompting",
              "Using optimized prompts",
              "revisiting previous assessments of PaLM’s MT capabilities with more recent test sets, modern MT metrics, and human evaluation"
            ],
            "Results": [
              "concluding that example quality is the most important factor",
              "its performance, while impressive, still lags that of state-of-the-art supervised systems"
            ],
            "Analysis": [
              "finding that its performance, while impressive, still lags that of state-of-the-art supervised systems"
            ],
            "Challenge": [
              "none explicit challenge mentioned"
            ],
            "Ethical": [
              "none explicit ethical concern mentioned"
            ],
            "Implications": [
              "none direct implication statement made about wider application or future research"
            ],
            "Contradictions": [
              "none explicit contradiction presented"
            ]
          }
        },
        {
          "Conclusions/Implications": "",
          "Text": "We conclude by providing an analysis of PaLM’s MT output which reveals some interesting properties and prospects for future work.",
          "Main Action": "providing",
          "Arguments": {
            "Agent": [
              "we"
            ],
            "Object": {
              "Primary Object": [
                "an analysis of PaLM's MT output"
              ],
              "Secondary Object": [
                "some interesting properties and prospects for future work"
              ]
            },
            "Context": [
              "by concluding"
            ],
            "Purpose": [
              "reveals some interesting properties and prospects for future work"
            ],
            "Method": [
              "<NONE>"
            ],
            "Results": [
              "<NONE>"
            ],
            "Analysis": [
              "reveals some interesting properties and prospects for future work"
            ],
            "Challenge": [
              "<NONE>"
            ],
            "Ethical": [
              "<NONE>"
            ],
            "Implications": [
              "for future work"
            ],
            "Contradictions": [
              "<NONE>"
            ]
          }
        }
      ]
    }
  ]
}