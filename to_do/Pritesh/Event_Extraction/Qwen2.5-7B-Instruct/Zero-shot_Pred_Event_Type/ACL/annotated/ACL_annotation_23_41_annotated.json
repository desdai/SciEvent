{
  "papers": [
    {
      "paper_code": "ACL_23_P_509",
      "abstract": "Fine-tuning has been proven to be a simple and effective technique to transfer the learned knowledge of Pre-trained Language Models (PLMs) to downstream tasks. However, vanilla fine-tuning easily overfits the target data and degrades the generalization ability. Most existing studies attribute it to catastrophic forgetting, and they retain the pre-trained knowledge indiscriminately without identifying what knowledge is transferable. Motivated by this, we frame fine-tuning into a causal graph and discover that the crux of catastrophic forgetting lies in the missing causal effects from the pre-trained data. Based on the causal view, we propose a unified objective for fine-tuning to retrieve the causality back. Intriguingly, the unified objective can be seen as the sum of the vanilla fine-tuning objective, which learns new knowledge from target data, and the causal objective, which preserves old knowledge from PLMs. Therefore, our method is flexible and can mitigate negative transfer while preserving knowledge. Since endowing models with commonsense is a long-standing challenge, we implement our method on commonsense QA with a proposed heuristic estimation to verify its effectiveness. In the experiments, our method outperforms state-of-the-art fine-tuning methods on all six commonsense QA datasets and can be implemented as a plug-in module to inflate the performance of existing QA models.",
      "events": [
        {
          "Background/Introduction": "",
          "Text": "Fine-tuning has been proven to be a simple and effective technique to transfer the learned knowledge of Pre-trained Language Models (PLMs) to downstream tasks. However, vanilla fine-tuning easily overfits the target data and degrades the generalization ability. Most existing studies attribute it to catastrophic forgetting, and they retain the pre-trained knowledge indiscriminately without identifying what knowledge is transferable.",
          "Main Action": "<NONE>",
          "Arguments": {
            "Agent": [
              "vanilla fine-tuning"
            ],
            "Object": {
              "Primary Object": [
                "target data",
                "generalization ability"
              ],
              "Secondary Object": [
                "pre-trained knowledge"
              ]
            },
            "Context": [
              "fine-tuning has been proven to be a simple and effective technique to transfer the learned knowledge of PLMs to downstream tasks"
            ],
            "Purpose": [
              "to transfer the learned knowledge of PLMs to downstream tasks"
            ],
            "Method": [
              "vanilla fine-tuning"
            ],
            "Results": [
              "overfits the target data and degrades the generalization ability"
            ],
            "Analysis": [
              "Most existing studies attribute it to catastrophic forgetting, and they retain the pre-trained knowledge indiscriminately without identifying what knowledge is transferable"
            ],
            "Challenge": [
              "degrades the generalization ability"
            ],
            "Ethical": [
              "<NONE>"
            ],
            "Implications": [
              "<NONE>"
            ],
            "Contradictions": [
              "<NONE>"
            ]
          }
        },
        {
          "Methods/Approach": "",
          "Text": "Motivated by this, we frame fine-tuning into a causal graph and discover that the crux of catastrophic forgetting lies in the missing causal effects from the pre-trained data. Based on the causal view, we propose a unified objective for fine-tuning to retrieve the causality back. Intriguingly, the unified objective can be seen as the sum of the vanilla fine-tuning objective, which learns new knowledge from target data, and the causal objective, which preserves old knowledge from PLMs. Therefore, our method is flexible and can mitigate negative transfer while preserving knowledge. Since endowing models with commonsense is a long-standing challenge, we implement our method on commonsense QA with a proposed heuristic estimation to verify its effectiveness.",
          "Main Action": "frame",
          "Arguments": {
            "Agent": [
              "we"
            ],
            "Object": {
              "Primary Object": [
                "fine-tuning"
              ],
              "Secondary Object": [
                "causal graph"
              ]
            },
            "Context": [
              "Motivated by this"
            ],
            "Purpose": [
              "discover that the crux of catastrophic forgetting lies in the missing causal effects from the pre-trained data"
            ],
            "Method": [
              "propose a unified objective for fine-tuning to retrieve the causality back"
            ],
            "Results": [
              "unified objective can be seen as the sum of the vanilla fine-tuning objective, which learns new knowledge from target data, and the causal objective, which preserves old knowledge from PLMs, therefore, our method is flexible and can mitigate negative transfer while preserving knowledge"
            ],
            "Analysis": [
              "<NONE>"
            ],
            "Challenge": [
              "endowing models with commonsense is a long-standing challenge"
            ],
            "Ethical": [
              "<NONE>"
            ],
            "Implications": [
              "implement our method on commonsense QA with a proposed heuristic estimation to verify its effectiveness"
            ],
            "Contradictions": [
              "<NONE>"
            ]
          }
        },
        {
          "Results/Findings": "",
          "Text": "In the experiments, our method outperforms state-of-the-art fine-tuning methods on all six commonsense QA datasets and can be implemented as a plug-in module to inflate the performance of existing QA models.",
          "Main Action": "outperforms",
          "Arguments": {
            "Agent": [
              "our method"
            ],
            "Object": {
              "Primary Object": [
                "state-of-the-art fine-tuning methods"
              ],
              "Secondary Object": [
                "commonsense QA datasets"
              ]
            },
            "Context": [
              "experiments"
            ],
            "Purpose": [
              "<NONE>"
            ],
            "Method": [
              "<NONE>"
            ],
            "Results": [
              "outperforms state-of-the-art fine-tuning methods on all six commonsense QA datasets"
            ],
            "Analysis": [
              "can be implemented as a plug-in module to inflate the performance of existing QA models"
            ],
            "Challenge": [
              "<NONE>"
            ],
            "Ethical": [
              "<NONE>"
            ],
            "Implications": [
              "<NONE>"
            ],
            "Contradictions": [
              "<NONE>"
            ]
          }
        }
      ]
    },
    {
      "paper_code": "ACL_23_P_316",
      "abstract": "We study grammar induction with mildly context-sensitive grammars for unsupervised discontinuous parsing. Using the probabilistic linear context-free rewriting system (LCFRS) formalism, our approach fixes the rule structure in advance and focuses on parameter learning with maximum likelihood. To reduce the computational complexity of both parsing and parameter estimation, we restrict the grammar formalism to LCFRS-2 (i.e., binary LCFRS with fan-out two) and further discard rules that require O(l⁶) time to parse, reducing inference to O(l⁵). We find that using a large number of nonterminals is beneficial and thus make use of tensor decomposition-based rank-space dynamic programming with an embedding-based parameterization of rule probabilities to scale up the number of nonterminals. Experiments on German and Dutch show that our approach is able to induce linguistically meaningful trees with continuous and discontinuous structures.",
      "events": [
        {
          "Background/Introduction": "",
          "Text": "We study grammar induction with mildly context-sensitive grammars for unsupervised discontinuous parsing. Using the probabilistic linear context-free rewriting system (LCFRS) formalism, our approach fixes the rule structure in advance and focuses on parameter learning with maximum likelihood.",
          "Main Action": "study",
          "Arguments": {
            "Agent": [
              "we"
            ],
            "Object": {
              "Primary Object": [
                "grammar induction"
              ],
              "Secondary Object": [
                "mildly context-sensitive grammars",
                "unsupervised discontinuous parsing"
              ]
            },
            "Context": [
              "grammars",
              "parsing"
            ],
            "Purpose": [
              "fixing the rule structure in advance and focusing on parameter learning with maximum likelihood using LCFRS formalism"
            ],
            "Method": [
              "using the probabilistic linear context-free rewriting system (LCFRS) formalism"
            ],
            "Results": [
              "<NONE>"
            ],
            "Analysis": [
              "<NONE>"
            ],
            "Challenge": [
              "<NONE>"
            ],
            "Ethical": [
              "<NONE>"
            ],
            "Implications": [
              "<NONE>"
            ],
            "Contradictions": [
              "<NONE>"
            ]
          }
        },
        {
          "Methods/Approach": "",
          "Text": "To reduce the computational complexity of both parsing and parameter estimation, we restrict the grammar formalism to LCFRS-2 (i.e., binary LCFRS with fan-out two) and further discard rules that require O(l⁶) time to parse, reducing inference to O(l⁵). We find that using a large number of nonterminals is beneficial and thus make use of tensor decomposition-based rank-space dynamic programming with an embedding-based parameterization of rule probabilities to scale up the number of nonterminals.",
          "Main Action": "<NONE>",
          "Arguments": {
            "Agent": [
              "we"
            ],
            "Object": {
              "Primary Object": [
                "grammar formalism",
                "inference"
              ],
              "Secondary Object": [
                "rules",
                "number of nonterminals"
              ]
            },
            "Context": [
              "to reduce the computational complexity",
              "of both parsing and parameter estimation"
            ],
            "Purpose": [
              "using a large number of nonterminals is beneficial"
            ],
            "Method": [
              "restricting the grammar formalism to LCFRS-2",
              "discarding rules that require O(l⁶) time to parse",
              "making use of tensor decomposition-based rank-space dynamic programming",
              "with an embedding-based parameterization of rule probabilities"
            ],
            "Results": [
              "finding that using a large number of nonterminals is beneficial"
            ],
            "Analysis": [
              "scaling up the number of nonterminals"
            ],
            "Challenge": [
              "none mentioned"
            ],
            "Ethical": [
              "none mentioned"
            ],
            "Implications": [
              "none mentioned"
            ],
            "Contradictions": [
              "none mentioned"
            ]
          }
        },
        {
          "Results/Findings": "",
          "Text": "Experiments on German and Dutch show that our approach is able to induce linguistically meaningful trees with continuous and discontinuous structures.",
          "Main Action": "show",
          "Arguments": {
            "Agent": [
              "our approach"
            ],
            "Object": {
              "Primary Object": [
                "that our approach is able to induce linguistically meaningful trees with continuous and discontinuous structures"
              ],
              "Secondary Object": [
                "German and Dutch experiments"
              ]
            },
            "Context": [
              "experiments on German and Dutch"
            ],
            "Purpose": [
              "<NONE>"
            ],
            "Method": [
              "<NONE>"
            ],
            "Results": [
              "induce linguistically meaningful trees with continuous and discontinuous structures"
            ],
            "Analysis": [
              "<NONE>"
            ],
            "Challenge": [
              "<NONE>"
            ],
            "Ethical": [
              "<NONE>"
            ],
            "Implications": [
              "<NONE>"
            ],
            "Contradictions": [
              "<NONE>"
            ]
          }
        }
      ]
    }
  ]
}