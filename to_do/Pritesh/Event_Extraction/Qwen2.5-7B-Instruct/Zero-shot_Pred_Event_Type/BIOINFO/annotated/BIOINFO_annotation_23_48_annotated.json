{
  "papers": [
    {
      "paper_code": "bioinfo_23_P_432",
      "abstract": "Interpretable deep learning (DL) models that can provide biological insights, in addition to accurate predictions, are of great interest to the biomedical community. Recently, interpretable DL models that incorporate signaling pathways have been proposed for drug response prediction (DRP). While these models improve interpretability, it is unclear whether this comes at the cost of less accurate DRPs, or a prediction improvement can also be obtained. We comprehensively and systematically assessed four state-of-the-art interpretable DL models using three pathway collections to assess their ability in making accurate predictions on unseen samples from the same dataset, as well as their generalizability to an independent dataset. Our results showed that models that explicitly incorporate pathway information in the form of a latent layer perform worse compared to models that incorporate this information implicitly. However, in most evaluation setups, the best performance was achieved using a black-box multilayer perceptron, and the performance of a random forests baseline was comparable to those of the interpretable models. Replacing the signaling pathways with randomly generated pathways showed a comparable performance for the majority of the models. Finally, the performance of all models deteriorated when applied to an independent dataset. These results highlight the importance of systematic evaluation of newly proposed models using carefully selected baselines. We provide different evaluation setups and baseline models that can be used to achieve this goal.",
      "events": [
        {
          "Background/Introduction": "",
          "Text": "Interpretable deep learning (DL) models that can provide biological insights, in addition to accurate predictions, are of great interest to the biomedical community. Recently, interpretable DL models that incorporate signaling pathways have been proposed for drug response prediction (DRP). While these models improve interpretability, it is unclear whether this comes at the cost of less accurate DRPs, or a prediction improvement can also be obtained.",
          "Main Action": "<NONE>",
          "Arguments": {
            "Agent": [
              "biomedical community"
            ],
            "Object": {
              "Primary Object": [
                "interpretable deep learning (DL) models"
              ],
              "Secondary Object": [
                "signaling pathways"
              ]
            },
            "Context": [
              "of great interest",
              "Recently, interpretable DL models that incorporate signaling pathways have been proposed for drug response prediction (DRP)"
            ],
            "Purpose": [
              "providing biological insights, in addition to accurate predictions"
            ],
            "Method": [
              "incorporate signaling pathways"
            ],
            "Results": [
              "it is unclear whether this comes at the cost of less accurate DRPs, or a prediction improvement can also be obtained"
            ],
            "Analysis": [
              "<NONE>"
            ],
            "Challenge": [
              "unclear whether this comes at the cost of less accurate DRPs"
            ],
            "Ethical": [
              "<NONE>"
            ],
            "Implications": [
              "potential for future applications/research"
            ],
            "Contradictions": [
              "<NONE>"
            ]
          }
        },
        {
          "Methods/Approach": "",
          "Text": "We comprehensively and systematically assessed four state-of-the-art interpretable DL models using three pathway collections to assess their ability in making accurate predictions on unseen samples from the same dataset, as well as their generalizability to an independent dataset.",
          "Main Action": "assessed",
          "Arguments": {
            "Agent": [
              "we"
            ],
            "Object": {
              "Primary Object": [
                "four state-of-the-art interpretable DL models"
              ],
              "Secondary Object": [
                "three pathway collections"
              ]
            },
            "Context": [
              "comprehensive and systematic assessment",
              "to assess their ability in making accurate predictions on unseen samples from the same dataset, as well as their generalizability to an independent dataset"
            ],
            "Purpose": [
              "none explicitly mentioned"
            ],
            "Method": [
              "using three pathway collections"
            ],
            "Results": [
              "none explicitly mentioned"
            ],
            "Analysis": [
              "none explicitly mentioned"
            ],
            "Challenge": [
              "none explicitly mentioned"
            ],
            "Ethical": [
              "none explicitly mentioned"
            ],
            "Implications": [
              "none explicitly mentioned"
            ],
            "Contradictions": [
              "none explicitly mentioned"
            ]
          }
        },
        {
          "Results/Findings": "",
          "Text": "Our results showed that models that explicitly incorporate pathway information in the form of a latent layer perform worse compared to models that incorporate this information implicitly. However, in most evaluation setups, the best performance was achieved using a black-box multilayer perceptron, and the performance of a random forests baseline was comparable to those of the interpretable models. Replacing the signaling pathways with randomly generated pathways showed a comparable performance for the majority of the models. Finally, the performance of all models deteriorated when applied to an independent dataset.",
          "Main Action": "<NONE>",
          "Arguments": {
            "Agent": [
              "models"
            ],
            "Object": {
              "Primary Object": [
                "perform worse",
                "achieve best performance",
                "show comparable performance",
                "deteriorate"
              ],
              "Secondary Object": [
                "pathway information",
                "black-box multilayer perceptron",
                "random forests baseline",
                "independent dataset",
                "randomly generated pathways"
              ]
            },
            "Context": [
              "In most evaluation setups"
            ],
            "Purpose": [
              "<NONE>"
            ],
            "Method": [
              "using a black-box multilayer perceptron",
              "with randomly generated pathways"
            ],
            "Results": [
              "models that explicitly incorporate pathway information...perform worse",
              "best performance was achieved using a black-box multilayer perceptron",
              "performance of a random forests baseline was comparable to those of the interpretable models",
              "replacing the signaling pathways...showed a comparable performance for the majority of the models",
              "performance of all models deteriorated when applied to an independent dataset"
            ],
            "Analysis": [
              "comparable performance for the majority of the models",
              "deterioration of model performance"
            ],
            "Challenge": [
              "<NONE>"
            ],
            "Ethical": [
              "<NONE>"
            ],
            "Implications": [
              "implications for interpretability vs. performance trade-offs",
              "potential limitations of current modeling approaches"
            ],
            "Contradictions": [
              "<NONE>"
            ]
          }
        },
        {
          "Conclusions/Implications": "",
          "Text": "These results highlight the importance of systematic evaluation of newly proposed models using carefully selected baselines. We provide different evaluation setups and baseline models that can be used to achieve this goal.",
          "Main Action": "<NONE>",
          "Arguments": {
            "Agent": [
              "We"
            ],
            "Object": {
              "Primary Object": [
                "systematic evaluation of newly proposed models using carefully selected baselines"
              ],
              "Secondary Object": [
                "different evaluation setups and baseline models"
              ]
            },
            "Context": [
              "highlight the importance of systematically evaluating newly proposed models"
            ],
            "Purpose": [
              "achieve the goal of systematically evaluating newly proposed models using carefully selected baselines"
            ],
            "Method": [
              "provide different evaluation setups and baseline models"
            ],
            "Results": [
              "<NONE>"
            ],
            "Analysis": [
              "<NONE>"
            ],
            "Challenge": [
              "<NONE>"
            ],
            "Ethical": [
              "<NONE>"
            ],
            "Implications": [
              "<NONE>"
            ],
            "Contradictions": [
              "<NONE>"
            ]
          }
        }
      ]
    },
    {
      "paper_code": "bioinfo_23_P_838",
      "abstract": "In whole genome sequencing data, polymerase chain reaction amplification results in duplicate DNA fragments coming from the same location in the genome. The process of preparing a whole genome bisulfite sequencing (WGBS) library, on the other hand, can create two DNA fragments from the same location that should not be considered duplicates. Currently, only one WGBS-aware duplicate marking tool exists. However, it only works with the output from a single tool, does not accept streaming input or output, and requires a substantial amount of memory relative to the input size. Dupsifter provides an aligner-agnostic duplicate marking tool that is lightweight, has streaming capabilities, and is memory efficient.",
      "events": [
        {
          "Background/Introduction": "",
          "Text": "In whole genome sequencing data, polymerase chain reaction amplification results in duplicate DNA fragments coming from the same location in the genome. The process of preparing a whole genome bisulfite sequencing (WGBS) library, on the other hand, can create two DNA fragments from the same location that should not be considered duplicates. Currently, only one WGBS-aware duplicate marking tool exists. However, it only works with the output from a single tool, does not accept streaming input or output, and requires a substantial amount of memory relative to the input size.",
          "Main Action": "<NONE>",
          "Arguments": {
            "Agent": [
              "Currently"
            ],
            "Object": {
              "Primary Object": [
                "one WGBS-aware duplicate marking tool"
              ],
              "Secondary Object": [
                "output from a single tool",
                "streaming input or output",
                "a substantial amount of memory relative to the input size"
              ]
            },
            "Context": [
              "In whole genome sequencing data",
              "The process of preparing a whole genome bisulfite sequencing (WGBS) library"
            ],
            "Purpose": [
              "does not work with the output from a single tool",
              "does not accept streaming input or output",
              "requires a substantial amount of memory relative to the input size"
            ],
            "Method": [
              "<NONE>"
            ],
            "Results": [
              "<NONE>"
            ],
            "Analysis": [
              "<NONE>"
            ],
            "Challenge": [
              "<NONE>"
            ],
            "Ethical": [
              "<NONE>"
            ],
            "Implications": [
              "<NONE>"
            ],
            "Contradictions": [
              "<NONE>"
            ]
          }
        },
        {
          "Methods/Approach": "",
          "Text": "Dupsifter provides an aligner-agnostic duplicate marking tool that is lightweight, has streaming capabilities, and is memory efficient.",
          "Main Action": "<NONE>",
          "Arguments": {
            "Agent": [
              "Dupsifter"
            ],
            "Object": {
              "Primary Object": [
                "duplicate marking tool"
              ],
              "Secondary Object": [
                "aligner-agnostic",
                "lightweight",
                "streaming capabilities",
                "memory efficiency"
              ]
            },
            "Context": [
              "<NONE>"
            ],
            "Purpose": [
              "<NONE>"
            ],
            "Method": [
              "<NONE>"
            ],
            "Results": [
              "<NONE>"
            ],
            "Analysis": [
              "<NONE>"
            ],
            "Challenge": [
              "<NONE>"
            ],
            "Ethical": [
              "<NONE>"
            ],
            "Implications": [
              "<NONE>"
            ],
            "Contradictions": [
              "<NONE>"
            ]
          }
        }
      ]
    }
  ]
}