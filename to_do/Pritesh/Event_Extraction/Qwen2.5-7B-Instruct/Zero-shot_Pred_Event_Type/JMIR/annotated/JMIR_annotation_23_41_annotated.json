{
  "papers": [
    {
      "paper_code": "jmir_23_P_462",
      "abstract": "Digital misinformation, primarily on social media, has led to harmful and costly beliefs in the general population. Notably, these beliefs have resulted in public health crises to the detriment of governments worldwide and their citizens. However, public health officials need access to a comprehensive system capable of mining and analyzing large volumes of social media data in real time. This study aimed to design and develop a big data pipeline and ecosystem (UbiLab Misinformation Analysis System [U-MAS]) to identify and analyze false or misleading information disseminated via social media on a certain topic or set of related topics. U-MAS is a platform-independent ecosystem developed in Python that leverages the Twitter V2 application programming interface and the Elastic Stack. The U-MAS expert system has 5 major components: data extraction framework, latent Dirichlet allocation (LDA) topic model, sentiment analyzer, misinformation classification model, and Elastic Cloud deployment (indexing of data and visualizations). The data extraction framework queries the data through the Twitter V2 application programming interface, with queries identified by public health experts. The LDA topic model, sentiment analyzer, and misinformation classification model are independently trained using a small, expert-validated subset of the extracted data. These models are then incorporated into U-MAS to analyze and classify the remaining data. Finally, the analyzed data are loaded into an index in the Elastic Cloud deployment and can then be presented on dashboards with advanced visualizations and analytics pertinent to infodemiology and infoveillance analysis. U-MAS performed efficiently and accurately. Independent investigators have successfully used the system to extract significant insights into a fluoride-related health misinformation use case (2016 to 2021). The system is currently used for a vaccine hesitancy use case (2007 to 2022) and a heat wave–related illnesses use case (2011 to 2022). Each component in the system for the fluoride misinformation use case performed as expected. The data extraction framework handles large amounts of data within short periods. The LDA topic models achieved relatively high coherence values (0.54), and the predicted topics were accurate and befitting to the data. The sentiment analyzer performed at a correlation coefficient of 0.72 but could be improved in further iterations. The misinformation classifier attained a satisfactory correlation coefficient of 0.82 against expert-validated data. Moreover, the output dashboard and analytics hosted on the Elastic Cloud deployment are intuitive for researchers without a technical background and comprehensive in their visualization and analytics capabilities. In fact, the investigators of the fluoride misinformation use case have successfully used the system to extract interesting and important insights into public health, which have been published separately. The novel U-MAS pipeline has the potential to detect and analyze misleading information related to a particular topic or set of related topics.",
      "events": [
        {
          "Background/Introduction": "",
          "Text": "Digital misinformation, primarily on social media, has led to harmful and costly beliefs in the general population. Notably, these beliefs have resulted in public health crises to the detriment of governments worldwide and their citizens. However, public health officials need access to a comprehensive system capable of mining and analyzing large volumes of social media data in real time.",
          "Main Action": "<NONE>",
          "Arguments": {
            "Agent": [
              "public health officials"
            ],
            "Object": {
              "Primary Object": [
                "a comprehensive system capable of mining and analyzing large volumes of social media data in real time"
              ],
              "Secondary Object": [
                "<NONE>"
              ]
            },
            "Context": [
              "Digital misinformation, primarily on social media",
              "harmful and costly beliefs in the general population",
              "public health crises"
            ],
            "Purpose": [
              "need access to...in real time"
            ],
            "Method": [
              "<NONE>"
            ],
            "Results": [
              "<NONE>"
            ],
            "Analysis": [
              "<NONE>"
            ],
            "Challenge": [
              "<NONE>"
            ],
            "Ethical": [
              "<NONE>"
            ],
            "Implications": [
              "<NONE>"
            ],
            "Contradictions": [
              "<NONE>"
            ]
          }
        },
        {
          "Methods/Approach": "",
          "Text": "This study aimed to design and develop a big data pipeline and ecosystem (UbiLab Misinformation Analysis System [U-MAS]) to identify and analyze false or misleading information disseminated via social media on a certain topic or set of related topics. U-MAS is a platform-independent ecosystem developed in Python that leverages the Twitter V2 application programming interface and the Elastic Stack. The U-MAS expert system has 5 major components: data extraction framework, latent Dirichlet allocation (LDA) topic model, sentiment analyzer, misinformation classification model, and Elastic Cloud deployment (indexing of data and visualizations). The data extraction framework queries the data through the Twitter V2 application programming interface, with queries identified by public health experts. The LDA topic model, sentiment analyzer, and misinformation classification model are independently trained using a small, expert-validated subset of the extracted data. These models are then incorporated into U-MAS to analyze and classify the remaining data. Finally, the analyzed data are loaded into an index in the Elastic Cloud deployment and can then be presented on dashboards with advanced visualizations and analytics pertinent to infodemiology and infoveillance analysis.",
          "Main Action": "design and develop",
          "Arguments": {
            "Agent": [
              "a big data pipeline and ecosystem (UbiLab Misinformation Analysis System [U-MAS])"
            ],
            "Object": {
              "Primary Object": [
                "big data pipeline and ecosystem (UbiLab Misinformation Analysis System [U-MAS])"
              ],
              "Secondary Object": [
                "platform-independent ecosystem developed in Python",
                "Twitter V2 application programming interface",
                "Elastic Stack",
                "data extraction framework",
                "latent Dirichlet allocation (LDA) topic model",
                "sentiment analyzer",
                "misinformation classification model",
                "Elastic Cloud deployment"
              ]
            },
            "Context": [
              "identify and analyze false or misleading information disseminated via social media on a certain topic or set of related topics"
            ],
            "Purpose": [
              "to identify and analyze false or misleading information disseminated via social media on a certain topic or set of related topics"
            ],
            "Method": [
              "developed in Python",
              "leverages the Twitter V2 application programming interface and the Elastic Stack",
              "queries the data through the Twitter V2 application programming interface",
              "independently trained using a small, expert-validated subset of the extracted data",
              "incorporated into U-MAS to analyze and classify the remaining data",
              "loaded into an index in the Elastic Cloud deployment and can then be presented on dashboards with advanced visualizations and analytics pertinent to infodemiology and infoveillance analysis"
            ],
            "Results": [
              "<NONE>"
            ],
            "Analysis": [
              "<NONE>"
            ],
            "Challenge": [
              "small, expert-validated subset of the extracted data"
            ],
            "Ethical": [
              "<NONE>"
            ],
            "Implications": [
              "analyze and classify the remaining data",
              "presented on dashboards with advanced visualizations and analytics pertinent to infodemiology and infoveillance analysis"
            ],
            "Contradictions": [
              "<NONE>"
            ]
          }
        },
        {
          "Results/Findings": "",
          "Text": "U-MAS performed efficiently and accurately. Independent investigators have successfully used the system to extract significant insights into a fluoride-related health misinformation use case (2016 to 2021). The system is currently used for a vaccine hesitancy use case (2007 to 2022) and a heat wave–related illnesses use case (2011 to 2022). Each component in the system for the fluoride misinformation use case performed as expected. The data extraction framework handles large amounts of data within short periods. The LDA topic models achieved relatively high coherence values (0.54), and the predicted topics were accurate and befitting to the data. The sentiment analyzer performed at a correlation coefficient of 0.72 but could be improved in further iterations. The misinformation classifier attained a satisfactory correlation coefficient of 0.82 against expert-validated data. Moreover, the output dashboard and analytics hosted on the Elastic Cloud deployment are intuitive for researchers without a technical background and comprehensive in their visualization and analytics capabilities. In fact, the investigators of the fluoride misinformation use case have successfully used the system to extract interesting and important insights into public health, which have been published separately.",
          "Main Action": "<NONE>",
          "Arguments": {
            "Agent": [
              "Independent investigators",
              "The U-MAS system"
            ],
            "Object": {
              "Primary Object": [
                "system",
                "insights",
                "data",
                "LDA topic models",
                "sentiment analyzer",
                "misinformation classifier",
                "output dashboard and analytics"
              ],
              "Secondary Object": [
                "fluoride-related health misinformation use case",
                "vaccine hesitancy use case",
                "heat wave–related illnesses use case",
                "large amounts of data",
                "predicted topics",
                "correlation coefficients",
                "researchers without a technical background"
              ]
            },
            "Context": [
              "independent investigators",
              "2016 to 2021",
              "2007 to 2022",
              "2011 to 2022"
            ],
            "Purpose": [
              "extract significant insights",
              "handle large amounts of data within short periods",
              "achieve relatively high coherence values",
              "perform well-correlated predictions",
              "be intuitive for non-technical users",
              "provide comprehensive visualizations and analytics"
            ],
            "Method": [
              "used the system",
              "handled large amounts of data",
              "applied LDA topic models",
              "performed at a correlation coefficient",
              "attained a satisfactory correlation coefficient",
              "hosted on the Elastic Cloud deployment"
            ],
            "Results": [
              "efficiently and accurately",
              "significant insights",
              "high coherence values (0.54)",
              "accurate and befitting to the data",
              "satisfactory correlation coefficient of 0.82",
              "intuitive for researchers without a technical background",
              "comprehensive in their visualization and analytics capabilities"
            ],
            "Analysis": [
              "could be improved in further iterations"
            ],
            "Challenge": [
              "none mentioned"
            ],
            "Ethical": [
              "none mentioned"
            ],
            "Implications": [
              "interesting and important insights into public health"
            ],
            "Contradictions": [
              "none mentioned"
            ]
          }
        },
        {
          "Conclusions/Implications": "",
          "Text": "The novel U-MAS pipeline has the potential to detect and analyze misleading information related to a particular topic or set of related topics.",
          "Main Action": "<NONE>",
          "Arguments": {
            "Agent": [
              "U-MAS pipeline"
            ],
            "Object": {
              "Primary Object": [
                "detect and analyze misleading information"
              ],
              "Secondary Object": [
                "related to a particular topic or set of related topics"
              ]
            },
            "Context": [
              "novel"
            ],
            "Purpose": [
              "has the potential to..."
            ],
            "Method": [
              "<NONE>"
            ],
            "Results": [
              "<NONE>"
            ],
            "Analysis": [
              "<NONE>"
            ],
            "Challenge": [
              "<NONE>"
            ],
            "Ethical": [
              "<NONE>"
            ],
            "Implications": [
              "<NONE>"
            ],
            "Contradictions": [
              "<NONE>"
            ]
          }
        }
      ]
    },
    {
      "paper_code": "jmir_23_P_808",
      "abstract": "ChatGPT-4 is the latest release of a novel artificial intelligence (AI) chatbot able to answer freely formulated and complex questions. In the near future, ChatGPT could become the new standard for health care professionals and patients to access medical information. However, little is known about the quality of medical information provided by the AI. We aimed to assess the reliability of medical information provided by ChatGPT. Medical information provided by ChatGPT-4 on the 5 hepato-pancreatico-biliary (HPB) conditions with the highest global disease burden was measured with the Ensuring Quality Information for Patients (EQIP) tool. The EQIP tool is used to measure the quality of internet-available information and consists of 36 items that are divided into 3 subsections. In addition, 5 guideline recommendations per analyzed condition were rephrased as questions and input to ChatGPT, and agreement between the guidelines and the AI answer was measured by 2 authors independently. All queries were repeated 3 times to measure the internal consistency of ChatGPT. Five conditions were identified (gallstone disease, pancreatitis, liver cirrhosis, pancreatic cancer, and hepatocellular carcinoma). The median EQIP score across all conditions was 16 (IQR 14.5-18) for the total of 36 items. Divided by subsection, median scores for content, identification, and structure data were 10 (IQR 9.5-12.5), 1 (IQR 1-1), and 4 (IQR 4-5), respectively. Agreement between guideline recommendations and answers provided by ChatGPT was 60% (15/25). Interrater agreement as measured by the Fleiss κ was 0.78 (P<.001), indicating substantial agreement. Internal consistency of the answers provided by ChatGPT was 100%. ChatGPT provides medical information of comparable quality to available static internet information. Although currently of limited quality, large language models could become the future standard for patients and health care professionals to gather medical information.",
      "events": [
        {
          "Background/Introduction": "",
          "Text": "ChatGPT-4 is the latest release of a novel artificial intelligence (AI) chatbot able to answer freely formulated and complex questions. In the near future, ChatGPT could become the new standard for health care professionals and patients to access medical information. However, little is known about the quality of medical information provided by the AI.",
          "Main Action": "<NONE>",
          "Arguments": {
            "Agent": [
              "little is known"
            ],
            "Object": {
              "Primary Object": [
                "quality of medical information provided by the AI"
              ],
              "Secondary Object": [
                "<NONE>"
              ]
            },
            "Context": [
              "ChatGPT-4 is the latest release of a novel artificial intelligence (AI) chatbot",
              "In the near future, ChatGPT could become the new standard for health care professionals and patients to access medical information"
            ],
            "Purpose": [
              "<NONE>"
            ],
            "Method": [
              "<NONE>"
            ],
            "Results": [
              "<NONE>"
            ],
            "Analysis": [
              "<NONE>"
            ],
            "Challenge": [
              "<NONE>"
            ],
            "Ethical": [
              "<NONE>"
            ],
            "Implications": [
              "However, little is known about the quality of medical information provided by the AI."
            ],
            "Contradictions": [
              "<NONE>"
            ]
          }
        },
        {
          "Methods/Approach": "",
          "Text": "We aimed to assess the reliability of medical information provided by ChatGPT. Medical information provided by ChatGPT-4 on the 5 hepato-pancreatico-biliary (HPB) conditions with the highest global disease burden was measured with the Ensuring Quality Information for Patients (EQIP) tool. The EQIP tool is used to measure the quality of internet-available information and consists of 36 items that are divided into 3 subsections. In addition, 5 guideline recommendations per analyzed condition were rephrased as questions and input to ChatGPT, and agreement between the guidelines and the AI answer was measured by 2 authors independently. All queries were repeated 3 times to measure the internal consistency of ChatGPT.",
          "Main Action": "<NONE>",
          "Arguments": {
            "Agent": [
              "We"
            ],
            "Object": {
              "Primary Object": [
                "reliability",
                "medical information provided by ChatGPT"
              ],
              "Secondary Object": [
                "hepato-pancreatico-biliary (HPB) conditions with the highest global disease burden"
              ]
            },
            "Context": [
              "Ensuring Quality Information for Patients (EQIP) tool is used to measure the quality of internet-available information and consists of 36 items that are divided into 3 subsections.",
              "guideline recommendations per analyzed condition were rephrased as questions and input to ChatGPT, and agreement between the guidelines and the AI answer was measured by 2 authors independently."
            ],
            "Purpose": [
              "aimed to assess"
            ],
            "Method": [
              "measured with the Ensuring Quality Information for Patients (EQIP) tool",
              "input to ChatGPT, and agreement between the guidelines and the AI answer was measured by 2 authors independently."
            ],
            "Results": [
              "agreement between the guidelines and the AI answer was measured by 2 authors independently.",
              "All queries were repeated 3 times to measure the internal consistency of ChatGPT."
            ],
            "Analysis": [
              "<NONE>"
            ],
            "Challenge": [
              "<NONE>"
            ],
            "Ethical": [
              "<NONE>"
            ],
            "Implications": [
              "<NONE>"
            ],
            "Contradictions": [
              "<NONE>"
            ]
          }
        },
        {
          "Results/Findings": "",
          "Text": "Five conditions were identified (gallstone disease, pancreatitis, liver cirrhosis, pancreatic cancer, and hepatocellular carcinoma). The median EQIP score across all conditions was 16 (IQR 14.5-18) for the total of 36 items. Divided by subsection, median scores for content, identification, and structure data were 10 (IQR 9.5-12.5), 1 (IQR 1-1), and 4 (IQR 4-5), respectively. Agreement between guideline recommendations and answers provided by ChatGPT was 60% (15/25). Interrater agreement as measured by the Fleiss κ was 0.78 (P<.001), indicating substantial agreement. Internal consistency of the answers provided by ChatGPT was 100%.",
          "Main Action": "<NONE>",
          "Arguments": {
            "Agent": [
              "ChatGPT"
            ],
            "Object": {
              "Primary Object": [
                "answers provided by ChatGPT"
              ],
              "Secondary Object": [
                "guideline recommendations"
              ]
            },
            "Context": [
              "median EQIP score",
              "content, identification, and structure data"
            ],
            "Purpose": [
              "<NONE>"
            ],
            "Method": [
              "Fleiss κ"
            ],
            "Results": [
              "Agreement between guideline recommendations and answers provided by ChatGPT was 60%",
              "Interrater agreement as measured by the Fleiss κ was 0.78 (P<.001)",
              "Internal consistency of the answers provided by ChatGPT was 100%"
            ],
            "Analysis": [
              "<NONE>"
            ],
            "Challenge": [
              "<NONE>"
            ],
            "Ethical": [
              "<NONE>"
            ],
            "Implications": [
              "<NONE>"
            ],
            "Contradictions": [
              "<NONE>"
            ]
          }
        },
        {
          "Conclusions/Implications": "",
          "Text": "ChatGPT provides medical information of comparable quality to available static internet information. Although currently of limited quality, large language models could become the future standard for patients and health care professionals to gather medical information.",
          "Main Action": "<NONE>",
          "Arguments": {
            "Agent": [
              "ChatGPT"
            ],
            "Object": {
              "Primary Object": [
                "medical information"
              ],
              "Secondary Object": [
                "static internet information"
              ]
            },
            "Context": [
              "of comparable quality to available static internet information",
              "currently of limited quality",
              "future standard for patients and health care professionals to gather medical information"
            ],
            "Purpose": [
              "to provide medical information"
            ],
            "Method": [
              "provides"
            ],
            "Results": [
              "of comparable quality to available static internet information"
            ],
            "Analysis": [
              "Although currently of limited quality, large language models could become the future standard for patients and health care professionals to gather medical information."
            ],
            "Challenge": [
              "currently of limited quality"
            ],
            "Ethical": [
              "<NONE>"
            ],
            "Implications": [
              "could become the future standard for patients and health care professionals to gather medical information"
            ],
            "Contradictions": [
              "<NONE>"
            ]
          }
        }
      ]
    }
  ]
}