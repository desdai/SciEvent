{"doc_id": "cscw_23_P_159", "sent_id": "cscw_23_P_159-1", "entity_mentions": [{"id": "cscw_23_P_159-1-E0", "text": "we", "start": 13, "end": 14, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "cscw_23_P_159-1-E1", "text": "at a small manufacturer located in the Southeastern United States", "start": 28, "end": 38, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "cscw_23_P_159-1-E2", "text": "To understand how these kinds of technologies are affecting the nature of work", "start": 0, "end": 13, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "cscw_23_P_159-1-E3", "text": "a 15-month qualitative study", "start": 15, "end": 19, "entity_type": "UNK", "mention_type": "UNK"}], "relation_mentions": [], "event_mentions": [{"event_type": "Methods/Approach", "id": "cscw_23_P_159-1-EV0", "trigger": {"text": "conducted", "start": 14, "end": 15}, "arguments": [{"entity_id": "cscw_23_P_159-1-E0", "text": "we", "role": "Agent"}, {"entity_id": "cscw_23_P_159-1-E1", "text": "at a small manufacturer located in the Southeastern United States", "role": "Context"}, {"entity_id": "cscw_23_P_159-1-E2", "text": "To understand how these kinds of technologies are affecting the nature of work", "role": "Purpose"}, {"entity_id": "cscw_23_P_159-1-E3", "text": "a 15-month qualitative study", "role": "PrimaryObject"}]}], "entity_coreference": [], "event_coreference": [], "tokens": ["To", "understand", "how", "these", "kinds", "of", "technologies", "are", "affecting", "the", "nature", "of", "work,", "we", "conducted", "a", "15-month", "qualitative", "study", "of", "the", "digitalization", "of", "the", "shipping", "and", "receiving", "department", "at", "a", "small", "manufacturer", "located", "in", "the", "Southeastern", "United", "States."], "pieces": ["To", "under", "stand", "how", "these", "kind", "s", "of", "techn", "ologies", "are", "aff", "ect", "ing", "the", "nature", "of", "work", ",", "we", "conduct", "ed", "a", "15", "-", "month", "qual", "itative", "study", "of", "the", "digital", "ization", "of", "the", "sh", "ipping", "and", "re", "ce", "iving", "dep", "artment", "at", "a", "small", "manufact", "urer", "l", "ocated", "in", "the", "S", "outheastern", "United", "States", "."], "token_lens": [1, 2, 1, 1, 2, 1, 2, 1, 3, 1, 1, 1, 2, 1, 2, 1, 3, 2, 1, 1, 1, 2, 1, 1, 2, 1, 3, 2, 1, 1, 1, 2, 2, 1, 1, 2, 1, 2], "sentence": "To understand how these kinds of technologies are affecting the nature of work, we conducted a 15-month qualitative study of the digitalization of the shipping and receiving department at a small manufacturer located in the Southeastern United States.", "sentence_starts": [0]}
{"doc_id": "cscw_23_P_243", "sent_id": "cscw_23_P_243-2", "entity_mentions": [{"id": "cscw_23_P_243-2-E0", "text": "We", "start": 0, "end": 1, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "cscw_23_P_243-2-E1", "text": "the visibility of followed topics, lists, and interactions with protected accounts is confusing", "start": 18, "end": 31, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "cscw_23_P_243-2-E2", "text": "Only 31% of the participants were aware that a reply by a public account to a protected account's tweet would be publicly visible", "start": 31, "end": 54, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "cscw_23_P_243-2-E3", "text": "having a protected account does not result in a better understanding of the account information or tweet visibility", "start": 55, "end": 73, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "cscw_23_P_243-2-E4", "text": "our participants are aware of the visibility of their profile information and individual tweets", "start": 3, "end": 17, "entity_type": "UNK", "mention_type": "UNK"}], "relation_mentions": [], "event_mentions": [{"event_type": "Results/Findings", "id": "cscw_23_P_243-2-EV0", "trigger": {"text": "find", "start": 1, "end": 2}, "arguments": [{"entity_id": "cscw_23_P_243-2-E0", "text": "We", "role": "Agent"}, {"entity_id": "cscw_23_P_243-2-E1", "text": "the visibility of followed topics, lists, and interactions with protected accounts is confusing", "role": "Results"}, {"entity_id": "cscw_23_P_243-2-E2", "text": "Only 31% of the participants were aware that a reply by a public account to a protected account's tweet would be publicly visible", "role": "Results"}, {"entity_id": "cscw_23_P_243-2-E3", "text": "having a protected account does not result in a better understanding of the account information or tweet visibility", "role": "Results"}, {"entity_id": "cscw_23_P_243-2-E4", "text": "our participants are aware of the visibility of their profile information and individual tweets", "role": "PrimaryObject"}]}], "entity_coreference": [], "event_coreference": [], "tokens": ["We", "find", "that", "our", "participants", "are", "aware", "of", "the", "visibility", "of", "their", "profile", "information", "and", "individual", "tweets.", "However,", "the", "visibility", "of", "followed", "topics,", "lists,", "and", "interactions", "with", "protected", "accounts", "is", "confusing.", "Only", "31%", "of", "the", "participants", "were", "aware", "that", "a", "reply", "by", "a", "public", "account", "to", "a", "protected", "account's", "tweet", "would", "be", "publicly", "visible.", "Surprisingly,", "having", "a", "protected", "account", "does", "not", "result", "in", "a", "better", "understanding", "of", "the", "account", "information", "or", "tweet", "visibility."], "pieces": ["We", "find", "that", "our", "particip", "ants", "are", "aware", "of", "the", "vis", "ibility", "of", "their", "profile", "information", "and", "individual", "t", "we", "ets", ".", "However", ",", "the", "vis", "ibility", "of", "follow", "ed", "top", "ics", ",", "lists", ",", "and", "inter", "actions", "with", "protected", "account", "s", "is", "conf", "using", ".", "Only", "31", "%", "of", "the", "particip", "ants", "were", "aware", "that", "a", "reply", "by", "a", "public", "account", "to", "a", "protected", "account", "'s", "t", "weet", "would", "be", "public", "ly", "visible", ".", "Sur", "prisingly", ",", "having", "a", "protected", "account", "does", "not", "result", "in", "a", "better", "under", "standing", "of", "the", "account", "information", "or", "t", "weet", "vis", "ibility", "."], "token_lens": [1, 1, 1, 1, 2, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 4, 2, 1, 2, 1, 2, 3, 2, 1, 2, 1, 1, 2, 1, 3, 1, 2, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 1, 1, 2, 2, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 2, 3], "sentence": "We find that our participants are aware of the visibility of their profile information and individual tweets. However, the visibility of followed topics, lists, and interactions with protected accounts is confusing. Only 31% of the participants were aware that a reply by a public account to a protected account's tweet would be publicly visible. Surprisingly, having a protected account does not result in a better understanding of the account information or tweet visibility.", "sentence_starts": [0]}
{"doc_id": "ACL_23_P_668", "sent_id": "ACL_23_P_668-2", "entity_mentions": [{"id": "ACL_23_P_668-2-E0", "text": "We", "start": 0, "end": 1, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_668-2-E1", "text": "The feature-augmented DA method achieves a 22% increase in accuracy adapting from a conversational to task-specific dataset compared to a jointly trained baseline", "start": 13, "end": 36, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_668-2-E2", "text": "adapted models exhibit better performance across conversational and task-oriented datasets.", "start": 3, "end": 13, "entity_type": "UNK", "mention_type": "UNK"}], "relation_mentions": [], "event_mentions": [{"event_type": "Results/Findings", "id": "ACL_23_P_668-2-EV0", "trigger": {"text": "find", "start": 1, "end": 2}, "arguments": [{"entity_id": "ACL_23_P_668-2-E0", "text": "We", "role": "Agent"}, {"entity_id": "ACL_23_P_668-2-E1", "text": "The feature-augmented DA method achieves a 22% increase in accuracy adapting from a conversational to task-specific dataset compared to a jointly trained baseline", "role": "Results"}, {"entity_id": "ACL_23_P_668-2-E2", "text": "adapted models exhibit better performance across conversational and task-oriented datasets.", "role": "PrimaryObject"}]}], "entity_coreference": [], "event_coreference": [], "tokens": ["We", "find", "that", "adapted", "models", "exhibit", "better", "performance", "across", "conversational", "and", "task-oriented", "datasets.", "The", "feature-augmented", "DA", "method", "achieves", "a", "22%", "increase", "in", "accuracy", "adapting", "from", "a", "conversational", "to", "task-specific", "dataset", "compared", "to", "a", "jointly", "trained", "baseline."], "pieces": ["We", "find", "that", "adapt", "ed", "models", "ex", "hibit", "better", "performance", "ac", "ross", "con", "vers", "ational", "and", "task", "-", "oriented", "dat", "as", "ets", ".", "The", "feature", "-", "au", "gment", "ed", "DA", "method", "ach", "ieves", "a", "22", "%", "incre", "ase", "in", "acc", "uracy", "adapt", "ing", "from", "a", "con", "vers", "ational", "to", "task", "-", "specific", "dat", "as", "et", "comp", "ared", "to", "a", "j", "oint", "ly", "trained", "bas", "eline", "."], "token_lens": [1, 1, 1, 2, 1, 2, 1, 1, 2, 3, 1, 3, 4, 1, 5, 1, 1, 2, 1, 2, 2, 1, 2, 2, 1, 1, 3, 1, 3, 3, 2, 1, 1, 3, 1, 3], "sentence": "We find that adapted models exhibit better performance across conversational and task-oriented datasets. The feature-augmented DA method achieves a 22% increase in accuracy adapting from a conversational to task-specific dataset compared to a jointly trained baseline.", "sentence_starts": [0]}
{"doc_id": "bioinfo_23_P_277", "sent_id": "bioinfo_23_P_277-2", "entity_mentions": [{"id": "bioinfo_23_P_277-2-E0", "text": "Our evaluation", "start": 0, "end": 2, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "bioinfo_23_P_277-2-E1", "text": "when performing sequence alignment for a variety of algorithms, read lengths, and edit distance thresholds", "start": 18, "end": 33, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "bioinfo_23_P_277-2-E2", "text": "a real PIM system can substantially outperform server-grade multi-threaded CPU systems running at full-scale", "start": 4, "end": 18, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "bioinfo_23_P_277-2-E3", "text": "a real PIM system can substantially outperform server-grade multi-threaded CPU systems running at full-scale", "start": 4, "end": 18, "entity_type": "UNK", "mention_type": "UNK"}], "relation_mentions": [], "event_mentions": [{"event_type": "Results/Findings", "id": "bioinfo_23_P_277-2-EV0", "trigger": {"text": "shows", "start": 2, "end": 3}, "arguments": [{"entity_id": "bioinfo_23_P_277-2-E0", "text": "Our evaluation", "role": "Agent"}, {"entity_id": "bioinfo_23_P_277-2-E1", "text": "when performing sequence alignment for a variety of algorithms, read lengths, and edit distance thresholds", "role": "Context"}, {"entity_id": "bioinfo_23_P_277-2-E2", "text": "a real PIM system can substantially outperform server-grade multi-threaded CPU systems running at full-scale", "role": "Results"}, {"entity_id": "bioinfo_23_P_277-2-E3", "text": "a real PIM system can substantially outperform server-grade multi-threaded CPU systems running at full-scale", "role": "PrimaryObject"}]}], "entity_coreference": [], "event_coreference": [], "tokens": ["Our", "evaluation", "shows", "that", "a", "real", "PIM", "system", "can", "substantially", "outperform", "server-grade", "multi-threaded", "CPU", "systems", "running", "at", "full-scale", "when", "performing", "sequence", "alignment", "for", "a", "variety", "of", "algorithms,", "read", "lengths,", "and", "edit", "distance", "thresholds."], "pieces": ["Our", "eval", "uation", "shows", "that", "a", "real", "P", "IM", "system", "can", "sub", "stant", "ially", "out", "per", "form", "server", "-", "grade", "multi", "-", "thread", "ed", "CPU", "system", "s", "running", "at", "full", "-", "scale", "when", "performing", "sequence", "al", "ignment", "for", "a", "var", "iety", "of", "al", "gorith", "ms", ",", "read", "length", "s", ",", "and", "edit", "distance", "th", "reshold", "s", "."], "token_lens": [1, 2, 1, 1, 1, 1, 2, 1, 1, 3, 3, 3, 4, 1, 2, 1, 1, 3, 1, 1, 1, 2, 1, 1, 2, 1, 4, 1, 3, 1, 1, 1, 4], "sentence": "Our evaluation shows that a real PIM system can substantially outperform server-grade multi-threaded CPU systems running at full-scale when performing sequence alignment for a variety of algorithms, read lengths, and edit distance thresholds.", "sentence_starts": [0]}
{"doc_id": "cscw_23_P_166", "sent_id": "cscw_23_P_166-3", "entity_mentions": [{"id": "cscw_23_P_166-3-E0", "text": "These insights", "start": 0, "end": 2, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "cscw_23_P_166-3-E1", "text": "to aid depressed older adults' recovery and engagement with social network members", "start": 12, "end": 24, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "cscw_23_P_166-3-E2", "text": "the consideration", "start": 5, "end": 7, "entity_type": "UNK", "mention_type": "UNK"}], "relation_mentions": [], "event_mentions": [{"event_type": "Conclusions/Implications", "id": "cscw_23_P_166-3-EV0", "trigger": {"text": "have implications for", "start": 2, "end": 5}, "arguments": [{"entity_id": "cscw_23_P_166-3-E0", "text": "These insights", "role": "Agent"}, {"entity_id": "cscw_23_P_166-3-E1", "text": "to aid depressed older adults' recovery and engagement with social network members", "role": "Purpose"}, {"entity_id": "cscw_23_P_166-3-E2", "text": "the consideration", "role": "PrimaryObject"}]}], "entity_coreference": [], "event_coreference": [], "tokens": ["These", "insights", "have", "implications", "for", "the", "consideration", "of", "information", "and", "communication", "systems", "to", "aid", "depressed", "older", "adults'", "recovery", "and", "engagement", "with", "social", "network", "members."], "pieces": ["These", "ins", "ights", "have", "impl", "ications", "for", "the", "consider", "ation", "of", "information", "and", "communication", "system", "s", "to", "aid", "dep", "ressed", "older", "ad", "ults", "'", "re", "co", "very", "and", "eng", "agement", "with", "social", "network", "members", "."], "token_lens": [1, 2, 1, 2, 1, 1, 2, 1, 1, 1, 1, 2, 1, 1, 2, 1, 3, 3, 1, 2, 1, 1, 1, 2], "sentence": "These insights have implications for the consideration of information and communication systems to aid depressed older adults' recovery and engagement with social network members.", "sentence_starts": [0]}
{"doc_id": "cscw_23_P_149", "sent_id": "cscw_23_P_149-0", "entity_mentions": [{"id": "cscw_23_P_149-0-E0", "text": "we", "start": 28, "end": 29, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "cscw_23_P_149-0-E1", "text": "Legal crowdfunding is an emerging domain where lawyers and individuals raise funds to fight legal actions", "start": 0, "end": 16, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "cscw_23_P_149-0-E2", "text": "To study how prospective donors can verify the credibility of legal campaigns", "start": 16, "end": 28, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "cscw_23_P_149-0-E3", "text": "the conversations", "start": 30, "end": 32, "entity_type": "UNK", "mention_type": "UNK"}], "relation_mentions": [], "event_mentions": [{"event_type": "Background/Introduction", "id": "cscw_23_P_149-0-EV0", "trigger": {"text": "analyzed", "start": 29, "end": 30}, "arguments": [{"entity_id": "cscw_23_P_149-0-E0", "text": "we", "role": "Agent"}, {"entity_id": "cscw_23_P_149-0-E1", "text": "Legal crowdfunding is an emerging domain where lawyers and individuals raise funds to fight legal actions", "role": "Context"}, {"entity_id": "cscw_23_P_149-0-E2", "text": "To study how prospective donors can verify the credibility of legal campaigns", "role": "Purpose"}, {"entity_id": "cscw_23_P_149-0-E3", "text": "the conversations", "role": "PrimaryObject"}]}], "entity_coreference": [], "event_coreference": [], "tokens": ["Legal", "crowdfunding", "is", "an", "emerging", "domain", "where", "lawyers", "and", "individuals", "raise", "funds", "to", "fight", "legal", "actions.", "To", "study", "how", "prospective", "donors", "can", "verify", "the", "credibility", "of", "legal", "campaigns,", "we", "analyzed", "the", "conversations", "surrounding", "these", "campaigns", "on", "Facebook."], "pieces": ["Legal", "c", "rowd", "funding", "is", "an", "emer", "ging", "domain", "where", "law", "yers", "and", "individual", "s", "raise", "fund", "s", "to", "fight", "legal", "actions", ".", "To", "study", "how", "pro", "spective", "don", "ors", "can", "ver", "ify", "the", "c", "red", "ibility", "of", "legal", "campaign", "s", ",", "we", "analy", "zed", "the", "con", "vers", "ations", "sur", "round", "ing", "these", "campaign", "s", "on", "Facebook", "."], "token_lens": [1, 3, 1, 1, 2, 1, 1, 2, 1, 2, 1, 2, 1, 1, 1, 2, 1, 1, 1, 2, 2, 1, 2, 1, 3, 1, 1, 3, 1, 2, 1, 3, 3, 1, 2, 1, 2], "sentence": "Legal crowdfunding is an emerging domain where lawyers and individuals raise funds to fight legal actions. To study how prospective donors can verify the credibility of legal campaigns, we analyzed the conversations surrounding these campaigns on Facebook.", "sentence_starts": [0]}
{"doc_id": "ACL_23_P_532", "sent_id": "ACL_23_P_532-2", "entity_mentions": [{"id": "ACL_23_P_532-2-E0", "text": "we", "start": 2, "end": 3, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_532-2-E1", "text": "it is data-efficient in low-resource scenarios and robust enough to defend against adversarial attacks.", "start": 24, "end": 38, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_532-2-E2", "text": "our approach outperforms previous methods by a significant margin on two standard benchmarks (over 6 points in F1)", "start": 5, "end": 23, "entity_type": "UNK", "mention_type": "UNK"}], "relation_mentions": [], "event_mentions": [{"event_type": "Results/Findings", "id": "ACL_23_P_532-2-EV0", "trigger": {"text": "show", "start": 3, "end": 4}, "arguments": [{"entity_id": "ACL_23_P_532-2-E0", "text": "we", "role": "Agent"}, {"entity_id": "ACL_23_P_532-2-E1", "text": "it is data-efficient in low-resource scenarios and robust enough to defend against adversarial attacks.", "role": "Results"}, {"entity_id": "ACL_23_P_532-2-E2", "text": "our approach outperforms previous methods by a significant margin on two standard benchmarks (over 6 points in F1)", "role": "PrimaryObject"}]}], "entity_coreference": [], "event_coreference": [], "tokens": ["In", "experiments,", "we", "show", "that", "our", "approach", "outperforms", "previous", "methods", "by", "a", "significant", "margin", "on", "two", "standard", "benchmarks", "(over", "6", "points", "in", "F1).", "Moreover,", "it", "is", "data-efficient", "in", "low-resource", "scenarios", "and", "robust", "enough", "to", "defend", "against", "adversarial", "attacks."], "pieces": ["In", "exper", "iments", ",", "we", "show", "that", "our", "appro", "ach", "out", "per", "forms", "pre", "vious", "method", "s", "by", "a", "significant", "margin", "on", "two", "standard", "bench", "marks", "(", "over", "6", "points", "in", "F", "1", ").", "Moreover", ",", "it", "is", "data", "-", "efficient", "in", "low", "-", "resource", "sc", "en", "arios", "and", "rob", "ust", "enough", "to", "def", "end", "against", "ad", "vers", "arial", "attacks", "."], "token_lens": [1, 3, 1, 1, 1, 1, 2, 3, 2, 2, 1, 1, 1, 1, 1, 1, 1, 2, 2, 1, 1, 1, 3, 2, 1, 1, 3, 1, 3, 3, 1, 2, 1, 1, 2, 1, 3, 2], "sentence": "In experiments, we show that our approach outperforms previous methods by a significant margin on two standard benchmarks (over 6 points in F1). Moreover, it is data-efficient in low-resource scenarios and robust enough to defend against adversarial attacks.", "sentence_starts": [0]}
{"doc_id": "bioinfo_23_P_159", "sent_id": "bioinfo_23_P_159-2", "entity_mentions": [{"id": "bioinfo_23_P_159-2-E0", "text": "we", "start": 66, "end": 67, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "bioinfo_23_P_159-2-E1", "text": "As proof of concept,", "start": 62, "end": 66, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "bioinfo_23_P_159-2-E2", "text": "The designed α-helical structures can bind specific targets or activate cellular receptors", "start": 0, "end": 12, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "bioinfo_23_P_159-2-E3", "text": "There is a significant agreement between the helix structures generated with HelixGAN and PEP-FOLD, a well-known de novo approach for predicting peptide structures from amino acid sequences", "start": 12, "end": 39, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "bioinfo_23_P_159-2-E4", "text": "HelixGAN outperformed RosettaDesign, and our previously developed structural similarity method to generate D-peptides matching a set of given hotspots in a known L-peptide", "start": 39, "end": 62, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "bioinfo_23_P_159-2-E5", "text": "MD simulations revealed a stable binding mode of the D-GLP1_1 analog coupled to the GLP1 receptor", "start": 83, "end": 99, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "bioinfo_23_P_159-2-E6", "text": "This novel D-peptide analog is more stable than our previous D-GLP1 design along the MD simulations", "start": 99, "end": 115, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "bioinfo_23_P_159-2-E7", "text": "a novel D-GLP1_1 analog", "start": 68, "end": 72, "entity_type": "UNK", "mention_type": "UNK"}], "relation_mentions": [], "event_mentions": [{"event_type": "Results/Findings", "id": "bioinfo_23_P_159-2-EV0", "trigger": {"text": "designed", "start": 1, "end": 2}, "arguments": [{"entity_id": "bioinfo_23_P_159-2-E0", "text": "we", "role": "Agent"}, {"entity_id": "bioinfo_23_P_159-2-E1", "text": "As proof of concept,", "role": "Context"}, {"entity_id": "bioinfo_23_P_159-2-E2", "text": "The designed α-helical structures can bind specific targets or activate cellular receptors", "role": "Results"}, {"entity_id": "bioinfo_23_P_159-2-E3", "text": "There is a significant agreement between the helix structures generated with HelixGAN and PEP-FOLD, a well-known de novo approach for predicting peptide structures from amino acid sequences", "role": "Results"}, {"entity_id": "bioinfo_23_P_159-2-E4", "text": "HelixGAN outperformed RosettaDesign, and our previously developed structural similarity method to generate D-peptides matching a set of given hotspots in a known L-peptide", "role": "Results"}, {"entity_id": "bioinfo_23_P_159-2-E5", "text": "MD simulations revealed a stable binding mode of the D-GLP1_1 analog coupled to the GLP1 receptor", "role": "Results"}, {"entity_id": "bioinfo_23_P_159-2-E6", "text": "This novel D-peptide analog is more stable than our previous D-GLP1 design along the MD simulations", "role": "Results"}, {"entity_id": "bioinfo_23_P_159-2-E7", "text": "a novel D-GLP1_1 analog", "role": "PrimaryObject"}]}], "entity_coreference": [], "event_coreference": [], "tokens": ["The", "designed", "α-helical", "structures", "can", "bind", "specific", "targets", "or", "activate", "cellular", "receptors.", "There", "is", "a", "significant", "agreement", "between", "the", "helix", "structures", "generated", "with", "HelixGAN", "and", "PEP-FOLD,", "a", "well-known", "de", "novo", "approach", "for", "predicting", "peptide", "structures", "from", "amino", "acid", "sequences.", "HelixGAN", "outperformed", "RosettaDesign,", "and", "our", "previously", "developed", "structural", "similarity", "method", "to", "generate", "D-peptides", "matching", "a", "set", "of", "given", "hotspots", "in", "a", "known", "L-peptide.", "As", "proof", "of", "concept,", "we", "designed", "a", "novel", "D-GLP1_1", "analog", "that", "matches", "the", "conformations", "of", "critical", "hotspots", "for", "the", "GLP1", "function.", "MD", "simulations", "revealed", "a", "stable", "binding", "mode", "of", "the", "D-GLP1_1", "analog", "coupled", "to", "the", "GLP1", "receptor.", "This", "novel", "D-peptide", "analog", "is", "more", "stable", "than", "our", "previous", "D-GLP1", "design", "along", "the", "MD", "simulations."], "pieces": ["The", "designed", "Î±", "-", "hel", "ical", "struct", "ures", "can", "bind", "specific", "t", "arg", "ets", "or", "activate", "cell", "ular", "re", "cept", "ors", ".", "There", "is", "a", "significant", "ag", "reement", "between", "the", "hel", "ix", "struct", "ures", "generated", "with", "Hel", "ix", "GAN", "and", "P", "EP", "-", "F", "OLD", ",", "a", "well", "-", "known", "de", "n", "ovo", "appro", "ach", "for", "p", "redict", "ing", "pe", "pt", "ide", "struct", "ures", "from", "am", "ino", "acid", "sequ", "ences", ".", "Hel", "ix", "GAN", "out", "per", "formed", "Ros", "etta", "Design", ",", "and", "our", "pre", "viously", "developed", "struct", "ural", "similar", "ity", "method", "to", "gener", "ate", "D", "-", "pe", "pt", "ides", "match", "ing", "a", "set", "of", "given", "hots", "pots", "in", "a", "known", "L", "-", "pe", "pt", "ide", ".", "As", "proof", "of", "concept", ",", "we", "designed", "a", "no", "vel", "D", "-", "GL", "P", "1", "_", "1", "an", "alog", "that", "mat", "ches", "the", "con", "form", "ations", "of", "critical", "hots", "pots", "for", "the", "GL", "P", "1", "function", ".", "MD", "sim", "ulations", "reve", "aled", "a", "stable", "binding", "mode", "of", "the", "D", "-", "GL", "P", "1", "_", "1", "an", "alog", "c", "ou", "pled", "to", "the", "GL", "P", "1", "re", "ceptor", ".", "This", "no", "vel", "D", "-", "pe", "pt", "ide", "an", "alog", "is", "more", "stable", "than", "our", "pre", "vious", "D", "-", "GL", "P", "1", "design", "along", "the", "MD", "sim", "ulations", "."], "token_lens": [1, 1, 4, 2, 1, 1, 1, 3, 1, 1, 2, 4, 1, 1, 1, 1, 2, 1, 1, 2, 2, 1, 1, 3, 1, 6, 1, 3, 1, 2, 2, 1, 3, 3, 2, 1, 2, 1, 3, 3, 3, 4, 1, 1, 2, 1, 2, 2, 1, 1, 2, 5, 2, 1, 1, 1, 1, 2, 1, 1, 1, 6, 1, 1, 1, 2, 1, 1, 1, 2, 7, 2, 1, 2, 1, 3, 1, 1, 2, 1, 1, 3, 2, 1, 2, 2, 1, 1, 1, 1, 1, 1, 7, 2, 3, 1, 1, 3, 3, 1, 2, 5, 2, 1, 1, 1, 1, 1, 2, 5, 1, 1, 1, 1, 3], "sentence": "The designed α-helical structures can bind specific targets or activate cellular receptors. There is a significant agreement between the helix structures generated with HelixGAN and PEP-FOLD, a well-known de novo approach for predicting peptide structures from amino acid sequences. HelixGAN outperformed RosettaDesign, and our previously developed structural similarity method to generate D-peptides matching a set of given hotspots in a known L-peptide. As proof of concept, we designed a novel D-GLP1_1 analog that matches the conformations of critical hotspots for the GLP1 function. MD simulations revealed a stable binding mode of the D-GLP1_1 analog coupled to the GLP1 receptor. This novel D-peptide analog is more stable than our previous D-GLP1 design along the MD simulations.", "sentence_starts": [0]}
{"doc_id": "cscw_23_P_105", "sent_id": "cscw_23_P_105-3", "entity_mentions": [{"id": "cscw_23_P_105-3-E0", "text": "our data", "start": 1, "end": 3, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "cscw_23_P_105-3-E1", "text": "peer matching in health storytelling is potentially beneficial for racially minoritized groups", "start": 5, "end": 17, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "cscw_23_P_105-3-E2", "text": "having diverse representations in health technology is required for promoting health equity", "start": 19, "end": 31, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "cscw_23_P_105-3-E3", "text": "peer matching in health storytelling is potentially beneficial for racially minoritized groups", "start": 5, "end": 17, "entity_type": "UNK", "mention_type": "UNK"}], "relation_mentions": [], "event_mentions": [{"event_type": "Conclusions/Implications", "id": "cscw_23_P_105-3-EV0", "trigger": {"text": "suggest", "start": 3, "end": 4}, "arguments": [{"entity_id": "cscw_23_P_105-3-E0", "text": "our data", "role": "Agent"}, {"entity_id": "cscw_23_P_105-3-E1", "text": "peer matching in health storytelling is potentially beneficial for racially minoritized groups", "role": "Results"}, {"entity_id": "cscw_23_P_105-3-E2", "text": "having diverse representations in health technology is required for promoting health equity", "role": "Implications"}, {"entity_id": "cscw_23_P_105-3-E3", "text": "peer matching in health storytelling is potentially beneficial for racially minoritized groups", "role": "PrimaryObject"}]}], "entity_coreference": [], "event_coreference": [], "tokens": ["Collectively,", "our", "data", "suggest", "that", "peer", "matching", "in", "health", "storytelling", "is", "potentially", "beneficial", "for", "racially", "minoritized", "groups;", "and", "that", "having", "diverse", "representations", "in", "health", "technology", "is", "required", "for", "promoting", "health", "equity."], "pieces": ["Collect", "ively", ",", "our", "data", "suggest", "that", "peer", "match", "ing", "in", "health", "story", "telling", "is", "pot", "entially", "benef", "icial", "for", "rac", "ially", "min", "or", "itized", "groups", ";", "and", "that", "having", "d", "iverse", "represent", "ations", "in", "health", "technology", "is", "required", "for", "prom", "oting", "health", "equ", "ity", "."], "token_lens": [3, 1, 1, 1, 1, 1, 2, 1, 1, 2, 1, 2, 2, 1, 2, 3, 2, 1, 1, 1, 2, 2, 1, 1, 1, 1, 1, 1, 2, 1, 3], "sentence": "Collectively, our data suggest that peer matching in health storytelling is potentially beneficial for racially minoritized groups; and that having diverse representations in health technology is required for promoting health equity.", "sentence_starts": [0]}
{"doc_id": "ACL_23_P_163", "sent_id": "ACL_23_P_163-2", "entity_mentions": [{"id": "ACL_23_P_163-2-E0", "text": "we", "start": 6, "end": 7, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_163-2-E1", "text": "To exemplify our theory in practice", "start": 0, "end": 6, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_163-2-E2", "text": "Our theory accurately predicts relative performance of multiple algorithms in generating equitable text as measured by both human and automated evaluation", "start": 27, "end": 48, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_163-2-E3", "text": "a group of algorithms", "start": 9, "end": 13, "entity_type": "UNK", "mention_type": "UNK"}], "relation_mentions": [], "event_mentions": [{"event_type": "Results/Findings", "id": "ACL_23_P_163-2-EV0", "trigger": {"text": "look at", "start": 7, "end": 9}, "arguments": [{"entity_id": "ACL_23_P_163-2-E0", "text": "we", "role": "Agent"}, {"entity_id": "ACL_23_P_163-2-E1", "text": "To exemplify our theory in practice", "role": "Context"}, {"entity_id": "ACL_23_P_163-2-E2", "text": "Our theory accurately predicts relative performance of multiple algorithms in generating equitable text as measured by both human and automated evaluation", "role": "Results"}, {"entity_id": "ACL_23_P_163-2-E3", "text": "a group of algorithms", "role": "PrimaryObject"}]}], "entity_coreference": [], "event_coreference": [], "tokens": ["To", "exemplify", "our", "theory", "in", "practice,", "we", "look", "at", "a", "group", "of", "algorithms", "for", "the", "GuessWhat?!", "visual", "dialogue", "game", "and,", "using", "this", "example,", "test", "our", "theory", "empirically.", "Our", "theory", "accurately", "predicts", "relative", "performance", "of", "multiple", "algorithms", "in", "generating", "equitable", "text", "as", "measured", "by", "both", "human", "and", "automated", "evaluation."], "pieces": ["To", "ex", "empl", "ify", "our", "the", "ory", "in", "practice", ",", "we", "look", "at", "a", "group", "of", "al", "gorith", "ms", "for", "the", "Gu", "ess", "What", "?!", "visual", "dial", "ogue", "game", "and", ",", "using", "this", "example", ",", "test", "our", "the", "ory", "em", "pir", "ically", ".", "Our", "the", "ory", "acc", "ur", "ately", "pred", "icts", "relative", "performance", "of", "multiple", "al", "gorith", "ms", "in", "gener", "ating", "equ", "itable", "text", "as", "me", "asured", "by", "both", "human", "and", "aut", "om", "ated", "eval", "uation", "."], "token_lens": [1, 3, 1, 2, 1, 2, 1, 1, 1, 1, 1, 1, 3, 1, 1, 4, 1, 2, 1, 2, 1, 1, 2, 1, 1, 2, 4, 1, 2, 3, 2, 1, 1, 1, 1, 3, 1, 2, 2, 1, 1, 2, 1, 1, 1, 1, 3, 3], "sentence": "To exemplify our theory in practice, we look at a group of algorithms for the GuessWhat?! visual dialogue game and, using this example, test our theory empirically. Our theory accurately predicts relative performance of multiple algorithms in generating equitable text as measured by both human and automated evaluation.", "sentence_starts": [0]}
{"doc_id": "cscw_23_P_137", "sent_id": "cscw_23_P_137-2", "entity_mentions": [{"id": "cscw_23_P_137-2-E0", "text": "We", "start": 0, "end": 1, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "cscw_23_P_137-2-E1", "text": "while peer competition and social stratification in contemporary China cause students at the top universities to feel anxious and lost", "start": 3, "end": 23, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "cscw_23_P_137-2-E2", "text": "they seek unofficial democracy, civic participation, and possibilities of social change", "start": 53, "end": 64, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "cscw_23_P_137-2-E3", "text": "the online community they build collectively supports them to create a new social identity", "start": 23, "end": 37, "entity_type": "UNK", "mention_type": "UNK"}], "relation_mentions": [], "event_mentions": [{"event_type": "Results/Findings", "id": "cscw_23_P_137-2-EV0", "trigger": {"text": "discover", "start": 1, "end": 2}, "arguments": [{"entity_id": "cscw_23_P_137-2-E0", "text": "We", "role": "Agent"}, {"entity_id": "cscw_23_P_137-2-E1", "text": "while peer competition and social stratification in contemporary China cause students at the top universities to feel anxious and lost", "role": "Context"}, {"entity_id": "cscw_23_P_137-2-E2", "text": "they seek unofficial democracy, civic participation, and possibilities of social change", "role": "Results"}, {"entity_id": "cscw_23_P_137-2-E3", "text": "the online community they build collectively supports them to create a new social identity", "role": "PrimaryObject"}]}], "entity_coreference": [], "event_coreference": [], "tokens": ["We", "discover", "that", "while", "peer", "competition", "and", "social", "stratification", "in", "contemporary", "China", "cause", "students", "at", "the", "top", "universities", "to", "feel", "anxious", "and", "lost,", "the", "online", "community", "they", "build", "collectively", "supports", "them", "to", "create", "a", "new", "social", "identity,", "the", "identity", "of", "'five,'", "which", "is", "the", "basis", "of", "their", "online", "activism.", "Through", "this", "new", "identity,", "they", "seek", "unofficial", "democracy,", "civic", "participation,", "and", "possibilities", "of", "social", "change."], "pieces": ["We", "d", "iscover", "that", "while", "peer", "comp", "etition", "and", "social", "str", "at", "ification", "in", "cont", "emporary", "China", "cause", "stud", "ents", "at", "the", "top", "un", "ivers", "ities", "to", "feel", "an", "xious", "and", "lost", ",", "the", "online", "community", "they", "build", "collect", "ively", "supp", "orts", "them", "to", "create", "a", "new", "social", "ident", "ity", ",", "the", "ident", "ity", "of", "'", "five", ",'", "which", "is", "the", "bas", "is", "of", "their", "online", "activ", "ism", ".", "Through", "this", "new", "ident", "ity", ",", "they", "seek", "un", "official", "democracy", ",", "c", "ivic", "particip", "ation", ",", "and", "p", "oss", "ibilities", "of", "social", "change", "."], "token_lens": [1, 2, 1, 1, 1, 2, 1, 1, 3, 1, 2, 1, 1, 2, 1, 1, 1, 3, 1, 1, 2, 1, 2, 1, 1, 1, 1, 1, 2, 2, 1, 1, 1, 1, 1, 1, 3, 1, 2, 1, 3, 1, 1, 1, 2, 1, 1, 1, 3, 1, 1, 1, 3, 1, 1, 2, 2, 2, 3, 1, 3, 1, 1, 2], "sentence": "We discover that while peer competition and social stratification in contemporary China cause students at the top universities to feel anxious and lost, the online community they build collectively supports them to create a new social identity, the identity of 'five,' which is the basis of their online activism. Through this new identity, they seek unofficial democracy, civic participation, and possibilities of social change.", "sentence_starts": [0]}
{"doc_id": "bioinfo_23_P_432", "sent_id": "bioinfo_23_P_432-0", "entity_mentions": [{"id": "bioinfo_23_P_432-0-E0", "text": "Interpretable deep learning (DL) models", "start": 0, "end": 5, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "bioinfo_23_P_432-0-E1", "text": "interpretable DL models that incorporate signaling pathways have been proposed for drug response prediction (DRP)", "start": 24, "end": 39, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "bioinfo_23_P_432-0-E2", "text": "these models improve interpretability", "start": 40, "end": 44, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "bioinfo_23_P_432-0-E3", "text": "it is unclear whether this comes at the cost of less accurate DRPs, or a prediction improvement can also be obtained", "start": 44, "end": 65, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "bioinfo_23_P_432-0-E4", "text": "the biomedical community.", "start": 20, "end": 23, "entity_type": "UNK", "mention_type": "UNK"}], "relation_mentions": [], "event_mentions": [{"event_type": "Background/Introduction", "id": "bioinfo_23_P_432-0-EV0", "trigger": {"text": "are of great interest to", "start": 15, "end": 20}, "arguments": [{"entity_id": "bioinfo_23_P_432-0-E0", "text": "Interpretable deep learning (DL) models", "role": "Agent"}, {"entity_id": "bioinfo_23_P_432-0-E1", "text": "interpretable DL models that incorporate signaling pathways have been proposed for drug response prediction (DRP)", "role": "Context"}, {"entity_id": "bioinfo_23_P_432-0-E2", "text": "these models improve interpretability", "role": "Context"}, {"entity_id": "bioinfo_23_P_432-0-E3", "text": "it is unclear whether this comes at the cost of less accurate DRPs, or a prediction improvement can also be obtained", "role": "Challenge"}, {"entity_id": "bioinfo_23_P_432-0-E4", "text": "the biomedical community.", "role": "PrimaryObject"}]}], "entity_coreference": [], "event_coreference": [], "tokens": ["Interpretable", "deep", "learning", "(DL)", "models", "that", "can", "provide", "biological", "insights,", "in", "addition", "to", "accurate", "predictions,", "are", "of", "great", "interest", "to", "the", "biomedical", "community.", "Recently,", "interpretable", "DL", "models", "that", "incorporate", "signaling", "pathways", "have", "been", "proposed", "for", "drug", "response", "prediction", "(DRP).", "While", "these", "models", "improve", "interpretability,", "it", "is", "unclear", "whether", "this", "comes", "at", "the", "cost", "of", "less", "accurate", "DRPs,", "or", "a", "prediction", "improvement", "can", "also", "be", "obtained."], "pieces": ["Inter", "pret", "able", "deep", "learning", "(", "DL", ")", "models", "that", "can", "prov", "ide", "bi", "ological", "ins", "ights", ",", "in", "add", "ition", "to", "acc", "urate", "pred", "ictions", ",", "are", "of", "great", "interest", "to", "the", "bi", "omedical", "community", ".", "Recently", ",", "interpret", "able", "DL", "models", "that", "inc", "orpor", "ate", "sign", "aling", "path", "ways", "have", "been", "prop", "osed", "for", "drug", "response", "pred", "iction", "(", "DR", "P", ").", "While", "these", "models", "improve", "interpret", "ability", ",", "it", "is", "un", "clear", "whether", "this", "comes", "at", "the", "cost", "of", "less", "acc", "urate", "DR", "Ps", ",", "or", "a", "pred", "iction", "improve", "ment", "can", "also", "be", "ob", "tained", "."], "token_lens": [3, 1, 1, 3, 1, 1, 1, 2, 2, 3, 1, 2, 1, 2, 3, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 1, 1, 1, 3, 2, 2, 1, 1, 2, 1, 1, 1, 2, 4, 1, 1, 1, 1, 3, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 2, 3, 1, 1, 2, 2, 1, 1, 1, 3], "sentence": "Interpretable deep learning (DL) models that can provide biological insights, in addition to accurate predictions, are of great interest to the biomedical community. Recently, interpretable DL models that incorporate signaling pathways have been proposed for drug response prediction (DRP). While these models improve interpretability, it is unclear whether this comes at the cost of less accurate DRPs, or a prediction improvement can also be obtained.", "sentence_starts": [0]}
{"doc_id": "bioinfo_23_P_547", "sent_id": "bioinfo_23_P_547-0", "entity_mentions": [{"id": "bioinfo_23_P_547-0-E0", "text": "Screening bioactive compounds in cancer cell lines", "start": 0, "end": 7, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "bioinfo_23_P_547-0-E1", "text": "Multidisciplinary drugs or drug combinations have a more effective role in treatments and selectively inhibit the growth of cancer cells", "start": 10, "end": 30, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "bioinfo_23_P_547-0-E2", "text": "more attention", "start": 8, "end": 10, "entity_type": "UNK", "mention_type": "UNK"}], "relation_mentions": [], "event_mentions": [{"event_type": "Background/Introduction", "id": "bioinfo_23_P_547-0-EV0", "trigger": {"text": "receive", "start": 7, "end": 8}, "arguments": [{"entity_id": "bioinfo_23_P_547-0-E0", "text": "Screening bioactive compounds in cancer cell lines", "role": "Agent"}, {"entity_id": "bioinfo_23_P_547-0-E1", "text": "Multidisciplinary drugs or drug combinations have a more effective role in treatments and selectively inhibit the growth of cancer cells", "role": "Context"}, {"entity_id": "bioinfo_23_P_547-0-E2", "text": "more attention", "role": "PrimaryObject"}]}], "entity_coreference": [], "event_coreference": [], "tokens": ["Screening", "bioactive", "compounds", "in", "cancer", "cell", "lines", "receive", "more", "attention.", "Multidisciplinary", "drugs", "or", "drug", "combinations", "have", "a", "more", "effective", "role", "in", "treatments", "and", "selectively", "inhibit", "the", "growth", "of", "cancer", "cells."], "pieces": ["Screen", "ing", "b", "io", "active", "comp", "ounds", "in", "cancer", "cell", "lines", "re", "ceive", "more", "att", "ention", ".", "Mult", "idis", "ciplinary", "drug", "s", "or", "drug", "comb", "inations", "have", "a", "more", "effective", "role", "in", "t", "reat", "ments", "and", "select", "ively", "in", "hibit", "the", "growth", "of", "cancer", "cells", "."], "token_lens": [2, 3, 2, 1, 1, 1, 1, 2, 1, 3, 3, 2, 1, 1, 2, 1, 1, 1, 1, 1, 1, 3, 1, 2, 2, 1, 1, 1, 1, 2], "sentence": "Screening bioactive compounds in cancer cell lines receive more attention. Multidisciplinary drugs or drug combinations have a more effective role in treatments and selectively inhibit the growth of cancer cells.", "sentence_starts": [0]}
{"doc_id": "bioinfo_23_P_646", "sent_id": "bioinfo_23_P_646-1", "entity_mentions": [{"id": "bioinfo_23_P_646-1-E0", "text": "We", "start": 0, "end": 1, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "bioinfo_23_P_646-1-E1", "text": "sentence classification using a prompt-based learning model", "start": 14, "end": 21, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "bioinfo_23_P_646-1-E2", "text": "PICO extraction using a named entity recognition (NER) model", "start": 23, "end": 32, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "bioinfo_23_P_646-1-E3", "text": "the sentences in abstracts were categorized into four sections namely background, methods, results, and conclusions", "start": 33, "end": 48, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "bioinfo_23_P_646-1-E4", "text": "the NER model was applied to extract the PICO elements from the sentences within the title and methods sections that include >96% of PICO information", "start": 49, "end": 74, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "bioinfo_23_P_646-1-E5", "text": "a two-step NLP pipeline", "start": 2, "end": 6, "entity_type": "UNK", "mention_type": "UNK"}], "relation_mentions": [], "event_mentions": [{"event_type": "Methods/Approach", "id": "bioinfo_23_P_646-1-EV0", "trigger": {"text": "propose", "start": 1, "end": 2}, "arguments": [{"entity_id": "bioinfo_23_P_646-1-E0", "text": "We", "role": "Agent"}, {"entity_id": "bioinfo_23_P_646-1-E1", "text": "sentence classification using a prompt-based learning model", "role": "Method"}, {"entity_id": "bioinfo_23_P_646-1-E2", "text": "PICO extraction using a named entity recognition (NER) model", "role": "Method"}, {"entity_id": "bioinfo_23_P_646-1-E3", "text": "the sentences in abstracts were categorized into four sections namely background, methods, results, and conclusions", "role": "Method"}, {"entity_id": "bioinfo_23_P_646-1-E4", "text": "the NER model was applied to extract the PICO elements from the sentences within the title and methods sections that include >96% of PICO information", "role": "Method"}, {"entity_id": "bioinfo_23_P_646-1-E5", "text": "a two-step NLP pipeline", "role": "PrimaryObject"}]}], "entity_coreference": [], "event_coreference": [], "tokens": ["We", "propose", "a", "two-step", "NLP", "pipeline", "to", "extract", "PICO", "elements", "from", "RCT", "abstracts:", "(i)", "sentence", "classification", "using", "a", "prompt-based", "learning", "model", "and", "(ii)", "PICO", "extraction", "using", "a", "named", "entity", "recognition", "(NER)", "model.", "First,", "the", "sentences", "in", "abstracts", "were", "categorized", "into", "four", "sections", "namely", "background,", "methods,", "results,", "and", "conclusions.", "Next,", "the", "NER", "model", "was", "applied", "to", "extract", "the", "PICO", "elements", "from", "the", "sentences", "within", "the", "title", "and", "methods", "sections", "that", "include", ">96%", "of", "PICO", "information."], "pieces": ["We", "pro", "pose", "a", "two", "-", "step", "N", "LP", "p", "ip", "eline", "to", "ext", "ract", "P", "ICO", "e", "lements", "from", "R", "CT", "ab", "stract", "s", ":", "(", "i", ")", "sent", "ence", "class", "ification", "using", "a", "prom", "pt", "-", "based", "learning", "model", "and", "(", "ii", ")", "P", "ICO", "ext", "raction", "using", "a", "named", "entity", "recogn", "ition", "(", "NER", ")", "model", ".", "First", ",", "the", "sent", "ences", "in", "ab", "stract", "s", "were", "c", "ategor", "ized", "into", "four", "sections", "name", "ly", "background", ",", "method", "s", ",", "results", ",", "and", "con", "clusions", ".", "Next", ",", "the", "NER", "model", "was", "app", "lied", "to", "ext", "ract", "the", "P", "ICO", "e", "lements", "from", "the", "sent", "ences", "within", "the", "title", "and", "method", "s", "sections", "that", "include", ">", "96", "%", "of", "P", "ICO", "information", "."], "token_lens": [1, 2, 1, 3, 2, 3, 1, 2, 2, 2, 1, 2, 4, 3, 2, 2, 1, 1, 4, 1, 1, 1, 3, 2, 2, 1, 1, 1, 1, 2, 3, 2, 2, 1, 2, 1, 3, 1, 3, 1, 1, 1, 2, 2, 3, 2, 1, 3, 2, 1, 1, 1, 1, 2, 1, 2, 1, 2, 2, 1, 1, 2, 1, 1, 1, 1, 2, 1, 1, 1, 3, 1, 2, 2], "sentence": "We propose a two-step NLP pipeline to extract PICO elements from RCT abstracts: (i) sentence classification using a prompt-based learning model and (ii) PICO extraction using a named entity recognition (NER) model. First, the sentences in abstracts were categorized into four sections namely background, methods, results, and conclusions. Next, the NER model was applied to extract the PICO elements from the sentences within the title and methods sections that include >96% of PICO information.", "sentence_starts": [0]}
{"doc_id": "bioinfo_23_P_570", "sent_id": "bioinfo_23_P_570-2", "entity_mentions": [{"id": "bioinfo_23_P_570-2-E0", "text": "Experimental results", "start": 0, "end": 2, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "bioinfo_23_P_570-2-E1", "text": "iGRLDTI yields better performance than several state-of-the-art computational methods on the benchmark dataset", "start": 4, "end": 17, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "bioinfo_23_P_570-2-E2", "text": "iGRLDTI can successfully identify novel DTIs with more distinguishable features of drugs and targets", "start": 23, "end": 37, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "bioinfo_23_P_570-2-E3", "text": "iGRLDTI yields better performance than several state-of-the-art computational methods on the benchmark dataset", "start": 4, "end": 17, "entity_type": "UNK", "mention_type": "UNK"}], "relation_mentions": [], "event_mentions": [{"event_type": "Results/Findings", "id": "bioinfo_23_P_570-2-EV0", "trigger": {"text": "demonstrate", "start": 2, "end": 3}, "arguments": [{"entity_id": "bioinfo_23_P_570-2-E0", "text": "Experimental results", "role": "Agent"}, {"entity_id": "bioinfo_23_P_570-2-E1", "text": "iGRLDTI yields better performance than several state-of-the-art computational methods on the benchmark dataset", "role": "Results"}, {"entity_id": "bioinfo_23_P_570-2-E2", "text": "iGRLDTI can successfully identify novel DTIs with more distinguishable features of drugs and targets", "role": "Results"}, {"entity_id": "bioinfo_23_P_570-2-E3", "text": "iGRLDTI yields better performance than several state-of-the-art computational methods on the benchmark dataset", "role": "PrimaryObject"}]}], "entity_coreference": [], "event_coreference": [], "tokens": ["Experimental", "results", "demonstrate", "that", "iGRLDTI", "yields", "better", "performance", "than", "several", "state-of-the-art", "computational", "methods", "on", "the", "benchmark", "dataset.", "Besides,", "our", "case", "study", "indicates", "that", "iGRLDTI", "can", "successfully", "identify", "novel", "DTIs", "with", "more", "distinguishable", "features", "of", "drugs", "and", "targets."], "pieces": ["Exper", "imental", "results", "demon", "strate", "that", "i", "G", "RL", "DT", "I", "y", "ield", "s", "better", "performance", "than", "sever", "al", "state", "-", "of", "-", "the", "-", "art", "com", "put", "ational", "method", "s", "on", "the", "bench", "mark", "dat", "as", "et", ".", "Besides", ",", "our", "case", "study", "ind", "icates", "that", "i", "G", "RL", "DT", "I", "can", "successfully", "ident", "ify", "no", "vel", "DT", "Is", "with", "more", "dist", "inguishable", "features", "of", "drug", "s", "and", "t", "arg", "ets", "."], "token_lens": [2, 1, 2, 1, 5, 3, 1, 1, 1, 2, 7, 3, 2, 1, 1, 2, 4, 2, 1, 1, 1, 2, 1, 5, 1, 1, 2, 2, 2, 1, 1, 2, 1, 1, 2, 1, 4], "sentence": "Experimental results demonstrate that iGRLDTI yields better performance than several state-of-the-art computational methods on the benchmark dataset. Besides, our case study indicates that iGRLDTI can successfully identify novel DTIs with more distinguishable features of drugs and targets.", "sentence_starts": [0]}
{"doc_id": "bioinfo_23_P_838", "sent_id": "bioinfo_23_P_838-0", "entity_mentions": [{"id": "bioinfo_23_P_838-0-E0", "text": "The process", "start": 22, "end": 24, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "bioinfo_23_P_838-0-E1", "text": "In whole genome sequencing data, polymerase chain reaction amplification results in duplicate DNA fragments coming from the same location in the genome", "start": 0, "end": 22, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "bioinfo_23_P_838-0-E2", "text": "only one WGBS-aware duplicate marking tool exists", "start": 53, "end": 60, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "bioinfo_23_P_838-0-E3", "text": "it only works with the output from a single tool, does not accept streaming input or output, and requires a substantial amount of memory relative to the input size", "start": 61, "end": 90, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "bioinfo_23_P_838-0-E4", "text": "two DNA fragments", "start": 39, "end": 42, "entity_type": "UNK", "mention_type": "UNK"}], "relation_mentions": [], "event_mentions": [{"event_type": "Background/Introduction", "id": "bioinfo_23_P_838-0-EV0", "trigger": {"text": "create", "start": 38, "end": 39}, "arguments": [{"entity_id": "bioinfo_23_P_838-0-E0", "text": "The process", "role": "Agent"}, {"entity_id": "bioinfo_23_P_838-0-E1", "text": "In whole genome sequencing data, polymerase chain reaction amplification results in duplicate DNA fragments coming from the same location in the genome", "role": "Context"}, {"entity_id": "bioinfo_23_P_838-0-E2", "text": "only one WGBS-aware duplicate marking tool exists", "role": "Context"}, {"entity_id": "bioinfo_23_P_838-0-E3", "text": "it only works with the output from a single tool, does not accept streaming input or output, and requires a substantial amount of memory relative to the input size", "role": "Challenge"}, {"entity_id": "bioinfo_23_P_838-0-E4", "text": "two DNA fragments", "role": "PrimaryObject"}]}], "entity_coreference": [], "event_coreference": [], "tokens": ["In", "whole", "genome", "sequencing", "data,", "polymerase", "chain", "reaction", "amplification", "results", "in", "duplicate", "DNA", "fragments", "coming", "from", "the", "same", "location", "in", "the", "genome.", "The", "process", "of", "preparing", "a", "whole", "genome", "bisulfite", "sequencing", "(WGBS)", "library,", "on", "the", "other", "hand,", "can", "create", "two", "DNA", "fragments", "from", "the", "same", "location", "that", "should", "not", "be", "considered", "duplicates.", "Currently,", "only", "one", "WGBS-aware", "duplicate", "marking", "tool", "exists.", "However,", "it", "only", "works", "with", "the", "output", "from", "a", "single", "tool,", "does", "not", "accept", "streaming", "input", "or", "output,", "and", "requires", "a", "substantial", "amount", "of", "memory", "relative", "to", "the", "input", "size."], "pieces": ["In", "wh", "ole", "gen", "ome", "sequ", "encing", "data", ",", "poly", "mer", "ase", "chain", "re", "action", "am", "pl", "ification", "results", "in", "du", "pl", "icate", "DNA", "fr", "ag", "ments", "coming", "from", "the", "same", "location", "in", "the", "gen", "ome", ".", "The", "process", "of", "prep", "aring", "a", "wh", "ole", "gen", "ome", "bis", "ulf", "ite", "sequ", "encing", "(", "W", "G", "BS", ")", "library", ",", "on", "the", "other", "hand", ",", "can", "create", "two", "DNA", "fr", "ag", "ments", "from", "the", "same", "location", "that", "should", "not", "be", "cons", "idered", "du", "pl", "icates", ".", "Currently", ",", "only", "one", "W", "G", "BS", "-", "aware", "du", "pl", "icate", "mark", "ing", "tool", "ex", "ists", ".", "However", ",", "it", "only", "works", "with", "the", "output", "from", "a", "single", "tool", ",", "does", "not", "accept", "stream", "ing", "input", "or", "output", ",", "and", "requires", "a", "sub", "stantial", "amount", "of", "memory", "relative", "to", "the", "input", "size", "."], "token_lens": [1, 2, 2, 2, 2, 3, 1, 2, 3, 1, 1, 3, 1, 3, 1, 1, 1, 1, 1, 1, 1, 3, 1, 1, 1, 2, 1, 2, 2, 3, 2, 5, 2, 1, 1, 1, 2, 1, 1, 1, 1, 3, 1, 1, 1, 1, 1, 1, 1, 1, 2, 4, 2, 1, 1, 5, 3, 2, 1, 3, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 2, 1, 1, 2, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 2], "sentence": "In whole genome sequencing data, polymerase chain reaction amplification results in duplicate DNA fragments coming from the same location in the genome. The process of preparing a whole genome bisulfite sequencing (WGBS) library, on the other hand, can create two DNA fragments from the same location that should not be considered duplicates. Currently, only one WGBS-aware duplicate marking tool exists. However, it only works with the output from a single tool, does not accept streaming input or output, and requires a substantial amount of memory relative to the input size.", "sentence_starts": [0]}
{"doc_id": "bioinfo_23_P_703", "sent_id": "bioinfo_23_P_703-2", "entity_mentions": [{"id": "bioinfo_23_P_703-2-E0", "text": "Insights gained from the optima package", "start": 0, "end": 6, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "bioinfo_23_P_703-2-E1", "text": "users", "start": 7, "end": 8, "entity_type": "UNK", "mention_type": "UNK"}], "relation_mentions": [], "event_mentions": [{"event_type": "Results/Findings", "id": "bioinfo_23_P_703-2-EV0", "trigger": {"text": "help", "start": 6, "end": 7}, "arguments": [{"entity_id": "bioinfo_23_P_703-2-E0", "text": "Insights gained from the optima package", "role": "Agent"}, {"entity_id": "bioinfo_23_P_703-2-E1", "text": "users", "role": "PrimaryObject"}]}], "entity_coreference": [], "event_coreference": [], "tokens": ["Insights", "gained", "from", "the", "optima", "package", "help", "users", "to", "identify", "unique", "cell", "populations", "and", "uncover", "surface", "protein", "expression", "patterns."], "pieces": ["Ins", "ights", "g", "ained", "from", "the", "opt", "ima", "package", "help", "users", "to", "ident", "ify", "unique", "cell", "pop", "ulations", "and", "un", "cover", "surface", "protein", "expression", "pattern", "s", "."], "token_lens": [2, 2, 1, 1, 2, 1, 1, 1, 1, 2, 1, 1, 2, 1, 2, 1, 1, 1, 3], "sentence": "Insights gained from the optima package help users to identify unique cell populations and uncover surface protein expression patterns.", "sentence_starts": [0]}
{"doc_id": "ACL_23_P_464", "sent_id": "ACL_23_P_464-2", "entity_mentions": [{"id": "ACL_23_P_464-2-E0", "text": "Experiments on four downstream tasks", "start": 0, "end": 5, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_464-2-E1", "text": "RELIT achieves new state-of-the-art results under the weakly supervised setting.", "start": 7, "end": 17, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_464-2-E2", "text": "RELIT achieves new state-of-the-art results under the weakly supervised setting", "start": 7, "end": 17, "entity_type": "UNK", "mention_type": "UNK"}], "relation_mentions": [], "event_mentions": [{"event_type": "Results/Findings", "id": "ACL_23_P_464-2-EV0", "trigger": {"text": "show", "start": 5, "end": 6}, "arguments": [{"entity_id": "ACL_23_P_464-2-E0", "text": "Experiments on four downstream tasks", "role": "Agent"}, {"entity_id": "ACL_23_P_464-2-E1", "text": "RELIT achieves new state-of-the-art results under the weakly supervised setting.", "role": "Results"}, {"entity_id": "ACL_23_P_464-2-E2", "text": "RELIT achieves new state-of-the-art results under the weakly supervised setting", "role": "PrimaryObject"}]}], "entity_coreference": [], "event_coreference": [], "tokens": ["Experiments", "on", "four", "downstream", "tasks", "show", "that", "RELIT", "achieves", "new", "state-of-the-art", "results", "under", "the", "weakly", "supervised", "setting."], "pieces": ["Exper", "iments", "on", "four", "down", "stream", "t", "asks", "show", "that", "REL", "IT", "ach", "ieves", "new", "state", "-", "of", "-", "the", "-", "art", "results", "under", "the", "weak", "ly", "super", "vised", "setting", "."], "token_lens": [2, 1, 1, 2, 2, 1, 1, 2, 2, 1, 7, 1, 1, 1, 2, 2, 2], "sentence": "Experiments on four downstream tasks show that RELIT achieves new state-of-the-art results under the weakly supervised setting.", "sentence_starts": [0]}
{"doc_id": "bioinfo_23_P_709", "sent_id": "bioinfo_23_P_709-2", "entity_mentions": [{"id": "bioinfo_23_P_709-2-E0", "text": "DeepPeptide", "start": 0, "end": 1, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "bioinfo_23_P_709-2-E1", "text": "the model is capable of identifying peptides in underannotated proteomes", "start": 17, "end": 27, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "bioinfo_23_P_709-2-E2", "text": "both improved precision and recall", "start": 2, "end": 7, "entity_type": "UNK", "mention_type": "UNK"}], "relation_mentions": [], "event_mentions": [{"event_type": "Results/Findings", "id": "bioinfo_23_P_709-2-EV0", "trigger": {"text": "shows", "start": 1, "end": 2}, "arguments": [{"entity_id": "bioinfo_23_P_709-2-E0", "text": "DeepPeptide", "role": "Agent"}, {"entity_id": "bioinfo_23_P_709-2-E1", "text": "the model is capable of identifying peptides in underannotated proteomes", "role": "Results"}, {"entity_id": "bioinfo_23_P_709-2-E2", "text": "both improved precision and recall", "role": "PrimaryObject"}]}], "entity_coreference": [], "event_coreference": [], "tokens": ["DeepPeptide", "shows", "both", "improved", "precision", "and", "recall", "for", "peptide", "detection", "compared", "to", "previous", "methodology.", "We", "show", "that", "the", "model", "is", "capable", "of", "identifying", "peptides", "in", "underannotated", "proteomes."], "pieces": ["Deep", "Pe", "pt", "ide", "shows", "both", "impro", "ved", "pre", "cision", "and", "rec", "all", "for", "pe", "pt", "ide", "det", "ection", "comp", "ared", "to", "pre", "vious", "method", "ology", ".", "We", "show", "that", "the", "model", "is", "cap", "able", "of", "ident", "ifying", "pe", "pt", "ides", "in", "under", "annot", "ated", "pro", "te", "omes", "."], "token_lens": [4, 1, 1, 2, 2, 1, 2, 1, 3, 2, 2, 1, 2, 3, 1, 1, 1, 1, 1, 1, 2, 1, 2, 3, 1, 3, 4], "sentence": "DeepPeptide shows both improved precision and recall for peptide detection compared to previous methodology. We show that the model is capable of identifying peptides in underannotated proteomes.", "sentence_starts": [0]}
{"doc_id": "bioinfo_23_P_697", "sent_id": "bioinfo_23_P_697-0", "entity_mentions": [{"id": "bioinfo_23_P_697-0-E0", "text": "Detecting oscillations in time series", "start": 0, "end": 5, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "bioinfo_23_P_697-0-E1", "text": "In chronobiology, rhythms (for instance in gene expression, eclosion, egg-laying, and feeding) tend to be low amplitude, display large variations amongst replicates, and often exhibit varying peak-to-peak distances (non-stationarity)", "start": 14, "end": 43, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "bioinfo_23_P_697-0-E2", "text": "Most currently available rhythm detection methods are not specifically designed to handle such datasets, and are also limited by their use of P-values in detecting oscillations", "start": 43, "end": 69, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "bioinfo_23_P_697-0-E3", "text": "a challenging problem", "start": 6, "end": 9, "entity_type": "UNK", "mention_type": "UNK"}], "relation_mentions": [], "event_mentions": [{"event_type": "Background/Introduction", "id": "bioinfo_23_P_697-0-EV0", "trigger": {"text": "remains", "start": 5, "end": 6}, "arguments": [{"entity_id": "bioinfo_23_P_697-0-E0", "text": "Detecting oscillations in time series", "role": "Agent"}, {"entity_id": "bioinfo_23_P_697-0-E1", "text": "In chronobiology, rhythms (for instance in gene expression, eclosion, egg-laying, and feeding) tend to be low amplitude, display large variations amongst replicates, and often exhibit varying peak-to-peak distances (non-stationarity)", "role": "Context"}, {"entity_id": "bioinfo_23_P_697-0-E2", "text": "Most currently available rhythm detection methods are not specifically designed to handle such datasets, and are also limited by their use of P-values in detecting oscillations", "role": "Challenge"}, {"entity_id": "bioinfo_23_P_697-0-E3", "text": "a challenging problem", "role": "PrimaryObject"}]}], "entity_coreference": [], "event_coreference": [], "tokens": ["Detecting", "oscillations", "in", "time", "series", "remains", "a", "challenging", "problem", "even", "after", "decades", "of", "research.", "In", "chronobiology,", "rhythms", "(for", "instance", "in", "gene", "expression,", "eclosion,", "egg-laying,", "and", "feeding)", "tend", "to", "be", "low", "amplitude,", "display", "large", "variations", "amongst", "replicates,", "and", "often", "exhibit", "varying", "peak-to-peak", "distances", "(non-stationarity).", "Most", "currently", "available", "rhythm", "detection", "methods", "are", "not", "specifically", "designed", "to", "handle", "such", "datasets,", "and", "are", "also", "limited", "by", "their", "use", "of", "P-values", "in", "detecting", "oscillations."], "pieces": ["Detect", "ing", "osc", "ill", "ations", "in", "time", "series", "rem", "ains", "a", "chall", "eng", "ing", "problem", "even", "after", "dec", "ades", "of", "research", ".", "In", "chron", "ob", "iology", ",", "rh", "yth", "ms", "(", "for", "instance", "in", "g", "ene", "expression", ",", "e", "cl", "osion", ",", "egg", "-", "l", "aying", ",", "and", "feeding", ")", "t", "end", "to", "be", "low", "am", "pl", "itude", ",", "display", "large", "vari", "ations", "among", "st", "repl", "icates", ",", "and", "often", "ex", "hibit", "v", "ary", "ing", "peak", "-", "to", "-", "peak", "dist", "ances", "(", "non", "-", "station", "arity", ").", "Most", "currently", "available", "rh", "ythm", "det", "ection", "method", "s", "are", "not", "specific", "ally", "designed", "to", "handle", "such", "dat", "as", "ets", ",", "and", "are", "also", "limited", "by", "their", "use", "of", "P", "-", "values", "in", "det", "ect", "ing", "osc", "ill", "ations", "."], "token_lens": [2, 3, 1, 1, 1, 2, 1, 3, 1, 1, 1, 2, 1, 2, 1, 4, 3, 2, 1, 1, 2, 2, 4, 5, 1, 2, 2, 1, 1, 1, 4, 1, 1, 2, 2, 3, 1, 1, 2, 3, 5, 2, 6, 1, 1, 1, 2, 2, 2, 1, 1, 2, 1, 1, 1, 1, 4, 1, 1, 1, 1, 1, 1, 1, 1, 3, 1, 3, 4], "sentence": "Detecting oscillations in time series remains a challenging problem even after decades of research. In chronobiology, rhythms (for instance in gene expression, eclosion, egg-laying, and feeding) tend to be low amplitude, display large variations amongst replicates, and often exhibit varying peak-to-peak distances (non-stationarity). Most currently available rhythm detection methods are not specifically designed to handle such datasets, and are also limited by their use of P-values in detecting oscillations.", "sentence_starts": [0]}
{"doc_id": "bioinfo_23_P_379", "sent_id": "bioinfo_23_P_379-1", "entity_mentions": [{"id": "bioinfo_23_P_379-1-E0", "text": "we", "start": 3, "end": 4, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "bioinfo_23_P_379-1-E1", "text": "ODNA is a software that classifies organellar DNA sequences within a genome assembly by machine learning based on a predefined genome annotation workflow", "start": 15, "end": 38, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "bioinfo_23_P_379-1-E2", "text": "ODNA", "start": 5, "end": 6, "entity_type": "UNK", "mention_type": "UNK"}], "relation_mentions": [], "event_mentions": [{"event_type": "Methods/Approach", "id": "bioinfo_23_P_379-1-EV0", "trigger": {"text": "developed", "start": 4, "end": 5}, "arguments": [{"entity_id": "bioinfo_23_P_379-1-E0", "text": "we", "role": "Agent"}, {"entity_id": "bioinfo_23_P_379-1-E1", "text": "ODNA is a software that classifies organellar DNA sequences within a genome assembly by machine learning based on a predefined genome annotation workflow", "role": "Method"}, {"entity_id": "bioinfo_23_P_379-1-E2", "text": "ODNA", "role": "PrimaryObject"}]}], "entity_coreference": [], "event_coreference": [], "tokens": ["To", "address", "this,", "we", "developed", "ODNA", "based", "on", "genome", "annotation", "and", "machine", "learning", "to", "fulfill.", "ODNA", "is", "a", "software", "that", "classifies", "organellar", "DNA", "sequences", "within", "a", "genome", "assembly", "by", "machine", "learning", "based", "on", "a", "predefined", "genome", "annotation", "workflow."], "pieces": ["To", "address", "this", ",", "we", "developed", "OD", "NA", "based", "on", "gen", "ome", "ann", "otation", "and", "machine", "learning", "to", "ful", "fill", ".", "OD", "NA", "is", "a", "software", "that", "class", "ifies", "organ", "ellar", "DNA", "sequ", "ences", "within", "a", "gen", "ome", "assembly", "by", "machine", "learning", "based", "on", "a", "pred", "efined", "gen", "ome", "ann", "otation", "work", "flow", "."], "token_lens": [1, 1, 2, 1, 1, 2, 1, 1, 2, 2, 1, 1, 1, 1, 3, 2, 1, 1, 1, 1, 2, 2, 1, 2, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 3], "sentence": "To address this, we developed ODNA based on genome annotation and machine learning to fulfill. ODNA is a software that classifies organellar DNA sequences within a genome assembly by machine learning based on a predefined genome annotation workflow.", "sentence_starts": [0]}
{"doc_id": "cscw_23_P_116", "sent_id": "cscw_23_P_116-0", "entity_mentions": [{"id": "cscw_23_P_116-0-E0", "text": "I", "start": 45, "end": 46, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "cscw_23_P_116-0-E1", "text": "Through intensive research on datasets, benchmarks, and models, the computer-vision community has taken great strides to identify the societal biases intrinsic to these technologies", "start": 0, "end": 24, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "cscw_23_P_116-0-E2", "text": "through its use as account verification in ride-hail work", "start": 51, "end": 60, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "cscw_23_P_116-0-E3", "text": "Less is known about the last mile of the computer-vision machine-learning pipeline: on-the-ground integration into the real world", "start": 24, "end": 42, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "cscw_23_P_116-0-E4", "text": "facial verification technology (FVT)", "start": 47, "end": 51, "entity_type": "UNK", "mention_type": "UNK"}], "relation_mentions": [], "event_mentions": [{"event_type": "Background/Introduction", "id": "cscw_23_P_116-0-EV0", "trigger": {"text": "analyze", "start": 46, "end": 47}, "arguments": [{"entity_id": "cscw_23_P_116-0-E0", "text": "I", "role": "Agent"}, {"entity_id": "cscw_23_P_116-0-E1", "text": "Through intensive research on datasets, benchmarks, and models, the computer-vision community has taken great strides to identify the societal biases intrinsic to these technologies", "role": "Context"}, {"entity_id": "cscw_23_P_116-0-E2", "text": "through its use as account verification in ride-hail work", "role": "Context"}, {"entity_id": "cscw_23_P_116-0-E3", "text": "Less is known about the last mile of the computer-vision machine-learning pipeline: on-the-ground integration into the real world", "role": "Challenge"}, {"entity_id": "cscw_23_P_116-0-E4", "text": "facial verification technology (FVT)", "role": "PrimaryObject"}]}], "entity_coreference": [], "event_coreference": [], "tokens": ["Through", "intensive", "research", "on", "datasets,", "benchmarks,", "and", "models,", "the", "computer-vision", "community", "has", "taken", "great", "strides", "to", "identify", "the", "societal", "biases", "intrinsic", "to", "these", "technologies.", "Less", "is", "known", "about", "the", "last", "mile", "of", "the", "computer-vision", "machine-learning", "pipeline:", "on-the-ground", "integration", "into", "the", "real", "world.", "In", "this", "paper,", "I", "analyze", "facial", "verification", "technology", "(FVT)", "through", "its", "use", "as", "account", "verification", "in", "ride-hail", "work."], "pieces": ["Through", "intensive", "research", "on", "dat", "as", "ets", ",", "bench", "marks", ",", "and", "models", ",", "the", "computer", "-", "vision", "community", "has", "t", "aken", "great", "str", "ides", "to", "ident", "ify", "the", "soc", "ietal", "bi", "ases", "int", "r", "ins", "ic", "to", "these", "techn", "ologies", ".", "Less", "is", "known", "about", "the", "last", "mile", "of", "the", "computer", "-", "vision", "machine", "-", "learning", "p", "ip", "eline", ":", "on", "-", "the", "-", "ground", "integ", "ration", "into", "the", "real", "world", ".", "In", "this", "paper", ",", "I", "analy", "ze", "f", "acial", "ver", "ification", "technology", "(", "F", "VT", ")", "through", "its", "use", "as", "account", "ver", "ification", "in", "ride", "-", "h", "ail", "work", "."], "token_lens": [1, 1, 1, 1, 4, 3, 1, 2, 1, 3, 1, 1, 2, 1, 2, 1, 2, 1, 2, 2, 4, 1, 1, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 3, 3, 4, 5, 2, 1, 1, 1, 2, 1, 1, 2, 1, 2, 2, 2, 1, 4, 1, 1, 1, 1, 1, 2, 1, 4, 2], "sentence": "Through intensive research on datasets, benchmarks, and models, the computer-vision community has taken great strides to identify the societal biases intrinsic to these technologies. Less is known about the last mile of the computer-vision machine-learning pipeline: on-the-ground integration into the real world. In this paper, I analyze facial verification technology (FVT) through its use as account verification in ride-hail work.", "sentence_starts": [0]}
{"doc_id": "ACL_23_P_23", "sent_id": "ACL_23_P_23-3", "entity_mentions": [{"id": "ACL_23_P_23-3-E0", "text": "we", "start": 11, "end": 12, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_23-3-E1", "text": "By surveying the opinions of affected native speakers from diverse languages", "start": 0, "end": 11, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_23-3-E2", "text": "recommendations to address the issue in future MT research", "start": 13, "end": 22, "entity_type": "UNK", "mention_type": "UNK"}], "relation_mentions": [], "event_mentions": [{"event_type": "Conclusions/Implications", "id": "ACL_23_P_23-3-EV0", "trigger": {"text": "provide", "start": 12, "end": 13}, "arguments": [{"entity_id": "ACL_23_P_23-3-E0", "text": "we", "role": "Agent"}, {"entity_id": "ACL_23_P_23-3-E1", "text": "By surveying the opinions of affected native speakers from diverse languages", "role": "Method"}, {"entity_id": "ACL_23_P_23-3-E2", "text": "recommendations to address the issue in future MT research", "role": "PrimaryObject"}]}], "entity_coreference": [], "event_coreference": [], "tokens": ["By", "surveying", "the", "opinions", "of", "affected", "native", "speakers", "from", "diverse", "languages,", "we", "provide", "recommendations", "to", "address", "the", "issue", "in", "future", "MT", "research."], "pieces": ["By", "sur", "ve", "ying", "the", "op", "in", "ions", "of", "affected", "native", "spe", "akers", "from", "d", "iverse", "l", "anguages", ",", "we", "prov", "ide", "recomm", "end", "ations", "to", "address", "the", "issue", "in", "future", "MT", "research", "."], "token_lens": [1, 3, 1, 3, 1, 1, 1, 2, 1, 2, 3, 1, 2, 3, 1, 1, 1, 1, 1, 1, 1, 2], "sentence": "By surveying the opinions of affected native speakers from diverse languages, we provide recommendations to address the issue in future MT research.", "sentence_starts": [0]}
{"doc_id": "ACL_23_P_829", "sent_id": "ACL_23_P_829-1", "entity_mentions": [{"id": "ACL_23_P_829-1-E0", "text": "we", "start": 3, "end": 4, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_829-1-E1", "text": "when training data is limited", "start": 15, "end": 20, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_829-1-E2", "text": "we propose SWEET (Separating Weights for Early-Exit Transformers) an Early-Exit fine-tuning method that assigns each classifier its own set of unique model weights, not updated by other classifiers", "start": 92, "end": 120, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_829-1-E3", "text": "we observe that for models with the same architecture and size, individual Multi-Model classifiers outperform their Early-Exit counterparts by an average of 2.3%", "start": 21, "end": 44, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_829-1-E4", "text": "We show that this gap is caused by Early-Exit classifiers sharing model parameters during training, resulting in conflicting gradient updates of model weights", "start": 44, "end": 67, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_829-1-E5", "text": "We find that despite this gap, Early-Exit still provides a better speed-accuracy trade-off due to the overhead of the Multi-Model approach", "start": 67, "end": 88, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_829-1-E6", "text": "the two main approaches", "start": 5, "end": 9, "entity_type": "UNK", "mention_type": "UNK"}], "relation_mentions": [], "event_mentions": [{"event_type": "Methods/Approach", "id": "ACL_23_P_829-1-EV0", "trigger": {"text": "compare", "start": 4, "end": 5}, "arguments": [{"entity_id": "ACL_23_P_829-1-E0", "text": "we", "role": "Agent"}, {"entity_id": "ACL_23_P_829-1-E1", "text": "when training data is limited", "role": "Context"}, {"entity_id": "ACL_23_P_829-1-E2", "text": "we propose SWEET (Separating Weights for Early-Exit Transformers) an Early-Exit fine-tuning method that assigns each classifier its own set of unique model weights, not updated by other classifiers", "role": "Method"}, {"entity_id": "ACL_23_P_829-1-E3", "text": "we observe that for models with the same architecture and size, individual Multi-Model classifiers outperform their Early-Exit counterparts by an average of 2.3%", "role": "Results"}, {"entity_id": "ACL_23_P_829-1-E4", "text": "We show that this gap is caused by Early-Exit classifiers sharing model parameters during training, resulting in conflicting gradient updates of model weights", "role": "Results"}, {"entity_id": "ACL_23_P_829-1-E5", "text": "We find that despite this gap, Early-Exit still provides a better speed-accuracy trade-off due to the overhead of the Multi-Model approach", "role": "Results"}, {"entity_id": "ACL_23_P_829-1-E6", "text": "the two main approaches", "role": "PrimaryObject"}]}], "entity_coreference": [], "event_coreference": [], "tokens": ["In", "this", "work,", "we", "compare", "the", "two", "main", "approaches", "for", "adaptive", "inference,", "Early-Exit", "and", "Multi-Model,", "when", "training", "data", "is", "limited.", "First,", "we", "observe", "that", "for", "models", "with", "the", "same", "architecture", "and", "size,", "individual", "Multi-Model", "classifiers", "outperform", "their", "Early-Exit", "counterparts", "by", "an", "average", "of", "2.3%.", "We", "show", "that", "this", "gap", "is", "caused", "by", "Early-Exit", "classifiers", "sharing", "model", "parameters", "during", "training,", "resulting", "in", "conflicting", "gradient", "updates", "of", "model", "weights.", "We", "find", "that", "despite", "this", "gap,", "Early-Exit", "still", "provides", "a", "better", "speed-accuracy", "trade-off", "due", "to", "the", "overhead", "of", "the", "Multi-Model", "approach.", "To", "address", "these", "issues,", "we", "propose", "SWEET", "(Separating", "Weights", "for", "Early-Exit", "Transformers)", "an", "Early-Exit", "fine-tuning", "method", "that", "assigns", "each", "classifier", "its", "own", "set", "of", "unique", "model", "weights,", "not", "updated", "by", "other", "classifiers."], "pieces": ["In", "this", "work", ",", "we", "comp", "are", "the", "two", "main", "appro", "aches", "for", "adapt", "ive", "in", "ference", ",", "Early", "-", "Exit", "and", "Multi", "-", "Model", ",", "when", "training", "data", "is", "limited", ".", "First", ",", "we", "ob", "ser", "ve", "that", "for", "models", "with", "the", "same", "arch", "itect", "ure", "and", "size", ",", "individual", "Multi", "-", "Model", "class", "ifiers", "out", "per", "form", "their", "Early", "-", "Exit", "counter", "parts", "by", "an", "average", "of", "2", ".", "3", "%.", "We", "show", "that", "this", "gap", "is", "ca", "used", "by", "Early", "-", "Exit", "class", "ifiers", "sharing", "model", "param", "eters", "during", "training", ",", "result", "ing", "in", "conf", "lic", "ting", "gradient", "up", "dates", "of", "model", "weights", ".", "We", "find", "that", "despite", "this", "gap", ",", "Early", "-", "Exit", "still", "prov", "ides", "a", "better", "speed", "-", "acc", "uracy", "trade", "-", "off", "due", "to", "the", "over", "head", "of", "the", "Multi", "-", "Model", "appro", "ach", ".", "To", "address", "these", "issues", ",", "we", "pro", "pose", "S", "WE", "ET", "(", "Sep", "ar", "ating", "We", "ights", "for", "Early", "-", "Exit", "Transform", "ers", ")", "an", "Early", "-", "Exit", "fine", "-", "tun", "ing", "method", "that", "ass", "ign", "s", "each", "class", "ifier", "its", "own", "set", "of", "unique", "model", "weights", ",", "not", "updated", "by", "other", "class", "ifiers", "."], "token_lens": [1, 1, 2, 1, 2, 1, 1, 1, 2, 1, 2, 3, 3, 1, 4, 1, 1, 1, 1, 2, 2, 1, 3, 1, 1, 1, 1, 1, 1, 3, 1, 2, 1, 3, 2, 3, 1, 3, 2, 1, 1, 1, 1, 4, 1, 1, 1, 1, 1, 1, 2, 1, 3, 2, 1, 1, 2, 1, 2, 2, 1, 3, 1, 2, 1, 1, 2, 1, 1, 1, 1, 1, 2, 3, 1, 2, 1, 1, 4, 3, 1, 1, 1, 2, 1, 1, 3, 3, 1, 1, 1, 2, 1, 2, 3, 4, 2, 1, 3, 3, 1, 3, 4, 1, 1, 3, 1, 2, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 3], "sentence": "In this work, we compare the two main approaches for adaptive inference, Early-Exit and Multi-Model, when training data is limited. First, we observe that for models with the same architecture and size, individual Multi-Model classifiers outperform their Early-Exit counterparts by an average of 2.3%. We show that this gap is caused by Early-Exit classifiers sharing model parameters during training, resulting in conflicting gradient updates of model weights. We find that despite this gap, Early-Exit still provides a better speed-accuracy trade-off due to the overhead of the Multi-Model approach. To address these issues, we propose SWEET (Separating Weights for Early-Exit Transformers) an Early-Exit fine-tuning method that assigns each classifier its own set of unique model weights, not updated by other classifiers.", "sentence_starts": [0]}
{"doc_id": "cscw_23_P_236", "sent_id": "cscw_23_P_236-0", "entity_mentions": [{"id": "cscw_23_P_236-0-E0", "text": "successful human-AI collaboration", "start": 5, "end": 8, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "cscw_23_P_236-0-E1", "text": "human decision-makers often lack understanding of what information an AI model has access to, in relation to themselves", "start": 23, "end": 41, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "cscw_23_P_236-0-E2", "text": "There are few available guidelines regarding how to effectively communicate about unobservables: features that may influence the outcome, but which are unavailable to the model", "start": 41, "end": 66, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "cscw_23_P_236-0-E3", "text": "humans to productively integrate complementary sources of information into AI-informed decisions", "start": 9, "end": 20, "entity_type": "UNK", "mention_type": "UNK"}], "relation_mentions": [], "event_mentions": [{"event_type": "Background/Introduction", "id": "cscw_23_P_236-0-EV0", "trigger": {"text": "requires", "start": 8, "end": 9}, "arguments": [{"entity_id": "cscw_23_P_236-0-E0", "text": "successful human-AI collaboration", "role": "Agent"}, {"entity_id": "cscw_23_P_236-0-E1", "text": "human decision-makers often lack understanding of what information an AI model has access to, in relation to themselves", "role": "Challenge"}, {"entity_id": "cscw_23_P_236-0-E2", "text": "There are few available guidelines regarding how to effectively communicate about unobservables: features that may influence the outcome, but which are unavailable to the model", "role": "Challenge"}, {"entity_id": "cscw_23_P_236-0-E3", "text": "humans to productively integrate complementary sources of information into AI-informed decisions", "role": "PrimaryObject"}]}], "entity_coreference": [], "event_coreference": [], "tokens": ["In", "many", "real", "world", "contexts,", "successful", "human-AI", "collaboration", "requires", "humans", "to", "productively", "integrate", "complementary", "sources", "of", "information", "into", "AI-informed", "decisions.", "However,", "in", "practice,", "human", "decision-makers", "often", "lack", "understanding", "of", "what", "information", "an", "AI", "model", "has", "access", "to,", "in", "relation", "to", "themselves.", "There", "are", "few", "available", "guidelines", "regarding", "how", "to", "effectively", "communicate", "about", "unobservables:", "features", "that", "may", "influence", "the", "outcome,", "but", "which", "are", "unavailable", "to", "the", "model."], "pieces": ["In", "many", "real", "world", "context", "s", ",", "successful", "human", "-", "AI", "coll", "abor", "ation", "requires", "humans", "to", "product", "ively", "integ", "rate", "com", "plement", "ary", "s", "ources", "of", "information", "into", "AI", "-", "informed", "dec", "isions", ".", "However", ",", "in", "practice", ",", "human", "dec", "ision", "-", "makers", "often", "l", "ack", "under", "standing", "of", "what", "information", "an", "AI", "model", "has", "access", "to", ",", "in", "relation", "to", "them", "selves", ".", "There", "are", "few", "available", "gu", "idelines", "reg", "arding", "how", "to", "effect", "ively", "commun", "icate", "about", "un", "ob", "serv", "ables", ":", "features", "that", "may", "inf", "luence", "the", "out", "come", ",", "but", "which", "are", "un", "available", "to", "the", "model", "."], "token_lens": [1, 1, 1, 1, 3, 1, 3, 3, 1, 1, 1, 2, 2, 3, 2, 1, 1, 1, 3, 3, 2, 1, 2, 1, 4, 1, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 3, 1, 1, 1, 1, 2, 2, 1, 1, 2, 2, 1, 5, 1, 1, 1, 2, 1, 3, 1, 1, 1, 2, 1, 1, 2], "sentence": "In many real world contexts, successful human-AI collaboration requires humans to productively integrate complementary sources of information into AI-informed decisions. However, in practice, human decision-makers often lack understanding of what information an AI model has access to, in relation to themselves. There are few available guidelines regarding how to effectively communicate about unobservables: features that may influence the outcome, but which are unavailable to the model.", "sentence_starts": [0]}
{"doc_id": "ACL_23_P_22", "sent_id": "ACL_23_P_22-0", "entity_mentions": [{"id": "ACL_23_P_22-0-E0", "text": "Classic approaches to content moderation typically", "start": 0, "end": 6, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_22-0-E1", "text": "While rules are easily customizable and intuitive for humans to interpret", "start": 14, "end": 25, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_22-0-E2", "text": "Recent advances in deep learning have demonstrated the promise of using highly effective deep neural models to overcome these challenges.", "start": 47, "end": 67, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_22-0-E3", "text": "they are inherently fragile and lack the flexibility or robustness needed to moderate the vast amount of undesirable content found online today", "start": 25, "end": 47, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_22-0-E4", "text": "despite the improved performance, these data-driven models lack transparency and explainability, often leading to mistrust from everyday users and a lack of adoption by many platforms", "start": 68, "end": 94, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_22-0-E5", "text": "a rule-based heuristic approach", "start": 7, "end": 11, "entity_type": "UNK", "mention_type": "UNK"}], "relation_mentions": [], "event_mentions": [{"event_type": "Background/Introduction", "id": "ACL_23_P_22-0-EV0", "trigger": {"text": "apply", "start": 6, "end": 7}, "arguments": [{"entity_id": "ACL_23_P_22-0-E0", "text": "Classic approaches to content moderation typically", "role": "Agent"}, {"entity_id": "ACL_23_P_22-0-E1", "text": "While rules are easily customizable and intuitive for humans to interpret", "role": "Context"}, {"entity_id": "ACL_23_P_22-0-E2", "text": "Recent advances in deep learning have demonstrated the promise of using highly effective deep neural models to overcome these challenges.", "role": "Context"}, {"entity_id": "ACL_23_P_22-0-E3", "text": "they are inherently fragile and lack the flexibility or robustness needed to moderate the vast amount of undesirable content found online today", "role": "Challenge"}, {"entity_id": "ACL_23_P_22-0-E4", "text": "despite the improved performance, these data-driven models lack transparency and explainability, often leading to mistrust from everyday users and a lack of adoption by many platforms", "role": "Challenge"}, {"entity_id": "ACL_23_P_22-0-E5", "text": "a rule-based heuristic approach", "role": "PrimaryObject"}]}], "entity_coreference": [], "event_coreference": [], "tokens": ["Classic", "approaches", "to", "content", "moderation", "typically", "apply", "a", "rule-based", "heuristic", "approach", "to", "flag", "content.", "While", "rules", "are", "easily", "customizable", "and", "intuitive", "for", "humans", "to", "interpret,", "they", "are", "inherently", "fragile", "and", "lack", "the", "flexibility", "or", "robustness", "needed", "to", "moderate", "the", "vast", "amount", "of", "undesirable", "content", "found", "online", "today.", "Recent", "advances", "in", "deep", "learning", "have", "demonstrated", "the", "promise", "of", "using", "highly", "effective", "deep", "neural", "models", "to", "overcome", "these", "challenges.", "However,", "despite", "the", "improved", "performance,", "these", "data-driven", "models", "lack", "transparency", "and", "explainability,", "often", "leading", "to", "mistrust", "from", "everyday", "users", "and", "a", "lack", "of", "adoption", "by", "many", "platforms."], "pieces": ["Classic", "appro", "aches", "to", "content", "mod", "er", "ation", "typically", "apply", "a", "rule", "-", "based", "he", "uristic", "appro", "ach", "to", "flag", "content", ".", "While", "rules", "are", "eas", "ily", "custom", "izable", "and", "intuitive", "for", "humans", "to", "interpret", ",", "they", "are", "in", "herent", "ly", "fr", "ag", "ile", "and", "l", "ack", "the", "flex", "ibility", "or", "rob", "ust", "ness", "needed", "to", "moderate", "the", "v", "ast", "amount", "of", "und", "es", "irable", "content", "found", "online", "today", ".", "Recent", "adv", "ances", "in", "deep", "learning", "have", "demon", "str", "ated", "the", "prom", "ise", "of", "using", "highly", "effective", "deep", "ne", "ural", "models", "to", "over", "come", "these", "chall", "enges", ".", "However", ",", "despite", "the", "impro", "ved", "performance", ",", "these", "data", "-", "driven", "models", "l", "ack", "trans", "parency", "and", "expl", "ain", "ability", ",", "often", "leading", "to", "mist", "rust", "from", "every", "day", "users", "and", "a", "l", "ack", "of", "ad", "option", "by", "many", "platform", "s", "."], "token_lens": [1, 2, 1, 1, 3, 1, 1, 1, 3, 2, 2, 1, 1, 2, 1, 1, 1, 2, 2, 1, 1, 1, 1, 1, 2, 1, 1, 3, 3, 1, 2, 1, 2, 1, 3, 1, 1, 1, 1, 2, 1, 1, 3, 1, 1, 1, 2, 1, 2, 1, 1, 1, 1, 3, 1, 2, 1, 1, 1, 1, 1, 2, 1, 1, 2, 1, 3, 2, 1, 1, 2, 2, 1, 3, 1, 2, 2, 1, 4, 1, 1, 1, 2, 1, 2, 1, 1, 1, 2, 1, 2, 1, 1, 3], "sentence": "Classic approaches to content moderation typically apply a rule-based heuristic approach to flag content. While rules are easily customizable and intuitive for humans to interpret, they are inherently fragile and lack the flexibility or robustness needed to moderate the vast amount of undesirable content found online today. Recent advances in deep learning have demonstrated the promise of using highly effective deep neural models to overcome these challenges. However, despite the improved performance, these data-driven models lack transparency and explainability, often leading to mistrust from everyday users and a lack of adoption by many platforms.", "sentence_starts": [0]}
{"doc_id": "cscw_23_P_97", "sent_id": "cscw_23_P_97-0", "entity_mentions": [{"id": "cscw_23_P_97-0-E0", "text": "recent works", "start": 24, "end": 26, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "cscw_23_P_97-0-E1", "text": "experimental studies suggest that crowds might be able to accurately assess the veracity of social media content", "start": 41, "end": 58, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "cscw_23_P_97-0-E2", "text": "The spread of misinformation on social media is a pressing societal problem that platforms, policymakers, and researchers continue to grapple with", "start": 0, "end": 21, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "cscw_23_P_97-0-E3", "text": "an understanding of how crowd fact-checked (mis-)information spreads is missing", "start": 58, "end": 68, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "cscw_23_P_97-0-E4", "text": "non-expert fact-checkers in the crowd", "start": 30, "end": 35, "entity_type": "UNK", "mention_type": "UNK"}], "relation_mentions": [], "event_mentions": [{"event_type": "Background/Introduction", "id": "cscw_23_P_97-0-EV0", "trigger": {"text": "have proposed to employ", "start": 26, "end": 30}, "arguments": [{"entity_id": "cscw_23_P_97-0-E0", "text": "recent works", "role": "Agent"}, {"entity_id": "cscw_23_P_97-0-E1", "text": "experimental studies suggest that crowds might be able to accurately assess the veracity of social media content", "role": "Context"}, {"entity_id": "cscw_23_P_97-0-E2", "text": "The spread of misinformation on social media is a pressing societal problem that platforms, policymakers, and researchers continue to grapple with", "role": "Challenge"}, {"entity_id": "cscw_23_P_97-0-E3", "text": "an understanding of how crowd fact-checked (mis-)information spreads is missing", "role": "Challenge"}, {"entity_id": "cscw_23_P_97-0-E4", "text": "non-expert fact-checkers in the crowd", "role": "PrimaryObject"}]}], "entity_coreference": [], "event_coreference": [], "tokens": ["The", "spread", "of", "misinformation", "on", "social", "media", "is", "a", "pressing", "societal", "problem", "that", "platforms,", "policymakers,", "and", "researchers", "continue", "to", "grapple", "with.", "As", "a", "countermeasure,", "recent", "works", "have", "proposed", "to", "employ", "non-expert", "fact-checkers", "in", "the", "crowd", "to", "fact-check", "social", "media", "content.", "While", "experimental", "studies", "suggest", "that", "crowds", "might", "be", "able", "to", "accurately", "assess", "the", "veracity", "of", "social", "media", "content,", "an", "understanding", "of", "how", "crowd", "fact-checked", "(mis-)information", "spreads", "is", "missing."], "pieces": ["The", "spread", "of", "mis", "information", "on", "social", "media", "is", "a", "press", "ing", "soc", "ietal", "problem", "that", "platform", "s", ",", "p", "olic", "ym", "akers", ",", "and", "re", "se", "ar", "chers", "continue", "to", "gra", "pp", "le", "with", ".", "As", "a", "counter", "me", "asure", ",", "recent", "works", "have", "prop", "osed", "to", "employ", "non", "-", "ex", "pert", "fact", "-", "check", "ers", "in", "the", "c", "rowd", "to", "fact", "-", "check", "social", "media", "content", ".", "While", "exper", "imental", "stud", "ies", "suggest", "that", "c", "rowd", "s", "might", "be", "able", "to", "acc", "ur", "ately", "ass", "ess", "the", "ver", "acity", "of", "social", "media", "content", ",", "an", "under", "standing", "of", "how", "c", "rowd", "fact", "-", "checked", "(", "mis", "-)", "information", "sp", "reads", "is", "missing", "."], "token_lens": [1, 1, 1, 2, 1, 1, 1, 1, 1, 2, 2, 1, 1, 3, 5, 1, 4, 1, 1, 3, 2, 1, 1, 4, 1, 1, 1, 2, 1, 1, 4, 4, 1, 1, 2, 1, 3, 1, 1, 2, 1, 2, 2, 1, 1, 3, 1, 1, 1, 1, 3, 2, 1, 2, 1, 1, 1, 2, 1, 2, 1, 1, 2, 3, 4, 2, 1, 2], "sentence": "The spread of misinformation on social media is a pressing societal problem that platforms, policymakers, and researchers continue to grapple with. As a countermeasure, recent works have proposed to employ non-expert fact-checkers in the crowd to fact-check social media content. While experimental studies suggest that crowds might be able to accurately assess the veracity of social media content, an understanding of how crowd fact-checked (mis-)information spreads is missing.", "sentence_starts": [0]}
{"doc_id": "bioinfo_23_P_135", "sent_id": "bioinfo_23_P_135-2", "entity_mentions": [{"id": "bioinfo_23_P_135-2-E0", "text": "We", "start": 0, "end": 1, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "bioinfo_23_P_135-2-E1", "text": "our model achieves relative improvements of 1.33%, 1.20% and 2.03% in Jaccard, F1 and PR-AUC scores, respectively, compared to state-of-the-art methods", "start": 10, "end": 31, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "bioinfo_23_P_135-2-E2", "text": "the proposed DAPSNet", "start": 2, "end": 5, "entity_type": "UNK", "mention_type": "UNK"}], "relation_mentions": [], "event_mentions": [{"event_type": "Results/Findings", "id": "bioinfo_23_P_135-2-EV0", "trigger": {"text": "evaluate", "start": 1, "end": 2}, "arguments": [{"entity_id": "bioinfo_23_P_135-2-E0", "text": "We", "role": "Agent"}, {"entity_id": "bioinfo_23_P_135-2-E1", "text": "our model achieves relative improvements of 1.33%, 1.20% and 2.03% in Jaccard, F1 and PR-AUC scores, respectively, compared to state-of-the-art methods", "role": "Results"}, {"entity_id": "bioinfo_23_P_135-2-E2", "text": "the proposed DAPSNet", "role": "PrimaryObject"}]}], "entity_coreference": [], "event_coreference": [], "tokens": ["We", "evaluate", "the", "proposed", "DAPSNet", "on", "the", "public", "MIMIC-III", "dataset,", "our", "model", "achieves", "relative", "improvements", "of", "1.33%,", "1.20%", "and", "2.03%", "in", "Jaccard,", "F1", "and", "PR-AUC", "scores,", "respectively,", "compared", "to", "state-of-the-art", "methods."], "pieces": ["We", "evaluate", "the", "prop", "osed", "D", "APS", "Net", "on", "the", "public", "M", "IM", "IC", "-", "III", "dat", "as", "et", ",", "our", "model", "ach", "ieves", "relative", "improve", "ments", "of", "1", ".", "33", "%,", "1", ".", "20", "%", "and", "2", ".", "03", "%", "in", "J", "acc", "ard", ",", "F", "1", "and", "PR", "-", "A", "UC", "sc", "ores", ",", "respect", "ively", ",", "comp", "ared", "to", "state", "-", "of", "-", "the", "-", "art", "method", "s", "."], "token_lens": [1, 1, 1, 2, 3, 1, 1, 1, 5, 4, 1, 1, 2, 1, 2, 1, 4, 4, 1, 4, 1, 4, 2, 1, 4, 3, 3, 2, 1, 7, 3], "sentence": "We evaluate the proposed DAPSNet on the public MIMIC-III dataset, our model achieves relative improvements of 1.33%, 1.20% and 2.03% in Jaccard, F1 and PR-AUC scores, respectively, compared to state-of-the-art methods.", "sentence_starts": [0]}
{"doc_id": "cscw_23_P_223", "sent_id": "cscw_23_P_223-2", "entity_mentions": [{"id": "cscw_23_P_223-2-E0", "text": "we", "start": 7, "end": 8, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "cscw_23_P_223-2-E1", "text": "The paper offers two main contributions", "start": 0, "end": 6, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "cscw_23_P_223-2-E2", "text": "for future design activities in the area of data work practices", "start": 42, "end": 53, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "cscw_23_P_223-2-E3", "text": "a data journey theoretical framework", "start": 9, "end": 14, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "cscw_23_P_223-2-E4", "text": "we use these insights to outline a set of tensions", "start": 32, "end": 42, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "cscw_23_P_223-2-E5", "text": "it is useful as a unit of analysis for uncovering tensions in data-oriented activities", "start": 17, "end": 31, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "cscw_23_P_223-2-E6", "text": "a data journey theoretical framework", "start": 9, "end": 14, "entity_type": "UNK", "mention_type": "UNK"}], "relation_mentions": [], "event_mentions": [{"event_type": "Results/Findings", "id": "cscw_23_P_223-2-EV0", "trigger": {"text": "develop", "start": 8, "end": 9}, "arguments": [{"entity_id": "cscw_23_P_223-2-E0", "text": "we", "role": "Agent"}, {"entity_id": "cscw_23_P_223-2-E1", "text": "The paper offers two main contributions", "role": "Context"}, {"entity_id": "cscw_23_P_223-2-E2", "text": "for future design activities in the area of data work practices", "role": "Purpose"}, {"entity_id": "cscw_23_P_223-2-E3", "text": "a data journey theoretical framework", "role": "Method"}, {"entity_id": "cscw_23_P_223-2-E4", "text": "we use these insights to outline a set of tensions", "role": "Method"}, {"entity_id": "cscw_23_P_223-2-E5", "text": "it is useful as a unit of analysis for uncovering tensions in data-oriented activities", "role": "Results"}, {"entity_id": "cscw_23_P_223-2-E6", "text": "a data journey theoretical framework", "role": "PrimaryObject"}]}], "entity_coreference": [], "event_coreference": [], "tokens": ["The", "paper", "offers", "two", "main", "contributions.", "First,", "we", "develop", "a", "data", "journey", "theoretical", "framework", "and", "show", "that", "it", "is", "useful", "as", "a", "unit", "of", "analysis", "for", "uncovering", "tensions", "in", "data-oriented", "activities.", "Second,", "we", "use", "these", "insights", "to", "outline", "a", "set", "of", "tensions", "for", "future", "design", "activities", "in", "the", "area", "of", "data", "work", "practices"], "pieces": ["The", "paper", "off", "ers", "two", "main", "cont", "ribut", "ions", ".", "First", ",", "we", "develop", "a", "data", "j", "ourney", "the", "oret", "ical", "framework", "and", "show", "that", "it", "is", "use", "ful", "as", "a", "unit", "of", "analysis", "for", "un", "cover", "ing", "t", "ensions", "in", "data", "-", "oriented", "activ", "ities", ".", "Second", ",", "we", "use", "these", "ins", "ights", "to", "out", "line", "a", "set", "of", "t", "ensions", "for", "future", "design", "activ", "ities", "in", "the", "area", "of", "data", "work", "pract", "ices"], "token_lens": [1, 1, 2, 1, 1, 4, 2, 1, 1, 1, 1, 2, 3, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 3, 2, 1, 3, 3, 2, 1, 1, 1, 2, 1, 2, 1, 1, 1, 2, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 2], "sentence": "The paper offers two main contributions. First, we develop a data journey theoretical framework and show that it is useful as a unit of analysis for uncovering tensions in data-oriented activities. Second, we use these insights to outline a set of tensions for future design activities in the area of data work practices", "sentence_starts": [0]}
{"doc_id": "ACL_23_P_247", "sent_id": "ACL_23_P_247-1", "entity_mentions": [{"id": "ACL_23_P_247-1-E0", "text": "we", "start": 5, "end": 6, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_247-1-E1", "text": "To collect such disappearing contexts", "start": 0, "end": 5, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_247-1-E2", "text": "=we actually build large-scale Twitter datasets of disappearing entities.=", "start": 23, "end": 32, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_247-1-E3", "text": "To ensure robust detection in noisy environments, we refine pretrained word embeddings for the detection model on microblog streams in a timely manner", "start": 32, "end": 55, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_247-1-E4", "text": "time-sensitive distant supervision", "start": 7, "end": 10, "entity_type": "UNK", "mention_type": "UNK"}], "relation_mentions": [], "event_mentions": [{"event_type": "Methods/Approach", "id": "ACL_23_P_247-1-EV0", "trigger": {"text": "design", "start": 6, "end": 7}, "arguments": [{"entity_id": "ACL_23_P_247-1-E0", "text": "we", "role": "Agent"}, {"entity_id": "ACL_23_P_247-1-E1", "text": "To collect such disappearing contexts", "role": "Purpose"}, {"entity_id": "ACL_23_P_247-1-E2", "text": "=we actually build large-scale Twitter datasets of disappearing entities.=", "role": "Method"}, {"entity_id": "ACL_23_P_247-1-E3", "text": "To ensure robust detection in noisy environments, we refine pretrained word embeddings for the detection model on microblog streams in a timely manner", "role": "Method"}, {"entity_id": "ACL_23_P_247-1-E4", "text": "time-sensitive distant supervision", "role": "PrimaryObject"}]}], "entity_coreference": [], "event_coreference": [], "tokens": ["To", "collect", "such", "disappearing", "contexts,", "we", "design", "time-sensitive", "distant", "supervision,", "which", "utilizes", "entities", "from", "the", "knowledge", "base", "and", "time-series", "posts.", "Using", "this", "method,", "we", "actually", "build", "large-scale", "Twitter", "datasets", "of", "disappearing", "entities.", "To", "ensure", "robust", "detection", "in", "noisy", "environments,", "we", "refine", "pretrained", "word", "embeddings", "for", "the", "detection", "model", "on", "microblog", "streams", "in", "a", "timely", "manner."], "pieces": ["To", "collect", "such", "dis", "app", "earing", "context", "s", ",", "we", "design", "time", "-", "sensitive", "d", "istant", "super", "vision", ",", "which", "util", "izes", "ent", "ities", "from", "the", "knowledge", "base", "and", "time", "-", "series", "posts", ".", "Using", "this", "method", ",", "we", "actually", "build", "large", "-", "scale", "Twitter", "dat", "as", "ets", "of", "dis", "app", "earing", "ent", "ities", ".", "To", "ens", "ure", "rob", "ust", "det", "ection", "in", "no", "isy", "en", "vironments", ",", "we", "ref", "ine", "pret", "rained", "word", "embed", "d", "ings", "for", "the", "det", "ection", "model", "on", "micro", "blog", "stream", "s", "in", "a", "time", "ly", "man", "ner", "."], "token_lens": [1, 1, 1, 3, 3, 1, 1, 3, 2, 3, 1, 2, 2, 1, 1, 1, 1, 1, 3, 2, 1, 1, 2, 1, 1, 1, 3, 1, 3, 1, 3, 3, 1, 2, 2, 2, 1, 2, 3, 1, 2, 2, 1, 3, 1, 1, 2, 1, 1, 2, 2, 1, 1, 2, 3], "sentence": "To collect such disappearing contexts, we design time-sensitive distant supervision, which utilizes entities from the knowledge base and time-series posts. Using this method, we actually build large-scale Twitter datasets of disappearing entities. To ensure robust detection in noisy environments, we refine pretrained word embeddings for the detection model on microblog streams in a timely manner.", "sentence_starts": [0]}
{"doc_id": "cscw_23_P_179", "sent_id": "cscw_23_P_179-1", "entity_mentions": [{"id": "cscw_23_P_179-1-E0", "text": "We", "start": 0, "end": 1, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "cscw_23_P_179-1-E1", "text": "explore how these perceptions change when assessments are obviously biased against a subgroup", "start": 22, "end": 35, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "cscw_23_P_179-1-E2", "text": "we conducted an online experiment that manipulated how biased risk assessments are in a loan repayment task, and reported the assessments as being made either by a statistical model or a human analyst", "start": 38, "end": 71, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "cscw_23_P_179-1-E3", "text": "whether individual algorithmic assessments are perceived to be more or less accurate, fair, and interpretable than identical human assessments", "start": 2, "end": 21, "entity_type": "UNK", "mention_type": "UNK"}], "relation_mentions": [], "event_mentions": [{"event_type": "Methods/Approach", "id": "cscw_23_P_179-1-EV0", "trigger": {"text": "investigate", "start": 1, "end": 2}, "arguments": [{"entity_id": "cscw_23_P_179-1-E0", "text": "We", "role": "Agent"}, {"entity_id": "cscw_23_P_179-1-E1", "text": "explore how these perceptions change when assessments are obviously biased against a subgroup", "role": "Context"}, {"entity_id": "cscw_23_P_179-1-E2", "text": "we conducted an online experiment that manipulated how biased risk assessments are in a loan repayment task, and reported the assessments as being made either by a statistical model or a human analyst", "role": "Method"}, {"entity_id": "cscw_23_P_179-1-E3", "text": "whether individual algorithmic assessments are perceived to be more or less accurate, fair, and interpretable than identical human assessments", "role": "PrimaryObject"}]}], "entity_coreference": [], "event_coreference": [], "tokens": ["We", "investigate", "whether", "individual", "algorithmic", "assessments", "are", "perceived", "to", "be", "more", "or", "less", "accurate,", "fair,", "and", "interpretable", "than", "identical", "human", "assessments,", "and", "explore", "how", "these", "perceptions", "change", "when", "assessments", "are", "obviously", "biased", "against", "a", "subgroup.", "To", "this", "end,", "we", "conducted", "an", "online", "experiment", "that", "manipulated", "how", "biased", "risk", "assessments", "are", "in", "a", "loan", "repayment", "task,", "and", "reported", "the", "assessments", "as", "being", "made", "either", "by", "a", "statistical", "model", "or", "a", "human", "analyst."], "pieces": ["We", "invest", "igate", "whether", "individual", "al", "gorith", "mic", "ass", "ess", "ments", "are", "per", "ceived", "to", "be", "more", "or", "less", "acc", "urate", ",", "fair", ",", "and", "interpret", "able", "than", "ident", "ical", "human", "ass", "ess", "ments", ",", "and", "expl", "ore", "how", "these", "per", "ceptions", "change", "when", "ass", "ess", "ments", "are", "ob", "viously", "biased", "against", "a", "sub", "group", ".", "To", "this", "end", ",", "we", "conduct", "ed", "an", "online", "exper", "iment", "that", "man", "ip", "ulated", "how", "biased", "risk", "ass", "ess", "ments", "are", "in", "a", "lo", "an", "rep", "ay", "ment", "task", ",", "and", "reported", "the", "ass", "ess", "ments", "as", "being", "made", "either", "by", "a", "stat", "istical", "model", "or", "a", "human", "an", "alyst", "."], "token_lens": [1, 2, 1, 1, 3, 3, 1, 2, 1, 1, 1, 1, 1, 3, 2, 1, 2, 1, 2, 1, 4, 1, 2, 1, 1, 2, 1, 1, 3, 1, 2, 1, 1, 1, 3, 1, 1, 2, 1, 2, 1, 1, 2, 1, 3, 1, 1, 1, 3, 1, 1, 1, 2, 3, 2, 1, 1, 1, 3, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 3], "sentence": "We investigate whether individual algorithmic assessments are perceived to be more or less accurate, fair, and interpretable than identical human assessments, and explore how these perceptions change when assessments are obviously biased against a subgroup. To this end, we conducted an online experiment that manipulated how biased risk assessments are in a loan repayment task, and reported the assessments as being made either by a statistical model or a human analyst.", "sentence_starts": [0]}
{"doc_id": "ACL_23_P_828", "sent_id": "ACL_23_P_828-1", "entity_mentions": [{"id": "ACL_23_P_828-1-E0", "text": "we", "start": 3, "end": 4, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_828-1-E1", "text": "to evaluate the temporal reasoning capability of large language models", "start": 10, "end": 20, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_828-1-E2", "text": "Our dataset includes questions of three temporal reasoning levels", "start": 20, "end": 29, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_828-1-E3", "text": "we also propose a novel learning framework to improve the temporal reasoning capability of large language models, based on temporal span extraction and time-sensitive reinforcement learning", "start": 31, "end": 57, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_828-1-E4", "text": "a comprehensive probing dataset TempReason", "start": 5, "end": 10, "entity_type": "UNK", "mention_type": "UNK"}], "relation_mentions": [], "event_mentions": [{"event_type": "Methods/Approach", "id": "ACL_23_P_828-1-EV0", "trigger": {"text": "introduce", "start": 4, "end": 5}, "arguments": [{"entity_id": "ACL_23_P_828-1-E0", "text": "we", "role": "Agent"}, {"entity_id": "ACL_23_P_828-1-E1", "text": "to evaluate the temporal reasoning capability of large language models", "role": "Purpose"}, {"entity_id": "ACL_23_P_828-1-E2", "text": "Our dataset includes questions of three temporal reasoning levels", "role": "Method"}, {"entity_id": "ACL_23_P_828-1-E3", "text": "we also propose a novel learning framework to improve the temporal reasoning capability of large language models, based on temporal span extraction and time-sensitive reinforcement learning", "role": "Method"}, {"entity_id": "ACL_23_P_828-1-E4", "text": "a comprehensive probing dataset TempReason", "role": "PrimaryObject"}]}], "entity_coreference": [], "event_coreference": [], "tokens": ["In", "this", "paper,", "we", "introduce", "a", "comprehensive", "probing", "dataset", "TempReason", "to", "evaluate", "the", "temporal", "reasoning", "capability", "of", "large", "language", "models.", "Our", "dataset", "includes", "questions", "of", "three", "temporal", "reasoning", "levels.", "In", "addition,", "we", "also", "propose", "a", "novel", "learning", "framework", "to", "improve", "the", "temporal", "reasoning", "capability", "of", "large", "language", "models,", "based", "on", "temporal", "span", "extraction", "and", "time-sensitive", "reinforcement", "learning."], "pieces": ["In", "this", "paper", ",", "we", "introdu", "ce", "a", "com", "pre", "hens", "ive", "pro", "bing", "dat", "as", "et", "Temp", "Reason", "to", "evaluate", "the", "tem", "poral", "reason", "ing", "cap", "ability", "of", "large", "language", "models", ".", "Our", "dat", "as", "et", "includes", "quest", "ions", "of", "three", "tem", "poral", "reason", "ing", "levels", ".", "In", "add", "ition", ",", "we", "also", "pro", "pose", "a", "no", "vel", "learning", "framework", "to", "improve", "the", "tem", "poral", "reason", "ing", "cap", "ability", "of", "large", "language", "models", ",", "based", "on", "tem", "poral", "span", "ext", "raction", "and", "time", "-", "sensitive", "re", "in", "forcement", "learning", "."], "token_lens": [1, 1, 2, 1, 2, 1, 4, 2, 3, 2, 1, 1, 1, 2, 2, 2, 1, 1, 1, 2, 1, 3, 1, 2, 1, 1, 2, 2, 2, 1, 3, 1, 1, 2, 1, 2, 1, 1, 1, 1, 1, 2, 2, 2, 1, 1, 1, 2, 1, 1, 2, 1, 2, 1, 3, 3, 2], "sentence": "In this paper, we introduce a comprehensive probing dataset TempReason to evaluate the temporal reasoning capability of large language models. Our dataset includes questions of three temporal reasoning levels. In addition, we also propose a novel learning framework to improve the temporal reasoning capability of large language models, based on temporal span extraction and time-sensitive reinforcement learning.", "sentence_starts": [0]}
{"doc_id": "ACL_23_P_697", "sent_id": "ACL_23_P_697-0", "entity_mentions": [{"id": "ACL_23_P_697-0-E0", "text": "there", "start": 5, "end": 6, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_697-0-E1", "text": "These PLMs have achieved impressive results on these benchmarks, even surpassing human performance in some cases.", "start": 42, "end": 58, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_697-0-E2", "text": "This has led to claims of superhuman capabilities and the provocative idea that certain tasks have been solved", "start": 58, "end": 76, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_697-0-E3", "text": "a significant focus in Natural Language Processing (NLP)", "start": 8, "end": 16, "entity_type": "UNK", "mention_type": "UNK"}], "relation_mentions": [], "event_mentions": [{"event_type": "Background/Introduction", "id": "ACL_23_P_697-0-EV0", "trigger": {"text": "has been", "start": 6, "end": 8}, "arguments": [{"entity_id": "ACL_23_P_697-0-E0", "text": "there", "role": "Agent"}, {"entity_id": "ACL_23_P_697-0-E1", "text": "These PLMs have achieved impressive results on these benchmarks, even surpassing human performance in some cases.", "role": "Context"}, {"entity_id": "ACL_23_P_697-0-E2", "text": "This has led to claims of superhuman capabilities and the provocative idea that certain tasks have been solved", "role": "Implications"}, {"entity_id": "ACL_23_P_697-0-E3", "text": "a significant focus in Natural Language Processing (NLP)", "role": "PrimaryObject"}]}], "entity_coreference": [], "event_coreference": [], "tokens": ["In", "the", "last", "five", "years,", "there", "has", "been", "a", "significant", "focus", "in", "Natural", "Language", "Processing", "(NLP)", "on", "developing", "larger", "Pretrained", "Language", "Models", "(PLMs)", "and", "introducing", "benchmarks", "such", "as", "SuperGLUE", "and", "SQuAD", "to", "measure", "their", "abilities", "in", "language", "understanding,", "reasoning,", "and", "reading", "comprehension.", "These", "PLMs", "have", "achieved", "impressive", "results", "on", "these", "benchmarks,", "even", "surpassing", "human", "performance", "in", "some", "cases.", "This", "has", "led", "to", "claims", "of", "superhuman", "capabilities", "and", "the", "provocative", "idea", "that", "certain", "tasks", "have", "been", "solved."], "pieces": ["In", "the", "last", "five", "years", ",", "there", "has", "been", "a", "significant", "focus", "in", "Natural", "Language", "Process", "ing", "(", "N", "LP", ")", "on", "develop", "ing", "larg", "er", "P", "ret", "rained", "Language", "Mod", "els", "(", "PL", "Ms", ")", "and", "introdu", "cing", "bench", "marks", "such", "as", "Super", "GL", "UE", "and", "S", "Qu", "AD", "to", "me", "asure", "their", "abilities", "in", "language", "under", "standing", ",", "reason", "ing", ",", "and", "reading", "com", "pre", "hens", "ion", ".", "These", "PL", "Ms", "have", "ach", "ieved", "imp", "ressive", "results", "on", "these", "bench", "marks", ",", "even", "sur", "pass", "ing", "human", "performance", "in", "some", "cases", ".", "This", "has", "led", "to", "claim", "s", "of", "super", "human", "cap", "abilities", "and", "the", "prov", "ocative", "ide", "a", "that", "certain", "t", "asks", "have", "been", "s", "olved", "."], "token_lens": [1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 4, 1, 2, 2, 3, 1, 2, 4, 1, 2, 2, 1, 1, 3, 1, 3, 1, 2, 1, 1, 1, 1, 3, 3, 1, 1, 5, 1, 2, 1, 2, 2, 1, 1, 1, 3, 1, 3, 1, 1, 1, 1, 2, 1, 1, 1, 1, 2, 1, 2, 2, 1, 1, 2, 2, 1, 1, 2, 1, 1, 3], "sentence": "In the last five years, there has been a significant focus in Natural Language Processing (NLP) on developing larger Pretrained Language Models (PLMs) and introducing benchmarks such as SuperGLUE and SQuAD to measure their abilities in language understanding, reasoning, and reading comprehension. These PLMs have achieved impressive results on these benchmarks, even surpassing human performance in some cases. This has led to claims of superhuman capabilities and the provocative idea that certain tasks have been solved.", "sentence_starts": [0]}
{"doc_id": "bioinfo_23_P_703", "sent_id": "bioinfo_23_P_703-1", "entity_mentions": [{"id": "bioinfo_23_P_703-1-E0", "text": "we", "start": 1, "end": 2, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "bioinfo_23_P_703-1-E1", "text": "This package provides streamlined functionality for raw data filtering, integration, normalization, transformation, and visualization", "start": 19, "end": 33, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "bioinfo_23_P_703-1-E2", "text": "optima", "start": 3, "end": 4, "entity_type": "UNK", "mention_type": "UNK"}], "relation_mentions": [], "event_mentions": [{"event_type": "Methods/Approach", "id": "bioinfo_23_P_703-1-EV0", "trigger": {"text": "present", "start": 2, "end": 3}, "arguments": [{"entity_id": "bioinfo_23_P_703-1-E0", "text": "we", "role": "Agent"}, {"entity_id": "bioinfo_23_P_703-1-E1", "text": "This package provides streamlined functionality for raw data filtering, integration, normalization, transformation, and visualization", "role": "Method"}, {"entity_id": "bioinfo_23_P_703-1-E2", "text": "optima", "role": "PrimaryObject"}]}], "entity_coreference": [], "event_coreference": [], "tokens": ["Here,", "we", "present", "optima,", "an", "R", "package", "for", "the", "processing", "and", "analysis", "of", "data", "generated", "from", "the", "Tapestri", "platform.", "This", "package", "provides", "streamlined", "functionality", "for", "raw", "data", "filtering,", "integration,", "normalization,", "transformation,", "and", "visualization."], "pieces": ["Here", ",", "we", "present", "opt", "ima", ",", "an", "R", "package", "for", "the", "processing", "and", "analysis", "of", "data", "generated", "from", "the", "T", "apest", "ri", "platform", ".", "This", "package", "prov", "ides", "stream", "lined", "function", "ality", "for", "raw", "data", "fil", "tering", ",", "integ", "ration", ",", "normal", "ization", ",", "trans", "formation", ",", "and", "visual", "ization", "."], "token_lens": [2, 1, 1, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 3, 2, 1, 1, 2, 2, 2, 1, 1, 1, 3, 3, 3, 3, 1, 3], "sentence": "Here, we present optima, an R package for the processing and analysis of data generated from the Tapestri platform. This package provides streamlined functionality for raw data filtering, integration, normalization, transformation, and visualization.", "sentence_starts": [0]}
{"doc_id": "cscw_23_P_222", "sent_id": "cscw_23_P_222-0", "entity_mentions": [{"id": "cscw_23_P_222-0-E0", "text": "Technology", "start": 0, "end": 1, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "cscw_23_P_222-0-E1", "text": "it is not clear how that mediation is occurring, to what end, and what technologies are implicated", "start": 16, "end": 33, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "cscw_23_P_222-0-E2", "text": "an increasingly pivotal role", "start": 2, "end": 6, "entity_type": "UNK", "mention_type": "UNK"}], "relation_mentions": [], "event_mentions": [{"event_type": "Background/Introduction", "id": "cscw_23_P_222-0-EV0", "trigger": {"text": "plays", "start": 1, "end": 2}, "arguments": [{"entity_id": "cscw_23_P_222-0-E0", "text": "Technology", "role": "Agent"}, {"entity_id": "cscw_23_P_222-0-E1", "text": "it is not clear how that mediation is occurring, to what end, and what technologies are implicated", "role": "Challenge"}, {"entity_id": "cscw_23_P_222-0-E2", "text": "an increasingly pivotal role", "role": "PrimaryObject"}]}], "entity_coreference": [], "event_coreference": [], "tokens": ["Technology", "plays", "an", "increasingly", "pivotal", "role", "in", "mediating", "mental", "health", "support", "in", "people's", "everyday", "lives.", "However,", "it", "is", "not", "clear", "how", "that", "mediation", "is", "occurring,", "to", "what", "end,", "and", "what", "technologies", "are", "implicated."], "pieces": ["Technology", "plays", "an", "increasing", "ly", "p", "iv", "otal", "role", "in", "medi", "ating", "mental", "health", "support", "in", "people", "'s", "every", "day", "l", "ives", ".", "However", ",", "it", "is", "not", "clear", "how", "that", "medi", "ation", "is", "occ", "urring", ",", "to", "what", "end", ",", "and", "what", "techn", "ologies", "are", "impl", "icated", "."], "token_lens": [1, 1, 1, 2, 3, 1, 1, 2, 1, 1, 1, 1, 2, 2, 3, 2, 1, 1, 1, 1, 1, 1, 2, 1, 3, 1, 1, 2, 1, 1, 2, 1, 3], "sentence": "Technology plays an increasingly pivotal role in mediating mental health support in people's everyday lives. However, it is not clear how that mediation is occurring, to what end, and what technologies are implicated.", "sentence_starts": [0]}
{"doc_id": "cscw_23_P_28", "sent_id": "cscw_23_P_28-1", "entity_mentions": [{"id": "cscw_23_P_28-1-E0", "text": "we", "start": 4, "end": 5, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "cscw_23_P_28-1-E1", "text": "theoretically guided by four modern HCI perspectives, namely psychological need satisfaction, activity theory, embodied interaction, and media equation theory", "start": 33, "end": 52, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "cscw_23_P_28-1-E2", "text": "We analyzed the interview and observation data using a reflexive thematic analysis and identified four themes", "start": 52, "end": 68, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "cscw_23_P_28-1-E3", "text": "a qualitative study", "start": 6, "end": 9, "entity_type": "UNK", "mention_type": "UNK"}], "relation_mentions": [], "event_mentions": [{"event_type": "Methods/Approach", "id": "cscw_23_P_28-1-EV0", "trigger": {"text": "report", "start": 5, "end": 6}, "arguments": [{"entity_id": "cscw_23_P_28-1-E0", "text": "we", "role": "Agent"}, {"entity_id": "cscw_23_P_28-1-E1", "text": "theoretically guided by four modern HCI perspectives, namely psychological need satisfaction, activity theory, embodied interaction, and media equation theory", "role": "Context"}, {"entity_id": "cscw_23_P_28-1-E2", "text": "We analyzed the interview and observation data using a reflexive thematic analysis and identified four themes", "role": "Method"}, {"entity_id": "cscw_23_P_28-1-E3", "text": "a qualitative study", "role": "PrimaryObject"}]}], "entity_coreference": [], "event_coreference": [], "tokens": ["In", "the", "present", "paper,", "we", "report", "a", "qualitative", "study", "including", "130", "hours", "of", "participant", "observation", "on", "acute", "care", "teams", "and", "retrospective", "interviews", "with", "nine", "anesthesiologists", "on", "their", "experiences", "with", "technology.", "Our", "approach", "is", "theoretically", "guided", "by", "four", "modern", "HCI", "perspectives,", "namely", "psychological", "need", "satisfaction,", "activity", "theory,", "embodied", "interaction,", "and", "media", "equation", "theory.", "We", "analyzed", "the", "interview", "and", "observation", "data", "using", "a", "reflexive", "thematic", "analysis", "and", "identified", "four", "themes."], "pieces": ["In", "the", "present", "paper", ",", "we", "report", "a", "qual", "itative", "study", "including", "130", "hours", "of", "particip", "ant", "ob", "serv", "ation", "on", "ac", "ute", "care", "te", "ams", "and", "ret", "ro", "spective", "inter", "views", "with", "nine", "an", "esthes", "i", "ologists", "on", "their", "exper", "iences", "with", "technology", ".", "Our", "appro", "ach", "is", "the", "oret", "ically", "guided", "by", "four", "modern", "HC", "I", "pers", "pect", "ives", ",", "name", "ly", "psych", "ological", "need", "s", "atisf", "action", ",", "activity", "the", "ory", ",", "emb", "odied", "inter", "action", ",", "and", "media", "equ", "ation", "the", "ory", ".", "We", "analy", "zed", "the", "inter", "view", "and", "ob", "serv", "ation", "data", "using", "a", "ref", "lex", "ive", "the", "matic", "analysis", "and", "identified", "four", "the", "mes", "."], "token_lens": [1, 1, 1, 2, 1, 1, 1, 2, 1, 1, 1, 1, 1, 2, 3, 1, 2, 1, 2, 1, 3, 2, 1, 1, 4, 1, 1, 2, 1, 2, 1, 2, 1, 3, 1, 1, 1, 1, 2, 4, 2, 2, 1, 4, 1, 3, 2, 3, 1, 1, 2, 3, 1, 2, 1, 2, 1, 3, 1, 1, 1, 3, 2, 1, 1, 1, 1, 3], "sentence": "In the present paper, we report a qualitative study including 130 hours of participant observation on acute care teams and retrospective interviews with nine anesthesiologists on their experiences with technology. Our approach is theoretically guided by four modern HCI perspectives, namely psychological need satisfaction, activity theory, embodied interaction, and media equation theory. We analyzed the interview and observation data using a reflexive thematic analysis and identified four themes.", "sentence_starts": [0]}
{"doc_id": "cscw_23_P_252", "sent_id": "cscw_23_P_252-0", "entity_mentions": [{"id": "cscw_23_P_252-0-E0", "text": "Understanding support seekers' experiences", "start": 21, "end": 25, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "cscw_23_P_252-0-E1", "text": "Digital platforms, including online forums and helplines, have emerged as avenues of support for caregivers suffering from postpartum mental health distress", "start": 0, "end": 21, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "cscw_23_P_252-0-E2", "text": "crucial insight into caregivers' needs", "start": 32, "end": 37, "entity_type": "UNK", "mention_type": "UNK"}], "relation_mentions": [], "event_mentions": [{"event_type": "Background/Introduction", "id": "cscw_23_P_252-0-EV0", "trigger": {"text": "could provide", "start": 30, "end": 32}, "arguments": [{"entity_id": "cscw_23_P_252-0-E0", "text": "Understanding support seekers' experiences", "role": "Agent"}, {"entity_id": "cscw_23_P_252-0-E1", "text": "Digital platforms, including online forums and helplines, have emerged as avenues of support for caregivers suffering from postpartum mental health distress", "role": "Context"}, {"entity_id": "cscw_23_P_252-0-E2", "text": "crucial insight into caregivers' needs", "role": "PrimaryObject"}]}], "entity_coreference": [], "event_coreference": [], "tokens": ["Digital", "platforms,", "including", "online", "forums", "and", "helplines,", "have", "emerged", "as", "avenues", "of", "support", "for", "caregivers", "suffering", "from", "postpartum", "mental", "health", "distress.", "Understanding", "support", "seekers'", "experiences", "as", "shared", "on", "these", "platforms", "could", "provide", "crucial", "insight", "into", "caregivers'", "needs", "during", "this", "vulnerable", "time."], "pieces": ["Digital", "platform", "s", ",", "including", "online", "forums", "and", "hel", "pl", "ines", ",", "have", "emer", "ged", "as", "aven", "ues", "of", "support", "for", "care", "g", "ivers", "suff", "ering", "from", "post", "part", "um", "mental", "health", "dist", "ress", ".", "Understanding", "support", "seekers", "'", "exper", "iences", "as", "shared", "on", "these", "platform", "s", "could", "prov", "ide", "cru", "cial", "ins", "ight", "into", "care", "g", "ivers", "'", "needs", "during", "this", "v", "ulnerable", "time", "."], "token_lens": [1, 3, 1, 1, 1, 1, 4, 1, 2, 1, 2, 1, 1, 1, 3, 2, 1, 3, 1, 1, 3, 1, 1, 2, 2, 1, 1, 1, 1, 2, 1, 2, 2, 2, 1, 4, 1, 1, 1, 2, 2], "sentence": "Digital platforms, including online forums and helplines, have emerged as avenues of support for caregivers suffering from postpartum mental health distress. Understanding support seekers' experiences as shared on these platforms could provide crucial insight into caregivers' needs during this vulnerable time.", "sentence_starts": [0]}
{"doc_id": "cscw_23_P_225", "sent_id": "cscw_23_P_225-0", "entity_mentions": [{"id": "cscw_23_P_225-0-E0", "text": "Youth", "start": 0, "end": 1, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "cscw_23_P_225-0-E1", "text": "users have played active roles in surfacing and mitigating harm from algorithmic bias", "start": 32, "end": 45, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "cscw_23_P_225-0-E2", "text": "Despite being frequent users of AI, youth have been under-explored as potential contributors and stakeholders to the future of AI", "start": 45, "end": 65, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "cscw_23_P_225-0-E3", "text": "AI can cause harm on small and large scales, especially for those underrepresented in tech fields", "start": 15, "end": 31, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "cscw_23_P_225-0-E4", "text": "technology", "start": 3, "end": 4, "entity_type": "UNK", "mention_type": "UNK"}], "relation_mentions": [], "event_mentions": [{"event_type": "Background/Introduction", "id": "cscw_23_P_225-0-EV0", "trigger": {"text": "use", "start": 2, "end": 3}, "arguments": [{"entity_id": "cscw_23_P_225-0-E0", "text": "Youth", "role": "Agent"}, {"entity_id": "cscw_23_P_225-0-E1", "text": "users have played active roles in surfacing and mitigating harm from algorithmic bias", "role": "Context"}, {"entity_id": "cscw_23_P_225-0-E2", "text": "Despite being frequent users of AI, youth have been under-explored as potential contributors and stakeholders to the future of AI", "role": "Context"}, {"entity_id": "cscw_23_P_225-0-E3", "text": "AI can cause harm on small and large scales, especially for those underrepresented in tech fields", "role": "Challenge"}, {"entity_id": "cscw_23_P_225-0-E4", "text": "technology", "role": "PrimaryObject"}]}], "entity_coreference": [], "event_coreference": [], "tokens": ["Youth", "regularly", "use", "technology", "driven", "by", "artificial", "intelligence", "(AI).", "However,", "it", "is", "increasingly", "well-known", "that", "AI", "can", "cause", "harm", "on", "small", "and", "large", "scales,", "especially", "for", "those", "underrepresented", "in", "tech", "fields.", "Recently,", "users", "have", "played", "active", "roles", "in", "surfacing", "and", "mitigating", "harm", "from", "algorithmic", "bias.", "Despite", "being", "frequent", "users", "of", "AI,", "youth", "have", "been", "under-explored", "as", "potential", "contributors", "and", "stakeholders", "to", "the", "future", "of", "AI."], "pieces": ["Y", "outh", "regular", "ly", "use", "technology", "driven", "by", "art", "ificial", "intelligence", "(", "AI", ").", "However", ",", "it", "is", "increasing", "ly", "well", "-", "known", "that", "AI", "can", "cause", "harm", "on", "small", "and", "large", "sc", "ales", ",", "especially", "for", "those", "under", "represented", "in", "tech", "fields", ".", "Recently", ",", "users", "have", "played", "active", "ro", "les", "in", "sur", "facing", "and", "mit", "igating", "harm", "from", "al", "gorith", "mic", "b", "ias", ".", "Despite", "being", "f", "requent", "users", "of", "AI", ",", "y", "outh", "have", "been", "under", "-", "expl", "ored", "as", "pot", "ential", "cont", "ribut", "ors", "and", "st", "ake", "holders", "to", "the", "future", "of", "AI", "."], "token_lens": [2, 2, 1, 1, 1, 1, 2, 1, 3, 2, 1, 1, 2, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 3, 1, 1, 1, 2, 1, 1, 2, 2, 1, 1, 1, 1, 2, 1, 2, 1, 2, 1, 1, 3, 3, 1, 1, 2, 1, 1, 2, 2, 1, 1, 4, 1, 2, 3, 1, 3, 1, 1, 1, 1, 2], "sentence": "Youth regularly use technology driven by artificial intelligence (AI). However, it is increasingly well-known that AI can cause harm on small and large scales, especially for those underrepresented in tech fields. Recently, users have played active roles in surfacing and mitigating harm from algorithmic bias. Despite being frequent users of AI, youth have been under-explored as potential contributors and stakeholders to the future of AI.", "sentence_starts": [0]}
{"doc_id": "bioinfo_23_P_502", "sent_id": "bioinfo_23_P_502-0", "entity_mentions": [{"id": "bioinfo_23_P_502-0-E0", "text": "Structural variation (SV)", "start": 0, "end": 3, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "bioinfo_23_P_502-0-E1", "text": "One crucial problem when analyzing and comparing SVs in several individuals is their accurate genotyping, that is determining whether a described SV is present or absent in one sequenced individual, and if present, in how many copies", "start": 21, "end": 58, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "bioinfo_23_P_502-0-E2", "text": "There are only a few methods dedicated to SV genotyping with long-read data, and all either suffer from a bias toward the reference allele by not representing equally all alleles, or have difficulties genotyping close or overlapping SVs due to a linear representation of the alleles", "start": 58, "end": 104, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "bioinfo_23_P_502-0-E3", "text": "a class of genetic diversity", "start": 4, "end": 9, "entity_type": "UNK", "mention_type": "UNK"}], "relation_mentions": [], "event_mentions": [{"event_type": "Background/Introduction", "id": "bioinfo_23_P_502-0-EV0", "trigger": {"text": "is", "start": 3, "end": 4}, "arguments": [{"entity_id": "bioinfo_23_P_502-0-E0", "text": "Structural variation (SV)", "role": "Agent"}, {"entity_id": "bioinfo_23_P_502-0-E1", "text": "One crucial problem when analyzing and comparing SVs in several individuals is their accurate genotyping, that is determining whether a described SV is present or absent in one sequenced individual, and if present, in how many copies", "role": "Challenge"}, {"entity_id": "bioinfo_23_P_502-0-E2", "text": "There are only a few methods dedicated to SV genotyping with long-read data, and all either suffer from a bias toward the reference allele by not representing equally all alleles, or have difficulties genotyping close or overlapping SVs due to a linear representation of the alleles", "role": "Challenge"}, {"entity_id": "bioinfo_23_P_502-0-E3", "text": "a class of genetic diversity", "role": "PrimaryObject"}]}], "entity_coreference": [], "event_coreference": [], "tokens": ["Structural", "variation", "(SV)", "is", "a", "class", "of", "genetic", "diversity", "whose", "importance", "is", "increasingly", "revealed", "by", "genome", "resequencing,", "especially", "with", "long-read", "technologies.", "One", "crucial", "problem", "when", "analyzing", "and", "comparing", "SVs", "in", "several", "individuals", "is", "their", "accurate", "genotyping,", "that", "is", "determining", "whether", "a", "described", "SV", "is", "present", "or", "absent", "in", "one", "sequenced", "individual,", "and", "if", "present,", "in", "how", "many", "copies.", "There", "are", "only", "a", "few", "methods", "dedicated", "to", "SV", "genotyping", "with", "long-read", "data,", "and", "all", "either", "suffer", "from", "a", "bias", "toward", "the", "reference", "allele", "by", "not", "representing", "equally", "all", "alleles,", "or", "have", "difficulties", "genotyping", "close", "or", "overlapping", "SVs", "due", "to", "a", "linear", "representation", "of", "the", "alleles."], "pieces": ["Struct", "ural", "vari", "ation", "(", "S", "V", ")", "is", "a", "class", "of", "gen", "etic", "d", "iversity", "whose", "import", "ance", "is", "increasing", "ly", "reve", "aled", "by", "gen", "ome", "re", "sequ", "encing", ",", "especially", "with", "long", "-", "read", "techn", "ologies", ".", "One", "cru", "cial", "problem", "when", "analy", "zing", "and", "comp", "aring", "S", "Vs", "in", "sever", "al", "individual", "s", "is", "their", "acc", "urate", "gen", "otyp", "ing", ",", "that", "is", "d", "etermin", "ing", "whether", "a", "described", "S", "V", "is", "present", "or", "abs", "ent", "in", "one", "sequ", "enced", "individual", ",", "and", "if", "present", ",", "in", "how", "many", "cop", "ies", ".", "There", "are", "only", "a", "few", "method", "s", "ded", "icated", "to", "S", "V", "gen", "otyp", "ing", "with", "long", "-", "read", "data", ",", "and", "all", "either", "s", "uffer", "from", "a", "b", "ias", "t", "oward", "the", "reference", "alle", "le", "by", "not", "represent", "ing", "equ", "ally", "all", "alle", "les", ",", "or", "have", "diff", "icult", "ies", "gen", "otyp", "ing", "close", "or", "over", "l", "apping", "S", "Vs", "due", "to", "a", "linear", "represent", "ation", "of", "the", "alle", "les", "."], "token_lens": [2, 2, 4, 1, 1, 1, 1, 2, 2, 1, 2, 1, 2, 2, 1, 2, 4, 1, 1, 3, 3, 1, 2, 1, 1, 2, 1, 2, 2, 1, 2, 2, 1, 1, 2, 4, 1, 1, 3, 1, 1, 1, 2, 1, 1, 1, 2, 1, 1, 2, 2, 1, 1, 2, 1, 1, 1, 3, 1, 1, 1, 1, 1, 2, 2, 1, 2, 3, 1, 3, 2, 1, 1, 1, 2, 1, 1, 2, 2, 1, 1, 2, 1, 1, 2, 2, 1, 3, 1, 1, 3, 3, 1, 1, 3, 2, 1, 1, 1, 1, 2, 1, 1, 3], "sentence": "Structural variation (SV) is a class of genetic diversity whose importance is increasingly revealed by genome resequencing, especially with long-read technologies. One crucial problem when analyzing and comparing SVs in several individuals is their accurate genotyping, that is determining whether a described SV is present or absent in one sequenced individual, and if present, in how many copies. There are only a few methods dedicated to SV genotyping with long-read data, and all either suffer from a bias toward the reference allele by not representing equally all alleles, or have difficulties genotyping close or overlapping SVs due to a linear representation of the alleles.", "sentence_starts": [0]}
{"doc_id": "bioinfo_23_P_159", "sent_id": "bioinfo_23_P_159-0", "entity_mentions": [{"id": "bioinfo_23_P_159-0-E0", "text": "Protein and peptide engineering", "start": 0, "end": 4, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "bioinfo_23_P_159-0-E1", "text": "Helices are both abundant structural feature in proteins and comprise a major portion of bioactive peptides", "start": 18, "end": 34, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "bioinfo_23_P_159-0-E2", "text": "Precise design of helices for binding or biological activity is still a challenging problem", "start": 34, "end": 48, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "bioinfo_23_P_159-0-E3", "text": "an essential field", "start": 6, "end": 9, "entity_type": "UNK", "mention_type": "UNK"}], "relation_mentions": [], "event_mentions": [{"event_type": "Background/Introduction", "id": "bioinfo_23_P_159-0-EV0", "trigger": {"text": "has become", "start": 4, "end": 6}, "arguments": [{"entity_id": "bioinfo_23_P_159-0-E0", "text": "Protein and peptide engineering", "role": "Agent"}, {"entity_id": "bioinfo_23_P_159-0-E1", "text": "Helices are both abundant structural feature in proteins and comprise a major portion of bioactive peptides", "role": "Context"}, {"entity_id": "bioinfo_23_P_159-0-E2", "text": "Precise design of helices for binding or biological activity is still a challenging problem", "role": "Challenge"}, {"entity_id": "bioinfo_23_P_159-0-E3", "text": "an essential field", "role": "PrimaryObject"}]}], "entity_coreference": [], "event_coreference": [], "tokens": ["Protein", "and", "peptide", "engineering", "has", "become", "an", "essential", "field", "in", "biomedicine", "with", "therapeutics,", "diagnostics", "and", "synthetic", "biology", "applications.", "Helices", "are", "both", "abundant", "structural", "feature", "in", "proteins", "and", "comprise", "a", "major", "portion", "of", "bioactive", "peptides.", "Precise", "design", "of", "helices", "for", "binding", "or", "biological", "activity", "is", "still", "a", "challenging", "problem."], "pieces": ["P", "rotein", "and", "pe", "pt", "ide", "engineering", "has", "bec", "ome", "an", "essential", "field", "in", "bi", "omed", "ic", "ine", "with", "ther", "ape", "utics", ",", "diagn", "ostics", "and", "sy", "nt", "hetic", "biology", "app", "lic", "ations", ".", "Hel", "ices", "are", "both", "ab", "und", "ant", "struct", "ural", "feature", "in", "pro", "te", "ins", "and", "com", "prise", "a", "major", "portion", "of", "b", "io", "active", "pe", "pt", "ides", ".", "Pre", "cise", "design", "of", "he", "lic", "es", "for", "binding", "or", "bi", "ological", "activity", "is", "still", "a", "chall", "eng", "ing", "problem", "."], "token_lens": [2, 1, 3, 1, 1, 2, 1, 1, 1, 1, 4, 1, 4, 2, 1, 3, 1, 4, 2, 1, 1, 3, 2, 1, 1, 3, 1, 2, 1, 1, 1, 1, 3, 4, 2, 1, 1, 3, 1, 1, 1, 2, 1, 1, 1, 1, 3, 2], "sentence": "Protein and peptide engineering has become an essential field in biomedicine with therapeutics, diagnostics and synthetic biology applications. Helices are both abundant structural feature in proteins and comprise a major portion of bioactive peptides. Precise design of helices for binding or biological activity is still a challenging problem.", "sentence_starts": [0]}
{"doc_id": "cscw_23_P_123", "sent_id": "cscw_23_P_123-0", "entity_mentions": [{"id": "cscw_23_P_123-0-E0", "text": "Livestreams", "start": 0, "end": 1, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "cscw_23_P_123-0-E1", "text": "viewership practices have also become varied and diverse: livestreams are used for interactive entertainment, social companionship, and multi-perspective spectatorship for music festivals and sporting events", "start": 21, "end": 46, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "cscw_23_P_123-0-E2", "text": "At the premier in-person gaming livestream event, Games Done Quick (GDQ), attendees engage in a variety of different viewership practices across different event spaces where the livestream is projected on large stage screens, onto walls as peripheral displays, and routed to televisions in hotel venue rooms", "start": 46, "end": 92, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "cscw_23_P_123-0-E3", "text": "web and mobile-based platforms", "start": 5, "end": 9, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "cscw_23_P_123-0-E4", "text": "into products", "start": 9, "end": 11, "entity_type": "UNK", "mention_type": "UNK"}], "relation_mentions": [], "event_mentions": [{"event_type": "Background/Introduction", "id": "cscw_23_P_123-0-EV0", "trigger": {"text": "are now ubiquitous-moving beyond", "start": 1, "end": 5}, "arguments": [{"entity_id": "cscw_23_P_123-0-E0", "text": "Livestreams", "role": "Agent"}, {"entity_id": "cscw_23_P_123-0-E1", "text": "viewership practices have also become varied and diverse: livestreams are used for interactive entertainment, social companionship, and multi-perspective spectatorship for music festivals and sporting events", "role": "Context"}, {"entity_id": "cscw_23_P_123-0-E2", "text": "At the premier in-person gaming livestream event, Games Done Quick (GDQ), attendees engage in a variety of different viewership practices across different event spaces where the livestream is projected on large stage screens, onto walls as peripheral displays, and routed to televisions in hotel venue rooms", "role": "Context"}, {"entity_id": "cscw_23_P_123-0-E3", "text": "web and mobile-based platforms", "role": "PrimaryObject"}, {"entity_id": "cscw_23_P_123-0-E4", "text": "into products", "role": "SecondaryObject"}]}], "entity_coreference": [], "event_coreference": [], "tokens": ["Livestreams", "are", "now", "ubiquitous-moving", "beyond", "web", "and", "mobile-based", "platforms", "into", "products", "such", "as", "fitness", "machines", "and", "smart", "home", "assistants.", "As", "such,", "viewership", "practices", "have", "also", "become", "varied", "and", "diverse:", "livestreams", "are", "used", "for", "interactive", "entertainment,", "social", "companionship,", "and", "multi-perspective", "spectatorship", "for", "music", "festivals", "and", "sporting", "events.", "At", "the", "premier", "in-person", "gaming", "livestream", "event,", "Games", "Done", "Quick", "(GDQ),", "attendees", "engage", "in", "a", "variety", "of", "different", "viewership", "practices", "across", "different", "event", "spaces", "where", "the", "livestream", "is", "projected", "on", "large", "stage", "screens,", "onto", "walls", "as", "peripheral", "displays,", "and", "routed", "to", "televisions", "in", "hotel", "venue", "rooms."], "pieces": ["L", "iv", "est", "ream", "s", "are", "now", "ub", "iqu", "itous", "-", "moving", "be", "yond", "web", "and", "mobile", "-", "based", "platform", "s", "into", "products", "such", "as", "f", "itness", "m", "ach", "ines", "and", "smart", "home", "ass", "ist", "ants", ".", "As", "such", ",", "view", "ership", "pract", "ices", "have", "also", "bec", "ome", "var", "ied", "and", "d", "iverse", ":", "liv", "est", "ream", "s", "are", "used", "for", "inter", "active", "ent", "ertain", "ment", ",", "social", "compan", "ions", "hip", ",", "and", "multi", "-", "pers", "pect", "ive", "spect", "ators", "hip", "for", "music", "fest", "ivals", "and", "s", "porting", "events", ".", "At", "the", "prem", "ier", "in", "-", "person", "gaming", "liv", "est", "ream", "event", ",", "Games", "Done", "Quick", "(", "GD", "Q", "),", "att", "end", "ees", "eng", "age", "in", "a", "var", "iety", "of", "different", "view", "ership", "pract", "ices", "ac", "ross", "different", "event", "sp", "aces", "where", "the", "liv", "est", "ream", "is", "project", "ed", "on", "large", "stage", "sc", "reens", ",", "onto", "w", "alls", "as", "per", "ipher", "al", "dis", "plays", ",", "and", "r", "outed", "to", "te", "lev", "isions", "in", "hot", "el", "venue", "rooms", "."], "token_lens": [5, 1, 1, 5, 2, 1, 1, 3, 2, 1, 1, 1, 1, 2, 3, 1, 1, 1, 4, 1, 2, 2, 2, 1, 1, 2, 2, 1, 3, 4, 1, 1, 1, 2, 4, 1, 4, 1, 5, 3, 1, 1, 2, 1, 2, 2, 1, 1, 2, 3, 1, 3, 2, 1, 1, 1, 4, 3, 2, 1, 1, 2, 1, 1, 2, 2, 2, 1, 1, 2, 1, 1, 3, 1, 2, 1, 1, 1, 3, 1, 2, 1, 3, 3, 1, 2, 1, 3, 1, 2, 1, 2], "sentence": "Livestreams are now ubiquitous-moving beyond web and mobile-based platforms into products such as fitness machines and smart home assistants. As such, viewership practices have also become varied and diverse: livestreams are used for interactive entertainment, social companionship, and multi-perspective spectatorship for music festivals and sporting events. At the premier in-person gaming livestream event, Games Done Quick (GDQ), attendees engage in a variety of different viewership practices across different event spaces where the livestream is projected on large stage screens, onto walls as peripheral displays, and routed to televisions in hotel venue rooms.", "sentence_starts": [0]}
{"doc_id": "ACL_23_P_725", "sent_id": "ACL_23_P_725-3", "entity_mentions": [{"id": "ACL_23_P_725-3-E0", "text": "We", "start": 0, "end": 1, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_725-3-E1", "text": "outperforms existing methods in defending against BITE", "start": 15, "end": 22, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_725-3-E2", "text": "generalizes well to handling other backdoor attacks", "start": 23, "end": 30, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_725-3-E3", "text": "a defense method", "start": 3, "end": 6, "entity_type": "UNK", "mention_type": "UNK"}], "relation_mentions": [], "event_mentions": [{"event_type": "Conclusions/Implications", "id": "ACL_23_P_725-3-EV0", "trigger": {"text": "propose", "start": 2, "end": 3}, "arguments": [{"entity_id": "ACL_23_P_725-3-E0", "text": "We", "role": "Agent"}, {"entity_id": "ACL_23_P_725-3-E1", "text": "outperforms existing methods in defending against BITE", "role": "Results"}, {"entity_id": "ACL_23_P_725-3-E2", "text": "generalizes well to handling other backdoor attacks", "role": "Results"}, {"entity_id": "ACL_23_P_725-3-E3", "text": "a defense method", "role": "PrimaryObject"}]}], "entity_coreference": [], "event_coreference": [], "tokens": ["We", "further", "propose", "a", "defense", "method", "named", "DeBITE", "based", "on", "potential", "trigger", "word", "removal,", "which", "outperforms", "existing", "methods", "in", "defending", "against", "BITE", "and", "generalizes", "well", "to", "handling", "other", "backdoor", "attacks."], "pieces": ["We", "f", "urther", "pro", "pose", "a", "defense", "method", "named", "De", "B", "ITE", "based", "on", "pot", "ential", "trigger", "word", "rem", "oval", ",", "which", "out", "per", "forms", "existing", "method", "s", "in", "def", "ending", "against", "B", "ITE", "and", "general", "izes", "well", "to", "hand", "ling", "other", "back", "door", "attacks", "."], "token_lens": [1, 2, 2, 1, 1, 1, 1, 3, 1, 1, 2, 1, 1, 3, 1, 3, 1, 2, 1, 2, 1, 2, 1, 2, 1, 1, 2, 1, 2, 2], "sentence": "We further propose a defense method named DeBITE based on potential trigger word removal, which outperforms existing methods in defending against BITE and generalizes well to handling other backdoor attacks.", "sentence_starts": [0]}
{"doc_id": "ACL_23_P_653", "sent_id": "ACL_23_P_653-0", "entity_mentions": [{"id": "ACL_23_P_653-0-E0", "text": "The BLOOM model", "start": 0, "end": 3, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_653-0-E1", "text": "To extend the benefits of BLOOM to other languages without incurring prohibitively large costs, it is desirable to adapt BLOOM to new languages not seen during pretraining", "start": 19, "end": 46, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_653-0-E2", "text": "its pretraining was limited to 46 languages", "start": 12, "end": 19, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_653-0-E3", "text": "a large publicly available multilingual language model", "start": 4, "end": 11, "entity_type": "UNK", "mention_type": "UNK"}], "relation_mentions": [], "event_mentions": [{"event_type": "Background/Introduction", "id": "ACL_23_P_653-0-EV0", "trigger": {"text": "is", "start": 3, "end": 4}, "arguments": [{"entity_id": "ACL_23_P_653-0-E0", "text": "The BLOOM model", "role": "Agent"}, {"entity_id": "ACL_23_P_653-0-E1", "text": "To extend the benefits of BLOOM to other languages without incurring prohibitively large costs, it is desirable to adapt BLOOM to new languages not seen during pretraining", "role": "Purpose"}, {"entity_id": "ACL_23_P_653-0-E2", "text": "its pretraining was limited to 46 languages", "role": "Challenge"}, {"entity_id": "ACL_23_P_653-0-E3", "text": "a large publicly available multilingual language model", "role": "PrimaryObject"}]}], "entity_coreference": [], "event_coreference": [], "tokens": ["The", "BLOOM", "model", "is", "a", "large", "publicly", "available", "multilingual", "language", "model,", "but", "its", "pretraining", "was", "limited", "to", "46", "languages.", "To", "extend", "the", "benefits", "of", "BLOOM", "to", "other", "languages", "without", "incurring", "prohibitively", "large", "costs,", "it", "is", "desirable", "to", "adapt", "BLOOM", "to", "new", "languages", "not", "seen", "during", "pretraining."], "pieces": ["The", "BL", "O", "OM", "model", "is", "a", "large", "public", "ly", "available", "mult", "ilingual", "language", "model", ",", "but", "its", "pret", "raining", "was", "limited", "to", "46", "l", "anguages", ".", "To", "ext", "end", "the", "benef", "its", "of", "BL", "O", "OM", "to", "other", "l", "anguages", "without", "inc", "urring", "pro", "hib", "itive", "ly", "large", "cost", "s", ",", "it", "is", "des", "irable", "to", "adapt", "BL", "O", "OM", "to", "new", "l", "anguages", "not", "seen", "during", "pret", "raining", "."], "token_lens": [1, 3, 1, 1, 1, 1, 2, 1, 2, 1, 2, 1, 1, 2, 1, 1, 1, 1, 3, 1, 2, 1, 2, 1, 3, 1, 1, 2, 1, 2, 4, 1, 3, 1, 1, 2, 1, 1, 3, 1, 1, 2, 1, 1, 1, 3], "sentence": "The BLOOM model is a large publicly available multilingual language model, but its pretraining was limited to 46 languages. To extend the benefits of BLOOM to other languages without incurring prohibitively large costs, it is desirable to adapt BLOOM to new languages not seen during pretraining.", "sentence_starts": [0]}
{"doc_id": "bioinfo_23_P_646", "sent_id": "bioinfo_23_P_646-0", "entity_mentions": [{"id": "bioinfo_23_P_646-0-E0", "text": "Previous studies", "start": 21, "end": 23, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "bioinfo_23_P_646-0-E1", "text": "Automated extraction of participants, intervention, comparison/control, and outcome (PICO) from the randomized controlled trial (RCT) abstracts is important for evidence synthesis", "start": 0, "end": 21, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "bioinfo_23_P_646-0-E2", "text": "the performance is not optimal due to the complexity of PICO information in RCT abstracts and the challenges involved in their annotation", "start": 37, "end": 59, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "bioinfo_23_P_646-0-E3", "text": "the feasibility of applying natural language processing (NLP) for PICO extraction", "start": 25, "end": 36, "entity_type": "UNK", "mention_type": "UNK"}], "relation_mentions": [], "event_mentions": [{"event_type": "Background/Introduction", "id": "bioinfo_23_P_646-0-EV0", "trigger": {"text": "demonstrated", "start": 24, "end": 25}, "arguments": [{"entity_id": "bioinfo_23_P_646-0-E0", "text": "Previous studies", "role": "Agent"}, {"entity_id": "bioinfo_23_P_646-0-E1", "text": "Automated extraction of participants, intervention, comparison/control, and outcome (PICO) from the randomized controlled trial (RCT) abstracts is important for evidence synthesis", "role": "Context"}, {"entity_id": "bioinfo_23_P_646-0-E2", "text": "the performance is not optimal due to the complexity of PICO information in RCT abstracts and the challenges involved in their annotation", "role": "Challenge"}, {"entity_id": "bioinfo_23_P_646-0-E3", "text": "the feasibility of applying natural language processing (NLP) for PICO extraction", "role": "PrimaryObject"}]}], "entity_coreference": [], "event_coreference": [], "tokens": ["Automated", "extraction", "of", "participants,", "intervention,", "comparison/control,", "and", "outcome", "(PICO)", "from", "the", "randomized", "controlled", "trial", "(RCT)", "abstracts", "is", "important", "for", "evidence", "synthesis.", "Previous", "studies", "have", "demonstrated", "the", "feasibility", "of", "applying", "natural", "language", "processing", "(NLP)", "for", "PICO", "extraction.", "However,", "the", "performance", "is", "not", "optimal", "due", "to", "the", "complexity", "of", "PICO", "information", "in", "RCT", "abstracts", "and", "the", "challenges", "involved", "in", "their", "annotation."], "pieces": ["Autom", "ated", "ext", "raction", "of", "particip", "ants", ",", "inter", "vention", ",", "com", "par", "ison", "/", "control", ",", "and", "out", "come", "(", "P", "ICO", ")", "from", "the", "random", "ized", "controlled", "trial", "(", "R", "CT", ")", "ab", "stract", "s", "is", "important", "for", "evidence", "sy", "nt", "hesis", ".", "Previous", "stud", "ies", "have", "demon", "str", "ated", "the", "fe", "as", "ibility", "of", "app", "lying", "natural", "language", "processing", "(", "N", "LP", ")", "for", "P", "ICO", "ext", "raction", ".", "However", ",", "the", "performance", "is", "not", "opt", "imal", "due", "to", "the", "complex", "ity", "of", "P", "ICO", "information", "in", "R", "CT", "ab", "stract", "s", "and", "the", "chall", "enges", "involved", "in", "their", "ann", "otation", "."], "token_lens": [2, 2, 1, 3, 3, 6, 1, 2, 4, 1, 1, 2, 1, 1, 4, 3, 1, 1, 1, 1, 4, 1, 2, 1, 3, 1, 3, 1, 2, 1, 1, 1, 4, 1, 2, 3, 2, 1, 1, 1, 1, 2, 1, 1, 1, 2, 1, 2, 1, 1, 2, 3, 1, 1, 2, 1, 1, 1, 3], "sentence": "Automated extraction of participants, intervention, comparison/control, and outcome (PICO) from the randomized controlled trial (RCT) abstracts is important for evidence synthesis. Previous studies have demonstrated the feasibility of applying natural language processing (NLP) for PICO extraction. However, the performance is not optimal due to the complexity of PICO information in RCT abstracts and the challenges involved in their annotation.", "sentence_starts": [0]}
{"doc_id": "ACL_23_P_241", "sent_id": "ACL_23_P_241-1", "entity_mentions": [{"id": "ACL_23_P_241-1-E0", "text": "We", "start": 0, "end": 1, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_241-1-E1", "text": "ACCENT first extracts event-relation tuples from a dialogue", "start": 14, "end": 22, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_241-1-E2", "text": "evaluates the response by scoring the tuples in terms of their compatibility with the CSKB", "start": 24, "end": 39, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_241-1-E3", "text": "ACCENT", "start": 2, "end": 3, "entity_type": "UNK", "mention_type": "UNK"}], "relation_mentions": [], "event_mentions": [{"event_type": "Methods/Approach", "id": "ACL_23_P_241-1-EV0", "trigger": {"text": "propose", "start": 1, "end": 2}, "arguments": [{"entity_id": "ACL_23_P_241-1-E0", "text": "We", "role": "Agent"}, {"entity_id": "ACL_23_P_241-1-E1", "text": "ACCENT first extracts event-relation tuples from a dialogue", "role": "Method"}, {"entity_id": "ACL_23_P_241-1-E2", "text": "evaluates the response by scoring the tuples in terms of their compatibility with the CSKB", "role": "Method"}, {"entity_id": "ACL_23_P_241-1-E3", "text": "ACCENT", "role": "PrimaryObject"}]}], "entity_coreference": [], "event_coreference": [], "tokens": ["We", "propose", "ACCENT,", "an", "event", "commonsense", "evaluation", "metric", "empowered", "by", "commonsense", "knowledge", "bases", "(CSKBs).", "ACCENT", "first", "extracts", "event-relation", "tuples", "from", "a", "dialogue,", "and", "then", "evaluates", "the", "response", "by", "scoring", "the", "tuples", "in", "terms", "of", "their", "compatibility", "with", "the", "CSKB."], "pieces": ["We", "pro", "pose", "ACC", "ENT", ",", "an", "event", "comm", "onsense", "eval", "uation", "met", "ric", "em", "powered", "by", "comm", "onsense", "knowledge", "b", "ases", "(", "CS", "KB", "s", ").", "ACC", "ENT", "first", "ext", "ract", "s", "event", "-", "relation", "tu", "ples", "from", "a", "dial", "ogue", ",", "and", "then", "eval", "uates", "the", "response", "by", "scoring", "the", "tu", "ples", "in", "terms", "of", "their", "comp", "atibility", "with", "the", "CS", "KB", "."], "token_lens": [1, 2, 3, 1, 1, 2, 2, 2, 2, 1, 2, 1, 2, 5, 2, 1, 3, 3, 2, 1, 1, 3, 1, 1, 2, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 2, 1, 1, 3], "sentence": "We propose ACCENT, an event commonsense evaluation metric empowered by commonsense knowledge bases (CSKBs). ACCENT first extracts event-relation tuples from a dialogue, and then evaluates the response by scoring the tuples in terms of their compatibility with the CSKB.", "sentence_starts": [0]}
{"doc_id": "ACL_23_P_64", "sent_id": "ACL_23_P_64-0", "entity_mentions": [{"id": "ACL_23_P_64-0-E0", "text": "Recent studies", "start": 0, "end": 2, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_64-0-E1", "text": "Many of them benefit from utilizing users’ behavior sequences as plain texts, representing rich information in any domain or system without losing generality", "start": 16, "end": 39, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_64-0-E2", "text": "Can language modeling for user history corpus help improve recommender systems", "start": 43, "end": 54, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_64-0-E3", "text": "While its versatile usability has been widely investigated in many domains, its applications to recommender systems still remain underexplored", "start": 54, "end": 73, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_64-0-E4", "text": "unified user modeling frameworks", "start": 4, "end": 8, "entity_type": "UNK", "mention_type": "UNK"}], "relation_mentions": [], "event_mentions": [{"event_type": "Background/Introduction", "id": "ACL_23_P_64-0-EV0", "trigger": {"text": "have proposed", "start": 2, "end": 4}, "arguments": [{"entity_id": "ACL_23_P_64-0-E0", "text": "Recent studies", "role": "Agent"}, {"entity_id": "ACL_23_P_64-0-E1", "text": "Many of them benefit from utilizing users’ behavior sequences as plain texts, representing rich information in any domain or system without losing generality", "role": "Context"}, {"entity_id": "ACL_23_P_64-0-E2", "text": "Can language modeling for user history corpus help improve recommender systems", "role": "Challenge"}, {"entity_id": "ACL_23_P_64-0-E3", "text": "While its versatile usability has been widely investigated in many domains, its applications to recommender systems still remain underexplored", "role": "Challenge"}, {"entity_id": "ACL_23_P_64-0-E4", "text": "unified user modeling frameworks", "role": "PrimaryObject"}]}], "entity_coreference": [], "event_coreference": [], "tokens": ["Recent", "studies", "have", "proposed", "unified", "user", "modeling", "frameworks", "that", "leverage", "user", "behavior", "data", "from", "various", "applications.", "Many", "of", "them", "benefit", "from", "utilizing", "users’", "behavior", "sequences", "as", "plain", "texts,", "representing", "rich", "information", "in", "any", "domain", "or", "system", "without", "losing", "generality.", "Hence,", "a", "question", "arises:", "Can", "language", "modeling", "for", "user", "history", "corpus", "help", "improve", "recommender", "systems?", "While", "its", "versatile", "usability", "has", "been", "widely", "investigated", "in", "many", "domains,", "its", "applications", "to", "recommender", "systems", "still", "remain", "underexplored."], "pieces": ["Recent", "stud", "ies", "have", "prop", "osed", "un", "ified", "user", "mod", "eling", "fram", "eworks", "that", "le", "verage", "user", "behavior", "data", "from", "var", "ious", "app", "lic", "ations", ".", "Many", "of", "them", "benefit", "from", "util", "izing", "users", "âĢ", "Ļ", "behavior", "sequ", "ences", "as", "plain", "text", "s", ",", "represent", "ing", "rich", "information", "in", "any", "domain", "or", "system", "without", "l", "osing", "gener", "ality", ".", "H", "ence", ",", "a", "question", "ar", "ises", ":", "Can", "language", "mod", "eling", "for", "user", "history", "cor", "p", "us", "help", "improve", "recomm", "ender", "system", "s", "?", "While", "its", "vers", "atile", "us", "ability", "has", "been", "wide", "ly", "invest", "igated", "in", "many", "dom", "ains", ",", "its", "app", "lic", "ations", "to", "recomm", "ender", "system", "s", "still", "rem", "ain", "und", "ere", "x", "pl", "ored", "."], "token_lens": [1, 2, 1, 2, 2, 1, 2, 2, 1, 2, 1, 1, 1, 1, 2, 4, 1, 1, 1, 1, 1, 2, 3, 1, 2, 1, 1, 3, 2, 1, 1, 1, 1, 1, 1, 1, 1, 2, 3, 3, 1, 1, 3, 1, 1, 2, 1, 1, 1, 3, 1, 1, 2, 3, 1, 1, 2, 2, 1, 1, 2, 2, 1, 1, 3, 1, 3, 1, 2, 2, 1, 2, 6], "sentence": "Recent studies have proposed unified user modeling frameworks that leverage user behavior data from various applications. Many of them benefit from utilizing users’ behavior sequences as plain texts, representing rich information in any domain or system without losing generality. Hence, a question arises: Can language modeling for user history corpus help improve recommender systems? While its versatile usability has been widely investigated in many domains, its applications to recommender systems still remain underexplored.", "sentence_starts": [0]}
{"doc_id": "cscw_23_P_168", "sent_id": "cscw_23_P_168-2", "entity_mentions": [{"id": "cscw_23_P_168-2-E0", "text": "Our analysis", "start": 0, "end": 2, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "cscw_23_P_168-2-E1", "text": "mobilization is dependent on the selective amplification of false or misleading tweets by influencers, the framing around those claims, as well as the perceived credibility of their source", "start": 28, "end": 56, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "cscw_23_P_168-2-E2", "text": "These processes are a self-reinforcing cycle where audiences collaborate in the construction of a misleading version of reality, which in turn leads to offline actions that are used to further reinforce a manufactured reality", "start": 56, "end": 90, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "cscw_23_P_168-2-E3", "text": "how users on Twitter collaboratively construct and amplify alleged evidence of fraud", "start": 3, "end": 15, "entity_type": "UNK", "mention_type": "UNK"}], "relation_mentions": [], "event_mentions": [{"event_type": "Results/Findings", "id": "cscw_23_P_168-2-EV0", "trigger": {"text": "highlights", "start": 2, "end": 3}, "arguments": [{"entity_id": "cscw_23_P_168-2-E0", "text": "Our analysis", "role": "Agent"}, {"entity_id": "cscw_23_P_168-2-E1", "text": "mobilization is dependent on the selective amplification of false or misleading tweets by influencers, the framing around those claims, as well as the perceived credibility of their source", "role": "Results"}, {"entity_id": "cscw_23_P_168-2-E2", "text": "These processes are a self-reinforcing cycle where audiences collaborate in the construction of a misleading version of reality, which in turn leads to offline actions that are used to further reinforce a manufactured reality", "role": "Analysis"}, {"entity_id": "cscw_23_P_168-2-E3", "text": "how users on Twitter collaboratively construct and amplify alleged evidence of fraud", "role": "PrimaryObject"}]}], "entity_coreference": [], "event_coreference": [], "tokens": ["Our", "analysis", "highlights", "how", "users", "on", "Twitter", "collaboratively", "construct", "and", "amplify", "alleged", "evidence", "of", "fraud", "that", "is", "used", "to", "facilitate", "action,", "both", "online", "and", "off.", "We", "find", "that", "mobilization", "is", "dependent", "on", "the", "selective", "amplification", "of", "false", "or", "misleading", "tweets", "by", "influencers,", "the", "framing", "around", "those", "claims,", "as", "well", "as", "the", "perceived", "credibility", "of", "their", "source.", "These", "processes", "are", "a", "self-reinforcing", "cycle", "where", "audiences", "collaborate", "in", "the", "construction", "of", "a", "misleading", "version", "of", "reality,", "which", "in", "turn", "leads", "to", "offline", "actions", "that", "are", "used", "to", "further", "reinforce", "a", "manufactured", "reality."], "pieces": ["Our", "analysis", "high", "lights", "how", "users", "on", "Twitter", "coll", "abor", "atively", "construct", "and", "am", "pl", "ify", "al", "leg", "ed", "evidence", "of", "f", "raud", "that", "is", "used", "to", "fac", "ilit", "ate", "action", ",", "both", "online", "and", "off", ".", "We", "find", "that", "m", "obil", "ization", "is", "dependent", "on", "the", "select", "ive", "am", "pl", "ification", "of", "false", "or", "mis", "leading", "t", "we", "ets", "by", "inf", "lu", "encers", ",", "the", "fram", "ing", "around", "those", "claim", "s", ",", "as", "well", "as", "the", "per", "ceived", "c", "red", "ibility", "of", "their", "source", ".", "These", "process", "es", "are", "a", "self", "-", "re", "in", "forcing", "cycle", "where", "aud", "iences", "coll", "abor", "ate", "in", "the", "const", "ruction", "of", "a", "mis", "leading", "version", "of", "reality", ",", "which", "in", "turn", "le", "ads", "to", "off", "line", "actions", "that", "are", "used", "to", "f", "urther", "re", "in", "force", "a", "manufact", "ured", "reality", "."], "token_lens": [1, 1, 2, 1, 1, 1, 1, 3, 1, 1, 3, 3, 1, 1, 2, 1, 1, 1, 1, 3, 2, 1, 1, 1, 2, 1, 1, 1, 3, 1, 1, 1, 1, 2, 3, 1, 1, 1, 2, 3, 1, 4, 1, 2, 1, 1, 3, 1, 1, 1, 1, 2, 3, 1, 1, 2, 1, 2, 1, 1, 5, 1, 1, 2, 3, 1, 1, 2, 1, 1, 2, 1, 1, 2, 1, 1, 1, 2, 1, 2, 1, 1, 1, 1, 1, 2, 3, 1, 2, 2], "sentence": "Our analysis highlights how users on Twitter collaboratively construct and amplify alleged evidence of fraud that is used to facilitate action, both online and off. We find that mobilization is dependent on the selective amplification of false or misleading tweets by influencers, the framing around those claims, as well as the perceived credibility of their source. These processes are a self-reinforcing cycle where audiences collaborate in the construction of a misleading version of reality, which in turn leads to offline actions that are used to further reinforce a manufactured reality.", "sentence_starts": [0]}
{"doc_id": "cscw_23_P_217", "sent_id": "cscw_23_P_217-0", "entity_mentions": [{"id": "cscw_23_P_217-0-E0", "text": "Self-regulation of learning in programming", "start": 0, "end": 5, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "cscw_23_P_217-0-E1", "text": "emphasising an individual's metacognitive and motivational regulation components", "start": 9, "end": 17, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "cscw_23_P_217-0-E2", "text": "learning often happens in socially situated contexts, and little emphasis has been paid to studying social modes of regulation in programming", "start": 18, "end": 39, "entity_type": "UNK", "mention_type": "UNK"}], "relation_mentions": [], "event_mentions": [{"event_type": "Background/Introduction", "id": "cscw_23_P_217-0-EV0", "trigger": {"text": "has been extensively investigated", "start": 5, "end": 9}, "arguments": [{"entity_id": "cscw_23_P_217-0-E0", "text": "Self-regulation of learning in programming", "role": "Agent"}, {"entity_id": "cscw_23_P_217-0-E1", "text": "emphasising an individual's metacognitive and motivational regulation components", "role": "Analysis"}, {"entity_id": "cscw_23_P_217-0-E2", "text": "learning often happens in socially situated contexts, and little emphasis has been paid to studying social modes of regulation in programming", "role": "Challenge"}]}], "entity_coreference": [], "event_coreference": [], "tokens": ["Self-regulation", "of", "learning", "in", "programming", "has", "been", "extensively", "investigated,", "emphasising", "an", "individual's", "metacognitive", "and", "motivational", "regulation", "components.", "However,", "learning", "often", "happens", "in", "socially", "situated", "contexts,", "and", "little", "emphasis", "has", "been", "paid", "to", "studying", "social", "modes", "of", "regulation", "in", "programming."], "pieces": ["Self", "-", "regulation", "of", "learning", "in", "program", "ming", "has", "been", "ext", "ensive", "ly", "invest", "igated", ",", "em", "phas", "ising", "an", "individual", "'s", "met", "ac", "ognitive", "and", "mot", "iv", "ational", "regulation", "comp", "onents", ".", "However", ",", "learning", "often", "h", "app", "ens", "in", "s", "oci", "ally", "sit", "uated", "context", "s", ",", "and", "little", "emphasis", "has", "been", "paid", "to", "stud", "ying", "social", "m", "odes", "of", "regulation", "in", "program", "ming", "."], "token_lens": [3, 1, 1, 1, 2, 1, 1, 3, 3, 3, 1, 2, 3, 1, 3, 1, 3, 2, 1, 1, 3, 1, 3, 2, 3, 1, 1, 1, 1, 1, 1, 1, 2, 1, 2, 1, 1, 1, 3], "sentence": "Self-regulation of learning in programming has been extensively investigated, emphasising an individual's metacognitive and motivational regulation components. However, learning often happens in socially situated contexts, and little emphasis has been paid to studying social modes of regulation in programming.", "sentence_starts": [0]}
{"doc_id": "ACL_23_P_866", "sent_id": "ACL_23_P_866-2", "entity_mentions": [{"id": "ACL_23_P_866-2-E0", "text": "we", "start": 8, "end": 9, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_866-2-E1", "text": "Based on the strong testbed and evaluation methods,", "start": 0, "end": 8, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_866-2-E2", "text": "suggest directions for further unlabeled data utilization and model design", "start": 20, "end": 30, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_866-2-E3", "text": "challenges", "start": 10, "end": 11, "entity_type": "UNK", "mention_type": "UNK"}], "relation_mentions": [], "event_mentions": [{"event_type": "Results/Findings", "id": "ACL_23_P_866-2-EV0", "trigger": {"text": "identify", "start": 9, "end": 10}, "arguments": [{"entity_id": "ACL_23_P_866-2-E0", "text": "we", "role": "Agent"}, {"entity_id": "ACL_23_P_866-2-E1", "text": "Based on the strong testbed and evaluation methods,", "role": "Context"}, {"entity_id": "ACL_23_P_866-2-E2", "text": "suggest directions for further unlabeled data utilization and model design", "role": "Implications"}, {"entity_id": "ACL_23_P_866-2-E3", "text": "challenges", "role": "PrimaryObject"}]}], "entity_coreference": [], "event_coreference": [], "tokens": ["Based", "on", "the", "strong", "testbed", "and", "evaluation", "methods,", "we", "identify", "challenges", "in", "training", "NMT", "models", "with", "high", "CR", "abilities", "and", "suggest", "directions", "for", "further", "unlabeled", "data", "utilization", "and", "model", "design."], "pieces": ["Based", "on", "the", "strong", "test", "bed", "and", "eval", "uation", "method", "s", ",", "we", "ident", "ify", "chall", "enges", "in", "training", "N", "MT", "models", "with", "high", "CR", "abilities", "and", "suggest", "direct", "ions", "for", "f", "urther", "un", "label", "ed", "data", "util", "ization", "and", "model", "design", "."], "token_lens": [1, 1, 1, 1, 2, 1, 2, 3, 1, 2, 2, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 2, 1, 2, 3, 1, 2, 1, 1, 2], "sentence": "Based on the strong testbed and evaluation methods, we identify challenges in training NMT models with high CR abilities and suggest directions for further unlabeled data utilization and model design.", "sentence_starts": [0]}
{"doc_id": "cscw_23_P_127", "sent_id": "cscw_23_P_127-0", "entity_mentions": [{"id": "cscw_23_P_127-0-E0", "text": "This study", "start": 27, "end": 29, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "cscw_23_P_127-0-E1", "text": "Online harassment and content moderation have been well-documented in online communities", "start": 0, "end": 11, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "cscw_23_P_127-0-E2", "text": "new contexts and systems always bring new ways of harassment and need new moderation mechanisms", "start": 12, "end": 27, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "cscw_23_P_127-0-E3", "text": "hate raids", "start": 31, "end": 33, "entity_type": "UNK", "mention_type": "UNK"}], "relation_mentions": [], "event_mentions": [{"event_type": "Background/Introduction", "id": "cscw_23_P_127-0-EV0", "trigger": {"text": "focuses on", "start": 29, "end": 31}, "arguments": [{"entity_id": "cscw_23_P_127-0-E0", "text": "This study", "role": "Agent"}, {"entity_id": "cscw_23_P_127-0-E1", "text": "Online harassment and content moderation have been well-documented in online communities", "role": "Context"}, {"entity_id": "cscw_23_P_127-0-E2", "text": "new contexts and systems always bring new ways of harassment and need new moderation mechanisms", "role": "Challenge"}, {"entity_id": "cscw_23_P_127-0-E3", "text": "hate raids", "role": "PrimaryObject"}]}], "entity_coreference": [], "event_coreference": [], "tokens": ["Online", "harassment", "and", "content", "moderation", "have", "been", "well-documented", "in", "online", "communities.", "However,", "new", "contexts", "and", "systems", "always", "bring", "new", "ways", "of", "harassment", "and", "need", "new", "moderation", "mechanisms.", "This", "study", "focuses", "on", "hate", "raids,", "a", "form", "of", "group", "attack", "in", "real-time", "in", "live", "streaming", "communities."], "pieces": ["Online", "har", "assment", "and", "content", "mod", "er", "ation", "have", "been", "well", "-", "documented", "in", "online", "commun", "ities", ".", "However", ",", "new", "context", "s", "and", "system", "s", "always", "bring", "new", "ways", "of", "har", "assment", "and", "need", "new", "mod", "er", "ation", "me", "chan", "isms", ".", "This", "study", "f", "oc", "uses", "on", "hate", "ra", "ids", ",", "a", "form", "of", "group", "attack", "in", "real", "-", "time", "in", "live", "stream", "ing", "commun", "ities", "."], "token_lens": [1, 2, 1, 1, 3, 1, 1, 3, 1, 1, 3, 2, 1, 2, 1, 2, 1, 1, 1, 1, 1, 2, 1, 1, 1, 3, 4, 1, 1, 3, 1, 1, 3, 1, 1, 1, 1, 1, 1, 3, 1, 1, 2, 3], "sentence": "Online harassment and content moderation have been well-documented in online communities. However, new contexts and systems always bring new ways of harassment and need new moderation mechanisms. This study focuses on hate raids, a form of group attack in real-time in live streaming communities.", "sentence_starts": [0]}
{"doc_id": "bioinfo_23_P_89", "sent_id": "bioinfo_23_P_89-2", "entity_mentions": [{"id": "bioinfo_23_P_89-2-E0", "text": "The major new findings", "start": 0, "end": 4, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "bioinfo_23_P_89-2-E1", "text": "cell2loction, RCTD and spatialDWLS are more accurate than other ST deconvolution methods, based on the evaluation of three metrics: RMSE, PCC and JSD", "start": 6, "end": 29, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "bioinfo_23_P_89-2-E2", "text": "cell2location and spatialDWLS are more robust to the variation of sequencing depth than RCTD", "start": 30, "end": 44, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "bioinfo_23_P_89-2-E3", "text": "the accuracy of the existing methods tends to decrease as the spot size becomes smaller", "start": 45, "end": 60, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "bioinfo_23_P_89-2-E4", "text": "most deconvolution methods perform best when they normalize ST data using the method described in their original papers", "start": 61, "end": 79, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "bioinfo_23_P_89-2-E5", "text": "the integrative method, EnDecon, could achieve more accurate ST deconvolution", "start": 81, "end": 91, "entity_type": "UNK", "mention_type": "UNK"}], "relation_mentions": [], "event_mentions": [{"event_type": "Results/Findings", "id": "bioinfo_23_P_89-2-EV0", "trigger": {"text": "include", "start": 4, "end": 5}, "arguments": [{"entity_id": "bioinfo_23_P_89-2-E0", "text": "The major new findings", "role": "Agent"}, {"entity_id": "bioinfo_23_P_89-2-E1", "text": "cell2loction, RCTD and spatialDWLS are more accurate than other ST deconvolution methods, based on the evaluation of three metrics: RMSE, PCC and JSD", "role": "Results"}, {"entity_id": "bioinfo_23_P_89-2-E2", "text": "cell2location and spatialDWLS are more robust to the variation of sequencing depth than RCTD", "role": "Results"}, {"entity_id": "bioinfo_23_P_89-2-E3", "text": "the accuracy of the existing methods tends to decrease as the spot size becomes smaller", "role": "Results"}, {"entity_id": "bioinfo_23_P_89-2-E4", "text": "most deconvolution methods perform best when they normalize ST data using the method described in their original papers", "role": "Results"}, {"entity_id": "bioinfo_23_P_89-2-E5", "text": "the integrative method, EnDecon, could achieve more accurate ST deconvolution", "role": "Results"}]}], "entity_coreference": [], "event_coreference": [], "tokens": ["The", "major", "new", "findings", "include:", "(i)", "cell2loction,", "RCTD", "and", "spatialDWLS", "are", "more", "accurate", "than", "other", "ST", "deconvolution", "methods,", "based", "on", "the", "evaluation", "of", "three", "metrics:", "RMSE,", "PCC", "and", "JSD;", "(ii)", "cell2location", "and", "spatialDWLS", "are", "more", "robust", "to", "the", "variation", "of", "sequencing", "depth", "than", "RCTD;", "(iii)", "the", "accuracy", "of", "the", "existing", "methods", "tends", "to", "decrease", "as", "the", "spot", "size", "becomes", "smaller;", "(iv)", "most", "deconvolution", "methods", "perform", "best", "when", "they", "normalize", "ST", "data", "using", "the", "method", "described", "in", "their", "original", "papers;", "and", "(v)", "the", "integrative", "method,", "EnDecon,", "could", "achieve", "more", "accurate", "ST", "deconvolution."], "pieces": ["The", "major", "new", "find", "ings", "include", ":", "(", "i", ")", "cell", "2", "lo", "ction", ",", "R", "CT", "D", "and", "sp", "atial", "DW", "LS", "are", "more", "acc", "urate", "than", "other", "ST", "dec", "on", "v", "olution", "method", "s", ",", "based", "on", "the", "eval", "uation", "of", "three", "met", "rics", ":", "RM", "SE", ",", "P", "CC", "and", "J", "SD", ";", "(", "ii", ")", "cell", "2", "location", "and", "sp", "atial", "DW", "LS", "are", "more", "rob", "ust", "to", "the", "vari", "ation", "of", "sequ", "encing", "depth", "than", "R", "CT", "D", ";", "(", "iii", ")", "the", "acc", "uracy", "of", "the", "existing", "method", "s", "t", "ends", "to", "dec", "re", "ase", "as", "the", "spot", "size", "bec", "omes", "small", "er", ";", "(", "iv", ")", "most", "dec", "on", "v", "olution", "method", "s", "per", "form", "best", "when", "they", "normal", "ize", "ST", "data", "using", "the", "method", "described", "in", "their", "original", "papers", ";", "and", "(", "v", ")", "the", "integ", "rative", "method", ",", "En", "Dec", "on", ",", "could", "ach", "ieve", "more", "acc", "urate", "ST", "dec", "on", "v", "olution", "."], "token_lens": [1, 1, 1, 2, 2, 3, 5, 3, 1, 4, 1, 1, 2, 1, 1, 1, 4, 3, 1, 1, 1, 2, 1, 1, 3, 3, 2, 1, 3, 3, 3, 1, 4, 1, 1, 2, 1, 1, 2, 1, 2, 1, 1, 4, 3, 1, 2, 1, 1, 1, 2, 2, 1, 3, 1, 1, 1, 1, 2, 3, 3, 1, 4, 2, 2, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 3, 1, 2, 2, 4, 1, 2, 1, 2, 1, 5], "sentence": "The major new findings include: (i) cell2loction, RCTD and spatialDWLS are more accurate than other ST deconvolution methods, based on the evaluation of three metrics: RMSE, PCC and JSD; (ii) cell2location and spatialDWLS are more robust to the variation of sequencing depth than RCTD; (iii) the accuracy of the existing methods tends to decrease as the spot size becomes smaller; (iv) most deconvolution methods perform best when they normalize ST data using the method described in their original papers; and (v) the integrative method, EnDecon, could achieve more accurate ST deconvolution.", "sentence_starts": [0]}
{"doc_id": "cscw_23_P_29", "sent_id": "cscw_23_P_29-2", "entity_mentions": [{"id": "cscw_23_P_29-2-E0", "text": "Our analysis", "start": 0, "end": 2, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "cscw_23_P_29-2-E1", "text": "We also highlight four additional value dimensions that were not previously identified in CBPP: cultural heritage value, rarity value, aesthetic value, and administrative value", "start": 16, "end": 40, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "cscw_23_P_29-2-E2", "text": "the prior values categories", "start": 3, "end": 7, "entity_type": "UNK", "mention_type": "UNK"}], "relation_mentions": [], "event_mentions": [{"event_type": "Results/Findings", "id": "cscw_23_P_29-2-EV0", "trigger": {"text": "supports", "start": 2, "end": 3}, "arguments": [{"entity_id": "cscw_23_P_29-2-E0", "text": "Our analysis", "role": "Agent"}, {"entity_id": "cscw_23_P_29-2-E1", "text": "We also highlight four additional value dimensions that were not previously identified in CBPP: cultural heritage value, rarity value, aesthetic value, and administrative value", "role": "Method"}, {"entity_id": "cscw_23_P_29-2-E2", "text": "the prior values categories", "role": "PrimaryObject"}]}], "entity_coreference": [], "event_coreference": [], "tokens": ["Our", "analysis", "supports", "the", "prior", "values", "categories", "while", "expanding", "how", "some", "dimensions", "are", "expressed", "by", "participants.", "We", "also", "highlight", "four", "additional", "value", "dimensions", "that", "were", "not", "previously", "identified", "in", "CBPP:", "cultural", "heritage", "value,", "rarity", "value,", "aesthetic", "value,", "and", "administrative", "value."], "pieces": ["Our", "analysis", "supp", "orts", "the", "pri", "or", "values", "c", "ategories", "while", "exp", "anding", "how", "some", "dim", "ensions", "are", "exp", "ressed", "by", "particip", "ants", ".", "We", "also", "high", "light", "four", "add", "itional", "value", "dim", "ensions", "that", "were", "not", "pre", "viously", "identified", "in", "CB", "PP", ":", "cultural", "her", "itage", "value", ",", "r", "arity", "value", ",", "a", "esthetic", "value", ",", "and", "administ", "rative", "value", "."], "token_lens": [1, 1, 2, 1, 2, 1, 2, 1, 2, 1, 1, 2, 1, 2, 1, 3, 1, 1, 2, 1, 2, 1, 2, 1, 1, 1, 2, 1, 1, 3, 1, 2, 2, 2, 2, 2, 2, 1, 2, 2], "sentence": "Our analysis supports the prior values categories while expanding how some dimensions are expressed by participants. We also highlight four additional value dimensions that were not previously identified in CBPP: cultural heritage value, rarity value, aesthetic value, and administrative value.", "sentence_starts": [0]}
{"doc_id": "cscw_23_P_60", "sent_id": "cscw_23_P_60-1", "entity_mentions": [{"id": "cscw_23_P_60-1-E0", "text": "we", "start": 8, "end": 9, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "cscw_23_P_60-1-E1", "text": "To identify tools that can support remote tutoring", "start": 0, "end": 8, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "cscw_23_P_60-1-E2", "text": "an instructor teaches a learner introductory programming concepts remotely, collaborating through screensharing alone, a shared notebook with real-time collaborative editing, or a shared notebook with additional awareness tools overlaid", "start": 24, "end": 53, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "cscw_23_P_60-1-E3", "text": "To embed the awareness tools, we designed a Chrome extension that enables real-time sharing of gaze and cursor data", "start": 53, "end": 72, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "cscw_23_P_60-1-E4", "text": "an experiment", "start": 10, "end": 12, "entity_type": "UNK", "mention_type": "UNK"}], "relation_mentions": [], "event_mentions": [{"event_type": "Methods/Approach", "id": "cscw_23_P_60-1-EV0", "trigger": {"text": "conducted", "start": 9, "end": 10}, "arguments": [{"entity_id": "cscw_23_P_60-1-E0", "text": "we", "role": "Agent"}, {"entity_id": "cscw_23_P_60-1-E1", "text": "To identify tools that can support remote tutoring", "role": "Purpose"}, {"entity_id": "cscw_23_P_60-1-E2", "text": "an instructor teaches a learner introductory programming concepts remotely, collaborating through screensharing alone, a shared notebook with real-time collaborative editing, or a shared notebook with additional awareness tools overlaid", "role": "Method"}, {"entity_id": "cscw_23_P_60-1-E3", "text": "To embed the awareness tools, we designed a Chrome extension that enables real-time sharing of gaze and cursor data", "role": "Method"}, {"entity_id": "cscw_23_P_60-1-E4", "text": "an experiment", "role": "PrimaryObject"}]}], "entity_coreference": [], "event_coreference": [], "tokens": ["To", "identify", "tools", "that", "can", "support", "remote", "tutoring,", "we", "conducted", "an", "experiment", "to", "assess", "two", "resources:", "synchronous", "editing", "and", "awareness", "tools.", "In", "our", "study,", "an", "instructor", "teaches", "a", "learner", "introductory", "programming", "concepts", "remotely,", "collaborating", "through", "screensharing", "alone,", "a", "shared", "notebook", "with", "real-time", "collaborative", "editing,", "or", "a", "shared", "notebook", "with", "additional", "awareness", "tools", "overlaid.", "To", "embed", "the", "awareness", "tools,", "we", "designed", "a", "Chrome", "extension", "that", "enables", "real-time", "sharing", "of", "gaze", "and", "cursor", "data."], "pieces": ["To", "ident", "ify", "tools", "that", "can", "support", "remote", "t", "ut", "oring", ",", "we", "conduct", "ed", "an", "exper", "iment", "to", "ass", "ess", "two", "resources", ":", "syn", "chron", "ous", "ed", "iting", "and", "awareness", "tools", ".", "In", "our", "study", ",", "an", "in", "struct", "or", "te", "aches", "a", "lear", "ner", "introdu", "ctory", "program", "ming", "concept", "s", "remote", "ly", ",", "coll", "abor", "ating", "through", "sc", "reens", "h", "aring", "alone", ",", "a", "shared", "note", "book", "with", "real", "-", "time", "coll", "abor", "ative", "ed", "iting", ",", "or", "a", "shared", "note", "book", "with", "add", "itional", "awareness", "tools", "over", "l", "aid", ".", "To", "embed", "the", "awareness", "tools", ",", "we", "designed", "a", "Ch", "rome", "ext", "ension", "that", "en", "ables", "real", "-", "time", "sharing", "of", "g", "aze", "and", "c", "ursor", "data", "."], "token_lens": [1, 2, 1, 1, 1, 1, 1, 4, 1, 2, 1, 2, 1, 2, 1, 2, 3, 2, 1, 1, 2, 1, 1, 2, 1, 3, 2, 1, 2, 2, 2, 2, 3, 3, 1, 4, 2, 1, 1, 2, 1, 3, 3, 3, 1, 1, 1, 2, 1, 2, 1, 1, 4, 1, 1, 1, 1, 2, 1, 1, 1, 2, 2, 1, 2, 3, 1, 1, 2, 1, 2, 2], "sentence": "To identify tools that can support remote tutoring, we conducted an experiment to assess two resources: synchronous editing and awareness tools. In our study, an instructor teaches a learner introductory programming concepts remotely, collaborating through screensharing alone, a shared notebook with real-time collaborative editing, or a shared notebook with additional awareness tools overlaid. To embed the awareness tools, we designed a Chrome extension that enables real-time sharing of gaze and cursor data.", "sentence_starts": [0]}
{"doc_id": "cscw_23_P_33", "sent_id": "cscw_23_P_33-1", "entity_mentions": [{"id": "cscw_23_P_33-1-E0", "text": "we", "start": 4, "end": 5, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "cscw_23_P_33-1-E1", "text": "We compare three distinct work locations — private and shared workspaces at home as well at the office — and explore how each location may impact individual perceptions of teamwork", "start": 21, "end": 51, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "cscw_23_P_33-1-E2", "text": "findings", "start": 6, "end": 7, "entity_type": "UNK", "mention_type": "UNK"}], "relation_mentions": [], "event_mentions": [{"event_type": "Methods/Approach", "id": "cscw_23_P_33-1-EV0", "trigger": {"text": "present", "start": 5, "end": 6}, "arguments": [{"entity_id": "cscw_23_P_33-1-E0", "text": "we", "role": "Agent"}, {"entity_id": "cscw_23_P_33-1-E1", "text": "We compare three distinct work locations — private and shared workspaces at home as well at the office — and explore how each location may impact individual perceptions of teamwork", "role": "Method"}, {"entity_id": "cscw_23_P_33-1-E2", "text": "findings", "role": "PrimaryObject"}]}], "entity_coreference": [], "event_coreference": [], "tokens": ["To", "address", "this", "gap,", "we", "present", "findings", "from", "a", "ten-week,", "in", "situ", "study", "of", "91", "information", "workers", "from", "27", "US-based", "teams.", "We", "compare", "three", "distinct", "work", "locations", "—", "private", "and", "shared", "workspaces", "at", "home", "as", "well", "at", "the", "office", "—", "and", "explore", "how", "each", "location", "may", "impact", "individual", "perceptions", "of", "teamwork."], "pieces": ["To", "address", "this", "gap", ",", "we", "present", "find", "ings", "from", "a", "ten", "-", "week", ",", "in", "s", "itu", "study", "of", "91", "information", "workers", "from", "27", "US", "-", "based", "te", "ams", ".", "We", "comp", "are", "three", "dist", "inct", "work", "loc", "ations", "âĢĶ", "private", "and", "shared", "works", "paces", "at", "home", "as", "well", "at", "the", "office", "âĢĶ", "and", "expl", "ore", "how", "each", "location", "may", "impact", "individual", "per", "ceptions", "of", "team", "work", "."], "token_lens": [1, 1, 1, 2, 1, 1, 2, 1, 1, 4, 1, 2, 1, 1, 1, 1, 1, 1, 1, 3, 3, 1, 2, 1, 2, 1, 2, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 2, 1, 3], "sentence": "To address this gap, we present findings from a ten-week, in situ study of 91 information workers from 27 US-based teams. We compare three distinct work locations — private and shared workspaces at home as well at the office — and explore how each location may impact individual perceptions of teamwork.", "sentence_starts": [0]}
{"doc_id": "bioinfo_23_P_716", "sent_id": "bioinfo_23_P_716-0", "entity_mentions": [{"id": "bioinfo_23_P_716-0-E0", "text": "The Kyoto Encyclopedia of Genes and Genomes (KEGG) database", "start": 0, "end": 9, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "bioinfo_23_P_716-0-E1", "text": "existing software does not allow flexible visualization and network analyses of the vast and complex KEGG data", "start": 25, "end": 42, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "bioinfo_23_P_716-0-E2", "text": "a valuable systems biology resource", "start": 11, "end": 16, "entity_type": "UNK", "mention_type": "UNK"}], "relation_mentions": [], "event_mentions": [{"event_type": "Background/Introduction", "id": "bioinfo_23_P_716-0-EV0", "trigger": {"text": "serves as", "start": 9, "end": 11}, "arguments": [{"entity_id": "bioinfo_23_P_716-0-E0", "text": "The Kyoto Encyclopedia of Genes and Genomes (KEGG) database", "role": "Agent"}, {"entity_id": "bioinfo_23_P_716-0-E1", "text": "existing software does not allow flexible visualization and network analyses of the vast and complex KEGG data", "role": "Challenge"}, {"entity_id": "bioinfo_23_P_716-0-E2", "text": "a valuable systems biology resource", "role": "PrimaryObject"}]}], "entity_coreference": [], "event_coreference": [], "tokens": ["The", "Kyoto", "Encyclopedia", "of", "Genes", "and", "Genomes", "(KEGG)", "database", "serves", "as", "a", "valuable", "systems", "biology", "resource", "and", "is", "widely", "utilized", "in", "diverse", "research", "fields.", "However,", "existing", "software", "does", "not", "allow", "flexible", "visualization", "and", "network", "analyses", "of", "the", "vast", "and", "complex", "KEGG", "data."], "pieces": ["The", "Ky", "oto", "En", "cyclopedia", "of", "Gen", "es", "and", "Gen", "omes", "(", "K", "EG", "G", ")", "database", "serv", "es", "as", "a", "val", "uable", "system", "s", "biology", "resource", "and", "is", "wide", "ly", "util", "ized", "in", "d", "iverse", "research", "fields", ".", "However", ",", "existing", "software", "does", "not", "allow", "flex", "ible", "visual", "ization", "and", "network", "an", "alyses", "of", "the", "v", "ast", "and", "complex", "K", "EG", "G", "data", "."], "token_lens": [1, 2, 2, 1, 2, 1, 2, 5, 1, 2, 1, 1, 2, 2, 1, 1, 1, 1, 2, 2, 1, 2, 1, 2, 2, 1, 1, 1, 1, 1, 2, 2, 1, 1, 2, 1, 1, 2, 1, 1, 3, 2], "sentence": "The Kyoto Encyclopedia of Genes and Genomes (KEGG) database serves as a valuable systems biology resource and is widely utilized in diverse research fields. However, existing software does not allow flexible visualization and network analyses of the vast and complex KEGG data.", "sentence_starts": [0]}
{"doc_id": "ACL_23_P_392", "sent_id": "ACL_23_P_392-0", "entity_mentions": [{"id": "ACL_23_P_392-0-E0", "text": "We", "start": 62, "end": 63, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_392-0-E1", "text": "Among the remarkable emergent capabilities of large language models (LMs) is free-text rationalization; beyond certain scale, large LMs are capable of generating seemingly useful rationalizations, which in turn, can dramatically enhance their performances on leaderboards.", "start": 0, "end": 35, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_392-0-E2", "text": "This phenomenon raises a question: can machine generated rationales also be useful for humans, especially when lay humans try to answer questions based on those machine rationales", "start": 35, "end": 62, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_392-0-E3", "text": "expensive to estimate with human studies", "start": 75, "end": 81, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_392-0-E4", "text": "Existing metrics like task performance of the LM generating the rationales or similarity between generated and gold rationales are not good indicators of their human utility", "start": 81, "end": 107, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_392-0-E5", "text": "While we observe that certain properties of rationales like conciseness and novelty are correlated with their human utility, estimating them without human involvement is challenging", "start": 107, "end": 132, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_392-0-E6", "text": "human utility of existing rationales is far from satisfactory", "start": 65, "end": 74, "entity_type": "UNK", "mention_type": "UNK"}], "relation_mentions": [], "event_mentions": [{"event_type": "Background/Introduction", "id": "ACL_23_P_392-0-EV0", "trigger": {"text": "observe", "start": 63, "end": 64}, "arguments": [{"entity_id": "ACL_23_P_392-0-E0", "text": "We", "role": "Agent"}, {"entity_id": "ACL_23_P_392-0-E1", "text": "Among the remarkable emergent capabilities of large language models (LMs) is free-text rationalization; beyond certain scale, large LMs are capable of generating seemingly useful rationalizations, which in turn, can dramatically enhance their performances on leaderboards.", "role": "Context"}, {"entity_id": "ACL_23_P_392-0-E2", "text": "This phenomenon raises a question: can machine generated rationales also be useful for humans, especially when lay humans try to answer questions based on those machine rationales", "role": "Context"}, {"entity_id": "ACL_23_P_392-0-E3", "text": "expensive to estimate with human studies", "role": "Challenge"}, {"entity_id": "ACL_23_P_392-0-E4", "text": "Existing metrics like task performance of the LM generating the rationales or similarity between generated and gold rationales are not good indicators of their human utility", "role": "Challenge"}, {"entity_id": "ACL_23_P_392-0-E5", "text": "While we observe that certain properties of rationales like conciseness and novelty are correlated with their human utility, estimating them without human involvement is challenging", "role": "Challenge"}, {"entity_id": "ACL_23_P_392-0-E6", "text": "human utility of existing rationales is far from satisfactory", "role": "PrimaryObject"}]}], "entity_coreference": [], "event_coreference": [], "tokens": ["Among", "the", "remarkable", "emergent", "capabilities", "of", "large", "language", "models", "(LMs)", "is", "free-text", "rationalization;", "beyond", "certain", "scale,", "large", "LMs", "are", "capable", "of", "generating", "seemingly", "useful", "rationalizations,", "which", "in", "turn,", "can", "dramatically", "enhance", "their", "performances", "on", "leaderboards.", "This", "phenomenon", "raises", "a", "question:", "can", "machine", "generated", "rationales", "also", "be", "useful", "for", "humans,", "especially", "when", "lay", "humans", "try", "to", "answer", "questions", "based", "on", "those", "machine", "rationales?", "We", "observe", "that", "human", "utility", "of", "existing", "rationales", "is", "far", "from", "satisfactory", "and", "expensive", "to", "estimate", "with", "human", "studies.", "Existing", "metrics", "like", "task", "performance", "of", "the", "LM", "generating", "the", "rationales", "or", "similarity", "between", "generated", "and", "gold", "rationales", "are", "not", "good", "indicators", "of", "their", "human", "utility.", "While", "we", "observe", "that", "certain", "properties", "of", "rationales", "like", "conciseness", "and", "novelty", "are", "correlated", "with", "their", "human", "utility,", "estimating", "them", "without", "human", "involvement", "is", "challenging."], "pieces": ["Among", "the", "rem", "arkable", "em", "erg", "ent", "cap", "abilities", "of", "large", "language", "models", "(", "L", "Ms", ")", "is", "free", "-", "text", "rational", "ization", ";", "be", "yond", "certain", "scale", ",", "large", "L", "Ms", "are", "cap", "able", "of", "gener", "ating", "se", "em", "ingly", "use", "ful", "rational", "izations", ",", "which", "in", "turn", ",", "can", "d", "ram", "atically", "enh", "ance", "their", "per", "form", "ances", "on", "leader", "boards", ".", "This", "phen", "omen", "on", "ra", "ises", "a", "question", ":", "can", "machine", "generated", "rational", "es", "also", "be", "use", "ful", "for", "humans", ",", "especially", "when", "lay", "humans", "try", "to", "answer", "quest", "ions", "based", "on", "those", "machine", "rational", "es", "?", "We", "ob", "ser", "ve", "that", "human", "ut", "ility", "of", "existing", "rational", "es", "is", "far", "from", "s", "atisf", "actory", "and", "expensive", "to", "est", "imate", "with", "human", "stud", "ies", ".", "Ex", "isting", "met", "rics", "like", "task", "performance", "of", "the", "LM", "gener", "ating", "the", "rational", "es", "or", "similar", "ity", "between", "generated", "and", "gold", "rational", "es", "are", "not", "good", "ind", "icators", "of", "their", "human", "ut", "ility", ".", "While", "we", "ob", "ser", "ve", "that", "certain", "properties", "of", "rational", "es", "like", "con", "c", "is", "eness", "and", "no", "vel", "ty", "are", "cor", "related", "with", "their", "human", "ut", "ility", ",", "est", "imating", "them", "without", "human", "inv", "olve", "ment", "is", "chall", "eng", "ing", "."], "token_lens": [1, 1, 2, 3, 2, 1, 1, 1, 1, 4, 1, 3, 3, 2, 1, 2, 1, 2, 1, 2, 1, 2, 3, 2, 3, 1, 1, 2, 1, 3, 2, 1, 3, 1, 3, 1, 3, 2, 1, 2, 1, 1, 1, 2, 1, 1, 2, 1, 2, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 3, 1, 3, 1, 1, 2, 1, 1, 2, 1, 1, 1, 3, 1, 1, 1, 2, 1, 1, 3, 2, 2, 1, 1, 1, 1, 1, 1, 2, 1, 2, 1, 2, 1, 1, 1, 1, 2, 1, 1, 1, 2, 1, 1, 1, 3, 1, 1, 3, 1, 1, 1, 1, 2, 1, 4, 1, 3, 1, 2, 1, 1, 1, 3, 2, 1, 1, 1, 3, 1, 4], "sentence": "Among the remarkable emergent capabilities of large language models (LMs) is free-text rationalization; beyond certain scale, large LMs are capable of generating seemingly useful rationalizations, which in turn, can dramatically enhance their performances on leaderboards. This phenomenon raises a question: can machine generated rationales also be useful for humans, especially when lay humans try to answer questions based on those machine rationales? We observe that human utility of existing rationales is far from satisfactory and expensive to estimate with human studies. Existing metrics like task performance of the LM generating the rationales or similarity between generated and gold rationales are not good indicators of their human utility. While we observe that certain properties of rationales like conciseness and novelty are correlated with their human utility, estimating them without human involvement is challenging.", "sentence_starts": [0]}
{"doc_id": "ACL_23_P_162", "sent_id": "ACL_23_P_162-1", "entity_mentions": [{"id": "ACL_23_P_162-1-E0", "text": "we", "start": 3, "end": 4, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_162-1-E1", "text": "our critical insight is to jointly utilize the non-autoregressive (NAR) generation and dynamic parameter pruning techniques, which can flexibly control the decoding iteration steps and model sizes according to memory and latency limitations", "start": 34, "end": 67, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_162-1-E2", "text": "we also explore the effectiveness of the pre-trained MLMs (i.e., the BERT family) for text generation tasks since their bidirectional attention nature is more suitable for the NAR training objective", "start": 68, "end": 98, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_162-1-E3", "text": "a novel fine-tuning method DEER", "start": 5, "end": 10, "entity_type": "UNK", "mention_type": "UNK"}], "relation_mentions": [], "event_mentions": [{"event_type": "Methods/Approach", "id": "ACL_23_P_162-1-EV0", "trigger": {"text": "propose", "start": 4, "end": 5}, "arguments": [{"entity_id": "ACL_23_P_162-1-E0", "text": "we", "role": "Agent"}, {"entity_id": "ACL_23_P_162-1-E1", "text": "our critical insight is to jointly utilize the non-autoregressive (NAR) generation and dynamic parameter pruning techniques, which can flexibly control the decoding iteration steps and model sizes according to memory and latency limitations", "role": "Method"}, {"entity_id": "ACL_23_P_162-1-E2", "text": "we also explore the effectiveness of the pre-trained MLMs (i.e., the BERT family) for text generation tasks since their bidirectional attention nature is more suitable for the NAR training objective", "role": "Method"}, {"entity_id": "ACL_23_P_162-1-E3", "text": "a novel fine-tuning method DEER", "role": "PrimaryObject"}]}], "entity_coreference": [], "event_coreference": [], "tokens": ["In", "this", "work,", "we", "propose", "a", "novel", "fine-tuning", "method", "DEER,", "which", "can", "make", "a", "single", "pre-trained", "model", "support", "Dynamic", "and", "Efficient", "infERence", "and", "achieve", "an", "adaptive", "trade-off", "between", "model", "performance", "and", "latency.", "In", "particular,", "our", "critical", "insight", "is", "to", "jointly", "utilize", "the", "non-autoregressive", "(NAR)", "generation", "and", "dynamic", "parameter", "pruning", "techniques,", "which", "can", "flexibly", "control", "the", "decoding", "iteration", "steps", "and", "model", "sizes", "according", "to", "memory", "and", "latency", "limitations.", "Besides,", "we", "also", "explore", "the", "effectiveness", "of", "the", "pre-trained", "MLMs", "(i.e.,", "the", "BERT", "family)", "for", "text", "generation", "tasks", "since", "their", "bidirectional", "attention", "nature", "is", "more", "suitable", "for", "the", "NAR", "training", "objective."], "pieces": ["In", "this", "work", ",", "we", "pro", "pose", "a", "no", "vel", "fine", "-", "tun", "ing", "method", "DE", "ER", ",", "which", "can", "make", "a", "single", "pre", "-", "trained", "model", "support", "Dynamic", "and", "E", "fficient", "inf", "ER", "ence", "and", "ach", "ieve", "an", "adapt", "ive", "trade", "-", "off", "between", "model", "performance", "and", "lat", "ency", ".", "In", "part", "icular", ",", "our", "critical", "ins", "ight", "is", "to", "j", "oint", "ly", "util", "ize", "the", "non", "-", "aut", "ore", "gressive", "(", "N", "AR", ")", "generation", "and", "d", "ynamic", "param", "eter", "pr", "uning", "techn", "iques", ",", "which", "can", "flex", "ibly", "control", "the", "dec", "oding", "iter", "ation", "steps", "and", "model", "s", "izes", "according", "to", "memory", "and", "lat", "ency", "lim", "itations", ".", "Besides", ",", "we", "also", "expl", "ore", "the", "effect", "iveness", "of", "the", "pre", "-", "trained", "ML", "Ms", "(", "i", ".", "e", ".,", "the", "BER", "T", "family", ")", "for", "text", "generation", "t", "asks", "since", "their", "bid", "irection", "al", "att", "ention", "nature", "is", "more", "su", "itable", "for", "the", "N", "AR", "training", "object", "ive", "."], "token_lens": [1, 1, 2, 1, 2, 1, 2, 4, 1, 3, 1, 1, 1, 1, 1, 3, 1, 1, 1, 1, 2, 3, 1, 2, 1, 2, 3, 1, 1, 1, 1, 3, 1, 3, 1, 1, 2, 1, 1, 3, 2, 1, 5, 4, 1, 1, 2, 2, 2, 3, 1, 1, 2, 1, 1, 2, 2, 1, 1, 1, 2, 1, 1, 1, 1, 2, 3, 2, 1, 1, 2, 1, 2, 1, 1, 3, 2, 5, 1, 2, 2, 1, 1, 1, 2, 1, 1, 3, 2, 1, 1, 1, 2, 1, 1, 2, 1, 3], "sentence": "In this work, we propose a novel fine-tuning method DEER, which can make a single pre-trained model support Dynamic and Efficient infERence and achieve an adaptive trade-off between model performance and latency. In particular, our critical insight is to jointly utilize the non-autoregressive (NAR) generation and dynamic parameter pruning techniques, which can flexibly control the decoding iteration steps and model sizes according to memory and latency limitations. Besides, we also explore the effectiveness of the pre-trained MLMs (i.e., the BERT family) for text generation tasks since their bidirectional attention nature is more suitable for the NAR training objective.", "sentence_starts": [0]}
{"doc_id": "bioinfo_23_P_725", "sent_id": "bioinfo_23_P_725-2", "entity_mentions": [{"id": "bioinfo_23_P_725-2-E0", "text": "PC_ali", "start": 10, "end": 11, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "bioinfo_23_P_725-2-E1", "text": "Compared with eight state-of-the-art multiple structure or sequence alignment tools", "start": 0, "end": 10, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "bioinfo_23_P_725-2-E2", "text": "sequence identity higher than structure aligners although lower than sequence aligners", "start": 20, "end": 31, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "bioinfo_23_P_725-2-E3", "text": "highest score PC_sim", "start": 31, "end": 34, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "bioinfo_23_P_725-2-E4", "text": "highest similarity with the MSAs produced by other tools and with the reference MSA Balibase", "start": 35, "end": 50, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "bioinfo_23_P_725-2-E5", "text": "higher or equal aligned fraction and structural scores", "start": 12, "end": 20, "entity_type": "UNK", "mention_type": "UNK"}], "relation_mentions": [], "event_mentions": [{"event_type": "Results/Findings", "id": "bioinfo_23_P_725-2-EV0", "trigger": {"text": "achieves", "start": 11, "end": 12}, "arguments": [{"entity_id": "bioinfo_23_P_725-2-E0", "text": "PC_ali", "role": "Agent"}, {"entity_id": "bioinfo_23_P_725-2-E1", "text": "Compared with eight state-of-the-art multiple structure or sequence alignment tools", "role": "Context"}, {"entity_id": "bioinfo_23_P_725-2-E2", "text": "sequence identity higher than structure aligners although lower than sequence aligners", "role": "Results"}, {"entity_id": "bioinfo_23_P_725-2-E3", "text": "highest score PC_sim", "role": "Results"}, {"entity_id": "bioinfo_23_P_725-2-E4", "text": "highest similarity with the MSAs produced by other tools and with the reference MSA Balibase", "role": "Results"}, {"entity_id": "bioinfo_23_P_725-2-E5", "text": "higher or equal aligned fraction and structural scores", "role": "PrimaryObject"}]}], "entity_coreference": [], "event_coreference": [], "tokens": ["Compared", "with", "eight", "state-of-the-art", "multiple", "structure", "or", "sequence", "alignment", "tools,", "PC_ali", "achieves", "higher", "or", "equal", "aligned", "fraction", "and", "structural", "scores,", "sequence", "identity", "higher", "than", "structure", "aligners", "although", "lower", "than", "sequence", "aligners,", "highest", "score", "PC_sim,", "and", "highest", "similarity", "with", "the", "MSAs", "produced", "by", "other", "tools", "and", "with", "the", "reference", "MSA", "Balibase."], "pieces": ["Compared", "with", "eight", "state", "-", "of", "-", "the", "-", "art", "multiple", "st", "ructure", "or", "sequence", "al", "ignment", "tools", ",", "PC", "_", "ali", "ach", "ieves", "higher", "or", "equal", "aligned", "f", "raction", "and", "struct", "ural", "sc", "ores", ",", "sequence", "ident", "ity", "higher", "than", "st", "ructure", "align", "ers", "although", "lower", "than", "sequence", "align", "ers", ",", "highest", "score", "PC", "_", "sim", ",", "and", "highest", "similar", "ity", "with", "the", "MS", "As", "produced", "by", "other", "tools", "and", "with", "the", "reference", "M", "SA", "Bal", "ib", "ase", "."], "token_lens": [1, 1, 1, 7, 1, 2, 1, 1, 2, 2, 3, 2, 1, 1, 1, 1, 2, 1, 2, 3, 1, 2, 1, 1, 2, 2, 1, 1, 1, 1, 3, 1, 1, 4, 1, 1, 2, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 2, 4], "sentence": "Compared with eight state-of-the-art multiple structure or sequence alignment tools, PC_ali achieves higher or equal aligned fraction and structural scores, sequence identity higher than structure aligners although lower than sequence aligners, highest score PC_sim, and highest similarity with the MSAs produced by other tools and with the reference MSA Balibase.", "sentence_starts": [0]}
{"doc_id": "ACL_23_P_85", "sent_id": "ACL_23_P_85-1", "entity_mentions": [{"id": "ACL_23_P_85-1-E0", "text": "we", "start": 3, "end": 4, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_85-1-E1", "text": "to take advantage of optional training data labels and targeted OOD data", "start": 28, "end": 40, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_85-1-E2", "text": "propose an unsupervised prefix-tuning based OOD detection framework termed PTO", "start": 17, "end": 27, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_85-1-E3", "text": "two practical extensions of PTO are further proposed", "start": 40, "end": 48, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_85-1-E4", "text": "PTO and its extensions offer several key advantages of being lightweight, easy-to-reproduce, and theoretically justified", "start": 49, "end": 64, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_85-1-E5", "text": "the classic fine-tuning based OOD detection", "start": 6, "end": 12, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_85-1-E6", "text": "toward a parameter-efficient alternative", "start": 12, "end": 16, "entity_type": "UNK", "mention_type": "UNK"}], "relation_mentions": [], "event_mentions": [{"event_type": "Methods/Approach", "id": "ACL_23_P_85-1-EV0", "trigger": {"text": "depart from", "start": 4, "end": 6}, "arguments": [{"entity_id": "ACL_23_P_85-1-E0", "text": "we", "role": "Agent"}, {"entity_id": "ACL_23_P_85-1-E1", "text": "to take advantage of optional training data labels and targeted OOD data", "role": "Purpose"}, {"entity_id": "ACL_23_P_85-1-E2", "text": "propose an unsupervised prefix-tuning based OOD detection framework termed PTO", "role": "Method"}, {"entity_id": "ACL_23_P_85-1-E3", "text": "two practical extensions of PTO are further proposed", "role": "Method"}, {"entity_id": "ACL_23_P_85-1-E4", "text": "PTO and its extensions offer several key advantages of being lightweight, easy-to-reproduce, and theoretically justified", "role": "Results"}, {"entity_id": "ACL_23_P_85-1-E5", "text": "the classic fine-tuning based OOD detection", "role": "PrimaryObject"}, {"entity_id": "ACL_23_P_85-1-E6", "text": "toward a parameter-efficient alternative", "role": "SecondaryObject"}]}], "entity_coreference": [], "event_coreference": [], "tokens": ["In", "this", "paper,", "we", "depart", "from", "the", "classic", "fine-tuning", "based", "OOD", "detection", "toward", "a", "parameter-efficient", "alternative,", "and", "propose", "an", "unsupervised", "prefix-tuning", "based", "OOD", "detection", "framework", "termed", "PTO.", "Additionally,", "to", "take", "advantage", "of", "optional", "training", "data", "labels", "and", "targeted", "OOD", "data,", "two", "practical", "extensions", "of", "PTO", "are", "further", "proposed.", "Overall,", "PTO", "and", "its", "extensions", "offer", "several", "key", "advantages", "of", "being", "lightweight,", "easy-to-reproduce,", "and", "theoretically", "justified."], "pieces": ["In", "this", "paper", ",", "we", "dep", "art", "from", "the", "classic", "fine", "-", "tun", "ing", "based", "OOD", "det", "ection", "t", "oward", "a", "param", "eter", "-", "efficient", "altern", "ative", ",", "and", "pro", "pose", "an", "un", "super", "vised", "prefix", "-", "tun", "ing", "based", "OOD", "det", "ection", "framework", "ter", "med", "P", "TO", ".", "Additionally", ",", "to", "take", "advant", "age", "of", "optional", "training", "data", "lab", "els", "and", "target", "ed", "OOD", "data", ",", "two", "pract", "ical", "ext", "ensions", "of", "P", "TO", "are", "f", "urther", "prop", "osed", ".", "Overall", ",", "P", "TO", "and", "its", "ext", "ensions", "offer", "sever", "al", "key", "advant", "ages", "of", "being", "light", "weight", ",", "easy", "-", "to", "-", "re", "produ", "ce", ",", "and", "the", "oret", "ically", "just", "ified", "."], "token_lens": [1, 1, 2, 1, 2, 1, 1, 1, 4, 1, 1, 2, 2, 1, 4, 3, 1, 2, 1, 3, 4, 1, 1, 2, 1, 2, 3, 2, 1, 1, 2, 1, 1, 1, 1, 2, 1, 2, 1, 2, 1, 2, 2, 1, 2, 1, 2, 3, 2, 2, 1, 1, 2, 1, 2, 1, 2, 1, 1, 3, 8, 1, 3, 3], "sentence": "In this paper, we depart from the classic fine-tuning based OOD detection toward a parameter-efficient alternative, and propose an unsupervised prefix-tuning based OOD detection framework termed PTO. Additionally, to take advantage of optional training data labels and targeted OOD data, two practical extensions of PTO are further proposed. Overall, PTO and its extensions offer several key advantages of being lightweight, easy-to-reproduce, and theoretically justified.", "sentence_starts": [0]}
{"doc_id": "cscw_23_P_159", "sent_id": "cscw_23_P_159-0", "entity_mentions": [{"id": "cscw_23_P_159-0-E0", "text": "we", "start": 5, "end": 6, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "cscw_23_P_159-0-E1", "text": "With rapid advances in computing", "start": 0, "end": 5, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "cscw_23_P_159-0-E2", "text": "Manufacturing is one industry undergoing a new phase of digital transformation", "start": 29, "end": 40, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "cscw_23_P_159-0-E3", "text": "Shop-floor workers are being equipped with tools to deliver efficiency and support data-driven decision making", "start": 40, "end": 55, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "cscw_23_P_159-0-E4", "text": "the expansion of technology", "start": 10, "end": 14, "entity_type": "UNK", "mention_type": "UNK"}], "relation_mentions": [], "event_mentions": [{"event_type": "Background/Introduction", "id": "cscw_23_P_159-0-EV0", "trigger": {"text": "are beginning to see", "start": 6, "end": 10}, "arguments": [{"entity_id": "cscw_23_P_159-0-E0", "text": "we", "role": "Agent"}, {"entity_id": "cscw_23_P_159-0-E1", "text": "With rapid advances in computing", "role": "Context"}, {"entity_id": "cscw_23_P_159-0-E2", "text": "Manufacturing is one industry undergoing a new phase of digital transformation", "role": "Context"}, {"entity_id": "cscw_23_P_159-0-E3", "text": "Shop-floor workers are being equipped with tools to deliver efficiency and support data-driven decision making", "role": "Context"}, {"entity_id": "cscw_23_P_159-0-E4", "text": "the expansion of technology", "role": "PrimaryObject"}]}], "entity_coreference": [], "event_coreference": [], "tokens": ["With", "rapid", "advances", "in", "computing,", "we", "are", "beginning", "to", "see", "the", "expansion", "of", "technology", "into", "domains", "far", "afield", "from", "traditional", "office", "settings", "historically", "at", "the", "center", "of", "CSCW", "research.", "Manufacturing", "is", "one", "industry", "undergoing", "a", "new", "phase", "of", "digital", "transformation.", "Shop-floor", "workers", "are", "being", "equipped", "with", "tools", "to", "deliver", "efficiency", "and", "support", "data-driven", "decision", "making."], "pieces": ["With", "rap", "id", "adv", "ances", "in", "com", "puting", ",", "we", "are", "begin", "ning", "to", "see", "the", "exp", "ansion", "of", "technology", "into", "dom", "ains", "far", "af", "ield", "from", "traditional", "office", "settings", "hist", "orically", "at", "the", "center", "of", "C", "SC", "W", "research", ".", "Manufact", "uring", "is", "one", "indust", "ry", "under", "going", "a", "new", "phase", "of", "digital", "trans", "formation", ".", "Shop", "-", "floor", "workers", "are", "being", "equipped", "with", "tools", "to", "del", "iver", "efficiency", "and", "support", "data", "-", "driven", "dec", "ision", "making", "."], "token_lens": [1, 2, 2, 1, 3, 1, 1, 2, 1, 1, 1, 2, 1, 1, 1, 2, 1, 2, 1, 1, 1, 1, 2, 1, 1, 1, 1, 3, 2, 2, 1, 1, 2, 2, 1, 1, 1, 1, 1, 3, 3, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 3, 2, 2], "sentence": "With rapid advances in computing, we are beginning to see the expansion of technology into domains far afield from traditional office settings historically at the center of CSCW research. Manufacturing is one industry undergoing a new phase of digital transformation. Shop-floor workers are being equipped with tools to deliver efficiency and support data-driven decision making.", "sentence_starts": [0]}
{"doc_id": "cscw_23_P_34", "sent_id": "cscw_23_P_34-2", "entity_mentions": [{"id": "cscw_23_P_34-2-E0", "text": "Our paper", "start": 0, "end": 2, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "cscw_23_P_34-2-E1", "text": "on technology appropriation and non-use as they relate to religious practices in the face of exogenous shocks such as the pandemic", "start": 6, "end": 27, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "cscw_23_P_34-2-E2", "text": "better cater to the religious lives of individuals and communities", "start": 31, "end": 41, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "cscw_23_P_34-2-E3", "text": "CSCW scholarship", "start": 4, "end": 6, "entity_type": "UNK", "mention_type": "UNK"}], "relation_mentions": [], "event_mentions": [{"event_type": "Conclusions/Implications", "id": "cscw_23_P_34-2-EV0", "trigger": {"text": "contributes to", "start": 2, "end": 4}, "arguments": [{"entity_id": "cscw_23_P_34-2-E0", "text": "Our paper", "role": "Agent"}, {"entity_id": "cscw_23_P_34-2-E1", "text": "on technology appropriation and non-use as they relate to religious practices in the face of exogenous shocks such as the pandemic", "role": "Context"}, {"entity_id": "cscw_23_P_34-2-E2", "text": "better cater to the religious lives of individuals and communities", "role": "Context"}, {"entity_id": "cscw_23_P_34-2-E3", "text": "CSCW scholarship", "role": "PrimaryObject"}]}], "entity_coreference": [], "event_coreference": [], "tokens": ["Our", "paper", "contributes", "to", "CSCW", "scholarship", "on", "technology", "appropriation", "and", "non-use", "as", "they", "relate", "to", "religious", "practices", "in", "the", "face", "of", "exogenous", "shocks", "such", "as", "the", "pandemic,", "and", "how", "design", "can", "better", "cater", "to", "the", "religious", "lives", "of", "individuals", "and", "communities."], "pieces": ["Our", "paper", "cont", "ributes", "to", "C", "SC", "W", "sch", "olars", "hip", "on", "technology", "appropri", "ation", "and", "non", "-", "use", "as", "they", "rel", "ate", "to", "religious", "pract", "ices", "in", "the", "face", "of", "ex", "ogenous", "sh", "ocks", "such", "as", "the", "p", "and", "emic", ",", "and", "how", "design", "can", "better", "c", "ater", "to", "the", "religious", "l", "ives", "of", "individual", "s", "and", "commun", "ities", "."], "token_lens": [1, 1, 2, 1, 3, 3, 1, 1, 2, 1, 3, 1, 1, 2, 1, 1, 2, 1, 1, 1, 1, 2, 2, 1, 1, 1, 4, 1, 1, 1, 1, 1, 2, 1, 1, 1, 2, 1, 2, 1, 3], "sentence": "Our paper contributes to CSCW scholarship on technology appropriation and non-use as they relate to religious practices in the face of exogenous shocks such as the pandemic, and how design can better cater to the religious lives of individuals and communities.", "sentence_starts": [0]}
{"doc_id": "bioinfo_23_P_262", "sent_id": "bioinfo_23_P_262-1", "entity_mentions": [{"id": "bioinfo_23_P_262-1-E0", "text": "we", "start": 1, "end": 2, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "bioinfo_23_P_262-1-E1", "text": "IntestLine", "start": 3, "end": 4, "entity_type": "UNK", "mention_type": "UNK"}], "relation_mentions": [], "event_mentions": [{"event_type": "Methods/Approach", "id": "bioinfo_23_P_262-1-EV0", "trigger": {"text": "present", "start": 2, "end": 3}, "arguments": [{"entity_id": "bioinfo_23_P_262-1-E0", "text": "we", "role": "Agent"}, {"entity_id": "bioinfo_23_P_262-1-E1", "text": "IntestLine", "role": "PrimaryObject"}]}], "entity_coreference": [], "event_coreference": [], "tokens": ["Here,", "we", "present", "IntestLine,", "a", "Shiny-based", "open-source", "application", "for", "processing", "imaging", "data", "of", "(rolled)", "intestinal", "tissues", "and", "subsequent", "mapping", "onto", "a", "line."], "pieces": ["Here", ",", "we", "present", "Int", "est", "Line", ",", "a", "Sh", "iny", "-", "based", "open", "-", "source", "application", "for", "processing", "im", "aging", "data", "of", "(", "rolled", ")", "intestinal", "t", "issues", "and", "sub", "sequent", "m", "apping", "onto", "a", "line", "."], "token_lens": [2, 1, 1, 4, 1, 4, 3, 1, 1, 1, 2, 1, 1, 3, 1, 2, 1, 2, 2, 1, 1, 2], "sentence": "Here, we present IntestLine, a Shiny-based open-source application for processing imaging data of (rolled) intestinal tissues and subsequent mapping onto a line.", "sentence_starts": [0]}
{"doc_id": "ACL_23_P_111", "sent_id": "ACL_23_P_111-0", "entity_mentions": [{"id": "ACL_23_P_111-0-E0", "text": "we", "start": 43, "end": 44, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_111-0-E1", "text": "It has been commonly observed that a teacher model with superior performance does not necessarily result in a stronger student", "start": 0, "end": 20, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_111-0-E2", "text": "to determine the impact of distillation from each training sample on the student’s generalization ability", "start": 50, "end": 65, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_111-0-E3", "text": "In order to enhance the guidance of the teacher training process", "start": 32, "end": 43, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_111-0-E4", "text": "discrepancy between current teacher training practices and effective knowledge transfer", "start": 22, "end": 32, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_111-0-E5", "text": "the concept of distillation influence", "start": 45, "end": 50, "entity_type": "UNK", "mention_type": "UNK"}], "relation_mentions": [], "event_mentions": [{"event_type": "Background/Introduction", "id": "ACL_23_P_111-0-EV0", "trigger": {"text": "introduce", "start": 44, "end": 45}, "arguments": [{"entity_id": "ACL_23_P_111-0-E0", "text": "we", "role": "Agent"}, {"entity_id": "ACL_23_P_111-0-E1", "text": "It has been commonly observed that a teacher model with superior performance does not necessarily result in a stronger student", "role": "Context"}, {"entity_id": "ACL_23_P_111-0-E2", "text": "to determine the impact of distillation from each training sample on the student’s generalization ability", "role": "Purpose"}, {"entity_id": "ACL_23_P_111-0-E3", "text": "In order to enhance the guidance of the teacher training process", "role": "Purpose"}, {"entity_id": "ACL_23_P_111-0-E4", "text": "discrepancy between current teacher training practices and effective knowledge transfer", "role": "Challenge"}, {"entity_id": "ACL_23_P_111-0-E5", "text": "the concept of distillation influence", "role": "PrimaryObject"}]}], "entity_coreference": [], "event_coreference": [], "tokens": ["It", "has", "been", "commonly", "observed", "that", "a", "teacher", "model", "with", "superior", "performance", "does", "not", "necessarily", "result", "in", "a", "stronger", "student,", "highlighting", "a", "discrepancy", "between", "current", "teacher", "training", "practices", "and", "effective", "knowledge", "transfer.", "In", "order", "to", "enhance", "the", "guidance", "of", "the", "teacher", "training", "process,", "we", "introduce", "the", "concept", "of", "distillation", "influence", "to", "determine", "the", "impact", "of", "distillation", "from", "each", "training", "sample", "on", "the", "student’s", "generalization", "ability."], "pieces": ["It", "has", "been", "common", "ly", "ob", "served", "that", "a", "te", "acher", "model", "with", "super", "ior", "performance", "does", "not", "necess", "arily", "result", "in", "a", "strong", "er", "student", ",", "high", "lighting", "a", "disc", "rep", "ancy", "between", "current", "te", "acher", "training", "pract", "ices", "and", "effective", "knowledge", "transfer", ".", "In", "order", "to", "enh", "ance", "the", "gu", "id", "ance", "of", "the", "te", "acher", "training", "process", ",", "we", "introdu", "ce", "the", "concept", "of", "dist", "illation", "inf", "luence", "to", "d", "eter", "mine", "the", "impact", "of", "dist", "illation", "from", "each", "training", "sample", "on", "the", "student", "âĢ", "Ļ", "s", "general", "ization", "ability", "."], "token_lens": [1, 1, 1, 2, 2, 1, 1, 2, 1, 1, 2, 1, 1, 1, 2, 1, 1, 1, 2, 2, 2, 1, 3, 1, 1, 2, 1, 2, 1, 1, 1, 2, 1, 1, 1, 2, 1, 3, 1, 1, 2, 1, 2, 1, 2, 1, 1, 1, 2, 2, 1, 3, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 4, 2, 2], "sentence": "It has been commonly observed that a teacher model with superior performance does not necessarily result in a stronger student, highlighting a discrepancy between current teacher training practices and effective knowledge transfer. In order to enhance the guidance of the teacher training process, we introduce the concept of distillation influence to determine the impact of distillation from each training sample on the student’s generalization ability.", "sentence_starts": [0]}
{"doc_id": "ACL_23_P_404", "sent_id": "ACL_23_P_404-1", "entity_mentions": [{"id": "ACL_23_P_404-1-E0", "text": "We", "start": 0, "end": 1, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_404-1-E1", "text": "Each instance in the X-CI dataset is annotated with five labels: complaint label, emotion label, polarity label, complaint severity level, and rationale (explainability), i.e., the causal span explaining the reason for the complaint/non-complaint label", "start": 15, "end": 49, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_404-1-E2", "text": "We address the task of explainable complaint detection and propose a commonsense-aware unified generative framework by reframing the multitask problem as a text-to-text generation task", "start": 49, "end": 74, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_404-1-E3", "text": "Our framework can predict the complaint cause, severity level, emotion, and polarity of the text in addition to detecting whether it is a complaint or not", "start": 74, "end": 100, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_404-1-E4", "text": "an explainable complaint dataset, X-CI", "start": 2, "end": 7, "entity_type": "UNK", "mention_type": "UNK"}], "relation_mentions": [], "event_mentions": [{"event_type": "Methods/Approach", "id": "ACL_23_P_404-1-EV0", "trigger": {"text": "introduce", "start": 1, "end": 2}, "arguments": [{"entity_id": "ACL_23_P_404-1-E0", "text": "We", "role": "Agent"}, {"entity_id": "ACL_23_P_404-1-E1", "text": "Each instance in the X-CI dataset is annotated with five labels: complaint label, emotion label, polarity label, complaint severity level, and rationale (explainability), i.e., the causal span explaining the reason for the complaint/non-complaint label", "role": "Method"}, {"entity_id": "ACL_23_P_404-1-E2", "text": "We address the task of explainable complaint detection and propose a commonsense-aware unified generative framework by reframing the multitask problem as a text-to-text generation task", "role": "Method"}, {"entity_id": "ACL_23_P_404-1-E3", "text": "Our framework can predict the complaint cause, severity level, emotion, and polarity of the text in addition to detecting whether it is a complaint or not", "role": "Method"}, {"entity_id": "ACL_23_P_404-1-E4", "text": "an explainable complaint dataset, X-CI", "role": "PrimaryObject"}]}], "entity_coreference": [], "event_coreference": [], "tokens": ["We", "introduce", "an", "explainable", "complaint", "dataset,", "X-CI,", "the", "first", "benchmark", "dataset", "for", "explainable", "complaint", "detection.", "Each", "instance", "in", "the", "X-CI", "dataset", "is", "annotated", "with", "five", "labels:", "complaint", "label,", "emotion", "label,", "polarity", "label,", "complaint", "severity", "level,", "and", "rationale", "(explainability),", "i.e.,", "the", "causal", "span", "explaining", "the", "reason", "for", "the", "complaint/non-complaint", "label.", "We", "address", "the", "task", "of", "explainable", "complaint", "detection", "and", "propose", "a", "commonsense-aware", "unified", "generative", "framework", "by", "reframing", "the", "multitask", "problem", "as", "a", "text-to-text", "generation", "task.", "Our", "framework", "can", "predict", "the", "complaint", "cause,", "severity", "level,", "emotion,", "and", "polarity", "of", "the", "text", "in", "addition", "to", "detecting", "whether", "it", "is", "a", "complaint", "or", "not."], "pieces": ["We", "introdu", "ce", "an", "expl", "ain", "able", "compl", "aint", "dat", "as", "et", ",", "X", "-", "CI", ",", "the", "first", "bench", "mark", "dat", "as", "et", "for", "expl", "ain", "able", "compl", "aint", "det", "ection", ".", "Each", "instance", "in", "the", "X", "-", "CI", "dat", "as", "et", "is", "annot", "ated", "with", "five", "lab", "els", ":", "compl", "aint", "label", ",", "em", "otion", "label", ",", "p", "olar", "ity", "label", ",", "compl", "aint", "sever", "ity", "level", ",", "and", "rational", "e", "(", "expl", "ain", "ability", "),", "i", ".", "e", ".,", "the", "ca", "usal", "span", "expl", "aining", "the", "reason", "for", "the", "compl", "aint", "/", "non", "-", "compl", "aint", "label", ".", "We", "address", "the", "task", "of", "expl", "ain", "able", "compl", "aint", "det", "ection", "and", "pro", "pose", "a", "comm", "onsense", "-", "aware", "un", "ified", "gener", "ative", "framework", "by", "ref", "ram", "ing", "the", "mult", "it", "ask", "problem", "as", "a", "text", "-", "to", "-", "text", "generation", "task", ".", "Our", "framework", "can", "p", "redict", "the", "compl", "aint", "cause", ",", "sever", "ity", "level", ",", "em", "otion", ",", "and", "p", "olar", "ity", "of", "the", "text", "in", "add", "ition", "to", "det", "ect", "ing", "whether", "it", "is", "a", "compl", "aint", "or", "not", "."], "token_lens": [1, 2, 1, 3, 2, 4, 4, 1, 1, 2, 3, 1, 3, 2, 3, 1, 1, 1, 1, 3, 3, 1, 2, 1, 1, 3, 2, 2, 2, 2, 3, 2, 2, 2, 2, 1, 2, 5, 4, 1, 2, 1, 2, 1, 1, 1, 1, 7, 2, 1, 1, 1, 1, 1, 3, 2, 2, 1, 2, 1, 4, 2, 2, 1, 1, 3, 1, 3, 1, 1, 1, 5, 1, 2, 1, 1, 1, 2, 1, 2, 2, 2, 2, 3, 1, 3, 1, 1, 1, 1, 2, 1, 3, 1, 1, 1, 1, 2, 1, 2], "sentence": "We introduce an explainable complaint dataset, X-CI, the first benchmark dataset for explainable complaint detection. Each instance in the X-CI dataset is annotated with five labels: complaint label, emotion label, polarity label, complaint severity level, and rationale (explainability), i.e., the causal span explaining the reason for the complaint/non-complaint label. We address the task of explainable complaint detection and propose a commonsense-aware unified generative framework by reframing the multitask problem as a text-to-text generation task. Our framework can predict the complaint cause, severity level, emotion, and polarity of the text in addition to detecting whether it is a complaint or not.", "sentence_starts": [0]}
{"doc_id": "bioinfo_23_P_520", "sent_id": "bioinfo_23_P_520-1", "entity_mentions": [{"id": "bioinfo_23_P_520-1-E0", "text": "we", "start": 3, "end": 4, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "bioinfo_23_P_520-1-E1", "text": "We also have designed a method to visualize the relational graph where the families are shown as nodes and their similarity information is represented as edges", "start": 24, "end": 50, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "bioinfo_23_P_520-1-E2", "text": "a method", "start": 5, "end": 7, "entity_type": "UNK", "mention_type": "UNK"}], "relation_mentions": [], "event_mentions": [{"event_type": "Methods/Approach", "id": "bioinfo_23_P_520-1-EV0", "trigger": {"text": "proposed", "start": 4, "end": 5}, "arguments": [{"entity_id": "bioinfo_23_P_520-1-E0", "text": "we", "role": "Agent"}, {"entity_id": "bioinfo_23_P_520-1-E1", "text": "We also have designed a method to visualize the relational graph where the families are shown as nodes and their similarity information is represented as edges", "role": "Method"}, {"entity_id": "bioinfo_23_P_520-1-E2", "text": "a method", "role": "PrimaryObject"}]}], "entity_coreference": [], "event_coreference": [], "tokens": ["In", "this", "work,", "we", "proposed", "a", "method,", "RNAMotifComp,", "that", "analyzes", "the", "instances", "of", "well-known", "structural", "motif", "families", "and", "establishes", "a", "relational", "graph", "among", "them.", "We", "also", "have", "designed", "a", "method", "to", "visualize", "the", "relational", "graph", "where", "the", "families", "are", "shown", "as", "nodes", "and", "their", "similarity", "information", "is", "represented", "as", "edges."], "pieces": ["In", "this", "work", ",", "we", "prop", "osed", "a", "method", ",", "RN", "AM", "ot", "if", "Comp", ",", "that", "analy", "zes", "the", "inst", "ances", "of", "well", "-", "known", "struct", "ural", "mot", "if", "fam", "ilies", "and", "est", "ab", "lishes", "a", "rel", "ational", "graph", "among", "them", ".", "We", "also", "have", "designed", "a", "method", "to", "visual", "ize", "the", "rel", "ational", "graph", "where", "the", "fam", "ilies", "are", "shown", "as", "n", "odes", "and", "their", "similar", "ity", "information", "is", "represented", "as", "ed", "ges", "."], "token_lens": [1, 1, 2, 1, 2, 1, 2, 6, 1, 2, 1, 2, 1, 3, 2, 2, 2, 1, 3, 1, 2, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 2, 1, 2, 1, 1, 1, 2, 1, 1, 1, 2, 1, 1, 2, 1, 1, 1, 1, 3], "sentence": "In this work, we proposed a method, RNAMotifComp, that analyzes the instances of well-known structural motif families and establishes a relational graph among them. We also have designed a method to visualize the relational graph where the families are shown as nodes and their similarity information is represented as edges.", "sentence_starts": [0]}
{"doc_id": "bioinfo_23_P_374", "sent_id": "bioinfo_23_P_374-0", "entity_mentions": [{"id": "bioinfo_23_P_374-0-E0", "text": "reconstruction of consensus genomes from sequence data", "start": 4, "end": 11, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "bioinfo_23_P_374-0-E1", "text": "as the number of samples that are sequenced grows rapidly, compute resources needed to reconstruct consensus genomes can become prohibitively large", "start": 21, "end": 42, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "bioinfo_23_P_374-0-E2", "text": "tracking mutations and variants of concern", "start": 14, "end": 20, "entity_type": "UNK", "mention_type": "UNK"}], "relation_mentions": [], "event_mentions": [{"event_type": "Background/Introduction", "id": "bioinfo_23_P_374-0-EV0", "trigger": {"text": "is critical for", "start": 11, "end": 14}, "arguments": [{"entity_id": "bioinfo_23_P_374-0-E0", "text": "reconstruction of consensus genomes from sequence data", "role": "Agent"}, {"entity_id": "bioinfo_23_P_374-0-E1", "text": "as the number of samples that are sequenced grows rapidly, compute resources needed to reconstruct consensus genomes can become prohibitively large", "role": "Challenge"}, {"entity_id": "bioinfo_23_P_374-0-E2", "text": "tracking mutations and variants of concern", "role": "PrimaryObject"}]}], "entity_coreference": [], "event_coreference": [], "tokens": ["In", "viral", "molecular", "epidemiology,", "reconstruction", "of", "consensus", "genomes", "from", "sequence", "data", "is", "critical", "for", "tracking", "mutations", "and", "variants", "of", "concern.", "However,", "as", "the", "number", "of", "samples", "that", "are", "sequenced", "grows", "rapidly,", "compute", "resources", "needed", "to", "reconstruct", "consensus", "genomes", "can", "become", "prohibitively", "large."], "pieces": ["In", "v", "iral", "m", "ole", "cular", "ep", "idem", "iology", ",", "re", "const", "ruction", "of", "cons", "ensus", "gen", "omes", "from", "sequence", "data", "is", "critical", "for", "tracking", "mut", "ations", "and", "vari", "ants", "of", "con", "cern", ".", "However", ",", "as", "the", "number", "of", "s", "amples", "that", "are", "sequ", "enced", "g", "rows", "rap", "id", "ly", ",", "comp", "ute", "resources", "needed", "to", "re", "construct", "cons", "ensus", "gen", "omes", "can", "bec", "ome", "pro", "hib", "itive", "ly", "large", "."], "token_lens": [1, 2, 3, 4, 3, 1, 2, 2, 1, 1, 1, 1, 1, 1, 1, 2, 1, 2, 1, 3, 2, 1, 1, 1, 1, 2, 1, 1, 2, 2, 4, 2, 1, 1, 1, 2, 2, 2, 1, 2, 4, 2], "sentence": "In viral molecular epidemiology, reconstruction of consensus genomes from sequence data is critical for tracking mutations and variants of concern. However, as the number of samples that are sequenced grows rapidly, compute resources needed to reconstruct consensus genomes can become prohibitively large.", "sentence_starts": [0]}
{"doc_id": "cscw_23_P_174", "sent_id": "cscw_23_P_174-1", "entity_mentions": [{"id": "cscw_23_P_174-1-E0", "text": "We", "start": 0, "end": 1, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "cscw_23_P_174-1-E1", "text": "this division of labor and software capacities emerged, articulated by the actors themselves as they went about their tasks", "start": 37, "end": 56, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "cscw_23_P_174-1-E2", "text": "The activities of making the novel software 'work' at all, and the 'extra work' of making that software repurposable or reusable could not be distinguished until near the end of the development process — rather than defined or structured in advance", "start": 56, "end": 97, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "cscw_23_P_174-1-E3", "text": "these two tasks — making the software work for themselves and also for their wider scientific community — could not be differentiated from each other at the beginning of the software development process", "start": 3, "end": 36, "entity_type": "UNK", "mention_type": "UNK"}], "relation_mentions": [], "event_mentions": [{"event_type": "Methods/Approach", "id": "cscw_23_P_174-1-EV0", "trigger": {"text": "argue", "start": 1, "end": 2}, "arguments": [{"entity_id": "cscw_23_P_174-1-E0", "text": "We", "role": "Agent"}, {"entity_id": "cscw_23_P_174-1-E1", "text": "this division of labor and software capacities emerged, articulated by the actors themselves as they went about their tasks", "role": "Results"}, {"entity_id": "cscw_23_P_174-1-E2", "text": "The activities of making the novel software 'work' at all, and the 'extra work' of making that software repurposable or reusable could not be distinguished until near the end of the development process — rather than defined or structured in advance", "role": "Results"}, {"entity_id": "cscw_23_P_174-1-E3", "text": "these two tasks — making the software work for themselves and also for their wider scientific community — could not be differentiated from each other at the beginning of the software development process", "role": "PrimaryObject"}]}], "entity_coreference": [], "event_coreference": [], "tokens": ["We", "argue", "that", "these", "two", "tasks", "—", "making", "the", "software", "work", "for", "themselves", "and", "also", "for", "their", "wider", "scientific", "community", "—", "could", "not", "be", "differentiated", "from", "each", "other", "at", "the", "beginning", "of", "the", "software", "development", "process.", "Rather,", "this", "division", "of", "labor", "and", "software", "capacities", "emerged,", "articulated", "by", "the", "actors", "themselves", "as", "they", "went", "about", "their", "tasks.", "The", "activities", "of", "making", "the", "novel", "software", "'work'", "at", "all,", "and", "the", "'extra", "work'", "of", "making", "that", "software", "repurposable", "or", "reusable", "could", "not", "be", "distinguished", "until", "near", "the", "end", "of", "the", "development", "process", "—", "rather", "than", "defined", "or", "structured", "in", "advance."], "pieces": ["We", "arg", "ue", "that", "these", "two", "t", "asks", "âĢĶ", "making", "the", "software", "work", "for", "them", "selves", "and", "also", "for", "their", "w", "ider", "scientific", "community", "âĢĶ", "could", "not", "be", "different", "iated", "from", "each", "other", "at", "the", "begin", "ning", "of", "the", "software", "development", "process", ".", "Rather", ",", "this", "division", "of", "l", "abor", "and", "software", "cap", "ac", "ities", "emer", "ged", ",", "art", "ic", "ulated", "by", "the", "act", "ors", "them", "selves", "as", "they", "went", "about", "their", "t", "asks", ".", "The", "activ", "ities", "of", "making", "the", "no", "vel", "software", "'", "work", "'", "at", "all", ",", "and", "the", "'", "extra", "work", "'", "of", "making", "that", "software", "rep", "ur", "pos", "able", "or", "re", "usable", "could", "not", "be", "dist", "inguished", "until", "near", "the", "end", "of", "the", "development", "process", "âĢĶ", "rather", "than", "defined", "or", "struct", "ured", "in", "ad", "vance", "."], "token_lens": [1, 2, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 2, 2, 1, 1, 1, 2, 1, 1, 3, 3, 3, 1, 1, 2, 2, 1, 1, 1, 1, 1, 3, 1, 2, 1, 1, 1, 2, 1, 3, 1, 2, 1, 1, 2, 2, 1, 1, 1, 1, 4, 1, 2, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 3], "sentence": "We argue that these two tasks — making the software work for themselves and also for their wider scientific community — could not be differentiated from each other at the beginning of the software development process. Rather, this division of labor and software capacities emerged, articulated by the actors themselves as they went about their tasks. The activities of making the novel software 'work' at all, and the 'extra work' of making that software repurposable or reusable could not be distinguished until near the end of the development process — rather than defined or structured in advance.", "sentence_starts": [0]}
{"doc_id": "ACL_23_P_215", "sent_id": "ACL_23_P_215-0", "entity_mentions": [{"id": "ACL_23_P_215-0-E0", "text": "we", "start": 3, "end": 4, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_215-0-E1", "text": "During training, DiffusionNER gradually adds noises to the golden entity boundaries by a fixed forward diffusion process and learns a reverse diffusion process to recover the entity boundaries", "start": 26, "end": 54, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_215-0-E2", "text": "In inference, DiffusionNER first randomly samples some noisy spans from a standard Gaussian distribution and then generates the named entities by denoising them with the learned reverse diffusion process.", "start": 54, "end": 83, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_215-0-E3", "text": "DiffusionNER", "start": 5, "end": 6, "entity_type": "UNK", "mention_type": "UNK"}], "relation_mentions": [], "event_mentions": [{"event_type": "Methods/Approach", "id": "ACL_23_P_215-0-EV0", "trigger": {"text": "propose", "start": 4, "end": 5}, "arguments": [{"entity_id": "ACL_23_P_215-0-E0", "text": "we", "role": "Agent"}, {"entity_id": "ACL_23_P_215-0-E1", "text": "During training, DiffusionNER gradually adds noises to the golden entity boundaries by a fixed forward diffusion process and learns a reverse diffusion process to recover the entity boundaries", "role": "Method"}, {"entity_id": "ACL_23_P_215-0-E2", "text": "In inference, DiffusionNER first randomly samples some noisy spans from a standard Gaussian distribution and then generates the named entities by denoising them with the learned reverse diffusion process.", "role": "Method"}, {"entity_id": "ACL_23_P_215-0-E3", "text": "DiffusionNER", "role": "PrimaryObject"}]}], "entity_coreference": [], "event_coreference": [], "tokens": ["In", "this", "paper,", "we", "propose", "DiffusionNER,", "which", "formulates", "the", "named", "entity", "recognition", "task", "as", "a", "boundary-denoising", "diffusion", "process", "and", "thus", "generates", "named", "entities", "from", "noisy", "spans.", "During", "training,", "DiffusionNER", "gradually", "adds", "noises", "to", "the", "golden", "entity", "boundaries", "by", "a", "fixed", "forward", "diffusion", "process", "and", "learns", "a", "reverse", "diffusion", "process", "to", "recover", "the", "entity", "boundaries.", "In", "inference,", "DiffusionNER", "first", "randomly", "samples", "some", "noisy", "spans", "from", "a", "standard", "Gaussian", "distribution", "and", "then", "generates", "the", "named", "entities", "by", "denoising", "them", "with", "the", "learned", "reverse", "diffusion", "process."], "pieces": ["In", "this", "paper", ",", "we", "pro", "pose", "Diff", "usion", "NER", ",", "which", "form", "ulates", "the", "named", "entity", "recogn", "ition", "task", "as", "a", "bound", "ary", "-", "den", "o", "ising", "diff", "usion", "process", "and", "thus", "gener", "ates", "named", "ent", "ities", "from", "no", "isy", "sp", "ans", ".", "During", "training", ",", "Diff", "usion", "NER", "grad", "ually", "add", "s", "no", "ises", "to", "the", "gold", "en", "entity", "bound", "aries", "by", "a", "fixed", "forward", "diff", "usion", "process", "and", "learn", "s", "a", "reverse", "diff", "usion", "process", "to", "re", "cover", "the", "entity", "bound", "aries", ".", "In", "in", "ference", ",", "Diff", "usion", "NER", "first", "random", "ly", "s", "amples", "some", "no", "isy", "sp", "ans", "from", "a", "standard", "Ga", "ussian", "dist", "ribution", "and", "then", "gener", "ates", "the", "named", "ent", "ities", "by", "den", "o", "ising", "them", "with", "the", "learn", "ed", "reverse", "diff", "usion", "process", "."], "token_lens": [1, 1, 2, 1, 2, 4, 1, 2, 1, 1, 1, 2, 1, 1, 1, 6, 2, 1, 1, 1, 2, 1, 2, 1, 2, 3, 1, 2, 3, 2, 2, 2, 1, 1, 2, 1, 2, 1, 1, 1, 1, 2, 1, 1, 2, 1, 1, 2, 1, 1, 2, 1, 1, 3, 1, 3, 3, 1, 2, 2, 1, 2, 2, 1, 1, 1, 2, 2, 1, 1, 2, 1, 1, 2, 1, 3, 1, 1, 1, 2, 1, 2, 2], "sentence": "In this paper, we propose DiffusionNER, which formulates the named entity recognition task as a boundary-denoising diffusion process and thus generates named entities from noisy spans. During training, DiffusionNER gradually adds noises to the golden entity boundaries by a fixed forward diffusion process and learns a reverse diffusion process to recover the entity boundaries. In inference, DiffusionNER first randomly samples some noisy spans from a standard Gaussian distribution and then generates the named entities by denoising them with the learned reverse diffusion process.", "sentence_starts": [0]}
{"doc_id": "ACL_23_P_606", "sent_id": "ACL_23_P_606-1", "entity_mentions": [{"id": "ACL_23_P_606-1-E0", "text": "we", "start": 3, "end": 4, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_606-1-E1", "text": "SACL applies contrast-aware adversarial training to generate worst-case samples and uses joint class-spread contrastive learning to extract structured representations", "start": 21, "end": 40, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_606-1-E2", "text": "It can effectively utilize label-level feature consistency and retain fine-grained intra-class features", "start": 40, "end": 52, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_606-1-E3", "text": "To avoid the negative impact of adversarial perturbations on context-dependent data, we design a contextual adversarial training (CAT) strategy to learn more diverse features from context and enhance the model’s context robustness", "start": 52, "end": 84, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_606-1-E4", "text": "Under the framework with CAT, we develop a sequence-based SACL-LSTM to learn label-consistent and context-robust features for ERC", "start": 84, "end": 102, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_606-1-E5", "text": "a supervised adversarial contrastive learning (SACL) framework", "start": 5, "end": 12, "entity_type": "UNK", "mention_type": "UNK"}], "relation_mentions": [], "event_mentions": [{"event_type": "Methods/Approach", "id": "ACL_23_P_606-1-EV0", "trigger": {"text": "propose", "start": 4, "end": 5}, "arguments": [{"entity_id": "ACL_23_P_606-1-E0", "text": "we", "role": "Agent"}, {"entity_id": "ACL_23_P_606-1-E1", "text": "SACL applies contrast-aware adversarial training to generate worst-case samples and uses joint class-spread contrastive learning to extract structured representations", "role": "Method"}, {"entity_id": "ACL_23_P_606-1-E2", "text": "It can effectively utilize label-level feature consistency and retain fine-grained intra-class features", "role": "Method"}, {"entity_id": "ACL_23_P_606-1-E3", "text": "To avoid the negative impact of adversarial perturbations on context-dependent data, we design a contextual adversarial training (CAT) strategy to learn more diverse features from context and enhance the model’s context robustness", "role": "Method"}, {"entity_id": "ACL_23_P_606-1-E4", "text": "Under the framework with CAT, we develop a sequence-based SACL-LSTM to learn label-consistent and context-robust features for ERC", "role": "Method"}, {"entity_id": "ACL_23_P_606-1-E5", "text": "a supervised adversarial contrastive learning (SACL) framework", "role": "PrimaryObject"}]}], "entity_coreference": [], "event_coreference": [], "tokens": ["To", "address", "this,", "we", "propose", "a", "supervised", "adversarial", "contrastive", "learning", "(SACL)", "framework", "for", "learning", "class-spread", "structured", "representations", "in", "a", "supervised", "manner.", "SACL", "applies", "contrast-aware", "adversarial", "training", "to", "generate", "worst-case", "samples", "and", "uses", "joint", "class-spread", "contrastive", "learning", "to", "extract", "structured", "representations.", "It", "can", "effectively", "utilize", "label-level", "feature", "consistency", "and", "retain", "fine-grained", "intra-class", "features.", "To", "avoid", "the", "negative", "impact", "of", "adversarial", "perturbations", "on", "context-dependent", "data,", "we", "design", "a", "contextual", "adversarial", "training", "(CAT)", "strategy", "to", "learn", "more", "diverse", "features", "from", "context", "and", "enhance", "the", "model’s", "context", "robustness.", "Under", "the", "framework", "with", "CAT,", "we", "develop", "a", "sequence-based", "SACL-LSTM", "to", "learn", "label-consistent", "and", "context-robust", "features", "for", "ERC."], "pieces": ["To", "address", "this", ",", "we", "pro", "pose", "a", "super", "vised", "ad", "vers", "arial", "cont", "rast", "ive", "learning", "(", "S", "AC", "L", ")", "framework", "for", "learning", "class", "-", "spread", "struct", "ured", "represent", "ations", "in", "a", "super", "vised", "man", "ner", ".", "S", "AC", "L", "app", "lies", "cont", "rast", "-", "aware", "ad", "vers", "arial", "training", "to", "gener", "ate", "worst", "-", "case", "s", "amples", "and", "uses", "j", "oint", "class", "-", "spread", "cont", "rast", "ive", "learning", "to", "ext", "ract", "struct", "ured", "represent", "ations", ".", "It", "can", "effect", "ively", "util", "ize", "label", "-", "level", "feature", "cons", "ist", "ency", "and", "ret", "ain", "fine", "-", "gr", "ained", "int", "ra", "-", "class", "features", ".", "To", "avoid", "the", "negative", "impact", "of", "ad", "vers", "arial", "pert", "urb", "ations", "on", "context", "-", "dependent", "data", ",", "we", "design", "a", "context", "ual", "ad", "vers", "arial", "training", "(", "C", "AT", ")", "str", "ategy", "to", "learn", "more", "d", "iverse", "features", "from", "context", "and", "enh", "ance", "the", "model", "âĢ", "Ļ", "s", "context", "rob", "ust", "ness", ".", "Under", "the", "framework", "with", "C", "AT", ",", "we", "develop", "a", "sequence", "-", "based", "S", "AC", "L", "-", "L", "ST", "M", "to", "learn", "label", "-", "cons", "istent", "and", "context", "-", "rob", "ust", "features", "for", "ERC", "."], "token_lens": [1, 1, 2, 1, 2, 1, 2, 3, 3, 1, 5, 1, 1, 1, 3, 2, 2, 1, 1, 2, 3, 3, 2, 4, 3, 1, 1, 2, 3, 2, 1, 1, 2, 3, 3, 1, 1, 2, 2, 3, 1, 1, 2, 2, 3, 1, 3, 1, 2, 4, 4, 2, 1, 1, 1, 1, 1, 1, 3, 3, 1, 3, 2, 1, 1, 1, 2, 3, 1, 4, 2, 1, 1, 1, 2, 1, 1, 1, 1, 2, 1, 4, 1, 4, 1, 1, 1, 1, 3, 1, 1, 1, 3, 7, 1, 1, 4, 1, 4, 1, 1, 2], "sentence": "To address this, we propose a supervised adversarial contrastive learning (SACL) framework for learning class-spread structured representations in a supervised manner. SACL applies contrast-aware adversarial training to generate worst-case samples and uses joint class-spread contrastive learning to extract structured representations. It can effectively utilize label-level feature consistency and retain fine-grained intra-class features. To avoid the negative impact of adversarial perturbations on context-dependent data, we design a contextual adversarial training (CAT) strategy to learn more diverse features from context and enhance the model’s context robustness. Under the framework with CAT, we develop a sequence-based SACL-LSTM to learn label-consistent and context-robust features for ERC.", "sentence_starts": [0]}
{"doc_id": "ACL_23_P_12", "sent_id": "ACL_23_P_12-2", "entity_mentions": [{"id": "ACL_23_P_12-2-E0", "text": "Our findings", "start": 0, "end": 2, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_12-2-E1", "text": "for psycholinguistic theories of anaphor resolution", "start": 19, "end": 25, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_12-2-E2", "text": "equally valuable", "start": 3, "end": 5, "entity_type": "UNK", "mention_type": "UNK"}], "relation_mentions": [], "event_mentions": [{"event_type": "Conclusions/Implications", "id": "ACL_23_P_12-2-EV0", "trigger": {"text": "are", "start": 2, "end": 3}, "arguments": [{"entity_id": "ACL_23_P_12-2-E0", "text": "Our findings", "role": "Agent"}, {"entity_id": "ACL_23_P_12-2-E1", "text": "for psycholinguistic theories of anaphor resolution", "role": "Implications"}, {"entity_id": "ACL_23_P_12-2-E2", "text": "equally valuable", "role": "PrimaryObject"}]}], "entity_coreference": [], "event_coreference": [], "tokens": ["Our", "findings", "are", "equally", "valuable", "for", "the", "evaluation", "of", "language", "models’", "ability", "to", "capture", "linguistic", "generalizations,", "as", "well", "as", "for", "psycholinguistic", "theories", "of", "anaphor", "resolution."], "pieces": ["Our", "find", "ings", "are", "equ", "ally", "val", "uable", "for", "the", "eval", "uation", "of", "language", "models", "âĢ", "Ļ", "ability", "to", "capt", "ure", "ling", "u", "istic", "general", "izations", ",", "as", "well", "as", "for", "psych", "ol", "ingu", "istic", "the", "ories", "of", "an", "aph", "or", "resolution", "."], "token_lens": [1, 2, 1, 2, 2, 1, 1, 2, 1, 1, 3, 1, 1, 2, 3, 3, 1, 1, 1, 1, 4, 2, 1, 3, 2], "sentence": "Our findings are equally valuable for the evaluation of language models’ ability to capture linguistic generalizations, as well as for psycholinguistic theories of anaphor resolution.", "sentence_starts": [0]}
{"doc_id": "bioinfo_23_P_246", "sent_id": "bioinfo_23_P_246-1", "entity_mentions": [{"id": "bioinfo_23_P_246-1-E0", "text": "We", "start": 0, "end": 1, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "bioinfo_23_P_246-1-E1", "text": "CFAGO is first pre-trained with an encoder-decoder architecture to capture the universal protein representation of the two sources", "start": 23, "end": 41, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "bioinfo_23_P_246-1-E2", "text": "It is then fine-tuned to learn more effective protein representations for protein function prediction", "start": 41, "end": 55, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "bioinfo_23_P_246-1-E3", "text": "a novel protein function prediction method", "start": 2, "end": 8, "entity_type": "UNK", "mention_type": "UNK"}], "relation_mentions": [], "event_mentions": [{"event_type": "Methods/Approach", "id": "bioinfo_23_P_246-1-EV0", "trigger": {"text": "develop", "start": 1, "end": 2}, "arguments": [{"entity_id": "bioinfo_23_P_246-1-E0", "text": "We", "role": "Agent"}, {"entity_id": "bioinfo_23_P_246-1-E1", "text": "CFAGO is first pre-trained with an encoder-decoder architecture to capture the universal protein representation of the two sources", "role": "Method"}, {"entity_id": "bioinfo_23_P_246-1-E2", "text": "It is then fine-tuned to learn more effective protein representations for protein function prediction", "role": "Method"}, {"entity_id": "bioinfo_23_P_246-1-E3", "text": "a novel protein function prediction method", "role": "PrimaryObject"}]}], "entity_coreference": [], "event_coreference": [], "tokens": ["We", "develop", "a", "novel", "protein", "function", "prediction", "method,", "CFAGO,", "to", "integrate", "single-species", "PPI", "networks", "and", "protein", "biological", "attributes", "via", "a", "multi-head", "attention", "mechanism.", "CFAGO", "is", "first", "pre-trained", "with", "an", "encoder-decoder", "architecture", "to", "capture", "the", "universal", "protein", "representation", "of", "the", "two", "sources.", "It", "is", "then", "fine-tuned", "to", "learn", "more", "effective", "protein", "representations", "for", "protein", "function", "prediction."], "pieces": ["We", "develop", "a", "no", "vel", "protein", "function", "pred", "iction", "method", ",", "CF", "AG", "O", ",", "to", "integ", "rate", "single", "-", "species", "PP", "I", "net", "works", "and", "protein", "bi", "ological", "att", "ributes", "via", "a", "multi", "-", "head", "att", "ention", "me", "chan", "ism", ".", "CF", "AG", "O", "is", "first", "pre", "-", "trained", "with", "an", "enc", "oder", "-", "dec", "oder", "arch", "itect", "ure", "to", "capt", "ure", "the", "universal", "protein", "represent", "ation", "of", "the", "two", "s", "ources", ".", "It", "is", "then", "fine", "-", "tun", "ed", "to", "learn", "more", "effective", "protein", "represent", "ations", "for", "protein", "function", "pred", "iction", "."], "token_lens": [1, 1, 1, 2, 1, 1, 2, 2, 4, 1, 2, 3, 2, 2, 1, 1, 2, 2, 1, 1, 3, 2, 4, 3, 1, 1, 3, 1, 1, 5, 3, 1, 2, 1, 1, 1, 2, 1, 1, 1, 3, 1, 1, 1, 4, 1, 1, 1, 1, 1, 2, 1, 1, 1, 3], "sentence": "We develop a novel protein function prediction method, CFAGO, to integrate single-species PPI networks and protein biological attributes via a multi-head attention mechanism. CFAGO is first pre-trained with an encoder-decoder architecture to capture the universal protein representation of the two sources. It is then fine-tuned to learn more effective protein representations for protein function prediction.", "sentence_starts": [0]}
{"doc_id": "bioinfo_23_P_406", "sent_id": "bioinfo_23_P_406-2", "entity_mentions": [{"id": "bioinfo_23_P_406-2-E0", "text": "We", "start": 0, "end": 1, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "bioinfo_23_P_406-2-E1", "text": "CGMS significantly outperforms other methods in the leave-drug combination-out scenario, as well as in the leave-cell line-out and leave-drug-out scenarios", "start": 14, "end": 34, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "bioinfo_23_P_406-2-E2", "text": "We further present the benefit of eliminating the order dependency and the discrimination power of whole-graph embeddings, interpret the rationality of the attention mechanism, and verify the contribution of multi-task learning", "start": 34, "end": 65, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "bioinfo_23_P_406-2-E3", "text": "CGMS's generalization ability", "start": 2, "end": 5, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "bioinfo_23_P_406-2-E4", "text": "with six state-of-the-art methods on a public dataset", "start": 5, "end": 13, "entity_type": "UNK", "mention_type": "UNK"}], "relation_mentions": [], "event_mentions": [{"event_type": "Results/Findings", "id": "bioinfo_23_P_406-2-EV0", "trigger": {"text": "compare", "start": 1, "end": 2}, "arguments": [{"entity_id": "bioinfo_23_P_406-2-E0", "text": "We", "role": "Agent"}, {"entity_id": "bioinfo_23_P_406-2-E1", "text": "CGMS significantly outperforms other methods in the leave-drug combination-out scenario, as well as in the leave-cell line-out and leave-drug-out scenarios", "role": "Results"}, {"entity_id": "bioinfo_23_P_406-2-E2", "text": "We further present the benefit of eliminating the order dependency and the discrimination power of whole-graph embeddings, interpret the rationality of the attention mechanism, and verify the contribution of multi-task learning", "role": "Results"}, {"entity_id": "bioinfo_23_P_406-2-E3", "text": "CGMS's generalization ability", "role": "PrimaryObject"}, {"entity_id": "bioinfo_23_P_406-2-E4", "text": "with six state-of-the-art methods on a public dataset", "role": "SecondaryObject"}]}], "entity_coreference": [], "event_coreference": [], "tokens": ["We", "compare", "CGMS's", "generalization", "ability", "with", "six", "state-of-the-art", "methods", "on", "a", "public", "dataset,", "and", "CGMS", "significantly", "outperforms", "other", "methods", "in", "the", "leave-drug", "combination-out", "scenario,", "as", "well", "as", "in", "the", "leave-cell", "line-out", "and", "leave-drug-out", "scenarios.", "We", "further", "present", "the", "benefit", "of", "eliminating", "the", "order", "dependency", "and", "the", "discrimination", "power", "of", "whole-graph", "embeddings,", "interpret", "the", "rationality", "of", "the", "attention", "mechanism,", "and", "verify", "the", "contribution", "of", "multi-task", "learning."], "pieces": ["We", "comp", "are", "CG", "MS", "'s", "general", "ization", "ability", "with", "six", "state", "-", "of", "-", "the", "-", "art", "method", "s", "on", "a", "public", "dat", "as", "et", ",", "and", "CG", "MS", "sign", "ificantly", "out", "per", "forms", "other", "method", "s", "in", "the", "leave", "-", "drug", "comb", "ination", "-", "out", "sc", "enario", ",", "as", "well", "as", "in", "the", "leave", "-", "cell", "line", "-", "out", "and", "leave", "-", "drug", "-", "out", "sc", "en", "arios", ".", "We", "f", "urther", "present", "the", "benefit", "of", "el", "im", "inating", "the", "order", "depend", "ency", "and", "the", "discrimination", "power", "of", "wh", "ole", "-", "graph", "embed", "d", "ings", ",", "interpret", "the", "rational", "ity", "of", "the", "att", "ention", "me", "chan", "ism", ",", "and", "ver", "ify", "the", "cont", "ribution", "of", "multi", "-", "task", "learning", "."], "token_lens": [1, 2, 3, 2, 1, 1, 1, 7, 2, 1, 1, 1, 4, 1, 2, 2, 3, 1, 2, 1, 1, 3, 4, 3, 1, 1, 1, 1, 1, 3, 3, 1, 5, 4, 1, 2, 1, 1, 1, 1, 3, 1, 1, 2, 1, 1, 1, 1, 1, 4, 4, 1, 1, 2, 1, 1, 2, 4, 1, 2, 1, 2, 1, 3, 2], "sentence": "We compare CGMS's generalization ability with six state-of-the-art methods on a public dataset, and CGMS significantly outperforms other methods in the leave-drug combination-out scenario, as well as in the leave-cell line-out and leave-drug-out scenarios. We further present the benefit of eliminating the order dependency and the discrimination power of whole-graph embeddings, interpret the rationality of the attention mechanism, and verify the contribution of multi-task learning.", "sentence_starts": [0]}
{"doc_id": "ACL_23_P_726", "sent_id": "ACL_23_P_726-2", "entity_mentions": [{"id": "ACL_23_P_726-2-E0", "text": "we", "start": 27, "end": 28, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_726-2-E1", "text": "languages", "start": 9, "end": 10, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_726-2-E2", "text": "to their correct family", "start": 31, "end": 35, "entity_type": "UNK", "mention_type": "UNK"}], "relation_mentions": [], "event_mentions": [{"event_type": "Results/Findings", "id": "ACL_23_P_726-2-EV0", "trigger": {"text": "assign", "start": 29, "end": 30}, "arguments": [{"entity_id": "ACL_23_P_726-2-E0", "text": "we", "role": "Agent"}, {"entity_id": "ACL_23_P_726-2-E1", "text": "languages", "role": "PrimaryObject"}, {"entity_id": "ACL_23_P_726-2-E2", "text": "to their correct family", "role": "SecondaryObject"}]}], "entity_coreference": [], "event_coreference": [], "tokens": ["The", "resulting", "measure", "for", "the", "conceptual", "similarity", "between", "two", "languages", "is", "complementary", "to", "standard", "genealogical,", "typological,", "and", "surface", "similarity", "measures.", "For", "four", "out", "of", "six", "language", "families,", "we", "can", "assign", "languages", "to", "their", "correct", "family", "based", "on", "conceptual", "similarity", "with", "accuracies", "between", "54%", "and", "87%."], "pieces": ["The", "result", "ing", "me", "asure", "for", "the", "concept", "ual", "similar", "ity", "between", "two", "l", "anguages", "is", "com", "plement", "ary", "to", "standard", "g", "ene", "alog", "ical", ",", "typ", "ological", ",", "and", "surface", "similar", "ity", "measures", ".", "For", "four", "out", "of", "six", "language", "fam", "ilies", ",", "we", "can", "ass", "ign", "l", "anguages", "to", "their", "correct", "family", "based", "on", "concept", "ual", "similar", "ity", "with", "acc", "ur", "acies", "between", "54", "%", "and", "87", "%."], "token_lens": [1, 2, 2, 1, 1, 2, 2, 1, 1, 2, 1, 3, 1, 1, 5, 3, 1, 1, 2, 2, 1, 1, 1, 1, 1, 1, 3, 1, 1, 2, 2, 1, 1, 1, 1, 1, 1, 2, 2, 1, 3, 1, 2, 1, 2], "sentence": "The resulting measure for the conceptual similarity between two languages is complementary to standard genealogical, typological, and surface similarity measures. For four out of six language families, we can assign languages to their correct family based on conceptual similarity with accuracies between 54% and 87%.", "sentence_starts": [0]}
{"doc_id": "ACL_23_P_373", "sent_id": "ACL_23_P_373-1", "entity_mentions": [{"id": "ACL_23_P_373-1-E0", "text": "we", "start": 4, "end": 5, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_373-1-E1", "text": "to learn abstract interpretable rules as policies", "start": 23, "end": 30, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_373-1-E2", "text": "a modular, NEuro-Symbolic Textual Agent (NESTA)", "start": 6, "end": 12, "entity_type": "UNK", "mention_type": "UNK"}], "relation_mentions": [], "event_mentions": [{"event_type": "Methods/Approach", "id": "ACL_23_P_373-1-EV0", "trigger": {"text": "propose", "start": 5, "end": 6}, "arguments": [{"entity_id": "ACL_23_P_373-1-E0", "text": "we", "role": "Agent"}, {"entity_id": "ACL_23_P_373-1-E1", "text": "to learn abstract interpretable rules as policies", "role": "Purpose"}, {"entity_id": "ACL_23_P_373-1-E2", "text": "a modular, NEuro-Symbolic Textual Agent (NESTA)", "role": "PrimaryObject"}]}], "entity_coreference": [], "event_coreference": [], "tokens": ["Therefore,", "in", "this", "paper,", "we", "propose", "a", "modular,", "NEuro-Symbolic", "Textual", "Agent", "(NESTA)", "that", "combines", "a", "generic", "semantic", "parser", "with", "a", "rule", "induction", "system", "to", "learn", "abstract", "interpretable", "rules", "as", "policies."], "pieces": ["Therefore", ",", "in", "this", "paper", ",", "we", "pro", "pose", "a", "mod", "ular", ",", "NE", "uro", "-", "Sy", "mb", "olic", "Text", "ual", "Agent", "(", "NES", "TA", ")", "that", "comb", "ines", "a", "generic", "sem", "antic", "parser", "with", "a", "rule", "ind", "uction", "system", "to", "learn", "ab", "stract", "interpret", "able", "rules", "as", "p", "olic", "ies", "."], "token_lens": [2, 1, 1, 2, 1, 2, 1, 3, 6, 2, 1, 4, 1, 2, 1, 1, 2, 1, 1, 1, 1, 2, 1, 1, 1, 2, 2, 1, 1, 4], "sentence": "Therefore, in this paper, we propose a modular, NEuro-Symbolic Textual Agent (NESTA) that combines a generic semantic parser with a rule induction system to learn abstract interpretable rules as policies.", "sentence_starts": [0]}
{"doc_id": "bioinfo_23_P_697", "sent_id": "bioinfo_23_P_697-1", "entity_mentions": [{"id": "bioinfo_23_P_697-1-E0", "text": "We", "start": 0, "end": 1, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "bioinfo_23_P_697-1-E1", "text": "By using Bayes factors, ODeGP models both the null (non-rhythmic) and the alternative (rhythmic) hypotheses, thus providing an advantage over P-values", "start": 37, "end": 58, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "bioinfo_23_P_697-1-E2", "text": "a new method", "start": 2, "end": 5, "entity_type": "UNK", "mention_type": "UNK"}], "relation_mentions": [], "event_mentions": [{"event_type": "Methods/Approach", "id": "bioinfo_23_P_697-1-EV0", "trigger": {"text": "introduce", "start": 1, "end": 2}, "arguments": [{"entity_id": "bioinfo_23_P_697-1-E0", "text": "We", "role": "Agent"}, {"entity_id": "bioinfo_23_P_697-1-E1", "text": "By using Bayes factors, ODeGP models both the null (non-rhythmic) and the alternative (rhythmic) hypotheses, thus providing an advantage over P-values", "role": "Method"}, {"entity_id": "bioinfo_23_P_697-1-E2", "text": "a new method", "role": "PrimaryObject"}]}], "entity_coreference": [], "event_coreference": [], "tokens": ["We", "introduce", "a", "new", "method,", "ODeGP", "(Oscillation", "Detection", "using", "Gaussian", "Processes),", "which", "combines", "Gaussian", "Process", "regression", "and", "Bayesian", "inference", "to", "incorporate", "measurement", "errors,", "non-uniformly", "sampled", "data,", "and", "a", "recently", "developed", "non-stationary", "kernel", "to", "improve", "detection", "of", "oscillations.", "By", "using", "Bayes", "factors,", "ODeGP", "models", "both", "the", "null", "(non-rhythmic)", "and", "the", "alternative", "(rhythmic)", "hypotheses,", "thus", "providing", "an", "advantage", "over", "P-values."], "pieces": ["We", "introdu", "ce", "a", "new", "method", ",", "OD", "e", "GP", "(", "O", "scill", "ation", "Det", "ection", "using", "Ga", "ussian", "Process", "es", "),", "which", "comb", "ines", "Ga", "ussian", "Process", "reg", "ression", "and", "Bay", "esian", "in", "ference", "to", "inc", "orpor", "ate", "me", "asure", "ment", "errors", ",", "non", "-", "un", "iform", "ly", "sam", "pled", "data", ",", "and", "a", "recent", "ly", "developed", "non", "-", "station", "ary", "kernel", "to", "improve", "det", "ection", "of", "osc", "ill", "ations", ".", "By", "using", "Bay", "es", "fact", "ors", ",", "OD", "e", "GP", "models", "both", "the", "null", "(", "non", "-", "rh", "yth", "mic", ")", "and", "the", "altern", "ative", "(", "rh", "yth", "mic", ")", "hyp", "othes", "es", ",", "thus", "prov", "iding", "an", "advant", "age", "over", "P", "-", "values", "."], "token_lens": [1, 2, 1, 1, 2, 3, 4, 2, 1, 2, 3, 1, 2, 2, 1, 2, 1, 2, 2, 1, 3, 3, 2, 5, 2, 2, 1, 1, 2, 1, 4, 1, 1, 1, 2, 1, 4, 1, 1, 2, 3, 3, 1, 1, 1, 1, 7, 1, 1, 2, 5, 4, 1, 2, 1, 2, 1, 4], "sentence": "We introduce a new method, ODeGP (Oscillation Detection using Gaussian Processes), which combines Gaussian Process regression and Bayesian inference to incorporate measurement errors, non-uniformly sampled data, and a recently developed non-stationary kernel to improve detection of oscillations. By using Bayes factors, ODeGP models both the null (non-rhythmic) and the alternative (rhythmic) hypotheses, thus providing an advantage over P-values.", "sentence_starts": [0]}