[
  {
    "paper_code": "cscw_23_P_57",
    "abstract": "Sexist content is widespread on social media and can reduce women's psychological well-being and their willingness to participate in online discourse, making it a societal issue. To counter these effects, social media platforms employ moderators. To date, little is known about the effectiveness of different forms of moderation in creating a safe space and their acceptance, in particular from the perspective of women as members of the targeted group and users in general (rather than perpetrators). In this research, we propose that some common forms of moderation can be systematized along two facets of visibility, namely visibility of sexist content and of counterspeech. In an online experiment (N = 839), we manipulated these two facets and tested how they shaped social norms, feelings of safety, and intent to participate, as well as fairness, trustworthiness, and efficacy evaluations. In line with our predictions, deletion of sexist content - i.e., its invisibility - and (public) counterspeech - i.e., its visibility - against visible sexist content contributed to creating a safe space. Looking at the underlying psychological mechanism, we found that these effects were largely driven by changes in what was perceived normative in the presented context. Interestingly, deletion of sexist content was judged as less fair than counterspeech against visible sexist content. Our research contributes to a growing body of literature that highlights the importance of norms in creating safer online environments and provides practical implications for moderators for selecting actions that can be effective and accepted.",
    "events": [
      {
        "Background/Introduction": "",
        "Text": "Sexist content is widespread on social media and can reduce women's psychological well-being and their willingness to participate in online discourse, making it a societal issue. To counter these effects, social media platforms employ moderators. To date, little is known about the effectiveness of different forms of moderation in creating a safe space and their acceptance, in particular from the perspective of women as members of the targeted group and users in general (rather than perpetrators).",
        "Main Action": "",
        "Arguments": {
          "Agent": "",
          "Object": {
            "Primary Object": "",
            "Primary Modifier": "",
            "Secondary Object": "",
            "Secondary Modifier": ""
          },
          "Context": "",
          "Purpose": "",
          "Method": "",
          "Results": "",
          "Analysis": "",
          "Challenge": "",
          "Ethical": "",
          "Implications": "",
          "Contradictions": ""
        }
      },
      {
        "Methods/Approach": "",
        "Text": "In this research, we propose that some common forms of moderation can be systematized along two facets of visibility, namely visibility of sexist content and of counterspeech. In an online experiment (N = 839), we manipulated these two facets and tested how they shaped social norms, feelings of safety, and intent to participate, as well as fairness, trustworthiness, and efficacy evaluations.",
        "Main Action": "",
        "Arguments": {
          "Agent": "",
          "Object": {
            "Primary Object": "",
            "Primary Modifier": "",
            "Secondary Object": "",
            "Secondary Modifier": ""
          },
          "Context": "",
          "Purpose": "",
          "Method": "",
          "Results": "",
          "Analysis": "",
          "Challenge": "",
          "Ethical": "",
          "Implications": "",
          "Contradictions": ""
        }
      },
      {
        "Results/Findings": "",
        "Text": "In line with our predictions, deletion of sexist content - i.e., its invisibility - and (public) counterspeech - i.e., its visibility - against visible sexist content contributed to creating a safe space. Looking at the underlying psychological mechanism, we found that these effects were largely driven by changes in what was perceived normative in the presented context. Interestingly, deletion of sexist content was judged as less fair than counterspeech against visible sexist content.",
        "Main Action": "",
        "Arguments": {
          "Agent": "",
          "Object": {
            "Primary Object": "",
            "Primary Modifier": "",
            "Secondary Object": "",
            "Secondary Modifier": ""
          },
          "Context": "",
          "Purpose": "",
          "Method": "",
          "Results": "",
          "Analysis": "",
          "Challenge": "",
          "Ethical": "",
          "Implications": "",
          "Contradictions": ""
        }
      },
      {
        "Conclusions/Implications": "",
        "Text": "Our research contributes to a growing body of literature that highlights the importance of norms in creating safer online environments and provides practical implications for moderators for selecting actions that can be effective and accepted.",
        "Main Action": "",
        "Arguments": {
          "Agent": "",
          "Object": {
            "Primary Object": "",
            "Primary Modifier": "",
            "Secondary Object": "",
            "Secondary Modifier": ""
          },
          "Context": "",
          "Purpose": "",
          "Method": "",
          "Results": "",
          "Analysis": "",
          "Challenge": "",
          "Ethical": "",
          "Implications": "",
          "Contradictions": ""
        }
      }
    ]
  },
  {
    "paper_code": "cscw_23_P_249",
    "abstract": "News sharing has become prevalent on many social media platforms. Users are not only exposed to news shared by others, but also actively share information with a diverse set of motivations. In this work, we propose five news sharing motivations based on the intrinsic and extrinsic factors found in prior literature. Through an online experiment, we further examine how a host of factors, including motivations, influence participants' decision to share news online. We then prompt participants to switch their original decision for extra compensation, observing how different news types, motivational and demographic factors may affect the switch. Our analysis suggests that sharing decisions can be reversed when a strong external stimulus (higher bonus) is presented. Further, there are motivational factors that independently influence participants' reversal decisions. Finally, using our work as an empirical basis, we propose designs for future new sharing systems.",
    "events": [
      {
        "Background/Introduction": "",
        "Text": "News sharing has become prevalent on many social media platforms. Users are not only exposed to news shared by others, but also actively share information with a diverse set of motivations.",
        "Main Action": "",
        "Arguments": {
          "Agent": "",
          "Object": {
            "Primary Object": "",
            "Primary Modifier": "",
            "Secondary Object": "",
            "Secondary Modifier": ""
          },
          "Context": "",
          "Purpose": "",
          "Method": "",
          "Results": "",
          "Analysis": "",
          "Challenge": "",
          "Ethical": "",
          "Implications": "",
          "Contradictions": ""
        }
      },
      {
        "Methods/Approach": "",
        "Text": "In this work, we propose five news sharing motivations based on the intrinsic and extrinsic factors found in prior literature. Through an online experiment, we further examine how a host of factors, including motivations, influence participants' decision to share news online. We then prompt participants to switch their original decision for extra compensation, observing how different news types, motivational and demographic factors may affect the switch.",
        "Main Action": "",
        "Arguments": {
          "Agent": "",
          "Object": {
            "Primary Object": "",
            "Primary Modifier": "",
            "Secondary Object": "",
            "Secondary Modifier": ""
          },
          "Context": "",
          "Purpose": "",
          "Method": "",
          "Results": "",
          "Analysis": "",
          "Challenge": "",
          "Ethical": "",
          "Implications": "",
          "Contradictions": ""
        }
      },
      {
        "Results/Findings": "",
        "Text": "Our analysis suggests that sharing decisions can be reversed when a strong external stimulus (higher bonus) is presented. Further, there are motivational factors that independently influence participants' reversal decisions.",
        "Main Action": "",
        "Arguments": {
          "Agent": "",
          "Object": {
            "Primary Object": "",
            "Primary Modifier": "",
            "Secondary Object": "",
            "Secondary Modifier": ""
          },
          "Context": "",
          "Purpose": "",
          "Method": "",
          "Results": "",
          "Analysis": "",
          "Challenge": "",
          "Ethical": "",
          "Implications": "",
          "Contradictions": ""
        }
      },
      {
        "Conclusions/Implications": "",
        "Text": "Finally, using our work as an empirical basis, we propose designs for future new sharing systems.",
        "Main Action": "",
        "Arguments": {
          "Agent": "",
          "Object": {
            "Primary Object": "",
            "Primary Modifier": "",
            "Secondary Object": "",
            "Secondary Modifier": ""
          },
          "Context": "",
          "Purpose": "",
          "Method": "",
          "Results": "",
          "Analysis": "",
          "Challenge": "",
          "Ethical": "",
          "Implications": "",
          "Contradictions": ""
        }
      }
    ]
  }
]
