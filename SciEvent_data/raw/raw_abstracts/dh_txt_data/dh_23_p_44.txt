How can we know what our computational infrastructures are doing to us? More to the point, how can we have any confidence that their effects on our minds are positive rather than negative? Certainly, it is the case that digital infrastructures combined with spatial and temporal organisation create forms of digitally-enabled structures that serve to change the cognitive capacity of humans. How then to assess these new digital infrastructures and machine learning systems? One of the most difficult tasks facing the critical theorist today is understanding the delegation and prescription of agency in digital infrastructures. These are capital intensive systems and hence tend to be developed by corporations or governments in order to combine multiple systems into a single unity. The systems they build are often difficult if not impossible to understand and require the public to trust but not to be able to verify the system decisions. In contrast, recent moves to assuage worries over the opaque and threatening potential of computation have been partially addressed through a new legal right to challenge algorithms and their decisions. This requirement, termed “explainability,” I suggest might contribute to tool criticism within digital humanities for investigating and potentially challenging these assemblages and creating a potential for democratic contestation.