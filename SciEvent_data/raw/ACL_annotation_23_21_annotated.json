{
  "papers": [
    {
      "paper_code": "ACL_23_P_657",
      "abstract": "Second language acquisition (SLA) research has extensively studied cross-linguistic transfer, the influence of linguistic structure of a speaker’s native language [L1] on the successful acquisition of a foreign language [L2]. Effects of such transfer can be positive (facilitating acquisition) or negative (impeding acquisition). We find that NLP literature has not given enough attention to the phenomenon of negative transfer. To understand patterns of both positive and negative transfer between L1 and L2, we model sequential second language acquisition in LMs. Further, we build a Multilingual Age Ordered CHILDES (MAO-CHILDES) — a dataset consisting of 5 typologically diverse languages, i.e., German, French, Polish, Indonesian, and Japanese — to understand the degree to which native Child-Directed Speech (CDS) [L1] can help or conflict with English language acquisition [L2]. To examine the impact of native CDS, we use the TILT-based cross lingual transfer learning approach established by Papadimitriou and Jurafsky (2020) and find that, as in human SLA, language family distance predicts more negative transfer. Additionally, we find that conversational speech data shows greater facilitation for language acquisition than scripted speech data. Our findings call for further research using our novel Transformer-based SLA models and we would like to encourage it by releasing our code, data, and models.",
      "events": [
        {
          "Background/Introduction": "Studies of SLA research",
          "Text": "Second language acquisition (SLA) research has extensively studied cross-linguistic transfer, the influence of linguistic structure of a speaker’s native language [L1] on the successful acquisition of a foreign language [L2]. Effects of such transfer can be positive (facilitating acquisition) or negative (impeding acquisition). We find that NLP literature has not given enough attention to the phenomenon of negative transfer.",
          "Action": "has extensively studied",
          "Arguments": {
            "Agent": [
              "Second language acquisition (SLA) research"
            ],
            "Object": {
              "Primary Object": [
                "cross-linguistic transfer"
              ],
              "Secondary Object": []
            },
            "Context": [
              "Effects of such transfer can be positive (facilitating acquisition) or negative (impeding acquisition)"
            ],
            "Purpose": [],
            "Method": [],
            "Results": [],
            "Analysis": [],
            "Challenge": [
              "NLP literature has not given enough attention to the phenomenon of negative transfer"
            ],
            "Ethical": [],
            "Implications": [],
            "Contradictions": []
          }
        },
        {
          "Methods/Approach": "building model and dataset of SLA in LMs",
          "Text": "To understand patterns of both positive and negative transfer between L1 and L2, we model sequential second language acquisition in LMs. Further, we build a Multilingual Age Ordered CHILDES (MAO-CHILDES) — a dataset consisting of 5 typologically diverse languages, i.e., German, French, Polish, Indonesian, and Japanese — to understand the degree to which native Child-Directed Speech (CDS) [L1] can help or conflict with English language acquisition [L2].",
          "Action": "model",
          "Arguments": {
            "Agent": [
              "we"
            ],
            "Object": {
              "Primary Object": [
                "sequential second language acquisition in LMs"
              ],
              "Secondary Object": []
            },
            "Context": [],
            "Purpose": [
              "To understand patterns of both positive and negative transfer between L1 and L2"
            ],
            "Method": [
              "we build a Multilingual Age Ordered CHILDES (MAO-CHILDES)"
            ],
            "Results": [],
            "Analysis": [
              "a dataset consisting of 5 typologically diverse languages, i.e., German, French, Polish, Indonesian, and Japanese"
            ],
            "Challenge": [],
            "Ethical": [],
            "Implications": [],
            "Contradictions": []
          }
        },
        {
          "Results/Findings": "The impacts of native CDS examined by using TILT based cross lingual transfer learning approach",
          "Text": "To examine the impact of native CDS, we use the TILT-based cross lingual transfer learning approach established by Papadimitriou and Jurafsky (2020) and find that, as in human SLA, language family distance predicts more negative transfer. Additionally, we find that conversational speech data shows greater facilitation for language acquisition than scripted speech data.",
          "Action": "use",
          "Arguments": {
            "Agent": [
              "we"
            ],
            "Object": {
              "Primary Object": [
                "the TILT-based cross lingual transfer learning approach"
              ],
              "Secondary Object": []
            },
            "Context": [],
            "Purpose": [
              "To examine the impact of native CDS"
            ],
            "Method": [],
            "Results": [
              "as in human SLA, language family distance predicts more negative transfer.",
              "conversational speech data shows greater facilitation for language acquisition than scripted speech data"
            ],
            "Analysis": [],
            "Challenge": [],
            "Ethical": [],
            "Implications": [],
            "Contradictions": []
          }
        },
        {
          "Conclusions/Implications": "Implication of findings",
          "Text": "Our findings call for further research using our novel Transformer-based SLA models and we would like to encourage it by releasing our code, data, and models.",
          "Action": "call for",
          "Arguments": {
            "Agent": [
              "Our findings"
            ],
            "Object": {
              "Primary Object": [
                "further research"
              ],
              "Secondary Object": []
            },
            "Context": [],
            "Purpose": [],
            "Method": [
              "using our novel Transformer-based SLA models"
            ],
            "Results": [],
            "Analysis": [],
            "Challenge": [],
            "Ethical": [],
            "Implications": [],
            "Contradictions": []
          }
        }
      ]
    },
    {
      "paper_code": "ACL_23_P_334",
      "abstract": "Despite significant progress having been made in question answering on tabular data (Table QA), it’s unclear whether, and to what extent existing Table QA models are robust to task-specific perturbations, e.g., replacing key question entities or shuffling table columns. To systematically study the robustness of Table QA models, we propose a benchmark called RobuT, which builds upon existing Table QA datasets (WTQ, WikiSQL-Weak, and SQA) and includes human-annotated adversarial perturbations in terms of table header, table content, and question. Our results indicate that both state-of-the-art Table QA models and large language models (e.g., GPT-3) with few-shot learning falter in these adversarial sets. We propose to address this problem by using large language models to generate adversarial examples to enhance training, which significantly improves the robustness of Table QA models.",
      "events": [
        {
          "Background/Introduction": "Intro to lack of clarity in robustness to task-specific perturbations of Table QA models",
          "Text": "Despite significant progress having been made in question answering on tabular data (Table QA), it’s unclear whether, and to what extent existing Table QA models are robust to task-specific perturbations, e.g., replacing key question entities or shuffling table columns.",
          "Action": "having been made",
          "Arguments": {
            "Agent": [
              "progress"
            ],
            "Object": {
              "Primary Object": [],
              "Secondary Object": []
            },
            "Context": [],
            "Purpose": [],
            "Method": [],
            "Results": [],
            "Analysis": [
              "e.g., replacing key question entities or shuffling table columns"
            ],
            "Challenge": [
              "it’s unclear whether, and to what extent existing Table QA models are robust to task-specific perturbations"
            ],
            "Ethical": [],
            "Implications": [],
            "Contradictions": []
          }
        },
        {
          "Methods/Approach": "proposal of new benchmark to study robustness of Table QA models",
          "Text": "To systematically study the robustness of Table QA models, we propose a benchmark called RobuT, which builds upon existing Table QA datasets (WTQ, WikiSQL-Weak, and SQA) and includes human-annotated adversarial perturbations in terms of table header, table content, and question.",
          "Action": "propose",
          "Arguments": {
            "Agent": [
              "we"
            ],
            "Object": {
              "Primary Object": [
                "a benchmark called RobuT"
              ],
              "Secondary Object": []
            },
            "Context": [],
            "Purpose": [
              "To systematically study the robustness of Table QA models"
            ],
            "Method": [],
            "Results": [],
            "Analysis": [],
            "Challenge": [],
            "Ethical": [],
            "Implications": [],
            "Contradictions": []
          }
        },
        {
          "Results/Findings": "Failure of both Table QA models and LLMs in these sets",
          "Text": "Our results indicate that both state-of-the-art Table QA models and large language models (e.g., GPT-3) with few-shot learning falter in these adversarial sets.",
          "Action": "indicate",
          "Arguments": {
            "Agent": [
              "Our results"
            ],
            "Object": {
              "Primary Object": [
                "both state-of-the-art Table QA models and large language models (e.g., GPT-3) with few-shot learning falter in these adversarial sets."
              ],
              "Secondary Object": []
            },
            "Context": [],
            "Purpose": [],
            "Method": [],
            "Results": [],
            "Analysis": [],
            "Challenge": [],
            "Ethical": [],
            "Implications": [],
            "Contradictions": []
          }
        },
        {
          "Conclusions/Implications": "Proposal to address the problem by using LLMs to generate adversarial examples",
          "Text": "We propose to address this problem by using large language models to generate adversarial examples to enhance training, which significantly improves the robustness of Table QA models.",
          "Action": "propose to address",
          "Arguments": {
            "Agent": [
              "We"
            ],
            "Object": {
              "Primary Object": [
                "this problem"
              ],
              "Secondary Object": []
            },
            "Context": [],
            "Purpose": [],
            "Method": [],
            "Results": [
              "significantly improves the robustness of Table QA models."
            ],
            "Analysis": [],
            "Challenge": [],
            "Ethical": [],
            "Implications": [],
            "Contradictions": []
          }
        }
      ]
    }
  ]
}