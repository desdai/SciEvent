{"doc_id": "ACL_23_P_247", "wnd_id": "ACL_23_P_247-0", "entity_mentions": [{"id": "ACL_23_P_247-0-E0", "text": "We", "start": 0, "end": 1, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_247-0-E1", "text": "We make decisions by reacting to changes in the real world, particularly the emergence and disappearance of impermanent entities such as restaurants, services, and events", "start": 0, "end": 25, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_247-0-E2", "text": "it is important to know when entities disappear as early as possible", "start": 43, "end": 55, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_247-0-E3", "text": "Because we want to avoid missing out on opportunities or making fruitless actions after those entities have disappeared", "start": 25, "end": 43, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_247-0-E4", "text": "The major challenge is detecting uncertain contexts of disappearing entities from noisy microblog posts", "start": 72, "end": 86, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_247-0-E5", "text": "the task of detecting disappearing entities", "start": 58, "end": 64, "entity_type": "UNK", "mention_type": "UNK"}], "relation_mentions": [], "event_mentions": [{"event_type": "Background/Introduction", "id": "ACL_23_P_247-0-EV0", "trigger": {"text": "tackle", "start": 57, "end": 58}, "arguments": [{"entity_id": "ACL_23_P_247-0-E0", "text": "We", "role": "Agent"}, {"entity_id": "ACL_23_P_247-0-E1", "text": "We make decisions by reacting to changes in the real world, particularly the emergence and disappearance of impermanent entities such as restaurants, services, and events", "role": "Context"}, {"entity_id": "ACL_23_P_247-0-E2", "text": "it is important to know when entities disappear as early as possible", "role": "Context"}, {"entity_id": "ACL_23_P_247-0-E3", "text": "Because we want to avoid missing out on opportunities or making fruitless actions after those entities have disappeared", "role": "Analysis"}, {"entity_id": "ACL_23_P_247-0-E4", "text": "The major challenge is detecting uncertain contexts of disappearing entities from noisy microblog posts", "role": "Challenge"}, {"entity_id": "ACL_23_P_247-0-E5", "text": "the task of detecting disappearing entities", "role": "PrimaryObject"}]}], "entity_coreference": [], "event_coreference": [], "tokens": ["We", "make", "decisions", "by", "reacting", "to", "changes", "in", "the", "real", "world,", "particularly", "the", "emergence", "and", "disappearance", "of", "impermanent", "entities", "such", "as", "restaurants,", "services,", "and", "events.", "Because", "we", "want", "to", "avoid", "missing", "out", "on", "opportunities", "or", "making", "fruitless", "actions", "after", "those", "entities", "have", "disappeared,", "it", "is", "important", "to", "know", "when", "entities", "disappear", "as", "early", "as", "possible.", "We", "thus", "tackle", "the", "task", "of", "detecting", "disappearing", "entities", "from", "microblogs", "where", "various", "information", "is", "shared", "timely.", "The", "major", "challenge", "is", "detecting", "uncertain", "contexts", "of", "disappearing", "entities", "from", "noisy", "microblog", "posts."], "pieces": ["We", "make", "dec", "isions", "by", "re", "acting", "to", "changes", "in", "the", "real", "world", ",", "particularly", "the", "em", "erg", "ence", "and", "dis", "app", "earance", "of", "im", "per", "manent", "ent", "ities", "such", "as", "rest", "aur", "ants", ",", "services", ",", "and", "events", ".", "Because", "we", "want", "to", "avoid", "missing", "out", "on", "opp", "ortun", "ities", "or", "making", "fruit", "less", "actions", "after", "those", "ent", "ities", "have", "dis", "app", "eared", ",", "it", "is", "important", "to", "know", "when", "ent", "ities", "dis", "app", "ear", "as", "early", "as", "p", "ossible", ".", "We", "thus", "tackle", "the", "task", "of", "det", "ect", "ing", "dis", "app", "earing", "ent", "ities", "from", "micro", "blogs", "where", "var", "ious", "information", "is", "shared", "time", "ly", ".", "The", "major", "chall", "enge", "is", "det", "ect", "ing", "unc", "ertain", "context", "s", "of", "dis", "app", "earing", "ent", "ities", "from", "no", "isy", "micro", "blog", "posts", "."], "token_lens": [1, 1, 2, 1, 2, 1, 1, 1, 1, 1, 2, 1, 1, 3, 1, 3, 1, 3, 2, 1, 1, 4, 2, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 3, 1, 1, 2, 1, 1, 1, 2, 1, 4, 1, 1, 1, 1, 1, 1, 2, 3, 1, 1, 1, 3, 1, 1, 1, 1, 1, 1, 3, 3, 2, 1, 2, 1, 2, 1, 1, 1, 3, 1, 1, 2, 1, 3, 2, 2, 1, 3, 2, 1, 2, 2, 2], "sentence": "We make decisions by reacting to changes in the real world, particularly the emergence and disappearance of impermanent entities such as restaurants, services, and events. Because we want to avoid missing out on opportunities or making fruitless actions after those entities have disappeared, it is important to know when entities disappear as early as possible. We thus tackle the task of detecting disappearing entities from microblogs where various information is shared timely. The major challenge is detecting uncertain contexts of disappearing entities from noisy microblog posts.", "sentence_starts": [0]}
{"doc_id": "ACL_23_P_247", "wnd_id": "ACL_23_P_247-1", "entity_mentions": [{"id": "ACL_23_P_247-1-E0", "text": "we", "start": 5, "end": 6, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_247-1-E1", "text": "To collect such disappearing contexts", "start": 0, "end": 5, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_247-1-E2", "text": "=we actually build large-scale Twitter datasets of disappearing entities.=", "start": 23, "end": 32, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_247-1-E3", "text": "To ensure robust detection in noisy environments, we refine pretrained word embeddings for the detection model on microblog streams in a timely manner", "start": 32, "end": 55, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_247-1-E4", "text": "time-sensitive distant supervision", "start": 7, "end": 10, "entity_type": "UNK", "mention_type": "UNK"}], "relation_mentions": [], "event_mentions": [{"event_type": "Methods/Approach", "id": "ACL_23_P_247-1-EV0", "trigger": {"text": "design", "start": 6, "end": 7}, "arguments": [{"entity_id": "ACL_23_P_247-1-E0", "text": "we", "role": "Agent"}, {"entity_id": "ACL_23_P_247-1-E1", "text": "To collect such disappearing contexts", "role": "Purpose"}, {"entity_id": "ACL_23_P_247-1-E2", "text": "=we actually build large-scale Twitter datasets of disappearing entities.=", "role": "Method"}, {"entity_id": "ACL_23_P_247-1-E3", "text": "To ensure robust detection in noisy environments, we refine pretrained word embeddings for the detection model on microblog streams in a timely manner", "role": "Method"}, {"entity_id": "ACL_23_P_247-1-E4", "text": "time-sensitive distant supervision", "role": "PrimaryObject"}]}], "entity_coreference": [], "event_coreference": [], "tokens": ["To", "collect", "such", "disappearing", "contexts,", "we", "design", "time-sensitive", "distant", "supervision,", "which", "utilizes", "entities", "from", "the", "knowledge", "base", "and", "time-series", "posts.", "Using", "this", "method,", "we", "actually", "build", "large-scale", "Twitter", "datasets", "of", "disappearing", "entities.", "To", "ensure", "robust", "detection", "in", "noisy", "environments,", "we", "refine", "pretrained", "word", "embeddings", "for", "the", "detection", "model", "on", "microblog", "streams", "in", "a", "timely", "manner."], "pieces": ["To", "collect", "such", "dis", "app", "earing", "context", "s", ",", "we", "design", "time", "-", "sensitive", "d", "istant", "super", "vision", ",", "which", "util", "izes", "ent", "ities", "from", "the", "knowledge", "base", "and", "time", "-", "series", "posts", ".", "Using", "this", "method", ",", "we", "actually", "build", "large", "-", "scale", "Twitter", "dat", "as", "ets", "of", "dis", "app", "earing", "ent", "ities", ".", "To", "ens", "ure", "rob", "ust", "det", "ection", "in", "no", "isy", "en", "vironments", ",", "we", "ref", "ine", "pret", "rained", "word", "embed", "d", "ings", "for", "the", "det", "ection", "model", "on", "micro", "blog", "stream", "s", "in", "a", "time", "ly", "man", "ner", "."], "token_lens": [1, 1, 1, 3, 3, 1, 1, 3, 2, 3, 1, 2, 2, 1, 1, 1, 1, 1, 3, 2, 1, 1, 2, 1, 1, 1, 3, 1, 3, 1, 3, 3, 1, 2, 2, 2, 1, 2, 3, 1, 2, 2, 1, 3, 1, 1, 2, 1, 1, 2, 2, 1, 1, 2, 3], "sentence": "To collect such disappearing contexts, we design time-sensitive distant supervision, which utilizes entities from the knowledge base and time-series posts. Using this method, we actually build large-scale Twitter datasets of disappearing entities. To ensure robust detection in noisy environments, we refine pretrained word embeddings for the detection model on microblog streams in a timely manner.", "sentence_starts": [0]}
{"doc_id": "ACL_23_P_247", "wnd_id": "ACL_23_P_247-2", "entity_mentions": [{"id": "ACL_23_P_247-2-E0", "text": "Experimental results on the Twitter datasets", "start": 0, "end": 6, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_247-2-E1", "text": "effectiveness of the collected labeled data and refined word embeddings", "start": 8, "end": 18, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_247-2-E2", "text": "the proposed method outperformed a baseline in terms of accuracy", "start": 18, "end": 28, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_247-2-E3", "text": "more than 70% of the detected disappearing entities in Wikipedia are discovered earlier than the update on Wikipedia, with the average lead-time over one month", "start": 29, "end": 54, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_247-2-E4", "text": "the effectiveness", "start": 7, "end": 9, "entity_type": "UNK", "mention_type": "UNK"}], "relation_mentions": [], "event_mentions": [{"event_type": "Results/Findings", "id": "ACL_23_P_247-2-EV0", "trigger": {"text": "confirmed", "start": 6, "end": 7}, "arguments": [{"entity_id": "ACL_23_P_247-2-E0", "text": "Experimental results on the Twitter datasets", "role": "Agent"}, {"entity_id": "ACL_23_P_247-2-E1", "text": "effectiveness of the collected labeled data and refined word embeddings", "role": "Results"}, {"entity_id": "ACL_23_P_247-2-E2", "text": "the proposed method outperformed a baseline in terms of accuracy", "role": "Results"}, {"entity_id": "ACL_23_P_247-2-E3", "text": "more than 70% of the detected disappearing entities in Wikipedia are discovered earlier than the update on Wikipedia, with the average lead-time over one month", "role": "Results"}, {"entity_id": "ACL_23_P_247-2-E4", "text": "the effectiveness", "role": "PrimaryObject"}]}], "entity_coreference": [], "event_coreference": [], "tokens": ["Experimental", "results", "on", "the", "Twitter", "datasets", "confirmed", "the", "effectiveness", "of", "the", "collected", "labeled", "data", "and", "refined", "word", "embeddings;", "the", "proposed", "method", "outperformed", "a", "baseline", "in", "terms", "of", "accuracy,", "and", "more", "than", "70%", "of", "the", "detected", "disappearing", "entities", "in", "Wikipedia", "are", "discovered", "earlier", "than", "the", "update", "on", "Wikipedia,", "with", "the", "average", "lead-time", "over", "one", "month."], "pieces": ["Exper", "imental", "results", "on", "the", "Twitter", "dat", "as", "ets", "confirmed", "the", "effect", "iveness", "of", "the", "col", "lected", "label", "ed", "data", "and", "ref", "ined", "word", "embed", "d", "ings", ";", "the", "prop", "osed", "method", "out", "per", "formed", "a", "bas", "eline", "in", "terms", "of", "acc", "uracy", ",", "and", "more", "than", "70", "%", "of", "the", "det", "ected", "dis", "app", "earing", "ent", "ities", "in", "Wikipedia", "are", "disc", "overed", "ear", "lier", "than", "the", "update", "on", "Wikipedia", ",", "with", "the", "average", "lead", "-", "time", "over", "one", "month", "."], "token_lens": [2, 1, 1, 1, 1, 3, 1, 1, 2, 1, 1, 2, 2, 1, 1, 2, 1, 4, 1, 2, 1, 3, 1, 2, 1, 1, 1, 3, 1, 1, 1, 2, 1, 1, 2, 3, 2, 1, 1, 1, 2, 2, 1, 1, 1, 1, 2, 1, 1, 1, 3, 1, 1, 2], "sentence": "Experimental results on the Twitter datasets confirmed the effectiveness of the collected labeled data and refined word embeddings; the proposed method outperformed a baseline in terms of accuracy, and more than 70% of the detected disappearing entities in Wikipedia are discovered earlier than the update on Wikipedia, with the average lead-time over one month.", "sentence_starts": [0]}
{"doc_id": "ACL_23_P_464", "wnd_id": "ACL_23_P_464-0", "entity_mentions": [{"id": "ACL_23_P_464-0-E0", "text": "current WVLP methods", "start": 32, "end": 35, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_464-0-E1", "text": "Weakly supervised vision-and-language pre-training (WVLP), which learns cross-modal representations with limited cross-modal supervision, has been shown to effectively reduce the data cost of pre-training while maintaining decent performance on downstream tasks", "start": 0, "end": 31, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_464-0-E2", "text": "This affects the data quality and thus the effectiveness of pre-training.", "start": 54, "end": 65, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_464-0-E3", "text": "only local descriptions of images", "start": 36, "end": 41, "entity_type": "UNK", "mention_type": "UNK"}], "relation_mentions": [], "event_mentions": [{"event_type": "Background/Introduction", "id": "ACL_23_P_464-0-EV0", "trigger": {"text": "use", "start": 35, "end": 36}, "arguments": [{"entity_id": "ACL_23_P_464-0-E0", "text": "current WVLP methods", "role": "Agent"}, {"entity_id": "ACL_23_P_464-0-E1", "text": "Weakly supervised vision-and-language pre-training (WVLP), which learns cross-modal representations with limited cross-modal supervision, has been shown to effectively reduce the data cost of pre-training while maintaining decent performance on downstream tasks", "role": "Method"}, {"entity_id": "ACL_23_P_464-0-E2", "text": "This affects the data quality and thus the effectiveness of pre-training.", "role": "Challenge"}, {"entity_id": "ACL_23_P_464-0-E3", "text": "only local descriptions of images", "role": "PrimaryObject"}]}], "entity_coreference": [], "event_coreference": [], "tokens": ["Weakly", "supervised", "vision-and-language", "pre-training", "(WVLP),", "which", "learns", "cross-modal", "representations", "with", "limited", "cross-modal", "supervision,", "has", "been", "shown", "to", "effectively", "reduce", "the", "data", "cost", "of", "pre-training", "while", "maintaining", "decent", "performance", "on", "downstream", "tasks.", "However,", "current", "WVLP", "methods", "use", "only", "local", "descriptions", "of", "images,", "i.e.,", "object", "tags,", "as", "cross-modal", "anchors", "to", "construct", "weakly-aligned", "image-text", "pairs", "for", "pre-training.", "This", "affects", "the", "data", "quality", "and", "thus", "the", "effectiveness", "of", "pre-training."], "pieces": ["Weak", "ly", "super", "vised", "vision", "-", "and", "-", "language", "pre", "-", "training", "(", "W", "V", "LP", "),", "which", "learn", "s", "cross", "-", "mod", "al", "represent", "ations", "with", "limited", "cross", "-", "mod", "al", "super", "vision", ",", "has", "been", "shown", "to", "effect", "ively", "red", "uce", "the", "data", "cost", "of", "pre", "-", "training", "while", "m", "aint", "aining", "dec", "ent", "performance", "on", "down", "stream", "t", "asks", ".", "However", ",", "current", "W", "V", "LP", "method", "s", "use", "only", "local", "desc", "ript", "ions", "of", "images", ",", "i", ".", "e", ".,", "object", "tags", ",", "as", "cross", "-", "mod", "al", "anch", "ors", "to", "construct", "weak", "ly", "-", "aligned", "image", "-", "text", "p", "airs", "for", "pre", "-", "training", ".", "This", "aff", "ect", "s", "the", "data", "quality", "and", "thus", "the", "effect", "iveness", "of", "pre", "-", "training", "."], "token_lens": [2, 2, 5, 3, 5, 1, 2, 4, 2, 1, 1, 4, 3, 1, 1, 1, 1, 2, 2, 1, 1, 1, 1, 3, 1, 3, 2, 1, 1, 2, 3, 2, 1, 3, 2, 1, 1, 1, 3, 1, 2, 4, 1, 2, 1, 4, 2, 1, 1, 4, 3, 2, 1, 4, 1, 3, 1, 1, 1, 1, 1, 1, 2, 1, 4], "sentence": "Weakly supervised vision-and-language pre-training (WVLP), which learns cross-modal representations with limited cross-modal supervision, has been shown to effectively reduce the data cost of pre-training while maintaining decent performance on downstream tasks. However, current WVLP methods use only local descriptions of images, i.e., object tags, as cross-modal anchors to construct weakly-aligned image-text pairs for pre-training. This affects the data quality and thus the effectiveness of pre-training.", "sentence_starts": [0]}
{"doc_id": "ACL_23_P_464", "wnd_id": "ACL_23_P_464-1", "entity_mentions": [{"id": "ACL_23_P_464-1-E0", "text": "we", "start": 3, "end": 4, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_464-1-E1", "text": "represent each unaligned image and text by its similarities to these anchors", "start": 18, "end": 30, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_464-1-E2", "text": "We build a WVLP framework based on the relative representations, namely RELIT, which collects high-quality weakly-aligned image-text pairs from large-scale image-only and text-only data for pre-training through relative representation-based retrieval and generation", "start": 33, "end": 65, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_464-1-E3", "text": "a small number of aligned image-text pairs as anchors", "start": 8, "end": 17, "entity_type": "UNK", "mention_type": "UNK"}], "relation_mentions": [], "event_mentions": [{"event_type": "Methods/Approach", "id": "ACL_23_P_464-1-EV0", "trigger": {"text": "propose to directly take", "start": 4, "end": 8}, "arguments": [{"entity_id": "ACL_23_P_464-1-E0", "text": "we", "role": "Agent"}, {"entity_id": "ACL_23_P_464-1-E1", "text": "represent each unaligned image and text by its similarities to these anchors", "role": "Method"}, {"entity_id": "ACL_23_P_464-1-E2", "text": "We build a WVLP framework based on the relative representations, namely RELIT, which collects high-quality weakly-aligned image-text pairs from large-scale image-only and text-only data for pre-training through relative representation-based retrieval and generation", "role": "Method"}, {"entity_id": "ACL_23_P_464-1-E3", "text": "a small number of aligned image-text pairs as anchors", "role": "PrimaryObject"}]}], "entity_coreference": [], "event_coreference": [], "tokens": ["In", "this", "paper,", "we", "propose", "to", "directly", "take", "a", "small", "number", "of", "aligned", "image-text", "pairs", "as", "anchors,", "and", "represent", "each", "unaligned", "image", "and", "text", "by", "its", "similarities", "to", "these", "anchors,", "i.e.,", "relative", "representations.", "We", "build", "a", "WVLP", "framework", "based", "on", "the", "relative", "representations,", "namely", "RELIT,", "which", "collects", "high-quality", "weakly-aligned", "image-text", "pairs", "from", "large-scale", "image-only", "and", "text-only", "data", "for", "pre-training", "through", "relative", "representation-based", "retrieval", "and", "generation."], "pieces": ["In", "this", "paper", ",", "we", "pro", "pose", "to", "direct", "ly", "take", "a", "small", "number", "of", "aligned", "image", "-", "text", "p", "airs", "as", "anch", "ors", ",", "and", "represent", "each", "unal", "igned", "image", "and", "text", "by", "its", "similar", "ities", "to", "these", "anch", "ors", ",", "i", ".", "e", ".,", "relative", "represent", "ations", ".", "We", "build", "a", "W", "V", "LP", "framework", "based", "on", "the", "relative", "represent", "ations", ",", "name", "ly", "REL", "IT", ",", "which", "collect", "s", "high", "-", "quality", "weak", "ly", "-", "aligned", "image", "-", "text", "p", "airs", "from", "large", "-", "scale", "image", "-", "only", "and", "text", "-", "only", "data", "for", "pre", "-", "training", "through", "relative", "represent", "ation", "-", "based", "ret", "ri", "eval", "and", "generation", "."], "token_lens": [1, 1, 2, 1, 2, 1, 2, 1, 1, 1, 1, 1, 1, 3, 2, 1, 3, 1, 1, 1, 2, 1, 1, 1, 1, 1, 2, 1, 1, 3, 4, 1, 3, 1, 1, 1, 3, 1, 1, 1, 1, 1, 3, 2, 3, 1, 2, 3, 4, 3, 2, 1, 3, 3, 1, 3, 1, 1, 3, 1, 1, 4, 3, 1, 2], "sentence": "In this paper, we propose to directly take a small number of aligned image-text pairs as anchors, and represent each unaligned image and text by its similarities to these anchors, i.e., relative representations. We build a WVLP framework based on the relative representations, namely RELIT, which collects high-quality weakly-aligned image-text pairs from large-scale image-only and text-only data for pre-training through relative representation-based retrieval and generation.", "sentence_starts": [0]}
{"doc_id": "ACL_23_P_464", "wnd_id": "ACL_23_P_464-2", "entity_mentions": [{"id": "ACL_23_P_464-2-E0", "text": "Experiments on four downstream tasks", "start": 0, "end": 5, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_464-2-E1", "text": "RELIT achieves new state-of-the-art results under the weakly supervised setting.", "start": 7, "end": 17, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_464-2-E2", "text": "RELIT achieves new state-of-the-art results under the weakly supervised setting", "start": 7, "end": 17, "entity_type": "UNK", "mention_type": "UNK"}], "relation_mentions": [], "event_mentions": [{"event_type": "Results/Findings", "id": "ACL_23_P_464-2-EV0", "trigger": {"text": "show", "start": 5, "end": 6}, "arguments": [{"entity_id": "ACL_23_P_464-2-E0", "text": "Experiments on four downstream tasks", "role": "Agent"}, {"entity_id": "ACL_23_P_464-2-E1", "text": "RELIT achieves new state-of-the-art results under the weakly supervised setting.", "role": "Results"}, {"entity_id": "ACL_23_P_464-2-E2", "text": "RELIT achieves new state-of-the-art results under the weakly supervised setting", "role": "PrimaryObject"}]}], "entity_coreference": [], "event_coreference": [], "tokens": ["Experiments", "on", "four", "downstream", "tasks", "show", "that", "RELIT", "achieves", "new", "state-of-the-art", "results", "under", "the", "weakly", "supervised", "setting."], "pieces": ["Exper", "iments", "on", "four", "down", "stream", "t", "asks", "show", "that", "REL", "IT", "ach", "ieves", "new", "state", "-", "of", "-", "the", "-", "art", "results", "under", "the", "weak", "ly", "super", "vised", "setting", "."], "token_lens": [2, 1, 1, 2, 2, 1, 1, 2, 2, 1, 7, 1, 1, 1, 2, 2, 2], "sentence": "Experiments on four downstream tasks show that RELIT achieves new state-of-the-art results under the weakly supervised setting.", "sentence_starts": [0]}
{"doc_id": "ACL_23_P_52", "wnd_id": "ACL_23_P_52-0", "entity_mentions": [{"id": "ACL_23_P_52-0-E0", "text": "Key Point Analysis (KPA)", "start": 0, "end": 4, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_52-0-E1", "text": "KPA extracts the main points in the data as a list of concise sentences or phrases, termed Key Points, and quantifies their prevalence", "start": 17, "end": 40, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_52-0-E2", "text": "While key points are more expressive than word clouds and key phrases, making sense of a long, flat list of key points, which often express related ideas in varying levels of granularity, may still be challenging", "start": 40, "end": 76, "entity_type": "UNK", "mention_type": "UNK"}], "relation_mentions": [], "event_mentions": [{"event_type": "Background/Introduction", "id": "ACL_23_P_52-0-EV0", "trigger": {"text": "has been recently proposed", "start": 4, "end": 8}, "arguments": [{"entity_id": "ACL_23_P_52-0-E0", "text": "Key Point Analysis (KPA)", "role": "Agent"}, {"entity_id": "ACL_23_P_52-0-E1", "text": "KPA extracts the main points in the data as a list of concise sentences or phrases, termed Key Points, and quantifies their prevalence", "role": "Context"}, {"entity_id": "ACL_23_P_52-0-E2", "text": "While key points are more expressive than word clouds and key phrases, making sense of a long, flat list of key points, which often express related ideas in varying levels of granularity, may still be challenging", "role": "Challenge"}]}], "entity_coreference": [], "event_coreference": [], "tokens": ["Key", "Point", "Analysis", "(KPA)", "has", "been", "recently", "proposed", "for", "deriving", "fine-grained", "insights", "from", "collections", "of", "textual", "comments.", "KPA", "extracts", "the", "main", "points", "in", "the", "data", "as", "a", "list", "of", "concise", "sentences", "or", "phrases,", "termed", "Key", "Points,", "and", "quantifies", "their", "prevalence.", "While", "key", "points", "are", "more", "expressive", "than", "word", "clouds", "and", "key", "phrases,", "making", "sense", "of", "a", "long,", "flat", "list", "of", "key", "points,", "which", "often", "express", "related", "ideas", "in", "varying", "levels", "of", "granularity,", "may", "still", "be", "challenging."], "pieces": ["Key", "Point", "Analysis", "(", "K", "PA", ")", "has", "been", "recent", "ly", "prop", "osed", "for", "der", "iving", "fine", "-", "gr", "ained", "ins", "ights", "from", "col", "lections", "of", "text", "ual", "comments", ".", "K", "PA", "ext", "ract", "s", "the", "main", "points", "in", "the", "data", "as", "a", "list", "of", "con", "cise", "sent", "ences", "or", "ph", "r", "ases", ",", "ter", "med", "Key", "Points", ",", "and", "quant", "ifies", "their", "pre", "val", "ence", ".", "While", "key", "points", "are", "more", "exp", "ressive", "than", "word", "cloud", "s", "and", "key", "ph", "r", "ases", ",", "making", "sense", "of", "a", "long", ",", "flat", "list", "of", "key", "points", ",", "which", "often", "express", "related", "ide", "as", "in", "v", "ary", "ing", "levels", "of", "gran", "ularity", ",", "may", "still", "be", "chall", "eng", "ing", "."], "token_lens": [1, 1, 1, 4, 1, 1, 2, 2, 1, 2, 4, 2, 1, 2, 1, 2, 2, 2, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 1, 4, 2, 1, 2, 1, 2, 1, 4, 1, 1, 1, 1, 1, 2, 1, 1, 2, 1, 1, 4, 1, 1, 1, 1, 2, 1, 1, 1, 1, 2, 1, 1, 1, 1, 2, 1, 3, 1, 1, 3, 1, 1, 1, 4], "sentence": "Key Point Analysis (KPA) has been recently proposed for deriving fine-grained insights from collections of textual comments. KPA extracts the main points in the data as a list of concise sentences or phrases, termed Key Points, and quantifies their prevalence. While key points are more expressive than word clouds and key phrases, making sense of a long, flat list of key points, which often express related ideas in varying levels of granularity, may still be challenging.", "sentence_starts": [0]}
{"doc_id": "ACL_23_P_52", "wnd_id": "ACL_23_P_52-1", "entity_mentions": [{"id": "ACL_23_P_52-1-E0", "text": "we", "start": 6, "end": 7, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_52-1-E1", "text": "To address this limitation of KPA", "start": 0, "end": 6, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_52-1-E2", "text": "We develop ThinkP, a high-quality benchmark dataset of key point hierarchies for business and product reviews, obtained by consolidating multiple annotations", "start": 38, "end": 59, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_52-1-E3", "text": "We compare different methods for predicting pairwise relations between key points, and for inferring a hierarchy from these pairwise predictions", "start": 59, "end": 79, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_52-1-E4", "text": "Such hierarchies may be viewed as a novel type of Textual Entailment Graph", "start": 25, "end": 38, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_52-1-E5", "text": "the task of organizing a given set of key points into a hierarchy", "start": 8, "end": 21, "entity_type": "UNK", "mention_type": "UNK"}], "relation_mentions": [], "event_mentions": [{"event_type": "Methods/Approach", "id": "ACL_23_P_52-1-EV0", "trigger": {"text": "introduce", "start": 7, "end": 8}, "arguments": [{"entity_id": "ACL_23_P_52-1-E0", "text": "we", "role": "Agent"}, {"entity_id": "ACL_23_P_52-1-E1", "text": "To address this limitation of KPA", "role": "Purpose"}, {"entity_id": "ACL_23_P_52-1-E2", "text": "We develop ThinkP, a high-quality benchmark dataset of key point hierarchies for business and product reviews, obtained by consolidating multiple annotations", "role": "Method"}, {"entity_id": "ACL_23_P_52-1-E3", "text": "We compare different methods for predicting pairwise relations between key points, and for inferring a hierarchy from these pairwise predictions", "role": "Method"}, {"entity_id": "ACL_23_P_52-1-E4", "text": "Such hierarchies may be viewed as a novel type of Textual Entailment Graph", "role": "Analysis"}, {"entity_id": "ACL_23_P_52-1-E5", "text": "the task of organizing a given set of key points into a hierarchy", "role": "PrimaryObject"}]}], "entity_coreference": [], "event_coreference": [], "tokens": ["To", "address", "this", "limitation", "of", "KPA,", "we", "introduce", "the", "task", "of", "organizing", "a", "given", "set", "of", "key", "points", "into", "a", "hierarchy,", "according", "to", "their", "specificity.", "Such", "hierarchies", "may", "be", "viewed", "as", "a", "novel", "type", "of", "Textual", "Entailment", "Graph.", "We", "develop", "ThinkP,", "a", "high-quality", "benchmark", "dataset", "of", "key", "point", "hierarchies", "for", "business", "and", "product", "reviews,", "obtained", "by", "consolidating", "multiple", "annotations.", "We", "compare", "different", "methods", "for", "predicting", "pairwise", "relations", "between", "key", "points,", "and", "for", "inferring", "a", "hierarchy", "from", "these", "pairwise", "predictions."], "pieces": ["To", "address", "this", "lim", "itation", "of", "K", "PA", ",", "we", "introdu", "ce", "the", "task", "of", "organ", "izing", "a", "given", "set", "of", "key", "points", "into", "a", "h", "ier", "archy", ",", "according", "to", "their", "specific", "ity", ".", "Such", "h", "ier", "arch", "ies", "may", "be", "view", "ed", "as", "a", "no", "vel", "type", "of", "Text", "ual", "Ent", "ail", "ment", "Graph", ".", "We", "develop", "Think", "P", ",", "a", "high", "-", "quality", "bench", "mark", "dat", "as", "et", "of", "key", "point", "h", "ier", "arch", "ies", "for", "business", "and", "product", "review", "s", ",", "ob", "tained", "by", "cons", "olid", "ating", "multiple", "annot", "ations", ".", "We", "comp", "are", "different", "method", "s", "for", "p", "redict", "ing", "pair", "wise", "relations", "between", "key", "points", ",", "and", "for", "in", "fer", "ring", "a", "h", "ier", "archy", "from", "these", "pair", "wise", "pred", "ictions", "."], "token_lens": [1, 1, 1, 2, 1, 3, 1, 2, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 4, 1, 1, 1, 3, 1, 4, 1, 1, 2, 1, 1, 2, 1, 1, 2, 3, 2, 1, 1, 3, 1, 3, 2, 3, 1, 1, 1, 4, 1, 1, 1, 1, 3, 2, 1, 3, 1, 3, 1, 2, 1, 2, 1, 3, 2, 1, 1, 1, 2, 1, 1, 3, 1, 3, 1, 1, 2, 3], "sentence": "To address this limitation of KPA, we introduce the task of organizing a given set of key points into a hierarchy, according to their specificity. Such hierarchies may be viewed as a novel type of Textual Entailment Graph. We develop ThinkP, a high-quality benchmark dataset of key point hierarchies for business and product reviews, obtained by consolidating multiple annotations. We compare different methods for predicting pairwise relations between key points, and for inferring a hierarchy from these pairwise predictions.", "sentence_starts": [0]}
{"doc_id": "ACL_23_P_52", "wnd_id": "ACL_23_P_52-2", "entity_mentions": [{"id": "ACL_23_P_52-2-E0", "text": "we", "start": 11, "end": 12, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_52-2-E1", "text": "for the task of computing pairwise key point relations", "start": 2, "end": 11, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_52-2-E2", "text": "applying directional distributional similarity methods to a novel distributional representation of key points", "start": 20, "end": 33, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_52-2-E3", "text": "further boost performance via weak supervision", "start": 34, "end": 40, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_52-2-E4", "text": "significant gains", "start": 13, "end": 15, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_52-2-E5", "text": "over existing strong baselines", "start": 15, "end": 19, "entity_type": "UNK", "mention_type": "UNK"}], "relation_mentions": [], "event_mentions": [{"event_type": "Results/Findings", "id": "ACL_23_P_52-2-EV0", "trigger": {"text": "achieve", "start": 12, "end": 13}, "arguments": [{"entity_id": "ACL_23_P_52-2-E0", "text": "we", "role": "Agent"}, {"entity_id": "ACL_23_P_52-2-E1", "text": "for the task of computing pairwise key point relations", "role": "Context"}, {"entity_id": "ACL_23_P_52-2-E2", "text": "applying directional distributional similarity methods to a novel distributional representation of key points", "role": "Method"}, {"entity_id": "ACL_23_P_52-2-E3", "text": "further boost performance via weak supervision", "role": "Method"}, {"entity_id": "ACL_23_P_52-2-E4", "text": "significant gains", "role": "PrimaryObject"}, {"entity_id": "ACL_23_P_52-2-E5", "text": "over existing strong baselines", "role": "SecondaryObject"}]}], "entity_coreference": [], "event_coreference": [], "tokens": ["In", "particular,", "for", "the", "task", "of", "computing", "pairwise", "key", "point", "relations,", "we", "achieve", "significant", "gains", "over", "existing", "strong", "baselines", "by", "applying", "directional", "distributional", "similarity", "methods", "to", "a", "novel", "distributional", "representation", "of", "key", "points,", "and", "further", "boost", "performance", "via", "weak", "supervision."], "pieces": ["In", "part", "icular", ",", "for", "the", "task", "of", "com", "puting", "pair", "wise", "key", "point", "relations", ",", "we", "ach", "ieve", "significant", "g", "ains", "over", "existing", "strong", "bas", "elines", "by", "app", "lying", "direction", "al", "dist", "ribution", "al", "similar", "ity", "method", "s", "to", "a", "no", "vel", "dist", "ribution", "al", "represent", "ation", "of", "key", "points", ",", "and", "f", "urther", "boost", "performance", "via", "weak", "super", "vision", "."], "token_lens": [1, 3, 1, 1, 1, 1, 2, 2, 1, 1, 2, 1, 2, 1, 2, 1, 1, 1, 2, 1, 2, 2, 3, 2, 2, 1, 1, 2, 3, 2, 1, 1, 2, 1, 2, 1, 1, 1, 1, 3], "sentence": "In particular, for the task of computing pairwise key point relations, we achieve significant gains over existing strong baselines by applying directional distributional similarity methods to a novel distributional representation of key points, and further boost performance via weak supervision.", "sentence_starts": [0]}
{"doc_id": "ACL_23_P_364", "wnd_id": "ACL_23_P_364-0", "entity_mentions": [{"id": "ACL_23_P_364-0-E0", "text": "Dialogue models", "start": 0, "end": 2, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_364-0-E1", "text": "to provide informative responses through a retrieval-augmented pipeline", "start": 9, "end": 17, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_364-0-E2", "text": "retrieval-augmented approaches rely on finely annotated retrieval training data and knowledge-grounded response generation data, making it costly to transfer", "start": 18, "end": 37, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_364-0-E3", "text": "enriched with extensive external knowledge", "start": 4, "end": 9, "entity_type": "UNK", "mention_type": "UNK"}], "relation_mentions": [], "event_mentions": [{"event_type": "Background/Introduction", "id": "ACL_23_P_364-0-EV0", "trigger": {"text": "are", "start": 2, "end": 3}, "arguments": [{"entity_id": "ACL_23_P_364-0-E0", "text": "Dialogue models", "role": "Agent"}, {"entity_id": "ACL_23_P_364-0-E1", "text": "to provide informative responses through a retrieval-augmented pipeline", "role": "Purpose"}, {"entity_id": "ACL_23_P_364-0-E2", "text": "retrieval-augmented approaches rely on finely annotated retrieval training data and knowledge-grounded response generation data, making it costly to transfer", "role": "Challenge"}, {"entity_id": "ACL_23_P_364-0-E3", "text": "enriched with extensive external knowledge", "role": "PrimaryObject"}]}], "entity_coreference": [], "event_coreference": [], "tokens": ["Dialogue", "models", "are", "often", "enriched", "with", "extensive", "external", "knowledge", "to", "provide", "informative", "responses", "through", "a", "retrieval-augmented", "pipeline.", "Nevertheless,", "retrieval-augmented", "approaches", "rely", "on", "finely", "annotated", "retrieval", "training", "data", "and", "knowledge-grounded", "response", "generation", "data,", "making", "it", "costly", "to", "transfer."], "pieces": ["Dialogue", "models", "are", "often", "en", "riched", "with", "ext", "ensive", "external", "knowledge", "to", "prov", "ide", "in", "form", "ative", "respons", "es", "through", "a", "ret", "ri", "eval", "-", "au", "gment", "ed", "p", "ip", "eline", ".", "Nevertheless", ",", "ret", "ri", "eval", "-", "au", "gment", "ed", "appro", "aches", "rely", "on", "fine", "ly", "annot", "ated", "ret", "ri", "eval", "training", "data", "and", "knowledge", "-", "ground", "ed", "response", "generation", "data", ",", "making", "it", "cost", "ly", "to", "transfer", "."], "token_lens": [1, 1, 1, 1, 2, 1, 2, 1, 1, 1, 2, 3, 2, 1, 1, 7, 4, 2, 7, 2, 1, 1, 2, 2, 3, 1, 1, 1, 4, 1, 1, 2, 1, 1, 2, 1, 2], "sentence": "Dialogue models are often enriched with extensive external knowledge to provide informative responses through a retrieval-augmented pipeline. Nevertheless, retrieval-augmented approaches rely on finely annotated retrieval training data and knowledge-grounded response generation data, making it costly to transfer.", "sentence_starts": [0]}
{"doc_id": "ACL_23_P_364", "wnd_id": "ACL_23_P_364-1", "entity_mentions": [{"id": "ACL_23_P_364-1-E0", "text": "this paper", "start": 4, "end": 6, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_364-1-E1", "text": "The simulated knowledge-intensive dialogues constructed by KiDG in one domain can be easily used to train and enhance pre-trained dialogue models\u2019 knowledge w.r.t. this domain without costly annotation", "start": 25, "end": 53, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_364-1-E2", "text": "a retrieval-free approach, KiDG", "start": 7, "end": 11, "entity_type": "UNK", "mention_type": "UNK"}], "relation_mentions": [], "event_mentions": [{"event_type": "Methods/Approach", "id": "ACL_23_P_364-1-EV0", "trigger": {"text": "proposes", "start": 6, "end": 7}, "arguments": [{"entity_id": "ACL_23_P_364-1-E0", "text": "this paper", "role": "Agent"}, {"entity_id": "ACL_23_P_364-1-E1", "text": "The simulated knowledge-intensive dialogues constructed by KiDG in one domain can be easily used to train and enhance pre-trained dialogue models\u2019 knowledge w.r.t. this domain without costly annotation", "role": "Method"}, {"entity_id": "ACL_23_P_364-1-E2", "text": "a retrieval-free approach, KiDG", "role": "PrimaryObject"}]}], "entity_coreference": [], "event_coreference": [], "tokens": ["To", "tackle", "this", "challenge,", "this", "paper", "proposes", "a", "retrieval-free", "approach,", "KiDG,", "by", "automatically", "turning", "knowledge", "documents", "into", "simulated", "multi-turn", "dialogues", "through", "a", "Multi-Document", "Traversal", "algorithm.", "The", "simulated", "knowledge-intensive", "dialogues", "constructed", "by", "KiDG", "in", "one", "domain", "can", "be", "easily", "used", "to", "train", "and", "enhance", "pre-trained", "dialogue", "models\u2019", "knowledge", "w.r.t.", "this", "domain", "without", "costly", "annotation."], "pieces": ["To", "tackle", "this", "chall", "enge", ",", "this", "paper", "pro", "poses", "a", "ret", "ri", "eval", "-", "free", "appro", "ach", ",", "K", "i", "D", "G", ",", "by", "aut", "om", "atically", "turn", "ing", "knowledge", "doc", "uments", "into", "sim", "ulated", "multi", "-", "turn", "dial", "og", "ues", "through", "a", "Multi", "-", "Document", "Tra", "vers", "al", "al", "gorithm", ".", "The", "sim", "ulated", "knowledge", "-", "intensive", "dial", "og", "ues", "con", "structed", "by", "K", "i", "D", "G", "in", "one", "domain", "can", "be", "eas", "ily", "used", "to", "train", "and", "enh", "ance", "pre", "-", "trained", "dial", "ogue", "models", "\u00e2\u0122", "\u013b", "knowledge", "w", ".", "r", ".", "t", ".", "this", "domain", "without", "cost", "ly", "ann", "otation", "."], "token_lens": [1, 1, 1, 3, 1, 1, 2, 1, 5, 3, 5, 1, 3, 2, 1, 2, 1, 2, 3, 3, 1, 1, 3, 3, 3, 1, 2, 3, 3, 2, 1, 4, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 2, 3, 2, 3, 1, 6, 1, 1, 1, 2, 3], "sentence": "To tackle this challenge, this paper proposes a retrieval-free approach, KiDG, by automatically turning knowledge documents into simulated multi-turn dialogues through a Multi-Document Traversal algorithm. The simulated knowledge-intensive dialogues constructed by KiDG in one domain can be easily used to train and enhance pre-trained dialogue models\u2019 knowledge w.r.t. this domain without costly annotation.", "sentence_starts": [0]}
{"doc_id": "ACL_23_P_364", "wnd_id": "ACL_23_P_364-2", "entity_mentions": [{"id": "ACL_23_P_364-2-E0", "text": "We", "start": 0, "end": 1, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_364-2-E1", "text": "dialogue models enhanced with data simulated with KiDG largely outperform state-of-the-art retrieval-free methods", "start": 16, "end": 29, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_364-2-E2", "text": "it achieves comparable performance compared to retrieval-augmented methods while being better, and cheaper at domain transfer", "start": 30, "end": 46, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_364-2-E3", "text": "extensive experiments", "start": 2, "end": 4, "entity_type": "UNK", "mention_type": "UNK"}], "relation_mentions": [], "event_mentions": [{"event_type": "Results/Findings", "id": "ACL_23_P_364-2-EV0", "trigger": {"text": "conduct", "start": 1, "end": 2}, "arguments": [{"entity_id": "ACL_23_P_364-2-E0", "text": "We", "role": "Agent"}, {"entity_id": "ACL_23_P_364-2-E1", "text": "dialogue models enhanced with data simulated with KiDG largely outperform state-of-the-art retrieval-free methods", "role": "Results"}, {"entity_id": "ACL_23_P_364-2-E2", "text": "it achieves comparable performance compared to retrieval-augmented methods while being better, and cheaper at domain transfer", "role": "Results"}, {"entity_id": "ACL_23_P_364-2-E3", "text": "extensive experiments", "role": "PrimaryObject"}]}], "entity_coreference": [], "event_coreference": [], "tokens": ["We", "conduct", "extensive", "experiments", "comparing", "retrieval-augmented", "models", "and", "a", "variety", "of", "retrieval-free", "models.", "We", "found", "that", "dialogue", "models", "enhanced", "with", "data", "simulated", "with", "KiDG", "largely", "outperform", "state-of-the-art", "retrieval-free", "methods,", "and", "it", "achieves", "comparable", "performance", "compared", "to", "retrieval-augmented", "methods", "while", "being", "better,", "and", "cheaper", "at", "domain", "transfer."], "pieces": ["We", "conduct", "ext", "ensive", "exper", "iments", "comp", "aring", "ret", "ri", "eval", "-", "au", "gment", "ed", "models", "and", "a", "var", "iety", "of", "ret", "ri", "eval", "-", "free", "models", ".", "We", "found", "that", "dial", "ogue", "models", "enh", "anced", "with", "data", "sim", "ulated", "with", "K", "i", "D", "G", "large", "ly", "out", "per", "form", "state", "-", "of", "-", "the", "-", "art", "ret", "ri", "eval", "-", "free", "method", "s", ",", "and", "it", "ach", "ieves", "com", "parable", "performance", "comp", "ared", "to", "ret", "ri", "eval", "-", "au", "gment", "ed", "method", "s", "while", "being", "better", ",", "and", "che", "aper", "at", "domain", "transfer", "."], "token_lens": [1, 1, 2, 2, 2, 7, 1, 1, 1, 2, 1, 5, 2, 1, 1, 1, 2, 1, 2, 1, 1, 2, 1, 4, 2, 3, 7, 5, 3, 1, 1, 2, 2, 1, 2, 1, 7, 2, 1, 1, 2, 1, 2, 1, 1, 2], "sentence": "We conduct extensive experiments comparing retrieval-augmented models and a variety of retrieval-free models. We found that dialogue models enhanced with data simulated with KiDG largely outperform state-of-the-art retrieval-free methods, and it achieves comparable performance compared to retrieval-augmented methods while being better, and cheaper at domain transfer.", "sentence_starts": [0]}
{"doc_id": "ACL_23_P_829", "wnd_id": "ACL_23_P_829-0", "entity_mentions": [{"id": "ACL_23_P_829-0-E0", "text": "The method", "start": 10, "end": 12, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_829-0-E1", "text": "Adaptive inference is a simple method for reducing inference costs", "start": 0, "end": 10, "entity_type": "UNK", "mention_type": "UNK"}], "relation_mentions": [], "event_mentions": [{"event_type": "Background/Introduction", "id": "ACL_23_P_829-0-EV0", "trigger": {"text": "works", "start": 12, "end": 13}, "arguments": [{"entity_id": "ACL_23_P_829-0-E0", "text": "The method", "role": "Agent"}, {"entity_id": "ACL_23_P_829-0-E1", "text": "Adaptive inference is a simple method for reducing inference costs", "role": "Context"}]}], "entity_coreference": [], "event_coreference": [], "tokens": ["Adaptive", "inference", "is", "a", "simple", "method", "for", "reducing", "inference", "costs.", "The", "method", "works", "by", "maintaining", "multiple", "classifiers", "of", "different", "capacities,", "and", "allocating", "resources", "to", "each", "test", "instance", "according", "to", "its", "difficulty."], "pieces": ["Adapt", "ive", "in", "ference", "is", "a", "simple", "method", "for", "red", "ucing", "in", "ference", "cost", "s", ".", "The", "method", "works", "by", "m", "aint", "aining", "multiple", "class", "ifiers", "of", "different", "cap", "ac", "ities", ",", "and", "all", "ocating", "resources", "to", "each", "test", "instance", "according", "to", "its", "diff", "iculty", "."], "token_lens": [2, 2, 1, 1, 1, 1, 1, 2, 2, 3, 1, 1, 1, 1, 3, 1, 2, 1, 1, 4, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 3], "sentence": "Adaptive inference is a simple method for reducing inference costs. The method works by maintaining multiple classifiers of different capacities, and allocating resources to each test instance according to its difficulty.", "sentence_starts": [0]}
{"doc_id": "ACL_23_P_829", "wnd_id": "ACL_23_P_829-1", "entity_mentions": [{"id": "ACL_23_P_829-1-E0", "text": "we", "start": 3, "end": 4, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_829-1-E1", "text": "when training data is limited", "start": 15, "end": 20, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_829-1-E2", "text": "we propose SWEET (Separating Weights for Early-Exit Transformers) an Early-Exit fine-tuning method that assigns each classifier its own set of unique model weights, not updated by other classifiers", "start": 92, "end": 120, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_829-1-E3", "text": "we observe that for models with the same architecture and size, individual Multi-Model classifiers outperform their Early-Exit counterparts by an average of 2.3%", "start": 21, "end": 44, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_829-1-E4", "text": "We show that this gap is caused by Early-Exit classifiers sharing model parameters during training, resulting in conflicting gradient updates of model weights", "start": 44, "end": 67, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_829-1-E5", "text": "We find that despite this gap, Early-Exit still provides a better speed-accuracy trade-off due to the overhead of the Multi-Model approach", "start": 67, "end": 88, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_829-1-E6", "text": "the two main approaches", "start": 5, "end": 9, "entity_type": "UNK", "mention_type": "UNK"}], "relation_mentions": [], "event_mentions": [{"event_type": "Methods/Approach", "id": "ACL_23_P_829-1-EV0", "trigger": {"text": "compare", "start": 4, "end": 5}, "arguments": [{"entity_id": "ACL_23_P_829-1-E0", "text": "we", "role": "Agent"}, {"entity_id": "ACL_23_P_829-1-E1", "text": "when training data is limited", "role": "Context"}, {"entity_id": "ACL_23_P_829-1-E2", "text": "we propose SWEET (Separating Weights for Early-Exit Transformers) an Early-Exit fine-tuning method that assigns each classifier its own set of unique model weights, not updated by other classifiers", "role": "Method"}, {"entity_id": "ACL_23_P_829-1-E3", "text": "we observe that for models with the same architecture and size, individual Multi-Model classifiers outperform their Early-Exit counterparts by an average of 2.3%", "role": "Results"}, {"entity_id": "ACL_23_P_829-1-E4", "text": "We show that this gap is caused by Early-Exit classifiers sharing model parameters during training, resulting in conflicting gradient updates of model weights", "role": "Results"}, {"entity_id": "ACL_23_P_829-1-E5", "text": "We find that despite this gap, Early-Exit still provides a better speed-accuracy trade-off due to the overhead of the Multi-Model approach", "role": "Results"}, {"entity_id": "ACL_23_P_829-1-E6", "text": "the two main approaches", "role": "PrimaryObject"}]}], "entity_coreference": [], "event_coreference": [], "tokens": ["In", "this", "work,", "we", "compare", "the", "two", "main", "approaches", "for", "adaptive", "inference,", "Early-Exit", "and", "Multi-Model,", "when", "training", "data", "is", "limited.", "First,", "we", "observe", "that", "for", "models", "with", "the", "same", "architecture", "and", "size,", "individual", "Multi-Model", "classifiers", "outperform", "their", "Early-Exit", "counterparts", "by", "an", "average", "of", "2.3%.", "We", "show", "that", "this", "gap", "is", "caused", "by", "Early-Exit", "classifiers", "sharing", "model", "parameters", "during", "training,", "resulting", "in", "conflicting", "gradient", "updates", "of", "model", "weights.", "We", "find", "that", "despite", "this", "gap,", "Early-Exit", "still", "provides", "a", "better", "speed-accuracy", "trade-off", "due", "to", "the", "overhead", "of", "the", "Multi-Model", "approach.", "To", "address", "these", "issues,", "we", "propose", "SWEET", "(Separating", "Weights", "for", "Early-Exit", "Transformers)", "an", "Early-Exit", "fine-tuning", "method", "that", "assigns", "each", "classifier", "its", "own", "set", "of", "unique", "model", "weights,", "not", "updated", "by", "other", "classifiers."], "pieces": ["In", "this", "work", ",", "we", "comp", "are", "the", "two", "main", "appro", "aches", "for", "adapt", "ive", "in", "ference", ",", "Early", "-", "Exit", "and", "Multi", "-", "Model", ",", "when", "training", "data", "is", "limited", ".", "First", ",", "we", "ob", "ser", "ve", "that", "for", "models", "with", "the", "same", "arch", "itect", "ure", "and", "size", ",", "individual", "Multi", "-", "Model", "class", "ifiers", "out", "per", "form", "their", "Early", "-", "Exit", "counter", "parts", "by", "an", "average", "of", "2", ".", "3", "%.", "We", "show", "that", "this", "gap", "is", "ca", "used", "by", "Early", "-", "Exit", "class", "ifiers", "sharing", "model", "param", "eters", "during", "training", ",", "result", "ing", "in", "conf", "lic", "ting", "gradient", "up", "dates", "of", "model", "weights", ".", "We", "find", "that", "despite", "this", "gap", ",", "Early", "-", "Exit", "still", "prov", "ides", "a", "better", "speed", "-", "acc", "uracy", "trade", "-", "off", "due", "to", "the", "over", "head", "of", "the", "Multi", "-", "Model", "appro", "ach", ".", "To", "address", "these", "issues", ",", "we", "pro", "pose", "S", "WE", "ET", "(", "Sep", "ar", "ating", "We", "ights", "for", "Early", "-", "Exit", "Transform", "ers", ")", "an", "Early", "-", "Exit", "fine", "-", "tun", "ing", "method", "that", "ass", "ign", "s", "each", "class", "ifier", "its", "own", "set", "of", "unique", "model", "weights", ",", "not", "updated", "by", "other", "class", "ifiers", "."], "token_lens": [1, 1, 2, 1, 2, 1, 1, 1, 2, 1, 2, 3, 3, 1, 4, 1, 1, 1, 1, 2, 2, 1, 3, 1, 1, 1, 1, 1, 1, 3, 1, 2, 1, 3, 2, 3, 1, 3, 2, 1, 1, 1, 1, 4, 1, 1, 1, 1, 1, 1, 2, 1, 3, 2, 1, 1, 2, 1, 2, 2, 1, 3, 1, 2, 1, 1, 2, 1, 1, 1, 1, 1, 2, 3, 1, 2, 1, 1, 4, 3, 1, 1, 1, 2, 1, 1, 3, 3, 1, 1, 1, 2, 1, 2, 3, 4, 2, 1, 3, 3, 1, 3, 4, 1, 1, 3, 1, 2, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 3], "sentence": "In this work, we compare the two main approaches for adaptive inference, Early-Exit and Multi-Model, when training data is limited. First, we observe that for models with the same architecture and size, individual Multi-Model classifiers outperform their Early-Exit counterparts by an average of 2.3%. We show that this gap is caused by Early-Exit classifiers sharing model parameters during training, resulting in conflicting gradient updates of model weights. We find that despite this gap, Early-Exit still provides a better speed-accuracy trade-off due to the overhead of the Multi-Model approach. To address these issues, we propose SWEET (Separating Weights for Early-Exit Transformers) an Early-Exit fine-tuning method that assigns each classifier its own set of unique model weights, not updated by other classifiers.", "sentence_starts": [0]}
{"doc_id": "ACL_23_P_829", "wnd_id": "ACL_23_P_829-2", "entity_mentions": [{"id": "ACL_23_P_829-2-E0", "text": "We", "start": 0, "end": 1, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_829-2-E1", "text": "SWEET individual classifiers outperform Early-Exit ones by 1.1% on average", "start": 32, "end": 42, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_829-2-E2", "text": "it outperforms both methods at fast speeds while maintaining comparable scores to Early- Exit at slow speeds", "start": 14, "end": 31, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_829-2-E3", "text": "SWEET enjoys the benefits of both methods, paving the way for further reduction of inference costs in NLP", "start": 42, "end": 60, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_829-2-E4", "text": "SWEET\u2019s speed-accuracy curve", "start": 2, "end": 5, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_829-2-E5", "text": "to standard Early-Exit and Multi-Model baselines", "start": 5, "end": 11, "entity_type": "UNK", "mention_type": "UNK"}], "relation_mentions": [], "event_mentions": [{"event_type": "Results/Findings", "id": "ACL_23_P_829-2-EV0", "trigger": {"text": "compare", "start": 1, "end": 2}, "arguments": [{"entity_id": "ACL_23_P_829-2-E0", "text": "We", "role": "Agent"}, {"entity_id": "ACL_23_P_829-2-E1", "text": "SWEET individual classifiers outperform Early-Exit ones by 1.1% on average", "role": "Results"}, {"entity_id": "ACL_23_P_829-2-E2", "text": "it outperforms both methods at fast speeds while maintaining comparable scores to Early- Exit at slow speeds", "role": "Results"}, {"entity_id": "ACL_23_P_829-2-E3", "text": "SWEET enjoys the benefits of both methods, paving the way for further reduction of inference costs in NLP", "role": "Implications"}, {"entity_id": "ACL_23_P_829-2-E4", "text": "SWEET\u2019s speed-accuracy curve", "role": "PrimaryObject"}, {"entity_id": "ACL_23_P_829-2-E5", "text": "to standard Early-Exit and Multi-Model baselines", "role": "SecondaryObject"}]}], "entity_coreference": [], "event_coreference": [], "tokens": ["We", "compare", "SWEET\u2019s", "speed-accuracy", "curve", "to", "standard", "Early-Exit", "and", "Multi-Model", "baselines", "and", "find", "that", "it", "outperforms", "both", "methods", "at", "fast", "speeds", "while", "maintaining", "comparable", "scores", "to", "Early-", "Exit", "at", "slow", "speeds.", "Moreover,", "SWEET", "individual", "classifiers", "outperform", "Early-Exit", "ones", "by", "1.1%", "on", "average.", "SWEET", "enjoys", "the", "benefits", "of", "both", "methods,", "paving", "the", "way", "for", "further", "reduction", "of", "inference", "costs", "in", "NLP."], "pieces": ["We", "comp", "are", "S", "WE", "ET", "\u00e2\u0122", "\u013b", "s", "speed", "-", "acc", "uracy", "cur", "ve", "to", "standard", "Early", "-", "Exit", "and", "Multi", "-", "Model", "bas", "elines", "and", "find", "that", "it", "out", "per", "forms", "both", "method", "s", "at", "fast", "spe", "eds", "while", "m", "aint", "aining", "com", "parable", "sc", "ores", "to", "Early", "-", "Exit", "at", "slow", "spe", "eds", ".", "Moreover", ",", "S", "WE", "ET", "individual", "class", "ifiers", "out", "per", "form", "Early", "-", "Exit", "ones", "by", "1", ".", "1", "%", "on", "average", ".", "S", "WE", "ET", "en", "joy", "s", "the", "benef", "its", "of", "both", "method", "s", ",", "p", "aving", "the", "way", "for", "f", "urther", "red", "uction", "of", "in", "ference", "cost", "s", "in", "N", "LP", "."], "token_lens": [1, 2, 6, 4, 2, 1, 1, 3, 1, 3, 2, 1, 1, 1, 1, 3, 1, 2, 1, 1, 2, 1, 3, 2, 2, 1, 2, 1, 1, 1, 3, 2, 3, 1, 2, 3, 3, 1, 1, 4, 1, 2, 3, 3, 1, 2, 1, 1, 3, 2, 1, 1, 1, 2, 2, 1, 2, 2, 1, 3], "sentence": "We compare SWEET\u2019s speed-accuracy curve to standard Early-Exit and Multi-Model baselines and find that it outperforms both methods at fast speeds while maintaining comparable scores to Early- Exit at slow speeds. Moreover, SWEET individual classifiers outperform Early-Exit ones by 1.1% on average. SWEET enjoys the benefits of both methods, paving the way for further reduction of inference costs in NLP.", "sentence_starts": [0]}
{"doc_id": "ACL_23_P_64", "wnd_id": "ACL_23_P_64-0", "entity_mentions": [{"id": "ACL_23_P_64-0-E0", "text": "Recent studies", "start": 0, "end": 2, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_64-0-E1", "text": "Many of them benefit from utilizing users\u2019 behavior sequences as plain texts, representing rich information in any domain or system without losing generality", "start": 16, "end": 39, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_64-0-E2", "text": "Can language modeling for user history corpus help improve recommender systems", "start": 43, "end": 54, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_64-0-E3", "text": "While its versatile usability has been widely investigated in many domains, its applications to recommender systems still remain underexplored", "start": 54, "end": 73, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_64-0-E4", "text": "unified user modeling frameworks", "start": 4, "end": 8, "entity_type": "UNK", "mention_type": "UNK"}], "relation_mentions": [], "event_mentions": [{"event_type": "Background/Introduction", "id": "ACL_23_P_64-0-EV0", "trigger": {"text": "have proposed", "start": 2, "end": 4}, "arguments": [{"entity_id": "ACL_23_P_64-0-E0", "text": "Recent studies", "role": "Agent"}, {"entity_id": "ACL_23_P_64-0-E1", "text": "Many of them benefit from utilizing users\u2019 behavior sequences as plain texts, representing rich information in any domain or system without losing generality", "role": "Context"}, {"entity_id": "ACL_23_P_64-0-E2", "text": "Can language modeling for user history corpus help improve recommender systems", "role": "Challenge"}, {"entity_id": "ACL_23_P_64-0-E3", "text": "While its versatile usability has been widely investigated in many domains, its applications to recommender systems still remain underexplored", "role": "Challenge"}, {"entity_id": "ACL_23_P_64-0-E4", "text": "unified user modeling frameworks", "role": "PrimaryObject"}]}], "entity_coreference": [], "event_coreference": [], "tokens": ["Recent", "studies", "have", "proposed", "unified", "user", "modeling", "frameworks", "that", "leverage", "user", "behavior", "data", "from", "various", "applications.", "Many", "of", "them", "benefit", "from", "utilizing", "users\u2019", "behavior", "sequences", "as", "plain", "texts,", "representing", "rich", "information", "in", "any", "domain", "or", "system", "without", "losing", "generality.", "Hence,", "a", "question", "arises:", "Can", "language", "modeling", "for", "user", "history", "corpus", "help", "improve", "recommender", "systems?", "While", "its", "versatile", "usability", "has", "been", "widely", "investigated", "in", "many", "domains,", "its", "applications", "to", "recommender", "systems", "still", "remain", "underexplored."], "pieces": ["Recent", "stud", "ies", "have", "prop", "osed", "un", "ified", "user", "mod", "eling", "fram", "eworks", "that", "le", "verage", "user", "behavior", "data", "from", "var", "ious", "app", "lic", "ations", ".", "Many", "of", "them", "benefit", "from", "util", "izing", "users", "\u00e2\u0122", "\u013b", "behavior", "sequ", "ences", "as", "plain", "text", "s", ",", "represent", "ing", "rich", "information", "in", "any", "domain", "or", "system", "without", "l", "osing", "gener", "ality", ".", "H", "ence", ",", "a", "question", "ar", "ises", ":", "Can", "language", "mod", "eling", "for", "user", "history", "cor", "p", "us", "help", "improve", "recomm", "ender", "system", "s", "?", "While", "its", "vers", "atile", "us", "ability", "has", "been", "wide", "ly", "invest", "igated", "in", "many", "dom", "ains", ",", "its", "app", "lic", "ations", "to", "recomm", "ender", "system", "s", "still", "rem", "ain", "und", "ere", "x", "pl", "ored", "."], "token_lens": [1, 2, 1, 2, 2, 1, 2, 2, 1, 2, 1, 1, 1, 1, 2, 4, 1, 1, 1, 1, 1, 2, 3, 1, 2, 1, 1, 3, 2, 1, 1, 1, 1, 1, 1, 1, 1, 2, 3, 3, 1, 1, 3, 1, 1, 2, 1, 1, 1, 3, 1, 1, 2, 3, 1, 1, 2, 2, 1, 1, 2, 2, 1, 1, 3, 1, 3, 1, 2, 2, 1, 2, 6], "sentence": "Recent studies have proposed unified user modeling frameworks that leverage user behavior data from various applications. Many of them benefit from utilizing users\u2019 behavior sequences as plain texts, representing rich information in any domain or system without losing generality. Hence, a question arises: Can language modeling for user history corpus help improve recommender systems? While its versatile usability has been widely investigated in many domains, its applications to recommender systems still remain underexplored.", "sentence_starts": [0]}
{"doc_id": "ACL_23_P_64", "wnd_id": "ACL_23_P_64-1", "entity_mentions": [{"id": "ACL_23_P_64-1-E0", "text": "We", "start": 0, "end": 1, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_64-1-E1", "text": "leveraging additional task-agnostic user histories delivers significant performance benefits", "start": 19, "end": 28, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_64-1-E2", "text": "our approach can provide promising transfer learning capabilities for a broad spectrum of real-world recommender systems, even on unseen domains and services.", "start": 32, "end": 54, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_64-1-E3", "text": "language modeling applied directly to task-specific user histories achieves excellent results on diverse recommendation tasks", "start": 3, "end": 18, "entity_type": "UNK", "mention_type": "UNK"}], "relation_mentions": [], "event_mentions": [{"event_type": "Results/Findings", "id": "ACL_23_P_64-1-EV0", "trigger": {"text": "show", "start": 1, "end": 2}, "arguments": [{"entity_id": "ACL_23_P_64-1-E0", "text": "We", "role": "Agent"}, {"entity_id": "ACL_23_P_64-1-E1", "text": "leveraging additional task-agnostic user histories delivers significant performance benefits", "role": "Results"}, {"entity_id": "ACL_23_P_64-1-E2", "text": "our approach can provide promising transfer learning capabilities for a broad spectrum of real-world recommender systems, even on unseen domains and services.", "role": "Results"}, {"entity_id": "ACL_23_P_64-1-E3", "text": "language modeling applied directly to task-specific user histories achieves excellent results on diverse recommendation tasks", "role": "PrimaryObject"}]}], "entity_coreference": [], "event_coreference": [], "tokens": ["We", "show", "that", "language", "modeling", "applied", "directly", "to", "task-specific", "user", "histories", "achieves", "excellent", "results", "on", "diverse", "recommendation", "tasks.", "Also,", "leveraging", "additional", "task-agnostic", "user", "histories", "delivers", "significant", "performance", "benefits.", "We", "further", "demonstrate", "that", "our", "approach", "can", "provide", "promising", "transfer", "learning", "capabilities", "for", "a", "broad", "spectrum", "of", "real-world", "recommender", "systems,", "even", "on", "unseen", "domains", "and", "services."], "pieces": ["We", "show", "that", "language", "mod", "eling", "app", "lied", "direct", "ly", "to", "task", "-", "specific", "user", "hist", "ories", "ach", "ieves", "ex", "cellent", "results", "on", "d", "iverse", "recomm", "end", "ation", "t", "asks", ".", "Also", ",", "le", "ver", "aging", "add", "itional", "task", "-", "agn", "ostic", "user", "hist", "ories", "del", "ivers", "significant", "performance", "benef", "its", ".", "We", "f", "urther", "demon", "strate", "that", "our", "appro", "ach", "can", "prov", "ide", "prom", "ising", "transfer", "learning", "cap", "abilities", "for", "a", "broad", "spect", "rum", "of", "real", "-", "world", "recomm", "ender", "system", "s", ",", "even", "on", "un", "seen", "dom", "ains", "and", "services", "."], "token_lens": [1, 1, 1, 1, 2, 2, 2, 1, 3, 1, 2, 2, 2, 1, 1, 2, 3, 3, 2, 3, 2, 4, 1, 2, 2, 1, 1, 3, 1, 2, 2, 1, 1, 2, 1, 2, 2, 1, 1, 2, 1, 1, 1, 2, 1, 3, 2, 3, 1, 1, 2, 2, 1, 2], "sentence": "We show that language modeling applied directly to task-specific user histories achieves excellent results on diverse recommendation tasks. Also, leveraging additional task-agnostic user histories delivers significant performance benefits. We further demonstrate that our approach can provide promising transfer learning capabilities for a broad spectrum of real-world recommender systems, even on unseen domains and services.", "sentence_starts": [0]}
{"doc_id": "ACL_23_P_671", "wnd_id": "ACL_23_P_671-0", "entity_mentions": [{"id": "ACL_23_P_671-0-E0", "text": "Temporal reasoning", "start": 0, "end": 2, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_671-0-E1", "text": "temporal reasoning models can perform reasonably well on in-domain benchmarks", "start": 13, "end": 23, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_671-0-E2", "text": "we have little idea of these systems\u2019 generalizability due to existing datasets\u2019 limitations", "start": 23, "end": 36, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_671-0-E3", "text": "task of predicting temporal relations of event pairs", "start": 4, "end": 12, "entity_type": "UNK", "mention_type": "UNK"}], "relation_mentions": [], "event_mentions": [{"event_type": "Background/Introduction", "id": "ACL_23_P_671-0-EV0", "trigger": {"text": "is", "start": 2, "end": 3}, "arguments": [{"entity_id": "ACL_23_P_671-0-E0", "text": "Temporal reasoning", "role": "Agent"}, {"entity_id": "ACL_23_P_671-0-E1", "text": "temporal reasoning models can perform reasonably well on in-domain benchmarks", "role": "Context"}, {"entity_id": "ACL_23_P_671-0-E2", "text": "we have little idea of these systems\u2019 generalizability due to existing datasets\u2019 limitations", "role": "Challenge"}, {"entity_id": "ACL_23_P_671-0-E3", "text": "task of predicting temporal relations of event pairs", "role": "PrimaryObject"}]}], "entity_coreference": [], "event_coreference": [], "tokens": ["Temporal", "reasoning", "is", "the", "task", "of", "predicting", "temporal", "relations", "of", "event", "pairs.", "While", "temporal", "reasoning", "models", "can", "perform", "reasonably", "well", "on", "in-domain", "benchmarks,", "we", "have", "little", "idea", "of", "these", "systems\u2019", "generalizability", "due", "to", "existing", "datasets\u2019", "limitations."], "pieces": ["Tem", "poral", "reason", "ing", "is", "the", "task", "of", "p", "redict", "ing", "tem", "poral", "relations", "of", "event", "p", "airs", ".", "While", "tem", "poral", "reason", "ing", "models", "can", "per", "form", "reason", "ably", "well", "on", "in", "-", "domain", "bench", "marks", ",", "we", "have", "little", "ide", "a", "of", "these", "system", "s", "\u00e2\u0122", "\u013b", "general", "iz", "ability", "due", "to", "existing", "dat", "as", "ets", "\u00e2\u0122", "\u013b", "lim", "itations", "."], "token_lens": [2, 2, 1, 1, 1, 1, 3, 2, 1, 1, 1, 3, 1, 2, 2, 1, 1, 2, 2, 1, 1, 3, 3, 1, 1, 1, 2, 1, 1, 4, 3, 1, 1, 1, 5, 3], "sentence": "Temporal reasoning is the task of predicting temporal relations of event pairs. While temporal reasoning models can perform reasonably well on in-domain benchmarks, we have little idea of these systems\u2019 generalizability due to existing datasets\u2019 limitations.", "sentence_starts": [0]}
{"doc_id": "ACL_23_P_671", "wnd_id": "ACL_23_P_671-1", "entity_mentions": [{"id": "ACL_23_P_671-1-E0", "text": "we", "start": 3, "end": 4, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_671-1-E1", "text": "evaluates whether systems can correctly understand the effect of incremental changes", "start": 23, "end": 34, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_671-1-E2", "text": "TODAY introduces slight contextual changes for given event pairs, and systems are asked to tell how this subtle contextual change would affect relevant temporal relation distributions", "start": 35, "end": 61, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_671-1-E3", "text": "TODAY also annotates human explanations", "start": 64, "end": 69, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_671-1-E4", "text": "a novel task named TODAY", "start": 5, "end": 10, "entity_type": "UNK", "mention_type": "UNK"}], "relation_mentions": [], "event_mentions": [{"event_type": "Methods/Approach", "id": "ACL_23_P_671-1-EV0", "trigger": {"text": "introduce", "start": 4, "end": 5}, "arguments": [{"entity_id": "ACL_23_P_671-1-E0", "text": "we", "role": "Agent"}, {"entity_id": "ACL_23_P_671-1-E1", "text": "evaluates whether systems can correctly understand the effect of incremental changes", "role": "Method"}, {"entity_id": "ACL_23_P_671-1-E2", "text": "TODAY introduces slight contextual changes for given event pairs, and systems are asked to tell how this subtle contextual change would affect relevant temporal relation distributions", "role": "Method"}, {"entity_id": "ACL_23_P_671-1-E3", "text": "TODAY also annotates human explanations", "role": "Method"}, {"entity_id": "ACL_23_P_671-1-E4", "text": "a novel task named TODAY", "role": "PrimaryObject"}]}], "entity_coreference": [], "event_coreference": [], "tokens": ["In", "this", "work,", "we", "introduce", "a", "novel", "task", "named", "TODAY", "that", "bridges", "this", "gap", "with", "temporal", "differential", "analysis,", "which,", "as", "the", "name", "suggests,", "evaluates", "whether", "systems", "can", "correctly", "understand", "the", "effect", "of", "incremental", "changes.", "Specifically,", "TODAY", "introduces", "slight", "contextual", "changes", "for", "given", "event", "pairs,", "and", "systems", "are", "asked", "to", "tell", "how", "this", "subtle", "contextual", "change", "would", "affect", "relevant", "temporal", "relation", "distributions.", "To", "facilitate", "learning,", "TODAY", "also", "annotates", "human", "explanations."], "pieces": ["In", "this", "work", ",", "we", "introdu", "ce", "a", "no", "vel", "task", "named", "T", "OD", "AY", "that", "brid", "ges", "this", "gap", "with", "tem", "poral", "different", "ial", "analysis", ",", "which", ",", "as", "the", "name", "suggest", "s", ",", "eval", "uates", "whether", "system", "s", "can", "correct", "ly", "under", "stand", "the", "effect", "of", "incre", "mental", "changes", ".", "Specifically", ",", "T", "OD", "AY", "introdu", "ces", "s", "light", "context", "ual", "changes", "for", "given", "event", "p", "airs", ",", "and", "system", "s", "are", "ask", "ed", "to", "tell", "how", "this", "sub", "tle", "context", "ual", "change", "would", "aff", "ect", "relevant", "tem", "poral", "relation", "dist", "ribut", "ions", ".", "To", "fac", "ilit", "ate", "learning", ",", "T", "OD", "AY", "also", "annot", "ates", "human", "ex", "plan", "ations", "."], "token_lens": [1, 1, 2, 1, 2, 1, 2, 1, 1, 3, 1, 2, 1, 1, 1, 2, 2, 2, 2, 1, 1, 1, 3, 2, 1, 2, 1, 2, 2, 1, 1, 1, 2, 2, 2, 3, 2, 2, 2, 1, 1, 1, 1, 3, 1, 2, 1, 2, 1, 1, 1, 1, 2, 2, 1, 1, 2, 1, 2, 1, 4, 1, 3, 2, 3, 1, 2, 1, 4], "sentence": "In this work, we introduce a novel task named TODAY that bridges this gap with temporal differential analysis, which, as the name suggests, evaluates whether systems can correctly understand the effect of incremental changes. Specifically, TODAY introduces slight contextual changes for given event pairs, and systems are asked to tell how this subtle contextual change would affect relevant temporal relation distributions. To facilitate learning, TODAY also annotates human explanations.", "sentence_starts": [0]}
{"doc_id": "ACL_23_P_671", "wnd_id": "ACL_23_P_671-2", "entity_mentions": [{"id": "ACL_23_P_671-2-E0", "text": "We", "start": 0, "end": 1, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_671-2-E1", "text": "TODAY\u2019s supervision style and explanation annotations can be used in joint learning, encouraging models to use more appropriate signals during training and thus outperform across several benchmarks.", "start": 35, "end": 62, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_671-2-E2", "text": "existing models, including GPT-3.5, drop to random guessing on TODAY", "start": 3, "end": 13, "entity_type": "UNK", "mention_type": "UNK"}], "relation_mentions": [], "event_mentions": [{"event_type": "Results/Findings", "id": "ACL_23_P_671-2-EV0", "trigger": {"text": "show", "start": 1, "end": 2}, "arguments": [{"entity_id": "ACL_23_P_671-2-E0", "text": "We", "role": "Agent"}, {"entity_id": "ACL_23_P_671-2-E1", "text": "TODAY\u2019s supervision style and explanation annotations can be used in joint learning, encouraging models to use more appropriate signals during training and thus outperform across several benchmarks.", "role": "Results"}, {"entity_id": "ACL_23_P_671-2-E2", "text": "existing models, including GPT-3.5, drop to random guessing on TODAY", "role": "PrimaryObject"}]}], "entity_coreference": [], "event_coreference": [], "tokens": ["We", "show", "that", "existing", "models,", "including", "GPT-3.5,", "drop", "to", "random", "guessing", "on", "TODAY,", "suggesting", "that", "they", "heavily", "rely", "on", "spurious", "information", "rather", "than", "proper", "reasoning", "for", "temporal", "predictions.", "On", "the", "other", "hand,", "we", "show", "that", "TODAY\u2019s", "supervision", "style", "and", "explanation", "annotations", "can", "be", "used", "in", "joint", "learning,", "encouraging", "models", "to", "use", "more", "appropriate", "signals", "during", "training", "and", "thus", "outperform", "across", "several", "benchmarks."], "pieces": ["We", "show", "that", "existing", "models", ",", "including", "G", "PT", "-", "3", ".", "5", ",", "drop", "to", "random", "gu", "essing", "on", "T", "OD", "AY", ",", "suggest", "ing", "that", "they", "he", "av", "ily", "rely", "on", "sp", "urious", "information", "rather", "than", "pro", "per", "reason", "ing", "for", "tem", "poral", "pred", "ictions", ".", "On", "the", "other", "hand", ",", "we", "show", "that", "T", "OD", "AY", "\u00e2\u0122", "\u013b", "s", "super", "vision", "style", "and", "ex", "plan", "ation", "annot", "ations", "can", "be", "used", "in", "j", "oint", "learning", ",", "enc", "our", "aging", "models", "to", "use", "more", "appropriate", "sign", "als", "during", "training", "and", "thus", "out", "per", "form", "ac", "ross", "sever", "al", "bench", "marks", "."], "token_lens": [1, 1, 1, 1, 2, 1, 7, 1, 1, 1, 2, 1, 4, 2, 1, 1, 3, 1, 1, 2, 1, 1, 1, 2, 2, 1, 2, 3, 1, 1, 1, 2, 1, 1, 1, 6, 2, 1, 1, 3, 2, 1, 1, 1, 1, 2, 2, 3, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 3, 2, 2, 3], "sentence": "We show that existing models, including GPT-3.5, drop to random guessing on TODAY, suggesting that they heavily rely on spurious information rather than proper reasoning for temporal predictions. On the other hand, we show that TODAY\u2019s supervision style and explanation annotations can be used in joint learning, encouraging models to use more appropriate signals during training and thus outperform across several benchmarks.", "sentence_starts": [0]}
{"doc_id": "ACL_23_P_671", "wnd_id": "ACL_23_P_671-3", "entity_mentions": [{"id": "ACL_23_P_671-3-E0", "text": "TODAY", "start": 0, "end": 1, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_671-3-E1", "text": "moving us more toward the goal of generic temporal reasoning systems", "start": 19, "end": 30, "entity_type": "UNK", "mention_type": "UNK"}], "relation_mentions": [], "event_mentions": [{"event_type": "Conclusions/Implications", "id": "ACL_23_P_671-3-EV0", "trigger": {"text": "can also be used", "start": 1, "end": 5}, "arguments": [{"entity_id": "ACL_23_P_671-3-E0", "text": "TODAY", "role": "Agent"}, {"entity_id": "ACL_23_P_671-3-E1", "text": "moving us more toward the goal of generic temporal reasoning systems", "role": "Implications"}]}], "entity_coreference": [], "event_coreference": [], "tokens": ["TODAY", "can", "also", "be", "used", "to", "train", "models", "to", "solicit", "incidental", "supervision", "from", "noisy", "sources", "such", "as", "GPT-3.5,", "thus", "moving", "us", "more", "toward", "the", "goal", "of", "generic", "temporal", "reasoning", "systems."], "pieces": ["T", "OD", "AY", "can", "also", "be", "used", "to", "train", "models", "to", "sol", "icit", "inc", "idental", "super", "vision", "from", "no", "isy", "s", "ources", "such", "as", "G", "PT", "-", "3", ".", "5", ",", "thus", "moving", "us", "more", "t", "oward", "the", "goal", "of", "generic", "tem", "poral", "reason", "ing", "system", "s", "."], "token_lens": [3, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 1, 2, 2, 1, 1, 7, 1, 1, 1, 1, 2, 1, 1, 1, 1, 2, 2, 3], "sentence": "TODAY can also be used to train models to solicit incidental supervision from noisy sources such as GPT-3.5, thus moving us more toward the goal of generic temporal reasoning systems.", "sentence_starts": [0]}
{"doc_id": "ACL_23_P_65", "wnd_id": "ACL_23_P_65-0", "entity_mentions": [{"id": "ACL_23_P_65-0-E0", "text": "Continual relation extraction (RE)", "start": 0, "end": 4, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_65-0-E1", "text": "Existing works store a small number of typical samples to re-train the model for alleviating forgetting", "start": 16, "end": 32, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_65-0-E2", "text": "We conduct an empirical study on existing works and observe that their performance is severely affected by analogous relations", "start": 42, "end": 61, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_65-0-E3", "text": "repeatedly replaying these samples may cause the overfitting problem", "start": 33, "end": 42, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_65-0-E4", "text": "constantly emerging relations", "start": 7, "end": 10, "entity_type": "UNK", "mention_type": "UNK"}], "relation_mentions": [], "event_mentions": [{"event_type": "Background/Introduction", "id": "ACL_23_P_65-0-EV0", "trigger": {"text": "aims to learn", "start": 4, "end": 7}, "arguments": [{"entity_id": "ACL_23_P_65-0-E0", "text": "Continual relation extraction (RE)", "role": "Agent"}, {"entity_id": "ACL_23_P_65-0-E1", "text": "Existing works store a small number of typical samples to re-train the model for alleviating forgetting", "role": "Context"}, {"entity_id": "ACL_23_P_65-0-E2", "text": "We conduct an empirical study on existing works and observe that their performance is severely affected by analogous relations", "role": "Method"}, {"entity_id": "ACL_23_P_65-0-E3", "text": "repeatedly replaying these samples may cause the overfitting problem", "role": "Challenge"}, {"entity_id": "ACL_23_P_65-0-E4", "text": "constantly emerging relations", "role": "PrimaryObject"}]}], "entity_coreference": [], "event_coreference": [], "tokens": ["Continual", "relation", "extraction", "(RE)", "aims", "to", "learn", "constantly", "emerging", "relations", "while", "avoiding", "forgetting", "the", "learned", "relations.", "Existing", "works", "store", "a", "small", "number", "of", "typical", "samples", "to", "re-train", "the", "model", "for", "alleviating", "forgetting.", "However,", "repeatedly", "replaying", "these", "samples", "may", "cause", "the", "overfitting", "problem.", "We", "conduct", "an", "empirical", "study", "on", "existing", "works", "and", "observe", "that", "their", "performance", "is", "severely", "affected", "by", "analogous", "relations."], "pieces": ["Contin", "ual", "relation", "ext", "raction", "(", "RE", ")", "aim", "s", "to", "learn", "const", "antly", "emer", "ging", "relations", "while", "avoid", "ing", "for", "getting", "the", "learn", "ed", "relations", ".", "Ex", "isting", "works", "store", "a", "small", "number", "of", "typ", "ical", "s", "amples", "to", "re", "-", "train", "the", "model", "for", "al", "lev", "iating", "for", "getting", ".", "However", ",", "repe", "ated", "ly", "re", "playing", "these", "s", "amples", "may", "cause", "the", "over", "fitting", "problem", ".", "We", "conduct", "an", "em", "pir", "ical", "study", "on", "existing", "works", "and", "ob", "ser", "ve", "that", "their", "performance", "is", "severe", "ly", "affected", "by", "an", "alog", "ous", "relations", "."], "token_lens": [2, 1, 2, 3, 2, 1, 1, 2, 2, 1, 1, 2, 2, 1, 2, 2, 2, 1, 1, 1, 1, 1, 1, 2, 2, 1, 3, 1, 1, 1, 3, 3, 2, 3, 2, 1, 2, 1, 1, 1, 2, 2, 1, 1, 1, 3, 1, 1, 1, 1, 1, 3, 1, 1, 1, 1, 2, 1, 1, 3, 2], "sentence": "Continual relation extraction (RE) aims to learn constantly emerging relations while avoiding forgetting the learned relations. Existing works store a small number of typical samples to re-train the model for alleviating forgetting. However, repeatedly replaying these samples may cause the overfitting problem. We conduct an empirical study on existing works and observe that their performance is severely affected by analogous relations.", "sentence_starts": [0]}
{"doc_id": "ACL_23_P_65", "wnd_id": "ACL_23_P_65-1", "entity_mentions": [{"id": "ACL_23_P_65-1-E0", "text": "we", "start": 4, "end": 5, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_65-1-E1", "text": "we design memory-insensitive relation prototypes and memory augmentation to overcome the overfitting problem", "start": 15, "end": 28, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_65-1-E2", "text": "We also introduce integrated training and focal knowledge distillation to enhance the performance on analogous relations.", "start": 28, "end": 44, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_65-1-E3", "text": "a novel continual extraction model for analogous relations", "start": 6, "end": 14, "entity_type": "UNK", "mention_type": "UNK"}], "relation_mentions": [], "event_mentions": [{"event_type": "Methods/Approach", "id": "ACL_23_P_65-1-EV0", "trigger": {"text": "propose", "start": 5, "end": 6}, "arguments": [{"entity_id": "ACL_23_P_65-1-E0", "text": "we", "role": "Agent"}, {"entity_id": "ACL_23_P_65-1-E1", "text": "we design memory-insensitive relation prototypes and memory augmentation to overcome the overfitting problem", "role": "Method"}, {"entity_id": "ACL_23_P_65-1-E2", "text": "We also introduce integrated training and focal knowledge distillation to enhance the performance on analogous relations.", "role": "Method"}, {"entity_id": "ACL_23_P_65-1-E3", "text": "a novel continual extraction model for analogous relations", "role": "PrimaryObject"}]}], "entity_coreference": [], "event_coreference": [], "tokens": ["To", "address", "this", "issue,", "we", "propose", "a", "novel", "continual", "extraction", "model", "for", "analogous", "relations.", "Specifically,", "we", "design", "memory-insensitive", "relation", "prototypes", "and", "memory", "augmentation", "to", "overcome", "the", "overfitting", "problem.", "We", "also", "introduce", "integrated", "training", "and", "focal", "knowledge", "distillation", "to", "enhance", "the", "performance", "on", "analogous", "relations."], "pieces": ["To", "address", "this", "issue", ",", "we", "pro", "pose", "a", "no", "vel", "contin", "ual", "ext", "raction", "model", "for", "an", "alog", "ous", "relations", ".", "Specifically", ",", "we", "design", "memory", "-", "ins", "ensitive", "relation", "prot", "otypes", "and", "memory", "au", "gment", "ation", "to", "over", "come", "the", "over", "fitting", "problem", ".", "We", "also", "introdu", "ce", "integ", "rated", "training", "and", "f", "ocal", "knowledge", "dist", "illation", "to", "enh", "ance", "the", "performance", "on", "an", "alog", "ous", "relations", "."], "token_lens": [1, 1, 1, 2, 1, 2, 1, 2, 2, 2, 1, 1, 3, 2, 2, 1, 1, 4, 1, 2, 1, 1, 3, 1, 2, 1, 2, 2, 1, 1, 2, 2, 1, 1, 2, 1, 2, 1, 2, 1, 1, 1, 3, 2], "sentence": "To address this issue, we propose a novel continual extraction model for analogous relations. Specifically, we design memory-insensitive relation prototypes and memory augmentation to overcome the overfitting problem. We also introduce integrated training and focal knowledge distillation to enhance the performance on analogous relations.", "sentence_starts": [0]}
{"doc_id": "ACL_23_P_65", "wnd_id": "ACL_23_P_65-2", "entity_mentions": [{"id": "ACL_23_P_65-2-E0", "text": "Experimental results", "start": 0, "end": 2, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_65-2-E1", "text": "effectiveness in distinguishing analogous relations and overcoming overfitting", "start": 11, "end": 19, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_65-2-E2", "text": "the superiority of our model", "start": 3, "end": 8, "entity_type": "UNK", "mention_type": "UNK"}], "relation_mentions": [], "event_mentions": [{"event_type": "Results/Findings", "id": "ACL_23_P_65-2-EV0", "trigger": {"text": "show", "start": 2, "end": 3}, "arguments": [{"entity_id": "ACL_23_P_65-2-E0", "text": "Experimental results", "role": "Agent"}, {"entity_id": "ACL_23_P_65-2-E1", "text": "effectiveness in distinguishing analogous relations and overcoming overfitting", "role": "Results"}, {"entity_id": "ACL_23_P_65-2-E2", "text": "the superiority of our model", "role": "PrimaryObject"}]}], "entity_coreference": [], "event_coreference": [], "tokens": ["Experimental", "results", "show", "the", "superiority", "of", "our", "model", "and", "demonstrate", "its", "effectiveness", "in", "distinguishing", "analogous", "relations", "and", "overcoming", "overfitting."], "pieces": ["Exper", "imental", "results", "show", "the", "super", "ior", "ity", "of", "our", "model", "and", "demon", "strate", "its", "effect", "iveness", "in", "dist", "ingu", "ishing", "an", "alog", "ous", "relations", "and", "over", "coming", "over", "fitting", "."], "token_lens": [2, 1, 1, 1, 3, 1, 1, 1, 1, 2, 1, 2, 1, 3, 3, 1, 1, 2, 3], "sentence": "Experimental results show the superiority of our model and demonstrate its effectiveness in distinguishing analogous relations and overcoming overfitting.", "sentence_starts": [0]}
{"doc_id": "ACL_23_P_404", "wnd_id": "ACL_23_P_404-0", "entity_mentions": [{"id": "ACL_23_P_404-0-E0", "text": "Complaining", "start": 0, "end": 1, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_404-0-E1", "text": "Considering breakthroughs in machine learning approaches, the complaint detection task has piqued the interest of the natural language processing (NLP) community", "start": 27, "end": 48, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_404-0-E2", "text": "Most of the earlier studies failed to justify their findings, necessitating the adoption of interpretable models that can explain the model\u2019s output in real time", "start": 48, "end": 73, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_404-0-E3", "text": "an illocutionary act", "start": 2, "end": 5, "entity_type": "UNK", "mention_type": "UNK"}], "relation_mentions": [], "event_mentions": [{"event_type": "Background/Introduction", "id": "ACL_23_P_404-0-EV0", "trigger": {"text": "is", "start": 1, "end": 2}, "arguments": [{"entity_id": "ACL_23_P_404-0-E0", "text": "Complaining", "role": "Agent"}, {"entity_id": "ACL_23_P_404-0-E1", "text": "Considering breakthroughs in machine learning approaches, the complaint detection task has piqued the interest of the natural language processing (NLP) community", "role": "Context"}, {"entity_id": "ACL_23_P_404-0-E2", "text": "Most of the earlier studies failed to justify their findings, necessitating the adoption of interpretable models that can explain the model\u2019s output in real time", "role": "Challenge"}, {"entity_id": "ACL_23_P_404-0-E3", "text": "an illocutionary act", "role": "PrimaryObject"}]}], "entity_coreference": [], "event_coreference": [], "tokens": ["Complaining", "is", "an", "illocutionary", "act", "in", "which", "the", "speaker", "communicates", "his/her", "dissatisfaction", "with", "a", "set", "of", "circumstances", "and", "holds", "the", "hearer", "(the", "complainee)", "answerable,", "directly", "or", "indirectly.", "Considering", "breakthroughs", "in", "machine", "learning", "approaches,", "the", "complaint", "detection", "task", "has", "piqued", "the", "interest", "of", "the", "natural", "language", "processing", "(NLP)", "community.", "Most", "of", "the", "earlier", "studies", "failed", "to", "justify", "their", "findings,", "necessitating", "the", "adoption", "of", "interpretable", "models", "that", "can", "explain", "the", "model\u2019s", "output", "in", "real", "time."], "pieces": ["Compl", "aining", "is", "an", "ill", "oc", "ution", "ary", "act", "in", "which", "the", "spe", "aker", "commun", "icates", "his", "/", "her", "d", "iss", "atisf", "action", "with", "a", "set", "of", "circ", "um", "st", "ances", "and", "hold", "s", "the", "he", "arer", "(", "the", "compl", "ain", "ee", ")", "answer", "able", ",", "direct", "ly", "or", "ind", "irect", "ly", ".", "Considering", "break", "through", "s", "in", "machine", "learning", "appro", "aches", ",", "the", "compl", "aint", "det", "ection", "task", "has", "p", "iqu", "ed", "the", "interest", "of", "the", "natural", "language", "processing", "(", "N", "LP", ")", "community", ".", "Most", "of", "the", "ear", "lier", "stud", "ies", "failed", "to", "just", "ify", "their", "find", "ings", ",", "necess", "itating", "the", "ad", "option", "of", "interpret", "able", "models", "that", "can", "expl", "ain", "the", "model", "\u00e2\u0122", "\u013b", "s", "output", "in", "real", "time", "."], "token_lens": [2, 1, 1, 4, 1, 1, 1, 1, 2, 2, 3, 4, 1, 1, 1, 1, 4, 1, 2, 1, 2, 2, 4, 3, 2, 1, 4, 1, 3, 1, 1, 1, 3, 1, 2, 2, 1, 1, 3, 1, 1, 1, 1, 1, 1, 1, 4, 2, 1, 1, 1, 2, 2, 1, 1, 2, 1, 3, 2, 1, 2, 1, 2, 1, 1, 1, 2, 1, 4, 1, 1, 1, 2], "sentence": "Complaining is an illocutionary act in which the speaker communicates his/her dissatisfaction with a set of circumstances and holds the hearer (the complainee) answerable, directly or indirectly. Considering breakthroughs in machine learning approaches, the complaint detection task has piqued the interest of the natural language processing (NLP) community. Most of the earlier studies failed to justify their findings, necessitating the adoption of interpretable models that can explain the model\u2019s output in real time.", "sentence_starts": [0]}
{"doc_id": "ACL_23_P_404", "wnd_id": "ACL_23_P_404-1", "entity_mentions": [{"id": "ACL_23_P_404-1-E0", "text": "We", "start": 0, "end": 1, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_404-1-E1", "text": "Each instance in the X-CI dataset is annotated with five labels: complaint label, emotion label, polarity label, complaint severity level, and rationale (explainability), i.e., the causal span explaining the reason for the complaint/non-complaint label", "start": 15, "end": 49, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_404-1-E2", "text": "We address the task of explainable complaint detection and propose a commonsense-aware unified generative framework by reframing the multitask problem as a text-to-text generation task", "start": 49, "end": 74, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_404-1-E3", "text": "Our framework can predict the complaint cause, severity level, emotion, and polarity of the text in addition to detecting whether it is a complaint or not", "start": 74, "end": 100, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_404-1-E4", "text": "an explainable complaint dataset, X-CI", "start": 2, "end": 7, "entity_type": "UNK", "mention_type": "UNK"}], "relation_mentions": [], "event_mentions": [{"event_type": "Methods/Approach", "id": "ACL_23_P_404-1-EV0", "trigger": {"text": "introduce", "start": 1, "end": 2}, "arguments": [{"entity_id": "ACL_23_P_404-1-E0", "text": "We", "role": "Agent"}, {"entity_id": "ACL_23_P_404-1-E1", "text": "Each instance in the X-CI dataset is annotated with five labels: complaint label, emotion label, polarity label, complaint severity level, and rationale (explainability), i.e., the causal span explaining the reason for the complaint/non-complaint label", "role": "Method"}, {"entity_id": "ACL_23_P_404-1-E2", "text": "We address the task of explainable complaint detection and propose a commonsense-aware unified generative framework by reframing the multitask problem as a text-to-text generation task", "role": "Method"}, {"entity_id": "ACL_23_P_404-1-E3", "text": "Our framework can predict the complaint cause, severity level, emotion, and polarity of the text in addition to detecting whether it is a complaint or not", "role": "Method"}, {"entity_id": "ACL_23_P_404-1-E4", "text": "an explainable complaint dataset, X-CI", "role": "PrimaryObject"}]}], "entity_coreference": [], "event_coreference": [], "tokens": ["We", "introduce", "an", "explainable", "complaint", "dataset,", "X-CI,", "the", "first", "benchmark", "dataset", "for", "explainable", "complaint", "detection.", "Each", "instance", "in", "the", "X-CI", "dataset", "is", "annotated", "with", "five", "labels:", "complaint", "label,", "emotion", "label,", "polarity", "label,", "complaint", "severity", "level,", "and", "rationale", "(explainability),", "i.e.,", "the", "causal", "span", "explaining", "the", "reason", "for", "the", "complaint/non-complaint", "label.", "We", "address", "the", "task", "of", "explainable", "complaint", "detection", "and", "propose", "a", "commonsense-aware", "unified", "generative", "framework", "by", "reframing", "the", "multitask", "problem", "as", "a", "text-to-text", "generation", "task.", "Our", "framework", "can", "predict", "the", "complaint", "cause,", "severity", "level,", "emotion,", "and", "polarity", "of", "the", "text", "in", "addition", "to", "detecting", "whether", "it", "is", "a", "complaint", "or", "not."], "pieces": ["We", "introdu", "ce", "an", "expl", "ain", "able", "compl", "aint", "dat", "as", "et", ",", "X", "-", "CI", ",", "the", "first", "bench", "mark", "dat", "as", "et", "for", "expl", "ain", "able", "compl", "aint", "det", "ection", ".", "Each", "instance", "in", "the", "X", "-", "CI", "dat", "as", "et", "is", "annot", "ated", "with", "five", "lab", "els", ":", "compl", "aint", "label", ",", "em", "otion", "label", ",", "p", "olar", "ity", "label", ",", "compl", "aint", "sever", "ity", "level", ",", "and", "rational", "e", "(", "expl", "ain", "ability", "),", "i", ".", "e", ".,", "the", "ca", "usal", "span", "expl", "aining", "the", "reason", "for", "the", "compl", "aint", "/", "non", "-", "compl", "aint", "label", ".", "We", "address", "the", "task", "of", "expl", "ain", "able", "compl", "aint", "det", "ection", "and", "pro", "pose", "a", "comm", "onsense", "-", "aware", "un", "ified", "gener", "ative", "framework", "by", "ref", "ram", "ing", "the", "mult", "it", "ask", "problem", "as", "a", "text", "-", "to", "-", "text", "generation", "task", ".", "Our", "framework", "can", "p", "redict", "the", "compl", "aint", "cause", ",", "sever", "ity", "level", ",", "em", "otion", ",", "and", "p", "olar", "ity", "of", "the", "text", "in", "add", "ition", "to", "det", "ect", "ing", "whether", "it", "is", "a", "compl", "aint", "or", "not", "."], "token_lens": [1, 2, 1, 3, 2, 4, 4, 1, 1, 2, 3, 1, 3, 2, 3, 1, 1, 1, 1, 3, 3, 1, 2, 1, 1, 3, 2, 2, 2, 2, 3, 2, 2, 2, 2, 1, 2, 5, 4, 1, 2, 1, 2, 1, 1, 1, 1, 7, 2, 1, 1, 1, 1, 1, 3, 2, 2, 1, 2, 1, 4, 2, 2, 1, 1, 3, 1, 3, 1, 1, 1, 5, 1, 2, 1, 1, 1, 2, 1, 2, 2, 2, 2, 3, 1, 3, 1, 1, 1, 1, 2, 1, 3, 1, 1, 1, 1, 2, 1, 2], "sentence": "We introduce an explainable complaint dataset, X-CI, the first benchmark dataset for explainable complaint detection. Each instance in the X-CI dataset is annotated with five labels: complaint label, emotion label, polarity label, complaint severity level, and rationale (explainability), i.e., the causal span explaining the reason for the complaint/non-complaint label. We address the task of explainable complaint detection and propose a commonsense-aware unified generative framework by reframing the multitask problem as a text-to-text generation task. Our framework can predict the complaint cause, severity level, emotion, and polarity of the text in addition to detecting whether it is a complaint or not.", "sentence_starts": [0]}
{"doc_id": "ACL_23_P_404", "wnd_id": "ACL_23_P_404-2", "entity_mentions": [{"id": "ACL_23_P_404-2-E0", "text": "We", "start": 0, "end": 1, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_404-2-E1", "text": "the advantages of our proposed model", "start": 3, "end": 9, "entity_type": "UNK", "mention_type": "UNK"}], "relation_mentions": [], "event_mentions": [{"event_type": "Results/Findings", "id": "ACL_23_P_404-2-EV0", "trigger": {"text": "establish", "start": 2, "end": 3}, "arguments": [{"entity_id": "ACL_23_P_404-2-E0", "text": "We", "role": "Agent"}, {"entity_id": "ACL_23_P_404-2-E1", "text": "the advantages of our proposed model", "role": "PrimaryObject"}]}], "entity_coreference": [], "event_coreference": [], "tokens": ["We", "further", "establish", "the", "advantages", "of", "our", "proposed", "model", "on", "various", "evaluation", "metrics", "over", "the", "state-of-the-art", "models", "and", "other", "baselines", "when", "applied", "to", "the", "X-CI", "dataset", "in", "both", "full", "and", "few-shot", "settings."], "pieces": ["We", "f", "urther", "establish", "the", "advant", "ages", "of", "our", "prop", "osed", "model", "on", "var", "ious", "eval", "uation", "met", "rics", "over", "the", "state", "-", "of", "-", "the", "-", "art", "models", "and", "other", "bas", "elines", "when", "app", "lied", "to", "the", "X", "-", "CI", "dat", "as", "et", "in", "both", "full", "and", "few", "-", "shot", "settings", "."], "token_lens": [1, 2, 1, 1, 2, 1, 1, 2, 1, 1, 2, 2, 2, 1, 1, 7, 1, 1, 1, 2, 1, 2, 1, 1, 3, 3, 1, 1, 1, 1, 3, 2], "sentence": "We further establish the advantages of our proposed model on various evaluation metrics over the state-of-the-art models and other baselines when applied to the X-CI dataset in both full and few-shot settings.", "sentence_starts": [0]}
{"doc_id": "ACL_23_P_532", "wnd_id": "ACL_23_P_532-0", "entity_mentions": [{"id": "ACL_23_P_532-0-E0", "text": "Document-level event argument extraction", "start": 0, "end": 4, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_532-0-E1", "text": "event arguments beyond sentence level", "start": 7, "end": 12, "entity_type": "UNK", "mention_type": "UNK"}], "relation_mentions": [], "event_mentions": [{"event_type": "Background/Introduction", "id": "ACL_23_P_532-0-EV0", "trigger": {"text": "aims to identify", "start": 4, "end": 7}, "arguments": [{"entity_id": "ACL_23_P_532-0-E0", "text": "Document-level event argument extraction", "role": "Agent"}, {"entity_id": "ACL_23_P_532-0-E1", "text": "event arguments beyond sentence level", "role": "PrimaryObject"}]}], "entity_coreference": [], "event_coreference": [], "tokens": ["Document-level", "event", "argument", "extraction", "aims", "to", "identify", "event", "arguments", "beyond", "sentence", "level,", "where", "a", "significant", "challenge", "is", "to", "model", "long-range", "dependencies."], "pieces": ["Document", "-", "level", "event", "argument", "ext", "raction", "aim", "s", "to", "ident", "ify", "event", "arg", "uments", "be", "yond", "sent", "ence", "level", ",", "where", "a", "significant", "chall", "enge", "is", "to", "model", "long", "-", "range", "depend", "encies", "."], "token_lens": [3, 1, 1, 2, 2, 1, 2, 1, 2, 2, 2, 2, 1, 1, 1, 2, 1, 1, 1, 3, 3], "sentence": "Document-level event argument extraction aims to identify event arguments beyond sentence level, where a significant challenge is to model long-range dependencies.", "sentence_starts": [0]}
{"doc_id": "ACL_23_P_532", "wnd_id": "ACL_23_P_532-1", "entity_mentions": [{"id": "ACL_23_P_532-1-E0", "text": "we", "start": 4, "end": 5, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_532-1-E1", "text": "This paradigm naturally captures long-range interdependence due to the chains\u2019 compositional nature, which also improves interpretability by explicitly modeling the reasoning process", "start": 23, "end": 45, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_532-1-E2", "text": "We introduce T-norm fuzzy logic for optimization, which permits end-to-end learning and shows promise for integrating the expressiveness of logical reasoning with the generalization of neural networks", "start": 45, "end": 72, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_532-1-E3", "text": "a new chain reasoning paradigm for the task", "start": 6, "end": 14, "entity_type": "UNK", "mention_type": "UNK"}], "relation_mentions": [], "event_mentions": [{"event_type": "Methods/Approach", "id": "ACL_23_P_532-1-EV0", "trigger": {"text": "present", "start": 5, "end": 6}, "arguments": [{"entity_id": "ACL_23_P_532-1-E0", "text": "we", "role": "Agent"}, {"entity_id": "ACL_23_P_532-1-E1", "text": "This paradigm naturally captures long-range interdependence due to the chains\u2019 compositional nature, which also improves interpretability by explicitly modeling the reasoning process", "role": "Method"}, {"entity_id": "ACL_23_P_532-1-E2", "text": "We introduce T-norm fuzzy logic for optimization, which permits end-to-end learning and shows promise for integrating the expressiveness of logical reasoning with the generalization of neural networks", "role": "Method"}, {"entity_id": "ACL_23_P_532-1-E3", "text": "a new chain reasoning paradigm for the task", "role": "PrimaryObject"}]}], "entity_coreference": [], "event_coreference": [], "tokens": ["Focusing", "on", "this", "challenge,", "we", "present", "a", "new", "chain", "reasoning", "paradigm", "for", "the", "task,", "which", "can", "generate", "decomposable", "first-order", "logic", "rules", "for", "reasoning.", "This", "paradigm", "naturally", "captures", "long-range", "interdependence", "due", "to", "the", "chains\u2019", "compositional", "nature,", "which", "also", "improves", "interpretability", "by", "explicitly", "modeling", "the", "reasoning", "process.", "We", "introduce", "T-norm", "fuzzy", "logic", "for", "optimization,", "which", "permits", "end-to-end", "learning", "and", "shows", "promise", "for", "integrating", "the", "expressiveness", "of", "logical", "reasoning", "with", "the", "generalization", "of", "neural", "networks."], "pieces": ["F", "ocusing", "on", "this", "chall", "enge", ",", "we", "present", "a", "new", "chain", "reason", "ing", "par", "ad", "igm", "for", "the", "task", ",", "which", "can", "gener", "ate", "dec", "om", "pos", "able", "first", "-", "order", "log", "ic", "rules", "for", "reason", "ing", ".", "This", "par", "ad", "igm", "n", "aturally", "capt", "ures", "long", "-", "range", "inter", "d", "ependence", "due", "to", "the", "chains", "\u00e2\u0122", "\u013b", "com", "pos", "itional", "nature", ",", "which", "also", "impro", "ves", "interpret", "ability", "by", "expl", "icit", "ly", "mod", "eling", "the", "reason", "ing", "process", ".", "We", "introdu", "ce", "T", "-", "norm", "f", "uzz", "y", "log", "ic", "for", "optim", "ization", ",", "which", "perm", "its", "end", "-", "to", "-", "end", "learning", "and", "shows", "prom", "ise", "for", "integ", "rating", "the", "express", "iveness", "of", "log", "ical", "reason", "ing", "with", "the", "general", "ization", "of", "ne", "ural", "net", "works", "."], "token_lens": [2, 1, 1, 3, 1, 1, 1, 1, 1, 2, 3, 1, 1, 2, 1, 1, 2, 4, 3, 2, 1, 1, 3, 1, 3, 2, 2, 3, 3, 1, 1, 1, 3, 3, 2, 1, 1, 2, 2, 1, 3, 2, 1, 2, 2, 1, 2, 3, 3, 2, 1, 3, 1, 2, 5, 1, 1, 1, 2, 1, 2, 1, 2, 1, 2, 2, 1, 1, 2, 1, 2, 3], "sentence": "Focusing on this challenge, we present a new chain reasoning paradigm for the task, which can generate decomposable first-order logic rules for reasoning. This paradigm naturally captures long-range interdependence due to the chains\u2019 compositional nature, which also improves interpretability by explicitly modeling the reasoning process. We introduce T-norm fuzzy logic for optimization, which permits end-to-end learning and shows promise for integrating the expressiveness of logical reasoning with the generalization of neural networks.", "sentence_starts": [0]}
{"doc_id": "ACL_23_P_532", "wnd_id": "ACL_23_P_532-2", "entity_mentions": [{"id": "ACL_23_P_532-2-E0", "text": "we", "start": 2, "end": 3, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_532-2-E1", "text": "it is data-efficient in low-resource scenarios and robust enough to defend against adversarial attacks.", "start": 24, "end": 38, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_532-2-E2", "text": "our approach outperforms previous methods by a significant margin on two standard benchmarks (over 6 points in F1)", "start": 5, "end": 23, "entity_type": "UNK", "mention_type": "UNK"}], "relation_mentions": [], "event_mentions": [{"event_type": "Results/Findings", "id": "ACL_23_P_532-2-EV0", "trigger": {"text": "show", "start": 3, "end": 4}, "arguments": [{"entity_id": "ACL_23_P_532-2-E0", "text": "we", "role": "Agent"}, {"entity_id": "ACL_23_P_532-2-E1", "text": "it is data-efficient in low-resource scenarios and robust enough to defend against adversarial attacks.", "role": "Results"}, {"entity_id": "ACL_23_P_532-2-E2", "text": "our approach outperforms previous methods by a significant margin on two standard benchmarks (over 6 points in F1)", "role": "PrimaryObject"}]}], "entity_coreference": [], "event_coreference": [], "tokens": ["In", "experiments,", "we", "show", "that", "our", "approach", "outperforms", "previous", "methods", "by", "a", "significant", "margin", "on", "two", "standard", "benchmarks", "(over", "6", "points", "in", "F1).", "Moreover,", "it", "is", "data-efficient", "in", "low-resource", "scenarios", "and", "robust", "enough", "to", "defend", "against", "adversarial", "attacks."], "pieces": ["In", "exper", "iments", ",", "we", "show", "that", "our", "appro", "ach", "out", "per", "forms", "pre", "vious", "method", "s", "by", "a", "significant", "margin", "on", "two", "standard", "bench", "marks", "(", "over", "6", "points", "in", "F", "1", ").", "Moreover", ",", "it", "is", "data", "-", "efficient", "in", "low", "-", "resource", "sc", "en", "arios", "and", "rob", "ust", "enough", "to", "def", "end", "against", "ad", "vers", "arial", "attacks", "."], "token_lens": [1, 3, 1, 1, 1, 1, 2, 3, 2, 2, 1, 1, 1, 1, 1, 1, 1, 2, 2, 1, 1, 1, 3, 2, 1, 1, 3, 1, 3, 3, 1, 2, 1, 1, 2, 1, 3, 2], "sentence": "In experiments, we show that our approach outperforms previous methods by a significant margin on two standard benchmarks (over 6 points in F1). Moreover, it is data-efficient in low-resource scenarios and robust enough to defend against adversarial attacks.", "sentence_starts": [0]}
{"doc_id": "ACL_23_P_162", "wnd_id": "ACL_23_P_162-0", "entity_mentions": [{"id": "ACL_23_P_162-0-E0", "text": "they", "start": 13, "end": 14, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_162-0-E1", "text": "the excellent performance of Pre-trained Language Models on many text generation tasks", "start": 1, "end": 13, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_162-0-E2", "text": "inefficient inference on computation and memory", "start": 16, "end": 22, "entity_type": "UNK", "mention_type": "UNK"}], "relation_mentions": [], "event_mentions": [{"event_type": "Background/Introduction", "id": "ACL_23_P_162-0-EV0", "trigger": {"text": "suffer from", "start": 14, "end": 16}, "arguments": [{"entity_id": "ACL_23_P_162-0-E0", "text": "they", "role": "Agent"}, {"entity_id": "ACL_23_P_162-0-E1", "text": "the excellent performance of Pre-trained Language Models on many text generation tasks", "role": "Context"}, {"entity_id": "ACL_23_P_162-0-E2", "text": "inefficient inference on computation and memory", "role": "PrimaryObject"}]}], "entity_coreference": [], "event_coreference": [], "tokens": ["Despite", "the", "excellent", "performance", "of", "Pre-trained", "Language", "Models", "on", "many", "text", "generation", "tasks,", "they", "suffer", "from", "inefficient", "inference", "on", "computation", "and", "memory", "due", "to", "their", "large-scale", "parameters", "and", "the", "universal", "autoregressive", "decoding", "paradigm."], "pieces": ["Despite", "the", "ex", "cellent", "performance", "of", "Pre", "-", "trained", "Language", "Mod", "els", "on", "many", "text", "generation", "t", "asks", ",", "they", "s", "uffer", "from", "ine", "fficient", "in", "ference", "on", "com", "put", "ation", "and", "memory", "due", "to", "their", "large", "-", "scale", "param", "eters", "and", "the", "universal", "aut", "ore", "gressive", "dec", "oding", "par", "ad", "igm", "."], "token_lens": [1, 1, 2, 1, 1, 3, 1, 2, 1, 1, 1, 1, 3, 1, 2, 1, 2, 2, 1, 3, 1, 1, 1, 1, 1, 3, 2, 1, 1, 1, 3, 2, 4], "sentence": "Despite the excellent performance of Pre-trained Language Models on many text generation tasks, they suffer from inefficient inference on computation and memory due to their large-scale parameters and the universal autoregressive decoding paradigm.", "sentence_starts": [0]}
{"doc_id": "ACL_23_P_162", "wnd_id": "ACL_23_P_162-1", "entity_mentions": [{"id": "ACL_23_P_162-1-E0", "text": "we", "start": 3, "end": 4, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_162-1-E1", "text": "our critical insight is to jointly utilize the non-autoregressive (NAR) generation and dynamic parameter pruning techniques, which can flexibly control the decoding iteration steps and model sizes according to memory and latency limitations", "start": 34, "end": 67, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_162-1-E2", "text": "we also explore the effectiveness of the pre-trained MLMs (i.e., the BERT family) for text generation tasks since their bidirectional attention nature is more suitable for the NAR training objective", "start": 68, "end": 98, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_162-1-E3", "text": "a novel fine-tuning method DEER", "start": 5, "end": 10, "entity_type": "UNK", "mention_type": "UNK"}], "relation_mentions": [], "event_mentions": [{"event_type": "Methods/Approach", "id": "ACL_23_P_162-1-EV0", "trigger": {"text": "propose", "start": 4, "end": 5}, "arguments": [{"entity_id": "ACL_23_P_162-1-E0", "text": "we", "role": "Agent"}, {"entity_id": "ACL_23_P_162-1-E1", "text": "our critical insight is to jointly utilize the non-autoregressive (NAR) generation and dynamic parameter pruning techniques, which can flexibly control the decoding iteration steps and model sizes according to memory and latency limitations", "role": "Method"}, {"entity_id": "ACL_23_P_162-1-E2", "text": "we also explore the effectiveness of the pre-trained MLMs (i.e., the BERT family) for text generation tasks since their bidirectional attention nature is more suitable for the NAR training objective", "role": "Method"}, {"entity_id": "ACL_23_P_162-1-E3", "text": "a novel fine-tuning method DEER", "role": "PrimaryObject"}]}], "entity_coreference": [], "event_coreference": [], "tokens": ["In", "this", "work,", "we", "propose", "a", "novel", "fine-tuning", "method", "DEER,", "which", "can", "make", "a", "single", "pre-trained", "model", "support", "Dynamic", "and", "Efficient", "infERence", "and", "achieve", "an", "adaptive", "trade-off", "between", "model", "performance", "and", "latency.", "In", "particular,", "our", "critical", "insight", "is", "to", "jointly", "utilize", "the", "non-autoregressive", "(NAR)", "generation", "and", "dynamic", "parameter", "pruning", "techniques,", "which", "can", "flexibly", "control", "the", "decoding", "iteration", "steps", "and", "model", "sizes", "according", "to", "memory", "and", "latency", "limitations.", "Besides,", "we", "also", "explore", "the", "effectiveness", "of", "the", "pre-trained", "MLMs", "(i.e.,", "the", "BERT", "family)", "for", "text", "generation", "tasks", "since", "their", "bidirectional", "attention", "nature", "is", "more", "suitable", "for", "the", "NAR", "training", "objective."], "pieces": ["In", "this", "work", ",", "we", "pro", "pose", "a", "no", "vel", "fine", "-", "tun", "ing", "method", "DE", "ER", ",", "which", "can", "make", "a", "single", "pre", "-", "trained", "model", "support", "Dynamic", "and", "E", "fficient", "inf", "ER", "ence", "and", "ach", "ieve", "an", "adapt", "ive", "trade", "-", "off", "between", "model", "performance", "and", "lat", "ency", ".", "In", "part", "icular", ",", "our", "critical", "ins", "ight", "is", "to", "j", "oint", "ly", "util", "ize", "the", "non", "-", "aut", "ore", "gressive", "(", "N", "AR", ")", "generation", "and", "d", "ynamic", "param", "eter", "pr", "uning", "techn", "iques", ",", "which", "can", "flex", "ibly", "control", "the", "dec", "oding", "iter", "ation", "steps", "and", "model", "s", "izes", "according", "to", "memory", "and", "lat", "ency", "lim", "itations", ".", "Besides", ",", "we", "also", "expl", "ore", "the", "effect", "iveness", "of", "the", "pre", "-", "trained", "ML", "Ms", "(", "i", ".", "e", ".,", "the", "BER", "T", "family", ")", "for", "text", "generation", "t", "asks", "since", "their", "bid", "irection", "al", "att", "ention", "nature", "is", "more", "su", "itable", "for", "the", "N", "AR", "training", "object", "ive", "."], "token_lens": [1, 1, 2, 1, 2, 1, 2, 4, 1, 3, 1, 1, 1, 1, 1, 3, 1, 1, 1, 1, 2, 3, 1, 2, 1, 2, 3, 1, 1, 1, 1, 3, 1, 3, 1, 1, 2, 1, 1, 3, 2, 1, 5, 4, 1, 1, 2, 2, 2, 3, 1, 1, 2, 1, 1, 2, 2, 1, 1, 1, 2, 1, 1, 1, 1, 2, 3, 2, 1, 1, 2, 1, 2, 1, 1, 3, 2, 5, 1, 2, 2, 1, 1, 1, 2, 1, 1, 3, 2, 1, 1, 1, 2, 1, 1, 2, 1, 3], "sentence": "In this work, we propose a novel fine-tuning method DEER, which can make a single pre-trained model support Dynamic and Efficient infERence and achieve an adaptive trade-off between model performance and latency. In particular, our critical insight is to jointly utilize the non-autoregressive (NAR) generation and dynamic parameter pruning techniques, which can flexibly control the decoding iteration steps and model sizes according to memory and latency limitations. Besides, we also explore the effectiveness of the pre-trained MLMs (i.e., the BERT family) for text generation tasks since their bidirectional attention nature is more suitable for the NAR training objective.", "sentence_starts": [0]}
{"doc_id": "ACL_23_P_162", "wnd_id": "ACL_23_P_162-2", "entity_mentions": [{"id": "ACL_23_P_162-2-E0", "text": "Extensive experiments on both monolingual and multilingual pre-trained MLMs", "start": 0, "end": 9, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_162-2-E1", "text": "higher BLEU scores than the strong autoregressive Transformer model on three neural machine translation tasks with 3 \u2192 12 times speedup", "start": 21, "end": 42, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_162-2-E2", "text": "competitive performance (but with much faster inference speed) compared with the BART model on four GLGE benchmark tasks", "start": 43, "end": 61, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_162-2-E3", "text": "the effectiveness", "start": 10, "end": 12, "entity_type": "UNK", "mention_type": "UNK"}], "relation_mentions": [], "event_mentions": [{"event_type": "Results/Findings", "id": "ACL_23_P_162-2-EV0", "trigger": {"text": "demonstrate", "start": 9, "end": 10}, "arguments": [{"entity_id": "ACL_23_P_162-2-E0", "text": "Extensive experiments on both monolingual and multilingual pre-trained MLMs", "role": "Agent"}, {"entity_id": "ACL_23_P_162-2-E1", "text": "higher BLEU scores than the strong autoregressive Transformer model on three neural machine translation tasks with 3 \u2192 12 times speedup", "role": "Results"}, {"entity_id": "ACL_23_P_162-2-E2", "text": "competitive performance (but with much faster inference speed) compared with the BART model on four GLGE benchmark tasks", "role": "Results"}, {"entity_id": "ACL_23_P_162-2-E3", "text": "the effectiveness", "role": "PrimaryObject"}]}], "entity_coreference": [], "event_coreference": [], "tokens": ["Extensive", "experiments", "on", "both", "monolingual", "and", "multilingual", "pre-trained", "MLMs", "demonstrate", "the", "effectiveness", "of", "our", "proposed", "DEER", "method", "by", "consistently", "achieving", "(1)", "higher", "BLEU", "scores", "than", "the", "strong", "autoregressive", "Transformer", "model", "on", "three", "neural", "machine", "translation", "tasks", "with", "3", "\u2192", "12", "times", "speedup,", "(2)", "competitive", "performance", "(but", "with", "much", "faster", "inference", "speed)", "compared", "with", "the", "BART", "model", "on", "four", "GLGE", "benchmark", "tasks."], "pieces": ["Ext", "ensive", "exper", "iments", "on", "both", "mon", "oling", "ual", "and", "mult", "ilingual", "pre", "-", "trained", "ML", "Ms", "demon", "strate", "the", "effect", "iveness", "of", "our", "prop", "osed", "DE", "ER", "method", "by", "cons", "ist", "ently", "ach", "ieving", "(", "1", ")", "higher", "BLE", "U", "sc", "ores", "than", "the", "strong", "aut", "ore", "gressive", "Trans", "former", "model", "on", "three", "ne", "ural", "machine", "translation", "t", "asks", "with", "3", "\u00e2\u0128\u0134", "12", "times", "speed", "up", ",", "(", "2", ")", "competitive", "performance", "(", "but", "with", "much", "f", "aster", "in", "ference", "speed", ")", "comp", "ared", "with", "the", "B", "ART", "model", "on", "four", "GL", "GE", "bench", "mark", "t", "asks", "."], "token_lens": [2, 2, 1, 1, 3, 1, 2, 3, 2, 2, 1, 2, 1, 1, 2, 2, 1, 1, 3, 2, 3, 1, 2, 2, 1, 1, 1, 3, 2, 1, 1, 1, 2, 1, 1, 2, 1, 1, 1, 1, 1, 3, 3, 1, 1, 2, 1, 1, 2, 2, 2, 2, 1, 1, 2, 1, 1, 1, 2, 2, 3], "sentence": "Extensive experiments on both monolingual and multilingual pre-trained MLMs demonstrate the effectiveness of our proposed DEER method by consistently achieving (1) higher BLEU scores than the strong autoregressive Transformer model on three neural machine translation tasks with 3 \u2192 12 times speedup, (2) competitive performance (but with much faster inference speed) compared with the BART model on four GLGE benchmark tasks.", "sentence_starts": [0]}
{"doc_id": "ACL_23_P_82", "wnd_id": "ACL_23_P_82-0", "entity_mentions": [{"id": "ACL_23_P_82-0-E0", "text": "Recent abstractive conversation summarization systems", "start": 0, "end": 5, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_82-0-E1", "text": "collecting and annotating these conversations can be a time-consuming and labor-intensive task", "start": 14, "end": 26, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_82-0-E2", "text": "large-scale datasets with annotated summaries", "start": 8, "end": 13, "entity_type": "UNK", "mention_type": "UNK"}], "relation_mentions": [], "event_mentions": [{"event_type": "Background/Introduction", "id": "ACL_23_P_82-0-EV0", "trigger": {"text": "rely on", "start": 6, "end": 8}, "arguments": [{"entity_id": "ACL_23_P_82-0-E0", "text": "Recent abstractive conversation summarization systems", "role": "Agent"}, {"entity_id": "ACL_23_P_82-0-E1", "text": "collecting and annotating these conversations can be a time-consuming and labor-intensive task", "role": "Challenge"}, {"entity_id": "ACL_23_P_82-0-E2", "text": "large-scale datasets with annotated summaries", "role": "PrimaryObject"}]}], "entity_coreference": [], "event_coreference": [], "tokens": ["Recent", "abstractive", "conversation", "summarization", "systems", "generally", "rely", "on", "large-scale", "datasets", "with", "annotated", "summaries.", "However,", "collecting", "and", "annotating", "these", "conversations", "can", "be", "a", "time-consuming", "and", "labor-intensive", "task."], "pieces": ["Recent", "ab", "stract", "ive", "con", "vers", "ation", "sum", "mar", "ization", "system", "s", "gener", "ally", "rely", "on", "large", "-", "scale", "dat", "as", "ets", "with", "annot", "ated", "s", "umm", "aries", ".", "However", ",", "collect", "ing", "and", "annot", "ating", "these", "con", "vers", "ations", "can", "be", "a", "time", "-", "consuming", "and", "l", "abor", "-", "intensive", "task", "."], "token_lens": [1, 3, 3, 3, 2, 2, 1, 1, 3, 3, 1, 2, 4, 2, 2, 1, 2, 1, 3, 1, 1, 1, 3, 1, 4, 2], "sentence": "Recent abstractive conversation summarization systems generally rely on large-scale datasets with annotated summaries. However, collecting and annotating these conversations can be a time-consuming and labor-intensive task.", "sentence_starts": [0]}
{"doc_id": "ACL_23_P_82", "wnd_id": "ACL_23_P_82-1", "entity_mentions": [{"id": "ACL_23_P_82-1-E0", "text": "we", "start": 7, "end": 8, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_82-1-E1", "text": "for generating diverse and high-quality pairs of conversations and summaries", "start": 17, "end": 27, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_82-1-E2", "text": "Compo first extracts conversation structures like topic splits and action triples as basic units", "start": 28, "end": 42, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_82-1-E3", "text": "Then we organize these semantically meaningful conversation snippets compositionally to create new training instances", "start": 42, "end": 56, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_82-1-E4", "text": "we explore noise-tolerant settings in both self-training and joint-training paradigms to make the most of these augmented samples", "start": 57, "end": 75, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_82-1-E5", "text": "a sub-structure level compositional data augmentation method, Compo", "start": 9, "end": 17, "entity_type": "UNK", "mention_type": "UNK"}], "relation_mentions": [], "event_mentions": [{"event_type": "Methods/Approach", "id": "ACL_23_P_82-1-EV0", "trigger": {"text": "present", "start": 8, "end": 9}, "arguments": [{"entity_id": "ACL_23_P_82-1-E0", "text": "we", "role": "Agent"}, {"entity_id": "ACL_23_P_82-1-E1", "text": "for generating diverse and high-quality pairs of conversations and summaries", "role": "Purpose"}, {"entity_id": "ACL_23_P_82-1-E2", "text": "Compo first extracts conversation structures like topic splits and action triples as basic units", "role": "Method"}, {"entity_id": "ACL_23_P_82-1-E3", "text": "Then we organize these semantically meaningful conversation snippets compositionally to create new training instances", "role": "Method"}, {"entity_id": "ACL_23_P_82-1-E4", "text": "we explore noise-tolerant settings in both self-training and joint-training paradigms to make the most of these augmented samples", "role": "Method"}, {"entity_id": "ACL_23_P_82-1-E5", "text": "a sub-structure level compositional data augmentation method, Compo", "role": "PrimaryObject"}]}], "entity_coreference": [], "event_coreference": [], "tokens": ["To", "address", "this", "issue,", "in", "this", "work,", "we", "present", "a", "sub-structure", "level", "compositional", "data", "augmentation", "method,", "Compo,", "for", "generating", "diverse", "and", "high-quality", "pairs", "of", "conversations", "and", "summaries.", "Specifically,", "Compo", "first", "extracts", "conversation", "structures", "like", "topic", "splits", "and", "action", "triples", "as", "basic", "units.", "Then", "we", "organize", "these", "semantically", "meaningful", "conversation", "snippets", "compositionally", "to", "create", "new", "training", "instances.", "Additionally,", "we", "explore", "noise-tolerant", "settings", "in", "both", "self-training", "and", "joint-training", "paradigms", "to", "make", "the", "most", "of", "these", "augmented", "samples."], "pieces": ["To", "address", "this", "issue", ",", "in", "this", "work", ",", "we", "present", "a", "sub", "-", "st", "ructure", "level", "com", "pos", "itional", "data", "au", "gment", "ation", "method", ",", "Comp", "o", ",", "for", "gener", "ating", "d", "iverse", "and", "high", "-", "quality", "p", "airs", "of", "con", "vers", "ations", "and", "s", "umm", "aries", ".", "Specifically", ",", "Comp", "o", "first", "ext", "ract", "s", "con", "vers", "ation", "struct", "ures", "like", "topic", "spl", "its", "and", "action", "tri", "ples", "as", "basic", "units", ".", "Then", "we", "organ", "ize", "these", "sem", "antically", "meaning", "ful", "con", "vers", "ation", "sn", "ipp", "ets", "com", "pos", "itionally", "to", "create", "new", "training", "inst", "ances", ".", "Additionally", ",", "we", "expl", "ore", "no", "ise", "-", "t", "oler", "ant", "settings", "in", "both", "self", "-", "training", "and", "j", "oint", "-", "training", "par", "ad", "ig", "ms", "to", "make", "the", "most", "of", "these", "au", "gment", "ed", "s", "amples", "."], "token_lens": [1, 1, 1, 2, 1, 1, 2, 1, 1, 1, 4, 1, 3, 1, 3, 2, 3, 1, 2, 2, 1, 3, 2, 1, 3, 1, 4, 2, 2, 1, 3, 3, 2, 1, 1, 2, 1, 1, 2, 1, 1, 2, 1, 1, 2, 1, 2, 2, 3, 3, 3, 1, 1, 1, 1, 3, 2, 1, 2, 6, 1, 1, 1, 3, 1, 4, 4, 1, 1, 1, 1, 1, 1, 3, 3], "sentence": "To address this issue, in this work, we present a sub-structure level compositional data augmentation method, Compo, for generating diverse and high-quality pairs of conversations and summaries. Specifically, Compo first extracts conversation structures like topic splits and action triples as basic units. Then we organize these semantically meaningful conversation snippets compositionally to create new training instances. Additionally, we explore noise-tolerant settings in both self-training and joint-training paradigms to make the most of these augmented samples.", "sentence_starts": [0]}
{"doc_id": "ACL_23_P_82", "wnd_id": "ACL_23_P_82-2", "entity_mentions": [{"id": "ACL_23_P_82-2-E0", "text": "Our experiments on benchmark datasets, SAMSum and DialogSum,", "start": 0, "end": 8, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_82-2-E1", "text": "Compo substantially outperforms prior baseline methods by achieving a nearly 10% increase of ROUGE scores with limited data.", "start": 10, "end": 28, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_82-2-E2", "text": "Compo substantially outperforms prior baseline methods by achieving a nearly 10% increase of ROUGE scores with limited data", "start": 10, "end": 28, "entity_type": "UNK", "mention_type": "UNK"}], "relation_mentions": [], "event_mentions": [{"event_type": "Results/Findings", "id": "ACL_23_P_82-2-EV0", "trigger": {"text": "show", "start": 8, "end": 9}, "arguments": [{"entity_id": "ACL_23_P_82-2-E0", "text": "Our experiments on benchmark datasets, SAMSum and DialogSum,", "role": "Agent"}, {"entity_id": "ACL_23_P_82-2-E1", "text": "Compo substantially outperforms prior baseline methods by achieving a nearly 10% increase of ROUGE scores with limited data.", "role": "Results"}, {"entity_id": "ACL_23_P_82-2-E2", "text": "Compo substantially outperforms prior baseline methods by achieving a nearly 10% increase of ROUGE scores with limited data", "role": "PrimaryObject"}]}], "entity_coreference": [], "event_coreference": [], "tokens": ["Our", "experiments", "on", "benchmark", "datasets,", "SAMSum", "and", "DialogSum,", "show", "that", "Compo", "substantially", "outperforms", "prior", "baseline", "methods", "by", "achieving", "a", "nearly", "10%", "increase", "of", "ROUGE", "scores", "with", "limited", "data."], "pieces": ["Our", "exper", "iments", "on", "bench", "mark", "dat", "as", "ets", ",", "SAM", "Sum", "and", "Dialog", "Sum", ",", "show", "that", "Comp", "o", "sub", "stant", "ially", "out", "per", "forms", "pri", "or", "bas", "eline", "method", "s", "by", "ach", "ieving", "a", "n", "early", "10", "%", "incre", "ase", "of", "R", "OU", "GE", "sc", "ores", "with", "limited", "data", "."], "token_lens": [1, 2, 1, 2, 4, 2, 1, 3, 1, 1, 2, 3, 3, 2, 2, 2, 1, 2, 1, 2, 2, 2, 1, 3, 2, 1, 1, 2], "sentence": "Our experiments on benchmark datasets, SAMSum and DialogSum, show that Compo substantially outperforms prior baseline methods by achieving a nearly 10% increase of ROUGE scores with limited data.", "sentence_starts": [0]}
{"doc_id": "ACL_23_P_540", "wnd_id": "ACL_23_P_540-0", "entity_mentions": [{"id": "ACL_23_P_540-0-E0", "text": "These models", "start": 44, "end": 46, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_540-0-E1", "text": "Reusing off-the-shelf code snippets from online repositories is a common practice, which significantly enhances the productivity of software developers", "start": 0, "end": 19, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_540-0-E2", "text": "To find desired code snippets, developers resort to code search engines through natural language queries", "start": 19, "end": 34, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_540-0-E3", "text": "Neural code search models are hence behind many such engines", "start": 34, "end": 44, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_540-0-E4", "text": "Particularly, an adversary can inject a backdoor in neural code search models, which return buggy or even vulnerable code with security/privacy issues", "start": 70, "end": 92, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_540-0-E5", "text": "the security aspect of these models is rarely studied", "start": 61, "end": 70, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_540-0-E6", "text": "impact the downstream software (e.g., stock trading systems and autonomous driving) and cause financial loss and/or life-threatening incidents.", "start": 94, "end": 112, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_540-0-E7", "text": "deep learning", "start": 49, "end": 51, "entity_type": "UNK", "mention_type": "UNK"}], "relation_mentions": [], "event_mentions": [{"event_type": "Background/Introduction", "id": "ACL_23_P_540-0-EV0", "trigger": {"text": "are based on", "start": 46, "end": 49}, "arguments": [{"entity_id": "ACL_23_P_540-0-E0", "text": "These models", "role": "Agent"}, {"entity_id": "ACL_23_P_540-0-E1", "text": "Reusing off-the-shelf code snippets from online repositories is a common practice, which significantly enhances the productivity of software developers", "role": "Context"}, {"entity_id": "ACL_23_P_540-0-E2", "text": "To find desired code snippets, developers resort to code search engines through natural language queries", "role": "Context"}, {"entity_id": "ACL_23_P_540-0-E3", "text": "Neural code search models are hence behind many such engines", "role": "Context"}, {"entity_id": "ACL_23_P_540-0-E4", "text": "Particularly, an adversary can inject a backdoor in neural code search models, which return buggy or even vulnerable code with security/privacy issues", "role": "Analysis"}, {"entity_id": "ACL_23_P_540-0-E5", "text": "the security aspect of these models is rarely studied", "role": "Challenge"}, {"entity_id": "ACL_23_P_540-0-E6", "text": "impact the downstream software (e.g., stock trading systems and autonomous driving) and cause financial loss and/or life-threatening incidents.", "role": "Challenge"}, {"entity_id": "ACL_23_P_540-0-E7", "text": "deep learning", "role": "PrimaryObject"}]}], "entity_coreference": [], "event_coreference": [], "tokens": ["Reusing", "off-the-shelf", "code", "snippets", "from", "online", "repositories", "is", "a", "common", "practice,", "which", "significantly", "enhances", "the", "productivity", "of", "software", "developers.", "To", "find", "desired", "code", "snippets,", "developers", "resort", "to", "code", "search", "engines", "through", "natural", "language", "queries.", "Neural", "code", "search", "models", "are", "hence", "behind", "many", "such", "engines.", "These", "models", "are", "based", "on", "deep", "learning", "and", "gain", "substantial", "attention", "due", "to", "their", "impressive", "performance.", "However,", "the", "security", "aspect", "of", "these", "models", "is", "rarely", "studied.", "Particularly,", "an", "adversary", "can", "inject", "a", "backdoor", "in", "neural", "code", "search", "models,", "which", "return", "buggy", "or", "even", "vulnerable", "code", "with", "security/privacy", "issues.", "This", "may", "impact", "the", "downstream", "software", "(e.g.,", "stock", "trading", "systems", "and", "autonomous", "driving)", "and", "cause", "financial", "loss", "and/or", "life-threatening", "incidents."], "pieces": ["Re", "using", "off", "-", "the", "-", "she", "lf", "code", "sn", "ipp", "ets", "from", "online", "re", "pos", "it", "ories", "is", "a", "common", "practice", ",", "which", "sign", "ificantly", "enh", "ances", "the", "product", "ivity", "of", "software", "develop", "ers", ".", "To", "find", "des", "ired", "code", "sn", "ipp", "ets", ",", "develop", "ers", "res", "ort", "to", "code", "search", "eng", "ines", "through", "natural", "language", "qu", "eries", ".", "Ne", "ural", "code", "search", "models", "are", "hen", "ce", "behind", "many", "such", "eng", "ines", ".", "These", "models", "are", "based", "on", "deep", "learning", "and", "gain", "sub", "stantial", "att", "ention", "due", "to", "their", "imp", "ressive", "performance", ".", "However", ",", "the", "security", "as", "pect", "of", "these", "models", "is", "ra", "rely", "stud", "ied", ".", "Part", "icularly", ",", "an", "ad", "vers", "ary", "can", "in", "ject", "a", "back", "door", "in", "ne", "ural", "code", "search", "models", ",", "which", "return", "bug", "gy", "or", "even", "v", "ulnerable", "code", "with", "security", "/", "priv", "acy", "issues", ".", "This", "may", "impact", "the", "down", "stream", "software", "(", "e", ".", "g", ".,", "stock", "tr", "ading", "system", "s", "and", "aut", "onomous", "driving", ")", "and", "cause", "financial", "loss", "and", "/", "or", "life", "-", "threatening", "inc", "idents", "."], "token_lens": [2, 6, 1, 3, 1, 1, 4, 1, 1, 1, 2, 1, 2, 2, 1, 2, 1, 1, 3, 1, 1, 2, 1, 4, 2, 2, 1, 1, 1, 2, 1, 1, 1, 3, 2, 1, 1, 1, 1, 2, 1, 1, 1, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 1, 1, 1, 2, 2, 2, 1, 1, 2, 1, 1, 1, 1, 2, 3, 3, 1, 3, 1, 2, 1, 2, 1, 2, 1, 1, 2, 1, 1, 2, 1, 1, 2, 1, 1, 4, 2, 1, 1, 1, 1, 2, 1, 5, 1, 2, 2, 1, 2, 2, 1, 1, 1, 1, 3, 3, 3], "sentence": "Reusing off-the-shelf code snippets from online repositories is a common practice, which significantly enhances the productivity of software developers. To find desired code snippets, developers resort to code search engines through natural language queries. Neural code search models are hence behind many such engines. These models are based on deep learning and gain substantial attention due to their impressive performance. However, the security aspect of these models is rarely studied. Particularly, an adversary can inject a backdoor in neural code search models, which return buggy or even vulnerable code with security/privacy issues. This may impact the downstream software (e.g., stock trading systems and autonomous driving) and cause financial loss and/or life-threatening incidents.", "sentence_starts": [0]}
{"doc_id": "ACL_23_P_540", "wnd_id": "ACL_23_P_540-1", "entity_mentions": [{"id": "ACL_23_P_540-1-E0", "text": "we", "start": 3, "end": 4, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_540-1-E1", "text": "By simply modifying one variable/function name, the attacker can make buggy/vulnerable code rank in the top 11%.", "start": 14, "end": 31, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_540-1-E2", "text": "Our attack BADCODE features a special trigger generation and injection procedure, making the attack more effective and stealthy", "start": 31, "end": 49, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_540-1-E3", "text": "such attacks are feasible and can be quite stealthy", "start": 5, "end": 14, "entity_type": "UNK", "mention_type": "UNK"}], "relation_mentions": [], "event_mentions": [{"event_type": "Methods/Approach", "id": "ACL_23_P_540-1-EV0", "trigger": {"text": "demonstrate", "start": 4, "end": 5}, "arguments": [{"entity_id": "ACL_23_P_540-1-E0", "text": "we", "role": "Agent"}, {"entity_id": "ACL_23_P_540-1-E1", "text": "By simply modifying one variable/function name, the attacker can make buggy/vulnerable code rank in the top 11%.", "role": "Method"}, {"entity_id": "ACL_23_P_540-1-E2", "text": "Our attack BADCODE features a special trigger generation and injection procedure, making the attack more effective and stealthy", "role": "Method"}, {"entity_id": "ACL_23_P_540-1-E3", "text": "such attacks are feasible and can be quite stealthy", "role": "PrimaryObject"}]}], "entity_coreference": [], "event_coreference": [], "tokens": ["In", "this", "paper,", "we", "demonstrate", "such", "attacks", "are", "feasible", "and", "can", "be", "quite", "stealthy.", "By", "simply", "modifying", "one", "variable/function", "name,", "the", "attacker", "can", "make", "buggy/vulnerable", "code", "rank", "in", "the", "top", "11%.", "Our", "attack", "BADCODE", "features", "a", "special", "trigger", "generation", "and", "injection", "procedure,", "making", "the", "attack", "more", "effective", "and", "stealthy."], "pieces": ["In", "this", "paper", ",", "we", "demon", "strate", "such", "attacks", "are", "fe", "as", "ible", "and", "can", "be", "quite", "ste", "alth", "y", ".", "By", "sim", "ply", "mod", "ifying", "one", "variable", "/", "function", "name", ",", "the", "att", "acker", "can", "make", "bug", "gy", "/", "v", "ulnerable", "code", "rank", "in", "the", "top", "11", "%.", "Our", "attack", "B", "AD", "C", "ODE", "features", "a", "special", "trigger", "generation", "and", "in", "jection", "pro", "ced", "ure", ",", "making", "the", "attack", "more", "effective", "and", "ste", "alth", "y", "."], "token_lens": [1, 1, 2, 1, 2, 1, 1, 1, 3, 1, 1, 1, 1, 4, 1, 2, 2, 1, 3, 2, 1, 2, 1, 1, 5, 1, 1, 1, 1, 1, 2, 1, 1, 4, 1, 1, 1, 1, 1, 1, 2, 4, 1, 1, 1, 1, 1, 1, 4], "sentence": "In this paper, we demonstrate such attacks are feasible and can be quite stealthy. By simply modifying one variable/function name, the attacker can make buggy/vulnerable code rank in the top 11%. Our attack BADCODE features a special trigger generation and injection procedure, making the attack more effective and stealthy.", "sentence_starts": [0]}
{"doc_id": "ACL_23_P_540", "wnd_id": "ACL_23_P_540-2", "entity_mentions": [{"id": "ACL_23_P_540-2-E0", "text": "The evaluation", "start": 0, "end": 2, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_540-2-E1", "text": "our attack is more stealthy than the baseline by two times based on the F1 score.", "start": 25, "end": 41, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_540-2-E2", "text": "results show our attack outperforms baselines by 60%", "start": 12, "end": 20, "entity_type": "UNK", "mention_type": "UNK"}], "relation_mentions": [], "event_mentions": [{"event_type": "Results/Findings", "id": "ACL_23_P_540-2-EV0", "trigger": {"text": "is conducted", "start": 2, "end": 4}, "arguments": [{"entity_id": "ACL_23_P_540-2-E0", "text": "The evaluation", "role": "Agent"}, {"entity_id": "ACL_23_P_540-2-E1", "text": "our attack is more stealthy than the baseline by two times based on the F1 score.", "role": "Results"}, {"entity_id": "ACL_23_P_540-2-E2", "text": "results show our attack outperforms baselines by 60%", "role": "Results"}]}], "entity_coreference": [], "event_coreference": [], "tokens": ["The", "evaluation", "is", "conducted", "on", "two", "neural", "code", "search", "models", "and", "the", "results", "show", "our", "attack", "outperforms", "baselines", "by", "60%.", "Our", "user", "study", "demonstrates", "that", "our", "attack", "is", "more", "stealthy", "than", "the", "baseline", "by", "two", "times", "based", "on", "the", "F1", "score."], "pieces": ["The", "eval", "uation", "is", "conduct", "ed", "on", "two", "ne", "ural", "code", "search", "models", "and", "the", "results", "show", "our", "attack", "out", "per", "forms", "bas", "elines", "by", "60", "%.", "Our", "user", "study", "demon", "str", "ates", "that", "our", "attack", "is", "more", "ste", "alth", "y", "than", "the", "bas", "eline", "by", "two", "times", "based", "on", "the", "F", "1", "score", "."], "token_lens": [1, 2, 1, 2, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 3, 2, 1, 2, 1, 1, 1, 3, 1, 1, 1, 1, 1, 3, 1, 1, 2, 1, 1, 1, 1, 1, 1, 2, 2], "sentence": "The evaluation is conducted on two neural code search models and the results show our attack outperforms baselines by 60%. Our user study demonstrates that our attack is more stealthy than the baseline by two times based on the F1 score.", "sentence_starts": [0]}
{"doc_id": "ACL_23_P_835", "wnd_id": "ACL_23_P_835-0", "entity_mentions": [{"id": "ACL_23_P_835-0-E0", "text": "we", "start": 12, "end": 13, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_835-0-E1", "text": "To prevent the costly and inefficient use of resources on low-quality annotations", "start": 0, "end": 12, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_835-0-E2", "text": "a method", "start": 14, "end": 16, "entity_type": "UNK", "mention_type": "UNK"}], "relation_mentions": [], "event_mentions": [{"event_type": "Background/Introduction", "id": "ACL_23_P_835-0-EV0", "trigger": {"text": "want", "start": 13, "end": 14}, "arguments": [{"entity_id": "ACL_23_P_835-0-E0", "text": "we", "role": "Agent"}, {"entity_id": "ACL_23_P_835-0-E1", "text": "To prevent the costly and inefficient use of resources on low-quality annotations", "role": "Purpose"}, {"entity_id": "ACL_23_P_835-0-E2", "text": "a method", "role": "PrimaryObject"}]}], "entity_coreference": [], "event_coreference": [], "tokens": ["To", "prevent", "the", "costly", "and", "inefficient", "use", "of", "resources", "on", "low-quality", "annotations,", "we", "want", "a", "method", "for", "creating", "a", "pool", "of", "dependable", "annotators", "who", "can", "effectively", "complete", "difficult", "tasks,", "such", "as", "evaluating", "automatic", "summarization."], "pieces": ["To", "pre", "vent", "the", "cost", "ly", "and", "ine", "fficient", "use", "of", "resources", "on", "low", "-", "quality", "annot", "ations", ",", "we", "want", "a", "method", "for", "creat", "ing", "a", "pool", "of", "depend", "able", "annot", "ators", "who", "can", "effect", "ively", "complete", "diff", "icult", "t", "asks", ",", "such", "as", "eval", "uating", "automatic", "sum", "mar", "ization", "."], "token_lens": [1, 2, 1, 2, 1, 2, 1, 1, 1, 1, 3, 3, 1, 1, 1, 1, 1, 2, 1, 1, 1, 2, 2, 1, 1, 2, 1, 2, 3, 1, 1, 2, 1, 4], "sentence": "To prevent the costly and inefficient use of resources on low-quality annotations, we want a method for creating a pool of dependable annotators who can effectively complete difficult tasks, such as evaluating automatic summarization.", "sentence_starts": [0]}
{"doc_id": "ACL_23_P_835", "wnd_id": "ACL_23_P_835-1", "entity_mentions": [{"id": "ACL_23_P_835-1-E0", "text": "we", "start": 1, "end": 2, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_835-1-E1", "text": "we can successfully filter out subpar workers before they carry out the evaluations and obtain high-agreement annotations with similar constraints on resources", "start": 18, "end": 40, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_835-1-E2", "text": "the recruitment of high-quality Amazon Mechanical Turk workers", "start": 3, "end": 11, "entity_type": "UNK", "mention_type": "UNK"}], "relation_mentions": [], "event_mentions": [{"event_type": "Methods/Approach", "id": "ACL_23_P_835-1-EV0", "trigger": {"text": "investigate", "start": 2, "end": 3}, "arguments": [{"entity_id": "ACL_23_P_835-1-E0", "text": "we", "role": "Agent"}, {"entity_id": "ACL_23_P_835-1-E1", "text": "we can successfully filter out subpar workers before they carry out the evaluations and obtain high-agreement annotations with similar constraints on resources", "role": "Results"}, {"entity_id": "ACL_23_P_835-1-E2", "text": "the recruitment of high-quality Amazon Mechanical Turk workers", "role": "PrimaryObject"}]}], "entity_coreference": [], "event_coreference": [], "tokens": ["Thus,", "we", "investigate", "the", "recruitment", "of", "high-quality", "Amazon", "Mechanical", "Turk", "workers", "via", "a", "two-step", "pipeline.", "We", "show", "that", "we", "can", "successfully", "filter", "out", "subpar", "workers", "before", "they", "carry", "out", "the", "evaluations", "and", "obtain", "high-agreement", "annotations", "with", "similar", "constraints", "on", "resources."], "pieces": ["Thus", ",", "we", "invest", "igate", "the", "rec", "ruit", "ment", "of", "high", "-", "quality", "Amazon", "Mech", "anical", "Tur", "k", "workers", "via", "a", "two", "-", "step", "p", "ip", "eline", ".", "We", "show", "that", "we", "can", "successfully", "filter", "out", "sub", "par", "workers", "before", "they", "carry", "out", "the", "eval", "uations", "and", "ob", "tain", "high", "-", "ag", "reement", "annot", "ations", "with", "similar", "con", "str", "aints", "on", "resources", "."], "token_lens": [2, 1, 2, 1, 3, 1, 3, 1, 2, 2, 1, 1, 1, 3, 4, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 2, 1, 2, 4, 2, 1, 1, 3, 1, 2], "sentence": "Thus, we investigate the recruitment of high-quality Amazon Mechanical Turk workers via a two-step pipeline. We show that we can successfully filter out subpar workers before they carry out the evaluations and obtain high-agreement annotations with similar constraints on resources.", "sentence_starts": [0]}
{"doc_id": "ACL_23_P_835", "wnd_id": "ACL_23_P_835-2", "entity_mentions": [{"id": "ACL_23_P_835-2-E0", "text": "our workers", "start": 1, "end": 3, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_835-2-E1", "text": "their alignment with expert judgments on a subset of the data is not as expected and needs further training in correctness", "start": 12, "end": 33, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_835-2-E2", "text": "a strong consensus", "start": 4, "end": 7, "entity_type": "UNK", "mention_type": "UNK"}], "relation_mentions": [], "event_mentions": [{"event_type": "Results/Findings", "id": "ACL_23_P_835-2-EV0", "trigger": {"text": "demonstrate", "start": 3, "end": 4}, "arguments": [{"entity_id": "ACL_23_P_835-2-E0", "text": "our workers", "role": "Agent"}, {"entity_id": "ACL_23_P_835-2-E1", "text": "their alignment with expert judgments on a subset of the data is not as expected and needs further training in correctness", "role": "Results"}, {"entity_id": "ACL_23_P_835-2-E2", "text": "a strong consensus", "role": "PrimaryObject"}]}], "entity_coreference": [], "event_coreference": [], "tokens": ["Although", "our", "workers", "demonstrate", "a", "strong", "consensus", "among", "themselves", "and", "CloudResearch", "workers,", "their", "alignment", "with", "expert", "judgments", "on", "a", "subset", "of", "the", "data", "is", "not", "as", "expected", "and", "needs", "further", "training", "in", "correctness."], "pieces": ["Although", "our", "workers", "demon", "strate", "a", "strong", "cons", "ensus", "among", "them", "selves", "and", "Cloud", "Research", "workers", ",", "their", "al", "ignment", "with", "ex", "pert", "jud", "gments", "on", "a", "sub", "set", "of", "the", "data", "is", "not", "as", "expected", "and", "needs", "f", "urther", "training", "in", "correct", "ness", "."], "token_lens": [1, 1, 1, 2, 1, 1, 2, 1, 2, 1, 2, 2, 1, 2, 1, 2, 2, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 3], "sentence": "Although our workers demonstrate a strong consensus among themselves and CloudResearch workers, their alignment with expert judgments on a subset of the data is not as expected and needs further training in correctness.", "sentence_starts": [0]}
{"doc_id": "ACL_23_P_835", "wnd_id": "ACL_23_P_835-3", "entity_mentions": [{"id": "ACL_23_P_835-3-E0", "text": "This paper", "start": 0, "end": 2, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_835-3-E1", "text": "a best practice", "start": 5, "end": 8, "entity_type": "UNK", "mention_type": "UNK"}], "relation_mentions": [], "event_mentions": [{"event_type": "Conclusions/Implications", "id": "ACL_23_P_835-3-EV0", "trigger": {"text": "serves as", "start": 3, "end": 5}, "arguments": [{"entity_id": "ACL_23_P_835-3-E0", "text": "This paper", "role": "Agent"}, {"entity_id": "ACL_23_P_835-3-E1", "text": "a best practice", "role": "PrimaryObject"}]}], "entity_coreference": [], "event_coreference": [], "tokens": ["This", "paper", "still", "serves", "as", "a", "best", "practice", "for", "the", "recruitment", "of", "qualified", "annotators", "in", "other", "challenging", "annotation", "tasks."], "pieces": ["This", "paper", "still", "serv", "es", "as", "a", "best", "practice", "for", "the", "rec", "ruit", "ment", "of", "qualified", "annot", "ators", "in", "other", "chall", "eng", "ing", "ann", "otation", "t", "asks", "."], "token_lens": [1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 3, 1, 1, 2, 1, 1, 3, 2, 3], "sentence": "This paper still serves as a best practice for the recruitment of qualified annotators in other challenging annotation tasks.", "sentence_starts": [0]}
{"doc_id": "ACL_23_P_783", "wnd_id": "ACL_23_P_783-0", "entity_mentions": [{"id": "ACL_23_P_783-0-E0", "text": "Various design settings for in-context learning (ICL)", "start": 0, "end": 7, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_783-0-E1", "text": "While many studies discuss these design choices, there have been few systematic investigations into categorizing them and mitigating their impact", "start": 22, "end": 42, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_783-0-E2", "text": "the model\u2019s predictions", "start": 19, "end": 22, "entity_type": "UNK", "mention_type": "UNK"}], "relation_mentions": [], "event_mentions": [{"event_type": "Background/Introduction", "id": "ACL_23_P_783-0-EV0", "trigger": {"text": "bias", "start": 18, "end": 19}, "arguments": [{"entity_id": "ACL_23_P_783-0-E0", "text": "Various design settings for in-context learning (ICL)", "role": "Agent"}, {"entity_id": "ACL_23_P_783-0-E1", "text": "While many studies discuss these design choices, there have been few systematic investigations into categorizing them and mitigating their impact", "role": "Challenge"}, {"entity_id": "ACL_23_P_783-0-E2", "text": "the model\u2019s predictions", "role": "PrimaryObject"}]}], "entity_coreference": [], "event_coreference": [], "tokens": ["Various", "design", "settings", "for", "in-context", "learning", "(ICL),", "such", "as", "the", "choice", "and", "order", "of", "the", "in-context", "examples,", "can", "bias", "the", "model\u2019s", "predictions.", "While", "many", "studies", "discuss", "these", "design", "choices,", "there", "have", "been", "few", "systematic", "investigations", "into", "categorizing", "them", "and", "mitigating", "their", "impact."], "pieces": ["Various", "design", "settings", "for", "in", "-", "context", "learning", "(", "IC", "L", "),", "such", "as", "the", "choice", "and", "order", "of", "the", "in", "-", "context", "ex", "amples", ",", "can", "b", "ias", "the", "model", "\u00e2\u0122", "\u013b", "s", "pred", "ictions", ".", "While", "many", "stud", "ies", "disc", "uss", "these", "design", "cho", "ices", ",", "there", "have", "been", "few", "system", "atic", "invest", "ig", "ations", "into", "c", "ategor", "izing", "them", "and", "mit", "igating", "their", "impact", "."], "token_lens": [1, 1, 1, 1, 3, 1, 4, 1, 1, 1, 1, 1, 1, 1, 1, 3, 3, 1, 2, 1, 4, 3, 1, 1, 2, 2, 1, 1, 3, 1, 1, 1, 1, 2, 3, 1, 3, 1, 1, 2, 1, 2], "sentence": "Various design settings for in-context learning (ICL), such as the choice and order of the in-context examples, can bias the model\u2019s predictions. While many studies discuss these design choices, there have been few systematic investigations into categorizing them and mitigating their impact.", "sentence_starts": [0]}
{"doc_id": "ACL_23_P_783", "wnd_id": "ACL_23_P_783-1", "entity_mentions": [{"id": "ACL_23_P_783-1-E0", "text": "we", "start": 3, "end": 4, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_783-1-E1", "text": "domain-label bias restricts LLMs to random-level performance on many tasks regardless of the choice of in-context examples", "start": 53, "end": 70, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_783-1-E2", "text": "we propose a simple bias calibration method that estimates a language model\u2019s label bias using random in-domain words from the task corpus", "start": 77, "end": 99, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_783-1-E3", "text": "Our analysis demonstrates that prior label bias calibration methods fall short of addressing all three types of biases", "start": 34, "end": 52, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_783-1-E4", "text": "After controlling for this estimated bias when making predictions, our novel domain-context calibration significantly improves the ICL performance of GPT-J and GPT-3 on a wide range of tasks", "start": 99, "end": 127, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_783-1-E5", "text": "a typology", "start": 5, "end": 7, "entity_type": "UNK", "mention_type": "UNK"}], "relation_mentions": [], "event_mentions": [{"event_type": "Methods/Approach", "id": "ACL_23_P_783-1-EV0", "trigger": {"text": "define", "start": 4, "end": 5}, "arguments": [{"entity_id": "ACL_23_P_783-1-E0", "text": "we", "role": "Agent"}, {"entity_id": "ACL_23_P_783-1-E1", "text": "domain-label bias restricts LLMs to random-level performance on many tasks regardless of the choice of in-context examples", "role": "Context"}, {"entity_id": "ACL_23_P_783-1-E2", "text": "we propose a simple bias calibration method that estimates a language model\u2019s label bias using random in-domain words from the task corpus", "role": "Method"}, {"entity_id": "ACL_23_P_783-1-E3", "text": "Our analysis demonstrates that prior label bias calibration methods fall short of addressing all three types of biases", "role": "Results"}, {"entity_id": "ACL_23_P_783-1-E4", "text": "After controlling for this estimated bias when making predictions, our novel domain-context calibration significantly improves the ICL performance of GPT-J and GPT-3 on a wide range of tasks", "role": "Results"}, {"entity_id": "ACL_23_P_783-1-E5", "text": "a typology", "role": "PrimaryObject"}]}], "entity_coreference": [], "event_coreference": [], "tokens": ["In", "this", "work,", "we", "define", "a", "typology", "for", "three", "types", "of", "label", "biases", "in", "ICL", "for", "text", "classification:", "vanilla-label", "bias,", "context-label", "bias,", "and", "domain-label", "bias", "(which", "we", "conceptualize", "and", "detect", "for", "the", "first", "time).", "Our", "analysis", "demonstrates", "that", "prior", "label", "bias", "calibration", "methods", "fall", "short", "of", "addressing", "all", "three", "types", "of", "biases.", "Specifically,", "domain-label", "bias", "restricts", "LLMs", "to", "random-level", "performance", "on", "many", "tasks", "regardless", "of", "the", "choice", "of", "in-context", "examples.", "To", "mitigate", "the", "effect", "of", "these", "biases,", "we", "propose", "a", "simple", "bias", "calibration", "method", "that", "estimates", "a", "language", "model\u2019s", "label", "bias", "using", "random", "in-domain", "words", "from", "the", "task", "corpus.", "After", "controlling", "for", "this", "estimated", "bias", "when", "making", "predictions,", "our", "novel", "domain-context", "calibration", "significantly", "improves", "the", "ICL", "performance", "of", "GPT-J", "and", "GPT-3", "on", "a", "wide", "range", "of", "tasks."], "pieces": ["In", "this", "work", ",", "we", "define", "a", "typ", "ology", "for", "three", "types", "of", "label", "bi", "ases", "in", "IC", "L", "for", "text", "class", "ification", ":", "van", "illa", "-", "label", "b", "ias", ",", "context", "-", "label", "b", "ias", ",", "and", "domain", "-", "label", "b", "ias", "(", "which", "we", "concept", "ual", "ize", "and", "det", "ect", "for", "the", "first", "time", ").", "Our", "analysis", "demon", "str", "ates", "that", "pri", "or", "label", "b", "ias", "cal", "ib", "ration", "method", "s", "fall", "short", "of", "add", "ressing", "all", "three", "types", "of", "bi", "ases", ".", "Specifically", ",", "domain", "-", "label", "b", "ias", "rest", "rict", "s", "LL", "Ms", "to", "random", "-", "level", "performance", "on", "many", "t", "asks", "reg", "ardless", "of", "the", "choice", "of", "in", "-", "context", "ex", "amples", ".", "To", "mit", "igate", "the", "effect", "of", "these", "bi", "ases", ",", "we", "pro", "pose", "a", "simple", "b", "ias", "cal", "ib", "ration", "method", "that", "est", "imates", "a", "language", "model", "\u00e2\u0122", "\u013b", "s", "label", "b", "ias", "using", "random", "in", "-", "domain", "words", "from", "the", "task", "cor", "p", "us", ".", "After", "cont", "rolling", "for", "this", "est", "imated", "b", "ias", "when", "making", "pred", "ictions", ",", "our", "no", "vel", "domain", "-", "context", "cal", "ib", "ration", "sign", "ificantly", "impro", "ves", "the", "IC", "L", "performance", "of", "G", "PT", "-", "J", "and", "G", "PT", "-", "3", "on", "a", "wide", "range", "of", "t", "asks", "."], "token_lens": [1, 1, 2, 1, 1, 1, 2, 1, 1, 1, 1, 1, 2, 1, 2, 1, 1, 3, 4, 3, 3, 3, 1, 3, 2, 2, 1, 3, 1, 2, 1, 1, 1, 2, 1, 1, 3, 1, 2, 1, 2, 3, 2, 1, 1, 1, 2, 1, 1, 1, 1, 3, 2, 3, 2, 3, 2, 1, 3, 1, 1, 1, 2, 2, 1, 1, 1, 1, 3, 3, 1, 2, 1, 1, 1, 1, 3, 1, 2, 1, 1, 2, 3, 1, 1, 2, 1, 1, 4, 1, 2, 1, 1, 3, 1, 1, 1, 1, 4, 1, 2, 1, 1, 2, 2, 1, 1, 3, 1, 2, 3, 3, 2, 2, 1, 2, 1, 1, 4, 1, 4, 1, 1, 1, 1, 1, 3], "sentence": "In this work, we define a typology for three types of label biases in ICL for text classification: vanilla-label bias, context-label bias, and domain-label bias (which we conceptualize and detect for the first time). Our analysis demonstrates that prior label bias calibration methods fall short of addressing all three types of biases. Specifically, domain-label bias restricts LLMs to random-level performance on many tasks regardless of the choice of in-context examples. To mitigate the effect of these biases, we propose a simple bias calibration method that estimates a language model\u2019s label bias using random in-domain words from the task corpus. After controlling for this estimated bias when making predictions, our novel domain-context calibration significantly improves the ICL performance of GPT-J and GPT-3 on a wide range of tasks.", "sentence_starts": [0]}
{"doc_id": "ACL_23_P_783", "wnd_id": "ACL_23_P_783-2", "entity_mentions": [{"id": "ACL_23_P_783-2-E0", "text": "our results", "start": 16, "end": 18, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_783-2-E1", "text": "The gain is substantial on tasks with large domain-label bias (up to 37% in Macro-F1)", "start": 0, "end": 15, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_783-2-E2", "text": "models with different scales, pretraining methods, and manually-designed task instructions", "start": 20, "end": 30, "entity_type": "UNK", "mention_type": "UNK"}], "relation_mentions": [], "event_mentions": [{"event_type": "Results/Findings", "id": "ACL_23_P_783-2-EV0", "trigger": {"text": "generalize to", "start": 18, "end": 20}, "arguments": [{"entity_id": "ACL_23_P_783-2-E0", "text": "our results", "role": "Agent"}, {"entity_id": "ACL_23_P_783-2-E1", "text": "The gain is substantial on tasks with large domain-label bias (up to 37% in Macro-F1)", "role": "Results"}, {"entity_id": "ACL_23_P_783-2-E2", "text": "models with different scales, pretraining methods, and manually-designed task instructions", "role": "PrimaryObject"}]}], "entity_coreference": [], "event_coreference": [], "tokens": ["The", "gain", "is", "substantial", "on", "tasks", "with", "large", "domain-label", "bias", "(up", "to", "37%", "in", "Macro-F1).", "Furthermore,", "our", "results", "generalize", "to", "models", "with", "different", "scales,", "pretraining", "methods,", "and", "manually-designed", "task", "instructions,", "showing", "the", "prevalence", "of", "label", "biases", "in", "ICL."], "pieces": ["The", "gain", "is", "sub", "stantial", "on", "t", "asks", "with", "large", "domain", "-", "label", "b", "ias", "(", "up", "to", "37", "%", "in", "Mac", "ro", "-", "F", "1", ").", "Furthermore", ",", "our", "results", "general", "ize", "to", "models", "with", "different", "sc", "ales", ",", "pret", "raining", "method", "s", ",", "and", "man", "ually", "-", "designed", "task", "in", "struct", "ions", ",", "sh", "owing", "the", "pre", "val", "ence", "of", "label", "bi", "ases", "in", "IC", "L", "."], "token_lens": [1, 1, 1, 2, 1, 2, 1, 1, 3, 2, 2, 1, 2, 1, 6, 2, 1, 1, 2, 1, 1, 1, 1, 3, 2, 3, 1, 4, 1, 4, 2, 1, 3, 1, 1, 2, 1, 3], "sentence": "The gain is substantial on tasks with large domain-label bias (up to 37% in Macro-F1). Furthermore, our results generalize to models with different scales, pretraining methods, and manually-designed task instructions, showing the prevalence of label biases in ICL.", "sentence_starts": [0]}
{"doc_id": "ACL_23_P_139", "wnd_id": "ACL_23_P_139-0", "entity_mentions": [{"id": "ACL_23_P_139-0-E0", "text": "previous methods", "start": 47, "end": 49, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_139-0-E1", "text": "Multimodal sarcasm detection is an important research topic in natural language processing and multimedia computing, and benefits a wide range of applications in multiple domains", "start": 0, "end": 25, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_139-0-E2", "text": "Most existing studies regard the incongruity between image and text as the indicative clue in identifying multimodal sarcasm", "start": 25, "end": 43, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_139-0-E3", "text": "fixed architectures in network design", "start": 51, "end": 56, "entity_type": "UNK", "mention_type": "UNK"}], "relation_mentions": [], "event_mentions": [{"event_type": "Background/Introduction", "id": "ACL_23_P_139-0-EV0", "trigger": {"text": "rely on", "start": 49, "end": 51}, "arguments": [{"entity_id": "ACL_23_P_139-0-E0", "text": "previous methods", "role": "Agent"}, {"entity_id": "ACL_23_P_139-0-E1", "text": "Multimodal sarcasm detection is an important research topic in natural language processing and multimedia computing, and benefits a wide range of applications in multiple domains", "role": "Context"}, {"entity_id": "ACL_23_P_139-0-E2", "text": "Most existing studies regard the incongruity between image and text as the indicative clue in identifying multimodal sarcasm", "role": "Context"}, {"entity_id": "ACL_23_P_139-0-E3", "text": "fixed architectures in network design", "role": "PrimaryObject"}]}], "entity_coreference": [], "event_coreference": [], "tokens": ["Multimodal", "sarcasm", "detection", "is", "an", "important", "research", "topic", "in", "natural", "language", "processing", "and", "multimedia", "computing,", "and", "benefits", "a", "wide", "range", "of", "applications", "in", "multiple", "domains.", "Most", "existing", "studies", "regard", "the", "incongruity", "between", "image", "and", "text", "as", "the", "indicative", "clue", "in", "identifying", "multimodal", "sarcasm.", "To", "capture", "cross-modal", "incongruity,", "previous", "methods", "rely", "on", "fixed", "architectures", "in", "network", "design,", "which", "restricts", "the", "model", "from", "dynamically", "adjusting", "to", "diverse", "image-text", "pairs."], "pieces": ["Mult", "im", "od", "al", "s", "arc", "asm", "det", "ection", "is", "an", "important", "research", "topic", "in", "natural", "language", "processing", "and", "mult", "imedia", "com", "puting", ",", "and", "benef", "its", "a", "wide", "range", "of", "app", "lic", "ations", "in", "multiple", "dom", "ains", ".", "Most", "existing", "stud", "ies", "reg", "ard", "the", "inc", "ong", "ru", "ity", "between", "image", "and", "text", "as", "the", "ind", "icative", "cl", "ue", "in", "ident", "ifying", "mult", "im", "od", "al", "s", "arc", "asm", ".", "To", "capt", "ure", "cross", "-", "mod", "al", "inc", "ong", "ru", "ity", ",", "pre", "vious", "method", "s", "rely", "on", "fixed", "arch", "itect", "ures", "in", "network", "design", ",", "which", "rest", "rict", "s", "the", "model", "from", "d", "ynam", "ically", "adjust", "ing", "to", "d", "iverse", "image", "-", "text", "p", "airs", "."], "token_lens": [4, 3, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 3, 1, 2, 1, 1, 1, 1, 3, 1, 1, 3, 1, 1, 2, 2, 1, 4, 1, 1, 1, 1, 1, 1, 2, 2, 1, 2, 4, 4, 1, 2, 4, 5, 2, 2, 1, 1, 1, 3, 1, 1, 2, 1, 3, 1, 1, 1, 3, 2, 1, 2, 3, 3], "sentence": "Multimodal sarcasm detection is an important research topic in natural language processing and multimedia computing, and benefits a wide range of applications in multiple domains. Most existing studies regard the incongruity between image and text as the indicative clue in identifying multimodal sarcasm. To capture cross-modal incongruity, previous methods rely on fixed architectures in network design, which restricts the model from dynamically adjusting to diverse image-text pairs.", "sentence_starts": [0]}
{"doc_id": "ACL_23_P_139", "wnd_id": "ACL_23_P_139-1", "entity_mentions": [{"id": "ACL_23_P_139-1-E0", "text": "we", "start": 5, "end": 6, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_139-1-E1", "text": "Our method utilizes dynamic paths to activate different routing transformer modules with hierarchical co-attention adapting to cross-modal incongruity", "start": 22, "end": 40, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_139-1-E2", "text": "the dynamic mechanism in multimodal sarcasm detection and propose the Dynamic Routing Transformer Network (DynRT-Net).", "start": 7, "end": 22, "entity_type": "UNK", "mention_type": "UNK"}], "relation_mentions": [], "event_mentions": [{"event_type": "Methods/Approach", "id": "ACL_23_P_139-1-EV0", "trigger": {"text": "model", "start": 6, "end": 7}, "arguments": [{"entity_id": "ACL_23_P_139-1-E0", "text": "we", "role": "Agent"}, {"entity_id": "ACL_23_P_139-1-E1", "text": "Our method utilizes dynamic paths to activate different routing transformer modules with hierarchical co-attention adapting to cross-modal incongruity", "role": "Method"}, {"entity_id": "ACL_23_P_139-1-E2", "text": "the dynamic mechanism in multimodal sarcasm detection and propose the Dynamic Routing Transformer Network (DynRT-Net).", "role": "PrimaryObject"}]}], "entity_coreference": [], "event_coreference": [], "tokens": ["Inspired", "by", "routing-based", "dynamic", "network,", "we", "model", "the", "dynamic", "mechanism", "in", "multimodal", "sarcasm", "detection", "and", "propose", "the", "Dynamic", "Routing", "Transformer", "Network", "(DynRT-Net).", "Our", "method", "utilizes", "dynamic", "paths", "to", "activate", "different", "routing", "transformer", "modules", "with", "hierarchical", "co-attention", "adapting", "to", "cross-modal", "incongruity."], "pieces": ["Insp", "ired", "by", "r", "outing", "-", "based", "d", "ynamic", "network", ",", "we", "model", "the", "d", "ynamic", "me", "chan", "ism", "in", "mult", "im", "od", "al", "s", "arc", "asm", "det", "ection", "and", "pro", "pose", "the", "Dynamic", "R", "outing", "Trans", "former", "Network", "(", "D", "yn", "RT", "-", "Net", ").", "Our", "method", "util", "izes", "d", "ynamic", "path", "s", "to", "activate", "different", "r", "outing", "trans", "former", "modules", "with", "h", "ier", "arch", "ical", "co", "-", "att", "ention", "adapt", "ing", "to", "cross", "-", "mod", "al", "inc", "ong", "ru", "ity", "."], "token_lens": [2, 1, 4, 2, 2, 1, 1, 1, 2, 3, 1, 4, 3, 2, 1, 2, 1, 1, 2, 2, 1, 7, 1, 1, 2, 2, 2, 1, 1, 1, 2, 2, 1, 1, 4, 4, 2, 1, 4, 5], "sentence": "Inspired by routing-based dynamic network, we model the dynamic mechanism in multimodal sarcasm detection and propose the Dynamic Routing Transformer Network (DynRT-Net). Our method utilizes dynamic paths to activate different routing transformer modules with hierarchical co-attention adapting to cross-modal incongruity.", "sentence_starts": [0]}
{"doc_id": "ACL_23_P_139", "wnd_id": "ACL_23_P_139-2", "entity_mentions": [{"id": "ACL_23_P_139-2-E0", "text": "Experimental results on a public dataset", "start": 0, "end": 6, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_139-2-E1", "text": "the effectiveness of our method", "start": 7, "end": 12, "entity_type": "UNK", "mention_type": "UNK"}], "relation_mentions": [], "event_mentions": [{"event_type": "Results/Findings", "id": "ACL_23_P_139-2-EV0", "trigger": {"text": "demonstrate", "start": 6, "end": 7}, "arguments": [{"entity_id": "ACL_23_P_139-2-E0", "text": "Experimental results on a public dataset", "role": "Agent"}, {"entity_id": "ACL_23_P_139-2-E1", "text": "the effectiveness of our method", "role": "PrimaryObject"}]}], "entity_coreference": [], "event_coreference": [], "tokens": ["Experimental", "results", "on", "a", "public", "dataset", "demonstrate", "the", "effectiveness", "of", "our", "method", "compared", "to", "the", "state-of-the-art", "methods."], "pieces": ["Exper", "imental", "results", "on", "a", "public", "dat", "as", "et", "demon", "strate", "the", "effect", "iveness", "of", "our", "method", "comp", "ared", "to", "the", "state", "-", "of", "-", "the", "-", "art", "method", "s", "."], "token_lens": [2, 1, 1, 1, 1, 3, 2, 1, 2, 1, 1, 1, 2, 1, 1, 7, 3], "sentence": "Experimental results on a public dataset demonstrate the effectiveness of our method compared to the state-of-the-art methods.", "sentence_starts": [0]}
{"doc_id": "ACL_23_P_398", "wnd_id": "ACL_23_P_398-0", "entity_mentions": [{"id": "ACL_23_P_398-0-E0", "text": "both central assumptions", "start": 31, "end": 34, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_398-0-E1", "text": "Many NLP pipelines split text into sentences as one of the crucial preprocessing steps", "start": 0, "end": 14, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_398-0-E2", "text": "Prior sentence segmentation tools either rely on punctuation or require a considerable amount of sentence-segmented training data:", "start": 14, "end": 31, "entity_type": "UNK", "mention_type": "UNK"}], "relation_mentions": [], "event_mentions": [{"event_type": "Background/Introduction", "id": "ACL_23_P_398-0-EV0", "trigger": {"text": "fail", "start": 35, "end": 36}, "arguments": [{"entity_id": "ACL_23_P_398-0-E0", "text": "both central assumptions", "role": "Agent"}, {"entity_id": "ACL_23_P_398-0-E1", "text": "Many NLP pipelines split text into sentences as one of the crucial preprocessing steps", "role": "Context"}, {"entity_id": "ACL_23_P_398-0-E2", "text": "Prior sentence segmentation tools either rely on punctuation or require a considerable amount of sentence-segmented training data:", "role": "Context"}]}], "entity_coreference": [], "event_coreference": [], "tokens": ["Many", "NLP", "pipelines", "split", "text", "into", "sentences", "as", "one", "of", "the", "crucial", "preprocessing", "steps.", "Prior", "sentence", "segmentation", "tools", "either", "rely", "on", "punctuation", "or", "require", "a", "considerable", "amount", "of", "sentence-segmented", "training", "data:", "both", "central", "assumptions", "might", "fail", "when", "porting", "sentence", "segmenters", "to", "diverse", "languages", "on", "a", "massive", "scale."], "pieces": ["Many", "N", "LP", "p", "ip", "elines", "split", "text", "into", "sent", "ences", "as", "one", "of", "the", "cru", "cial", "pre", "processing", "steps", ".", "Prior", "sent", "ence", "se", "gment", "ation", "tools", "either", "rely", "on", "p", "unct", "uation", "or", "require", "a", "consider", "able", "amount", "of", "sent", "ence", "-", "se", "gment", "ed", "training", "data", ":", "both", "central", "ass", "um", "ptions", "might", "fail", "when", "porting", "sent", "ence", "se", "gment", "ers", "to", "d", "iverse", "l", "anguages", "on", "a", "massive", "scale", "."], "token_lens": [1, 2, 3, 1, 1, 1, 2, 1, 1, 1, 1, 2, 2, 2, 1, 2, 3, 1, 1, 1, 1, 3, 1, 1, 1, 2, 1, 1, 6, 1, 2, 1, 1, 3, 1, 1, 1, 1, 2, 3, 1, 2, 2, 1, 1, 1, 2], "sentence": "Many NLP pipelines split text into sentences as one of the crucial preprocessing steps. Prior sentence segmentation tools either rely on punctuation or require a considerable amount of sentence-segmented training data: both central assumptions might fail when porting sentence segmenters to diverse languages on a massive scale.", "sentence_starts": [0]}
{"doc_id": "ACL_23_P_398", "wnd_id": "ACL_23_P_398-1", "entity_mentions": [{"id": "ACL_23_P_398-1-E0", "text": "we", "start": 3, "end": 4, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_398-1-E1", "text": "making use of newline characters which implicitly perform segmentation into paragraphs", "start": 25, "end": 36, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_398-1-E2", "text": "We further propose an approach that adapts our method to the segmentation in a given corpus by using only a small number (64-256) of sentence-segmented examples", "start": 36, "end": 62, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_398-1-E3", "text": "a multilingual punctuation-agnostic sentence segmentation method", "start": 6, "end": 12, "entity_type": "UNK", "mention_type": "UNK"}], "relation_mentions": [], "event_mentions": [{"event_type": "Methods/Approach", "id": "ACL_23_P_398-1-EV0", "trigger": {"text": "introduce", "start": 5, "end": 6}, "arguments": [{"entity_id": "ACL_23_P_398-1-E0", "text": "we", "role": "Agent"}, {"entity_id": "ACL_23_P_398-1-E1", "text": "making use of newline characters which implicitly perform segmentation into paragraphs", "role": "Method"}, {"entity_id": "ACL_23_P_398-1-E2", "text": "We further propose an approach that adapts our method to the segmentation in a given corpus by using only a small number (64-256) of sentence-segmented examples", "role": "Method"}, {"entity_id": "ACL_23_P_398-1-E3", "text": "a multilingual punctuation-agnostic sentence segmentation method", "role": "PrimaryObject"}]}], "entity_coreference": [], "event_coreference": [], "tokens": ["In", "this", "work,", "we", "thus", "introduce", "a", "multilingual", "punctuation-agnostic", "sentence", "segmentation", "method,", "currently", "covering", "85", "languages,", "trained", "in", "a", "self-supervised", "fashion", "on", "unsegmented", "text,", "by", "making", "use", "of", "newline", "characters", "which", "implicitly", "perform", "segmentation", "into", "paragraphs.", "We", "further", "propose", "an", "approach", "that", "adapts", "our", "method", "to", "the", "segmentation", "in", "a", "given", "corpus", "by", "using", "only", "a", "small", "number", "(64-256)", "of", "sentence-segmented", "examples."], "pieces": ["In", "this", "work", ",", "we", "thus", "introdu", "ce", "a", "mult", "ilingual", "p", "unct", "uation", "-", "agn", "ostic", "sent", "ence", "se", "gment", "ation", "method", ",", "currently", "cover", "ing", "85", "l", "anguages", ",", "trained", "in", "a", "self", "-", "super", "vised", "fashion", "on", "un", "se", "gment", "ed", "text", ",", "by", "making", "use", "of", "new", "line", "char", "acters", "which", "impl", "icit", "ly", "per", "form", "se", "gment", "ation", "into", "paragraph", "s", ".", "We", "f", "urther", "pro", "pose", "an", "appro", "ach", "that", "adapt", "s", "our", "method", "to", "the", "se", "gment", "ation", "in", "a", "given", "cor", "p", "us", "by", "using", "only", "a", "small", "number", "(", "64", "-", "256", ")", "of", "sent", "ence", "-", "se", "gment", "ed", "ex", "amples", "."], "token_lens": [1, 1, 2, 1, 1, 2, 1, 2, 6, 2, 3, 2, 1, 2, 1, 3, 1, 1, 1, 4, 1, 1, 4, 2, 1, 1, 1, 1, 2, 2, 1, 3, 2, 3, 1, 3, 1, 2, 2, 1, 2, 1, 2, 1, 1, 1, 1, 3, 1, 1, 1, 3, 1, 1, 1, 1, 1, 1, 5, 1, 6, 3], "sentence": "In this work, we thus introduce a multilingual punctuation-agnostic sentence segmentation method, currently covering 85 languages, trained in a self-supervised fashion on unsegmented text, by making use of newline characters which implicitly perform segmentation into paragraphs. We further propose an approach that adapts our method to the segmentation in a given corpus by using only a small number (64-256) of sentence-segmented examples.", "sentence_starts": [0]}
{"doc_id": "ACL_23_P_398", "wnd_id": "ACL_23_P_398-2", "entity_mentions": [{"id": "ACL_23_P_398-2-E0", "text": "main results", "start": 1, "end": 3, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_398-2-E1", "text": "By using our method to match sentence segmentation to the segmentation used during training of MT models", "start": 51, "end": 68, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_398-2-E2", "text": "Furthermore, we demonstrate that proper sentence segmentation has a point: the use of a (powerful) sentence segmenter makes a considerable difference for a downstream application such as machine translation (MT)", "start": 21, "end": 51, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_398-2-E3", "text": "we achieve an average improvement of 2.3 BLEU points over the best prior segmentation tool, as well as massive gains over a trivial segmenter that splits text into equally-sized blocks", "start": 68, "end": 98, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_398-2-E4", "text": "our method outperforms all the prior best sentence-segmentation tools by an average of 6.1% F1 points", "start": 5, "end": 21, "entity_type": "UNK", "mention_type": "UNK"}], "relation_mentions": [], "event_mentions": [{"event_type": "Results/Findings", "id": "ACL_23_P_398-2-EV0", "trigger": {"text": "indicate", "start": 3, "end": 4}, "arguments": [{"entity_id": "ACL_23_P_398-2-E0", "text": "main results", "role": "Agent"}, {"entity_id": "ACL_23_P_398-2-E1", "text": "By using our method to match sentence segmentation to the segmentation used during training of MT models", "role": "Method"}, {"entity_id": "ACL_23_P_398-2-E2", "text": "Furthermore, we demonstrate that proper sentence segmentation has a point: the use of a (powerful) sentence segmenter makes a considerable difference for a downstream application such as machine translation (MT)", "role": "Results"}, {"entity_id": "ACL_23_P_398-2-E3", "text": "we achieve an average improvement of 2.3 BLEU points over the best prior segmentation tool, as well as massive gains over a trivial segmenter that splits text into equally-sized blocks", "role": "Results"}, {"entity_id": "ACL_23_P_398-2-E4", "text": "our method outperforms all the prior best sentence-segmentation tools by an average of 6.1% F1 points", "role": "PrimaryObject"}]}], "entity_coreference": [], "event_coreference": [], "tokens": ["The", "main", "results", "indicate", "that", "our", "method", "outperforms", "all", "the", "prior", "best", "sentence-segmentation", "tools", "by", "an", "average", "of", "6.1%", "F1", "points.", "Furthermore,", "we", "demonstrate", "that", "proper", "sentence", "segmentation", "has", "a", "point:", "the", "use", "of", "a", "(powerful)", "sentence", "segmenter", "makes", "a", "considerable", "difference", "for", "a", "downstream", "application", "such", "as", "machine", "translation", "(MT).", "By", "using", "our", "method", "to", "match", "sentence", "segmentation", "to", "the", "segmentation", "used", "during", "training", "of", "MT", "models,", "we", "achieve", "an", "average", "improvement", "of", "2.3", "BLEU", "points", "over", "the", "best", "prior", "segmentation", "tool,", "as", "well", "as", "massive", "gains", "over", "a", "trivial", "segmenter", "that", "splits", "text", "into", "equally-sized", "blocks."], "pieces": ["The", "main", "results", "ind", "icate", "that", "our", "method", "out", "per", "forms", "all", "the", "pri", "or", "best", "sent", "ence", "-", "se", "gment", "ation", "tools", "by", "an", "average", "of", "6", ".", "1", "%", "F", "1", "points", ".", "Furthermore", ",", "we", "demon", "strate", "that", "pro", "per", "sent", "ence", "se", "gment", "ation", "has", "a", "point", ":", "the", "use", "of", "a", "(", "powerful", ")", "sent", "ence", "se", "gment", "er", "makes", "a", "consider", "able", "diff", "erence", "for", "a", "down", "stream", "application", "such", "as", "machine", "translation", "(", "MT", ").", "By", "using", "our", "method", "to", "match", "sent", "ence", "se", "gment", "ation", "to", "the", "se", "gment", "ation", "used", "during", "training", "of", "MT", "models", ",", "we", "ach", "ieve", "an", "average", "improve", "ment", "of", "2", ".", "3", "BLE", "U", "points", "over", "the", "best", "pri", "or", "se", "gment", "ation", "tool", ",", "as", "well", "as", "massive", "g", "ains", "over", "a", "t", "riv", "ial", "se", "gment", "er", "that", "spl", "its", "text", "into", "equ", "ally", "-", "sized", "blocks", "."], "token_lens": [1, 1, 1, 2, 1, 1, 1, 3, 1, 1, 2, 1, 6, 1, 1, 1, 1, 1, 4, 2, 2, 2, 1, 2, 1, 2, 2, 3, 1, 1, 2, 1, 1, 1, 1, 3, 2, 3, 1, 1, 2, 2, 1, 1, 2, 1, 1, 1, 1, 1, 3, 1, 1, 1, 1, 1, 1, 2, 3, 1, 1, 3, 1, 1, 1, 1, 1, 2, 1, 2, 1, 1, 2, 1, 3, 2, 1, 1, 1, 1, 2, 3, 2, 1, 1, 1, 1, 2, 1, 1, 3, 3, 1, 2, 1, 1, 4, 2], "sentence": "The main results indicate that our method outperforms all the prior best sentence-segmentation tools by an average of 6.1% F1 points. Furthermore, we demonstrate that proper sentence segmentation has a point: the use of a (powerful) sentence segmenter makes a considerable difference for a downstream application such as machine translation (MT). By using our method to match sentence segmentation to the segmentation used during training of MT models, we achieve an average improvement of 2.3 BLEU points over the best prior segmentation tool, as well as massive gains over a trivial segmenter that splits text into equally-sized blocks.", "sentence_starts": [0]}
{"doc_id": "ACL_23_P_67", "wnd_id": "ACL_23_P_67-0", "entity_mentions": [{"id": "ACL_23_P_67-0-E0", "text": "Unsupervised speech recognition (ASR-U)", "start": 0, "end": 4, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_67-0-E1", "text": "While various algorithms exist to solve this problem", "start": 20, "end": 28, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_67-0-E2", "text": "a theoretical framework is missing to study their properties and address such issues as sensitivity to hyperparameters and training instability", "start": 28, "end": 48, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_67-0-E3", "text": "problem of learning automatic speech recognition (ASR) systems", "start": 6, "end": 14, "entity_type": "UNK", "mention_type": "UNK"}], "relation_mentions": [], "event_mentions": [{"event_type": "Background/Introduction", "id": "ACL_23_P_67-0-EV0", "trigger": {"text": "is", "start": 4, "end": 5}, "arguments": [{"entity_id": "ACL_23_P_67-0-E0", "text": "Unsupervised speech recognition (ASR-U)", "role": "Agent"}, {"entity_id": "ACL_23_P_67-0-E1", "text": "While various algorithms exist to solve this problem", "role": "Context"}, {"entity_id": "ACL_23_P_67-0-E2", "text": "a theoretical framework is missing to study their properties and address such issues as sensitivity to hyperparameters and training instability", "role": "Challenge"}, {"entity_id": "ACL_23_P_67-0-E3", "text": "problem of learning automatic speech recognition (ASR) systems", "role": "PrimaryObject"}]}], "entity_coreference": [], "event_coreference": [], "tokens": ["Unsupervised", "speech", "recognition", "(ASR-U)", "is", "the", "problem", "of", "learning", "automatic", "speech", "recognition", "(ASR)", "systems", "from", "unpaired", "speech-only", "and", "text-only", "corpora.", "While", "various", "algorithms", "exist", "to", "solve", "this", "problem,", "a", "theoretical", "framework", "is", "missing", "to", "study", "their", "properties", "and", "address", "such", "issues", "as", "sensitivity", "to", "hyperparameters", "and", "training", "instability."], "pieces": ["Un", "super", "vised", "speech", "recogn", "ition", "(", "AS", "R", "-", "U", ")", "is", "the", "problem", "of", "learning", "automatic", "speech", "recogn", "ition", "(", "AS", "R", ")", "system", "s", "from", "un", "pa", "ired", "speech", "-", "only", "and", "text", "-", "only", "cor", "pora", ".", "While", "var", "ious", "al", "gorith", "ms", "exist", "to", "s", "olve", "this", "problem", ",", "a", "the", "oret", "ical", "framework", "is", "missing", "to", "study", "their", "properties", "and", "address", "such", "issues", "as", "s", "ensitivity", "to", "hyper", "param", "eters", "and", "training", "inst", "ability", "."], "token_lens": [3, 1, 2, 6, 1, 1, 1, 1, 1, 1, 1, 2, 4, 2, 1, 3, 3, 1, 3, 3, 1, 2, 3, 1, 1, 2, 1, 2, 1, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 3, 1, 1, 3], "sentence": "Unsupervised speech recognition (ASR-U) is the problem of learning automatic speech recognition (ASR) systems from unpaired speech-only and text-only corpora. While various algorithms exist to solve this problem, a theoretical framework is missing to study their properties and address such issues as sensitivity to hyperparameters and training instability.", "sentence_starts": [0]}
{"doc_id": "ACL_23_P_67", "wnd_id": "ACL_23_P_67-1", "entity_mentions": [{"id": "ACL_23_P_67-1-E0", "text": "we", "start": 3, "end": 4, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_67-1-E1", "text": "to study the properties of ASR-U systems based on random matrix theory and the theory of neural tangent kernels", "start": 9, "end": 28, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_67-1-E2", "text": "Such a framework allows us to prove various learnability conditions and sample complexity bounds of ASR-U", "start": 28, "end": 44, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_67-1-E3", "text": "a general theoretical framework", "start": 5, "end": 9, "entity_type": "UNK", "mention_type": "UNK"}], "relation_mentions": [], "event_mentions": [{"event_type": "Methods/Approach", "id": "ACL_23_P_67-1-EV0", "trigger": {"text": "proposed", "start": 4, "end": 5}, "arguments": [{"entity_id": "ACL_23_P_67-1-E0", "text": "we", "role": "Agent"}, {"entity_id": "ACL_23_P_67-1-E1", "text": "to study the properties of ASR-U systems based on random matrix theory and the theory of neural tangent kernels", "role": "Purpose"}, {"entity_id": "ACL_23_P_67-1-E2", "text": "Such a framework allows us to prove various learnability conditions and sample complexity bounds of ASR-U", "role": "Results"}, {"entity_id": "ACL_23_P_67-1-E3", "text": "a general theoretical framework", "role": "PrimaryObject"}]}], "entity_coreference": [], "event_coreference": [], "tokens": ["In", "this", "paper,", "we", "proposed", "a", "general", "theoretical", "framework", "to", "study", "the", "properties", "of", "ASR-U", "systems", "based", "on", "random", "matrix", "theory", "and", "the", "theory", "of", "neural", "tangent", "kernels.", "Such", "a", "framework", "allows", "us", "to", "prove", "various", "learnability", "conditions", "and", "sample", "complexity", "bounds", "of", "ASR-U."], "pieces": ["In", "this", "paper", ",", "we", "prop", "osed", "a", "general", "the", "oret", "ical", "framework", "to", "study", "the", "properties", "of", "AS", "R", "-", "U", "system", "s", "based", "on", "random", "mat", "rix", "the", "ory", "and", "the", "the", "ory", "of", "ne", "ural", "t", "ang", "ent", "k", "ernels", ".", "Such", "a", "framework", "allows", "us", "to", "pro", "ve", "var", "ious", "learn", "ability", "cond", "itions", "and", "sample", "complex", "ity", "b", "ounds", "of", "AS", "R", "-", "U", "."], "token_lens": [1, 1, 2, 1, 2, 1, 1, 3, 1, 1, 1, 1, 1, 1, 4, 2, 1, 1, 1, 2, 2, 1, 1, 2, 1, 2, 3, 3, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 1, 1, 2, 2, 1, 5], "sentence": "In this paper, we proposed a general theoretical framework to study the properties of ASR-U systems based on random matrix theory and the theory of neural tangent kernels. Such a framework allows us to prove various learnability conditions and sample complexity bounds of ASR-U.", "sentence_starts": [0]}
{"doc_id": "ACL_23_P_67", "wnd_id": "ACL_23_P_67-2", "entity_mentions": [{"id": "ACL_23_P_67-2-E0", "text": "Extensive ASR-U experiments", "start": 0, "end": 3, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_67-2-E1", "text": "strong empirical evidence", "start": 13, "end": 16, "entity_type": "UNK", "mention_type": "UNK"}], "relation_mentions": [], "event_mentions": [{"event_type": "Results/Findings", "id": "ACL_23_P_67-2-EV0", "trigger": {"text": "provide", "start": 12, "end": 13}, "arguments": [{"entity_id": "ACL_23_P_67-2-E0", "text": "Extensive ASR-U experiments", "role": "Agent"}, {"entity_id": "ACL_23_P_67-2-E1", "text": "strong empirical evidence", "role": "PrimaryObject"}]}], "entity_coreference": [], "event_coreference": [], "tokens": ["Extensive", "ASR-U", "experiments", "on", "synthetic", "languages", "with", "three", "classes", "of", "transition", "graphs", "provide", "strong", "empirical", "evidence", "for", "our", "theory."], "pieces": ["Ext", "ensive", "AS", "R", "-", "U", "exper", "iments", "on", "sy", "nt", "hetic", "l", "anguages", "with", "three", "classes", "of", "trans", "ition", "graph", "s", "prov", "ide", "strong", "em", "pir", "ical", "evidence", "for", "our", "the", "ory", "."], "token_lens": [2, 4, 2, 1, 3, 2, 1, 1, 1, 1, 2, 2, 2, 1, 3, 1, 1, 1, 3], "sentence": "Extensive ASR-U experiments on synthetic languages with three classes of transition graphs provide strong empirical evidence for our theory.", "sentence_starts": [0]}
{"doc_id": "ACL_23_P_34", "wnd_id": "ACL_23_P_34-0", "entity_mentions": [{"id": "ACL_23_P_34-0-E0", "text": "Large language models (LLMs)", "start": 0, "end": 4, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_34-0-E1", "text": "creating high-quality datasets with LLMs can be challenging.", "start": 18, "end": 26, "entity_type": "UNK", "mention_type": "UNK"}], "relation_mentions": [], "event_mentions": [{"event_type": "Background/Introduction", "id": "ACL_23_P_34-0-EV0", "trigger": {"text": "can be used", "start": 4, "end": 7}, "arguments": [{"entity_id": "ACL_23_P_34-0-E0", "text": "Large language models (LLMs)", "role": "Agent"}, {"entity_id": "ACL_23_P_34-0-E1", "text": "creating high-quality datasets with LLMs can be challenging.", "role": "Challenge"}]}], "entity_coreference": [], "event_coreference": [], "tokens": ["Large", "language", "models", "(LLMs)", "can", "be", "used", "to", "generate", "text", "data", "for", "training", "and", "evaluating", "other", "models.", "However,", "creating", "high-quality", "datasets", "with", "LLMs", "can", "be", "challenging."], "pieces": ["Large", "language", "models", "(", "LL", "Ms", ")", "can", "be", "used", "to", "gener", "ate", "text", "data", "for", "training", "and", "eval", "uating", "other", "models", ".", "However", ",", "creat", "ing", "high", "-", "quality", "dat", "as", "ets", "with", "LL", "Ms", "can", "be", "chall", "eng", "ing", "."], "token_lens": [1, 1, 1, 4, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 2, 1, 2, 2, 2, 3, 3, 1, 2, 1, 1, 4], "sentence": "Large language models (LLMs) can be used to generate text data for training and evaluating other models. However, creating high-quality datasets with LLMs can be challenging.", "sentence_starts": [0]}
{"doc_id": "ACL_23_P_34", "wnd_id": "ACL_23_P_34-1", "entity_mentions": [{"id": "ACL_23_P_34-1-E0", "text": "we", "start": 3, "end": 4, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_34-1-E1", "text": "logit suppression, which minimizes the generation of languages that have already been frequently generated", "start": 28, "end": 42, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_34-1-E2", "text": "temperature sampling, which flattens the token sampling probability", "start": 44, "end": 52, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_34-1-E3", "text": "we examined two human interventions, 1) label replacement (LR), correcting misaligned labels, and 2) out-of-scope filtering (OOSF), removing instances that are out of the user\u2019s domain of interest or to which no considered label applies", "start": 83, "end": 118, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_34-1-E4", "text": "We found that diversification approaches can increase data diversity but often at the cost of data accuracy (i.e., text and labels being appropriate for the target domain)", "start": 52, "end": 79, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_34-1-E5", "text": "human-AI partnerships", "start": 5, "end": 7, "entity_type": "UNK", "mention_type": "UNK"}], "relation_mentions": [], "event_mentions": [{"event_type": "Methods/Approach", "id": "ACL_23_P_34-1-EV0", "trigger": {"text": "explore", "start": 4, "end": 5}, "arguments": [{"entity_id": "ACL_23_P_34-1-E0", "text": "we", "role": "Agent"}, {"entity_id": "ACL_23_P_34-1-E1", "text": "logit suppression, which minimizes the generation of languages that have already been frequently generated", "role": "Method"}, {"entity_id": "ACL_23_P_34-1-E2", "text": "temperature sampling, which flattens the token sampling probability", "role": "Method"}, {"entity_id": "ACL_23_P_34-1-E3", "text": "we examined two human interventions, 1) label replacement (LR), correcting misaligned labels, and 2) out-of-scope filtering (OOSF), removing instances that are out of the user\u2019s domain of interest or to which no considered label applies", "role": "Method"}, {"entity_id": "ACL_23_P_34-1-E4", "text": "We found that diversification approaches can increase data diversity but often at the cost of data accuracy (i.e., text and labels being appropriate for the target domain)", "role": "Results"}, {"entity_id": "ACL_23_P_34-1-E5", "text": "human-AI partnerships", "role": "PrimaryObject"}]}], "entity_coreference": [], "event_coreference": [], "tokens": ["In", "this", "work,", "we", "explore", "human-AI", "partnerships", "to", "facilitate", "high", "diversity", "and", "accuracy", "in", "LLM-based", "text", "data", "generation.", "We", "first", "examine", "two", "approaches", "to", "diversify", "text", "generation:", "1)", "logit", "suppression,", "which", "minimizes", "the", "generation", "of", "languages", "that", "have", "already", "been", "frequently", "generated,", "and", "2)", "temperature", "sampling,", "which", "flattens", "the", "token", "sampling", "probability.", "We", "found", "that", "diversification", "approaches", "can", "increase", "data", "diversity", "but", "often", "at", "the", "cost", "of", "data", "accuracy", "(i.e.,", "text", "and", "labels", "being", "appropriate", "for", "the", "target", "domain).", "To", "address", "this", "issue,", "we", "examined", "two", "human", "interventions,", "1)", "label", "replacement", "(LR),", "correcting", "misaligned", "labels,", "and", "2)", "out-of-scope", "filtering", "(OOSF),", "removing", "instances", "that", "are", "out", "of", "the", "user\u2019s", "domain", "of", "interest", "or", "to", "which", "no", "considered", "label", "applies."], "pieces": ["In", "this", "work", ",", "we", "expl", "ore", "human", "-", "AI", "part", "ners", "hips", "to", "fac", "ilit", "ate", "high", "d", "iversity", "and", "acc", "uracy", "in", "LL", "M", "-", "based", "text", "data", "generation", ".", "We", "first", "ex", "amine", "two", "appro", "aches", "to", "d", "ivers", "ify", "text", "generation", ":", "1", ")", "log", "it", "supp", "ression", ",", "which", "min", "im", "izes", "the", "generation", "of", "l", "anguages", "that", "have", "al", "ready", "been", "f", "requently", "generated", ",", "and", "2", ")", "tem", "perature", "sam", "pling", ",", "which", "fl", "att", "ens", "the", "token", "sam", "pling", "pro", "b", "ability", ".", "We", "found", "that", "d", "ivers", "ification", "appro", "aches", "can", "incre", "ase", "data", "d", "iversity", "but", "often", "at", "the", "cost", "of", "data", "acc", "uracy", "(", "i", ".", "e", ".,", "text", "and", "lab", "els", "being", "appropriate", "for", "the", "target", "domain", ").", "To", "address", "this", "issue", ",", "we", "ex", "am", "ined", "two", "human", "inter", "ventions", ",", "1", ")", "label", "repl", "acement", "(", "LR", "),", "correct", "ing", "mis", "aligned", "lab", "els", ",", "and", "2", ")", "out", "-", "of", "-", "scope", "fil", "tering", "(", "O", "OS", "F", "),", "rem", "oving", "inst", "ances", "that", "are", "out", "of", "the", "user", "\u00e2\u0122", "\u013b", "s", "domain", "of", "interest", "or", "to", "which", "no", "cons", "idered", "label", "app", "lies", "."], "token_lens": [1, 1, 2, 1, 2, 3, 3, 1, 3, 1, 2, 1, 2, 1, 4, 1, 1, 2, 1, 1, 2, 1, 2, 1, 3, 1, 2, 2, 2, 3, 1, 3, 1, 1, 1, 2, 1, 1, 2, 1, 2, 2, 1, 2, 2, 3, 1, 3, 1, 1, 2, 4, 1, 1, 1, 3, 2, 1, 2, 1, 2, 1, 1, 1, 1, 1, 1, 1, 2, 5, 1, 1, 2, 1, 1, 1, 1, 1, 2, 1, 1, 1, 2, 1, 3, 1, 1, 3, 2, 1, 2, 3, 2, 2, 3, 1, 2, 5, 2, 5, 2, 2, 1, 1, 1, 1, 1, 4, 1, 1, 1, 1, 1, 1, 1, 2, 1, 3], "sentence": "In this work, we explore human-AI partnerships to facilitate high diversity and accuracy in LLM-based text data generation. We first examine two approaches to diversify text generation: 1) logit suppression, which minimizes the generation of languages that have already been frequently generated, and 2) temperature sampling, which flattens the token sampling probability. We found that diversification approaches can increase data diversity but often at the cost of data accuracy (i.e., text and labels being appropriate for the target domain). To address this issue, we examined two human interventions, 1) label replacement (LR), correcting misaligned labels, and 2) out-of-scope filtering (OOSF), removing instances that are out of the user\u2019s domain of interest or to which no considered label applies.", "sentence_starts": [0]}
{"doc_id": "ACL_23_P_34", "wnd_id": "ACL_23_P_34-2", "entity_mentions": [{"id": "ACL_23_P_34-2-E0", "text": "we", "start": 3, "end": 4, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_34-2-E1", "text": "we found that some models trained with data generated with LR interventions outperformed LLM-based few-shot classification", "start": 20, "end": 36, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_34-2-E2", "text": "In contrast, OOSF was not effective in increasing model accuracy", "start": 36, "end": 46, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_34-2-E3", "text": "the need for future work in human-in-the-loop text data generation", "start": 47, "end": 57, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_34-2-E4", "text": "LR increases the absolute accuracy of models trained with diversified datasets by 14.4%", "start": 6, "end": 19, "entity_type": "UNK", "mention_type": "UNK"}], "relation_mentions": [], "event_mentions": [{"event_type": "Results/Findings", "id": "ACL_23_P_34-2-EV0", "trigger": {"text": "found", "start": 4, "end": 5}, "arguments": [{"entity_id": "ACL_23_P_34-2-E0", "text": "we", "role": "Agent"}, {"entity_id": "ACL_23_P_34-2-E1", "text": "we found that some models trained with data generated with LR interventions outperformed LLM-based few-shot classification", "role": "Results"}, {"entity_id": "ACL_23_P_34-2-E2", "text": "In contrast, OOSF was not effective in increasing model accuracy", "role": "Results"}, {"entity_id": "ACL_23_P_34-2-E3", "text": "the need for future work in human-in-the-loop text data generation", "role": "Implications"}, {"entity_id": "ACL_23_P_34-2-E4", "text": "LR increases the absolute accuracy of models trained with diversified datasets by 14.4%", "role": "PrimaryObject"}]}], "entity_coreference": [], "event_coreference": [], "tokens": ["With", "oracle", "studies,", "we", "found", "that", "LR", "increases", "the", "absolute", "accuracy", "of", "models", "trained", "with", "diversified", "datasets", "by", "14.4%.", "Moreover,", "we", "found", "that", "some", "models", "trained", "with", "data", "generated", "with", "LR", "interventions", "outperformed", "LLM-based", "few-shot", "classification.", "In", "contrast,", "OOSF", "was", "not", "effective", "in", "increasing", "model", "accuracy,", "implying", "the", "need", "for", "future", "work", "in", "human-in-the-loop", "text", "data", "generation."], "pieces": ["With", "or", "acle", "stud", "ies", ",", "we", "found", "that", "LR", "incre", "ases", "the", "absolute", "acc", "uracy", "of", "models", "trained", "with", "d", "ivers", "ified", "dat", "as", "ets", "by", "14", ".", "4", "%.", "Moreover", ",", "we", "found", "that", "some", "models", "trained", "with", "data", "generated", "with", "LR", "inter", "ventions", "out", "per", "formed", "LL", "M", "-", "based", "few", "-", "shot", "class", "ification", ".", "In", "cont", "rast", ",", "O", "OS", "F", "was", "not", "effective", "in", "increasing", "model", "acc", "uracy", ",", "im", "ply", "ing", "the", "need", "for", "future", "work", "in", "human", "-", "in", "-", "the", "-", "loop", "text", "data", "generation", "."], "token_lens": [1, 2, 3, 1, 1, 1, 1, 2, 1, 1, 2, 1, 1, 1, 1, 3, 3, 1, 4, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 3, 4, 3, 3, 1, 3, 3, 1, 1, 1, 1, 1, 1, 3, 3, 1, 1, 1, 1, 1, 1, 7, 1, 1, 2], "sentence": "With oracle studies, we found that LR increases the absolute accuracy of models trained with diversified datasets by 14.4%. Moreover, we found that some models trained with data generated with LR interventions outperformed LLM-based few-shot classification. In contrast, OOSF was not effective in increasing model accuracy, implying the need for future work in human-in-the-loop text data generation.", "sentence_starts": [0]}
{"doc_id": "ACL_23_P_823", "wnd_id": "ACL_23_P_823-0", "entity_mentions": [{"id": "ACL_23_P_823-0-E0", "text": "Existing research on multimodal relation extraction (MRE)", "start": 0, "end": 7, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_823-0-E1", "text": "internal-information over-utilization and external-information under-exploitation", "start": 11, "end": 16, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_823-0-E2", "text": "two co-existing challenges", "start": 8, "end": 11, "entity_type": "UNK", "mention_type": "UNK"}], "relation_mentions": [], "event_mentions": [{"event_type": "Background/Introduction", "id": "ACL_23_P_823-0-EV0", "trigger": {"text": "faces", "start": 7, "end": 8}, "arguments": [{"entity_id": "ACL_23_P_823-0-E0", "text": "Existing research on multimodal relation extraction (MRE)", "role": "Agent"}, {"entity_id": "ACL_23_P_823-0-E1", "text": "internal-information over-utilization and external-information under-exploitation", "role": "Challenge"}, {"entity_id": "ACL_23_P_823-0-E2", "text": "two co-existing challenges", "role": "PrimaryObject"}]}], "entity_coreference": [], "event_coreference": [], "tokens": ["Existing", "research", "on", "multimodal", "relation", "extraction", "(MRE)", "faces", "two", "co-existing", "challenges,", "internal-information", "over-utilization", "and", "external-information", "under-exploitation."], "pieces": ["Ex", "isting", "research", "on", "mult", "im", "od", "al", "relation", "ext", "raction", "(", "M", "RE", ")", "faces", "two", "co", "-", "existing", "chall", "enges", ",", "internal", "-", "information", "over", "-", "util", "ization", "and", "external", "-", "information", "under", "-", "expl", "o", "itation", "."], "token_lens": [2, 1, 1, 4, 1, 2, 4, 1, 1, 3, 3, 3, 4, 1, 3, 6], "sentence": "Existing research on multimodal relation extraction (MRE) faces two co-existing challenges, internal-information over-utilization and external-information under-exploitation.", "sentence_starts": [0]}
{"doc_id": "ACL_23_P_823", "wnd_id": "ACL_23_P_823-1", "entity_mentions": [{"id": "ACL_23_P_823-1-E0", "text": "we", "start": 3, "end": 4, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_823-1-E1", "text": "we represent the fine-grained semantic structures of the input image and text with the visual and textual scene graphs, which are further fused into a unified cross-modal graph (CMG)", "start": 20, "end": 49, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_823-1-E2", "text": "Based on CMG, we perform structure refinement with the guidance of the graph information bottleneck principle, actively denoising the less-informative features", "start": 49, "end": 70, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_823-1-E3", "text": "we perform topic modeling over the input image and text, incorporating latent multimodal topic features to enrich the contexts", "start": 71, "end": 90, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_823-1-E4", "text": "a novel framework", "start": 5, "end": 8, "entity_type": "UNK", "mention_type": "UNK"}], "relation_mentions": [], "event_mentions": [{"event_type": "Methods/Approach", "id": "ACL_23_P_823-1-EV0", "trigger": {"text": "propose", "start": 4, "end": 5}, "arguments": [{"entity_id": "ACL_23_P_823-1-E0", "text": "we", "role": "Agent"}, {"entity_id": "ACL_23_P_823-1-E1", "text": "we represent the fine-grained semantic structures of the input image and text with the visual and textual scene graphs, which are further fused into a unified cross-modal graph (CMG)", "role": "Method"}, {"entity_id": "ACL_23_P_823-1-E2", "text": "Based on CMG, we perform structure refinement with the guidance of the graph information bottleneck principle, actively denoising the less-informative features", "role": "Method"}, {"entity_id": "ACL_23_P_823-1-E3", "text": "we perform topic modeling over the input image and text, incorporating latent multimodal topic features to enrich the contexts", "role": "Method"}, {"entity_id": "ACL_23_P_823-1-E4", "text": "a novel framework", "role": "PrimaryObject"}]}], "entity_coreference": [], "event_coreference": [], "tokens": ["To", "combat", "that,", "we", "propose", "a", "novel", "framework", "that", "simultaneously", "implements", "the", "idea", "of", "internal-information", "screening", "and", "external-information", "exploiting.", "First,", "we", "represent", "the", "fine-grained", "semantic", "structures", "of", "the", "input", "image", "and", "text", "with", "the", "visual", "and", "textual", "scene", "graphs,", "which", "are", "further", "fused", "into", "a", "unified", "cross-modal", "graph", "(CMG).", "Based", "on", "CMG,", "we", "perform", "structure", "refinement", "with", "the", "guidance", "of", "the", "graph", "information", "bottleneck", "principle,", "actively", "denoising", "the", "less-informative", "features.", "Next,", "we", "perform", "topic", "modeling", "over", "the", "input", "image", "and", "text,", "incorporating", "latent", "multimodal", "topic", "features", "to", "enrich", "the", "contexts."], "pieces": ["To", "combat", "that", ",", "we", "pro", "pose", "a", "no", "vel", "framework", "that", "sim", "ultane", "ously", "im", "ple", "ments", "the", "ide", "a", "of", "internal", "-", "information", "screen", "ing", "and", "external", "-", "information", "expl", "o", "iting", ".", "First", ",", "we", "represent", "the", "fine", "-", "gr", "ained", "sem", "antic", "struct", "ures", "of", "the", "input", "image", "and", "text", "with", "the", "visual", "and", "text", "ual", "scene", "graph", "s", ",", "which", "are", "f", "urther", "f", "used", "into", "a", "un", "ified", "cross", "-", "mod", "al", "graph", "(", "C", "MG", ").", "Based", "on", "C", "MG", ",", "we", "per", "form", "st", "ructure", "ref", "inement", "with", "the", "gu", "id", "ance", "of", "the", "graph", "information", "bott", "leneck", "pr", "inc", "iple", ",", "actively", "den", "o", "ising", "the", "less", "-", "in", "form", "ative", "features", ".", "Next", ",", "we", "per", "form", "topic", "mod", "eling", "over", "the", "input", "image", "and", "text", ",", "inc", "orpor", "ating", "lat", "ent", "mult", "im", "od", "al", "topic", "features", "to", "en", "rich", "the", "context", "s", "."], "token_lens": [1, 1, 2, 1, 2, 1, 2, 1, 1, 3, 3, 1, 2, 1, 3, 2, 1, 3, 4, 2, 1, 1, 1, 4, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 3, 1, 1, 2, 2, 1, 1, 2, 4, 1, 4, 1, 1, 3, 1, 2, 2, 2, 1, 1, 3, 1, 1, 1, 1, 2, 4, 1, 3, 1, 5, 2, 2, 1, 2, 1, 2, 1, 1, 1, 1, 1, 2, 3, 2, 4, 1, 1, 1, 2, 1, 3], "sentence": "To combat that, we propose a novel framework that simultaneously implements the idea of internal-information screening and external-information exploiting. First, we represent the fine-grained semantic structures of the input image and text with the visual and textual scene graphs, which are further fused into a unified cross-modal graph (CMG). Based on CMG, we perform structure refinement with the guidance of the graph information bottleneck principle, actively denoising the less-informative features. Next, we perform topic modeling over the input image and text, incorporating latent multimodal topic features to enrich the contexts.", "sentence_starts": [0]}
{"doc_id": "ACL_23_P_823", "wnd_id": "ACL_23_P_823-2", "entity_mentions": [{"id": "ACL_23_P_823-2-E0", "text": "our system", "start": 5, "end": 7, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_823-2-E1", "text": "With further in-depth analyses, we reveal the great potential of our method for the MRE task", "start": 13, "end": 29, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_823-2-E2", "text": "the current best model", "start": 8, "end": 12, "entity_type": "UNK", "mention_type": "UNK"}], "relation_mentions": [], "event_mentions": [{"event_type": "Results/Findings", "id": "ACL_23_P_823-2-EV0", "trigger": {"text": "outperforms", "start": 7, "end": 8}, "arguments": [{"entity_id": "ACL_23_P_823-2-E0", "text": "our system", "role": "Agent"}, {"entity_id": "ACL_23_P_823-2-E1", "text": "With further in-depth analyses, we reveal the great potential of our method for the MRE task", "role": "Results"}, {"entity_id": "ACL_23_P_823-2-E2", "text": "the current best model", "role": "PrimaryObject"}]}], "entity_coreference": [], "event_coreference": [], "tokens": ["On", "the", "benchmark", "MRE", "dataset,", "our", "system", "outperforms", "the", "current", "best", "model", "significantly.", "With", "further", "in-depth", "analyses,", "we", "reveal", "the", "great", "potential", "of", "our", "method", "for", "the", "MRE", "task."], "pieces": ["On", "the", "bench", "mark", "M", "RE", "dat", "as", "et", ",", "our", "system", "out", "per", "forms", "the", "current", "best", "model", "sign", "ificantly", ".", "With", "f", "urther", "in", "-", "depth", "an", "alyses", ",", "we", "reve", "al", "the", "great", "pot", "ential", "of", "our", "method", "for", "the", "M", "RE", "task", "."], "token_lens": [1, 1, 2, 2, 4, 1, 1, 3, 1, 1, 1, 1, 3, 1, 2, 3, 3, 1, 2, 1, 1, 2, 1, 1, 1, 1, 1, 2, 2], "sentence": "On the benchmark MRE dataset, our system outperforms the current best model significantly. With further in-depth analyses, we reveal the great potential of our method for the MRE task.", "sentence_starts": [0]}
{"doc_id": "ACL_23_P_891", "wnd_id": "ACL_23_P_891-0", "entity_mentions": [{"id": "ACL_23_P_891-0-E0", "text": "Multitask prompted finetuning (MTF)", "start": 0, "end": 4, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_891-0-E1", "text": "so far explorations of MTF have focused on English data and models", "start": 21, "end": 33, "entity_type": "UNK", "mention_type": "UNK"}], "relation_mentions": [], "event_mentions": [{"event_type": "Background/Introduction", "id": "ACL_23_P_891-0-EV0", "trigger": {"text": "has been shown", "start": 4, "end": 7}, "arguments": [{"entity_id": "ACL_23_P_891-0-E0", "text": "Multitask prompted finetuning (MTF)", "role": "Agent"}, {"entity_id": "ACL_23_P_891-0-E1", "text": "so far explorations of MTF have focused on English data and models", "role": "Challenge"}]}], "entity_coreference": [], "event_coreference": [], "tokens": ["Multitask", "prompted", "finetuning", "(MTF)", "has", "been", "shown", "to", "help", "large", "language", "models", "generalize", "to", "new", "tasks", "in", "a", "zero-shot", "setting,", "but", "so", "far", "explorations", "of", "MTF", "have", "focused", "on", "English", "data", "and", "models."], "pieces": ["Mult", "it", "ask", "prom", "pt", "ed", "fin", "et", "uning", "(", "M", "TF", ")", "has", "been", "shown", "to", "help", "large", "language", "models", "general", "ize", "to", "new", "t", "asks", "in", "a", "zero", "-", "shot", "setting", ",", "but", "so", "far", "expl", "or", "ations", "of", "M", "TF", "have", "focused", "on", "English", "data", "and", "models", "."], "token_lens": [3, 3, 3, 4, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 2, 1, 1, 3, 2, 1, 1, 1, 3, 1, 2, 1, 1, 1, 1, 1, 1, 2], "sentence": "Multitask prompted finetuning (MTF) has been shown to help large language models generalize to new tasks in a zero-shot setting, but so far explorations of MTF have focused on English data and models.", "sentence_starts": [0]}
{"doc_id": "ACL_23_P_891", "wnd_id": "ACL_23_P_891-1", "entity_mentions": [{"id": "ACL_23_P_891-1-E0", "text": "We", "start": 0, "end": 1, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_891-1-E1", "text": "finetuning large multilingual language models on English tasks with English prompts allows for task generalization to non-English languages that appear only in the pretraining corpus", "start": 22, "end": 47, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_891-1-E2", "text": "Finetuning on multilingual tasks with English prompts further improves performance on English and non-English tasks leading to various state-of-the-art zero-shot results.", "start": 47, "end": 68, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_891-1-E3", "text": "MTF", "start": 2, "end": 3, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_891-1-E4", "text": "to the pretrained multilingual BLOOM and mT5 model families", "start": 3, "end": 12, "entity_type": "UNK", "mention_type": "UNK"}], "relation_mentions": [], "event_mentions": [{"event_type": "Methods/Approach", "id": "ACL_23_P_891-1-EV0", "trigger": {"text": "apply", "start": 1, "end": 2}, "arguments": [{"entity_id": "ACL_23_P_891-1-E0", "text": "We", "role": "Agent"}, {"entity_id": "ACL_23_P_891-1-E1", "text": "finetuning large multilingual language models on English tasks with English prompts allows for task generalization to non-English languages that appear only in the pretraining corpus", "role": "Analysis"}, {"entity_id": "ACL_23_P_891-1-E2", "text": "Finetuning on multilingual tasks with English prompts further improves performance on English and non-English tasks leading to various state-of-the-art zero-shot results.", "role": "Analysis"}, {"entity_id": "ACL_23_P_891-1-E3", "text": "MTF", "role": "PrimaryObject"}, {"entity_id": "ACL_23_P_891-1-E4", "text": "to the pretrained multilingual BLOOM and mT5 model families", "role": "SecondaryObject"}]}], "entity_coreference": [], "event_coreference": [], "tokens": ["We", "apply", "MTF", "to", "the", "pretrained", "multilingual", "BLOOM", "and", "mT5", "model", "families", "to", "produce", "finetuned", "variants", "called", "BLOOMZ", "and", "mT0.", "We", "find", "finetuning", "large", "multilingual", "language", "models", "on", "English", "tasks", "with", "English", "prompts", "allows", "for", "task", "generalization", "to", "non-English", "languages", "that", "appear", "only", "in", "the", "pretraining", "corpus.", "Finetuning", "on", "multilingual", "tasks", "with", "English", "prompts", "further", "improves", "performance", "on", "English", "and", "non-English", "tasks", "leading", "to", "various", "state-of-the-art", "zero-shot", "results."], "pieces": ["We", "apply", "M", "TF", "to", "the", "pret", "rained", "mult", "ilingual", "BL", "O", "OM", "and", "m", "T", "5", "model", "fam", "ilies", "to", "produ", "ce", "fin", "et", "uned", "vari", "ants", "called", "BL", "O", "OM", "Z", "and", "m", "T", "0", ".", "We", "find", "fin", "et", "uning", "large", "mult", "ilingual", "language", "models", "on", "English", "t", "asks", "with", "English", "prom", "pt", "s", "allows", "for", "task", "general", "ization", "to", "non", "-", "English", "l", "anguages", "that", "app", "ear", "only", "in", "the", "pret", "raining", "cor", "p", "us", ".", "Fin", "et", "uning", "on", "mult", "ilingual", "t", "asks", "with", "English", "prom", "pt", "s", "f", "urther", "impro", "ves", "performance", "on", "English", "and", "non", "-", "English", "t", "asks", "leading", "to", "var", "ious", "state", "-", "of", "-", "the", "-", "art", "zero", "-", "shot", "results", "."], "token_lens": [1, 1, 2, 1, 1, 2, 2, 3, 1, 3, 1, 2, 1, 2, 3, 2, 1, 4, 1, 4, 1, 1, 3, 1, 2, 1, 1, 1, 1, 2, 1, 1, 3, 1, 1, 1, 2, 1, 3, 2, 1, 2, 1, 1, 1, 2, 4, 3, 1, 2, 2, 1, 1, 3, 2, 2, 1, 1, 1, 1, 3, 2, 1, 1, 2, 7, 3, 2], "sentence": "We apply MTF to the pretrained multilingual BLOOM and mT5 model families to produce finetuned variants called BLOOMZ and mT0. We find finetuning large multilingual language models on English tasks with English prompts allows for task generalization to non-English languages that appear only in the pretraining corpus. Finetuning on multilingual tasks with English prompts further improves performance on English and non-English tasks leading to various state-of-the-art zero-shot results.", "sentence_starts": [0]}
{"doc_id": "ACL_23_P_891", "wnd_id": "ACL_23_P_891-2", "entity_mentions": [{"id": "ACL_23_P_891-2-E0", "text": "We", "start": 0, "end": 1, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_891-2-E1", "text": "training on these machine-translated prompts leads to better performance on human-written prompts in the respective languages", "start": 24, "end": 40, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_891-2-E2", "text": "models are capable of zero-shot generalization to tasks in languages they have never intentionally seen", "start": 43, "end": 58, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_891-2-E3", "text": "models are learning higher-level capabilities that are both task- and language-agnostic", "start": 62, "end": 73, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_891-2-E4", "text": "finetuning", "start": 3, "end": 4, "entity_type": "UNK", "mention_type": "UNK"}], "relation_mentions": [], "event_mentions": [{"event_type": "Results/Findings", "id": "ACL_23_P_891-2-EV0", "trigger": {"text": "investigate", "start": 2, "end": 3}, "arguments": [{"entity_id": "ACL_23_P_891-2-E0", "text": "We", "role": "Agent"}, {"entity_id": "ACL_23_P_891-2-E1", "text": "training on these machine-translated prompts leads to better performance on human-written prompts in the respective languages", "role": "Results"}, {"entity_id": "ACL_23_P_891-2-E2", "text": "models are capable of zero-shot generalization to tasks in languages they have never intentionally seen", "role": "Results"}, {"entity_id": "ACL_23_P_891-2-E3", "text": "models are learning higher-level capabilities that are both task- and language-agnostic", "role": "Results"}, {"entity_id": "ACL_23_P_891-2-E4", "text": "finetuning", "role": "PrimaryObject"}]}], "entity_coreference": [], "event_coreference": [], "tokens": ["We", "also", "investigate", "finetuning", "on", "multilingual", "tasks", "with", "prompts", "that", "have", "been", "machine-translated", "from", "English", "to", "match", "the", "language", "of", "each", "dataset.", "We", "find", "training", "on", "these", "machine-translated", "prompts", "leads", "to", "better", "performance", "on", "human-written", "prompts", "in", "the", "respective", "languages.", "Surprisingly,", "we", "find", "models", "are", "capable", "of", "zero-shot", "generalization", "to", "tasks", "in", "languages", "they", "have", "never", "intentionally", "seen.", "We", "conjecture", "that", "the", "models", "are", "learning", "higher-level", "capabilities", "that", "are", "both", "task-", "and", "language-agnostic."], "pieces": ["We", "also", "invest", "igate", "fin", "et", "uning", "on", "mult", "ilingual", "t", "asks", "with", "prom", "pt", "s", "that", "have", "been", "machine", "-", "trans", "lated", "from", "English", "to", "match", "the", "language", "of", "each", "dat", "as", "et", ".", "We", "find", "training", "on", "these", "machine", "-", "trans", "lated", "prom", "pt", "s", "le", "ads", "to", "better", "performance", "on", "human", "-", "written", "prom", "pt", "s", "in", "the", "respective", "l", "anguages", ".", "Sur", "prisingly", ",", "we", "find", "models", "are", "cap", "able", "of", "zero", "-", "shot", "general", "ization", "to", "t", "asks", "in", "l", "anguages", "they", "have", "never", "intention", "ally", "seen", ".", "We", "con", "ject", "ure", "that", "the", "models", "are", "learning", "higher", "-", "level", "cap", "abilities", "that", "are", "both", "task", "-", "and", "language", "-", "agn", "ostic", "."], "token_lens": [1, 1, 2, 3, 1, 2, 2, 1, 3, 1, 1, 1, 4, 1, 1, 1, 1, 1, 1, 1, 1, 4, 1, 1, 1, 1, 1, 4, 3, 2, 1, 1, 1, 1, 3, 3, 1, 1, 1, 3, 3, 1, 1, 1, 1, 2, 1, 3, 2, 1, 2, 1, 2, 1, 1, 1, 2, 2, 1, 3, 1, 1, 1, 1, 1, 3, 2, 1, 1, 1, 2, 1, 5], "sentence": "We also investigate finetuning on multilingual tasks with prompts that have been machine-translated from English to match the language of each dataset. We find training on these machine-translated prompts leads to better performance on human-written prompts in the respective languages. Surprisingly, we find models are capable of zero-shot generalization to tasks in languages they have never intentionally seen. We conjecture that the models are learning higher-level capabilities that are both task- and language-agnostic.", "sentence_starts": [0]}
{"doc_id": "ACL_23_P_891", "wnd_id": "ACL_23_P_891-3", "entity_mentions": [{"id": "ACL_23_P_891-3-E0", "text": "we", "start": 2, "end": 3, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_891-3-E1", "text": "xP3", "start": 4, "end": 5, "entity_type": "UNK", "mention_type": "UNK"}], "relation_mentions": [], "event_mentions": [{"event_type": "Conclusions/Implications", "id": "ACL_23_P_891-3-EV0", "trigger": {"text": "introduce", "start": 3, "end": 4}, "arguments": [{"entity_id": "ACL_23_P_891-3-E0", "text": "we", "role": "Agent"}, {"entity_id": "ACL_23_P_891-3-E1", "text": "xP3", "role": "PrimaryObject"}]}], "entity_coreference": [], "event_coreference": [], "tokens": ["In", "addition,", "we", "introduce", "xP3,", "a", "composite", "of", "supervised", "datasets", "in", "46", "languages", "with", "English", "and", "machine-translated", "prompts."], "pieces": ["In", "add", "ition", ",", "we", "introdu", "ce", "x", "P", "3", ",", "a", "com", "pos", "ite", "of", "super", "vised", "dat", "as", "ets", "in", "46", "l", "anguages", "with", "English", "and", "machine", "-", "trans", "lated", "prom", "pt", "s", "."], "token_lens": [1, 3, 1, 2, 4, 1, 3, 1, 2, 3, 1, 1, 2, 1, 1, 1, 4, 4], "sentence": "In addition, we introduce xP3, a composite of supervised datasets in 46 languages with English and machine-translated prompts.", "sentence_starts": [0]}
{"doc_id": "ACL_23_P_697", "wnd_id": "ACL_23_P_697-0", "entity_mentions": [{"id": "ACL_23_P_697-0-E0", "text": "there", "start": 5, "end": 6, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_697-0-E1", "text": "These PLMs have achieved impressive results on these benchmarks, even surpassing human performance in some cases.", "start": 42, "end": 58, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_697-0-E2", "text": "This has led to claims of superhuman capabilities and the provocative idea that certain tasks have been solved", "start": 58, "end": 76, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_697-0-E3", "text": "a significant focus in Natural Language Processing (NLP)", "start": 8, "end": 16, "entity_type": "UNK", "mention_type": "UNK"}], "relation_mentions": [], "event_mentions": [{"event_type": "Background/Introduction", "id": "ACL_23_P_697-0-EV0", "trigger": {"text": "has been", "start": 6, "end": 8}, "arguments": [{"entity_id": "ACL_23_P_697-0-E0", "text": "there", "role": "Agent"}, {"entity_id": "ACL_23_P_697-0-E1", "text": "These PLMs have achieved impressive results on these benchmarks, even surpassing human performance in some cases.", "role": "Context"}, {"entity_id": "ACL_23_P_697-0-E2", "text": "This has led to claims of superhuman capabilities and the provocative idea that certain tasks have been solved", "role": "Implications"}, {"entity_id": "ACL_23_P_697-0-E3", "text": "a significant focus in Natural Language Processing (NLP)", "role": "PrimaryObject"}]}], "entity_coreference": [], "event_coreference": [], "tokens": ["In", "the", "last", "five", "years,", "there", "has", "been", "a", "significant", "focus", "in", "Natural", "Language", "Processing", "(NLP)", "on", "developing", "larger", "Pretrained", "Language", "Models", "(PLMs)", "and", "introducing", "benchmarks", "such", "as", "SuperGLUE", "and", "SQuAD", "to", "measure", "their", "abilities", "in", "language", "understanding,", "reasoning,", "and", "reading", "comprehension.", "These", "PLMs", "have", "achieved", "impressive", "results", "on", "these", "benchmarks,", "even", "surpassing", "human", "performance", "in", "some", "cases.", "This", "has", "led", "to", "claims", "of", "superhuman", "capabilities", "and", "the", "provocative", "idea", "that", "certain", "tasks", "have", "been", "solved."], "pieces": ["In", "the", "last", "five", "years", ",", "there", "has", "been", "a", "significant", "focus", "in", "Natural", "Language", "Process", "ing", "(", "N", "LP", ")", "on", "develop", "ing", "larg", "er", "P", "ret", "rained", "Language", "Mod", "els", "(", "PL", "Ms", ")", "and", "introdu", "cing", "bench", "marks", "such", "as", "Super", "GL", "UE", "and", "S", "Qu", "AD", "to", "me", "asure", "their", "abilities", "in", "language", "under", "standing", ",", "reason", "ing", ",", "and", "reading", "com", "pre", "hens", "ion", ".", "These", "PL", "Ms", "have", "ach", "ieved", "imp", "ressive", "results", "on", "these", "bench", "marks", ",", "even", "sur", "pass", "ing", "human", "performance", "in", "some", "cases", ".", "This", "has", "led", "to", "claim", "s", "of", "super", "human", "cap", "abilities", "and", "the", "prov", "ocative", "ide", "a", "that", "certain", "t", "asks", "have", "been", "s", "olved", "."], "token_lens": [1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 4, 1, 2, 2, 3, 1, 2, 4, 1, 2, 2, 1, 1, 3, 1, 3, 1, 2, 1, 1, 1, 1, 3, 3, 1, 1, 5, 1, 2, 1, 2, 2, 1, 1, 1, 3, 1, 3, 1, 1, 1, 1, 2, 1, 1, 1, 1, 2, 1, 2, 2, 1, 1, 2, 2, 1, 1, 2, 1, 1, 3], "sentence": "In the last five years, there has been a significant focus in Natural Language Processing (NLP) on developing larger Pretrained Language Models (PLMs) and introducing benchmarks such as SuperGLUE and SQuAD to measure their abilities in language understanding, reasoning, and reading comprehension. These PLMs have achieved impressive results on these benchmarks, even surpassing human performance in some cases. This has led to claims of superhuman capabilities and the provocative idea that certain tasks have been solved.", "sentence_starts": [0]}
{"doc_id": "ACL_23_P_697", "wnd_id": "ACL_23_P_697-1", "entity_mentions": [{"id": "ACL_23_P_697-1-E0", "text": "we", "start": 4, "end": 5, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_697-1-E1", "text": "a critical look at these claims", "start": 6, "end": 12, "entity_type": "UNK", "mention_type": "UNK"}], "relation_mentions": [], "event_mentions": [{"event_type": "Methods/Approach", "id": "ACL_23_P_697-1-EV0", "trigger": {"text": "take", "start": 5, "end": 6}, "arguments": [{"entity_id": "ACL_23_P_697-1-E0", "text": "we", "role": "Agent"}, {"entity_id": "ACL_23_P_697-1-E1", "text": "a critical look at these claims", "role": "PrimaryObject"}]}], "entity_coreference": [], "event_coreference": [], "tokens": ["In", "this", "position", "paper,", "we", "take", "a", "critical", "look", "at", "these", "claims", "and", "ask", "whether", "PLMs", "truly", "have", "superhuman", "abilities", "and", "what", "the", "current", "benchmarks", "are", "really", "evaluating."], "pieces": ["In", "this", "position", "paper", ",", "we", "take", "a", "critical", "look", "at", "these", "claim", "s", "and", "ask", "whether", "PL", "Ms", "t", "ruly", "have", "super", "human", "abilities", "and", "what", "the", "current", "bench", "marks", "are", "really", "eval", "uating", "."], "token_lens": [1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 2, 2, 1, 2, 1, 1, 1, 1, 1, 2, 1, 1, 3], "sentence": "In this position paper, we take a critical look at these claims and ask whether PLMs truly have superhuman abilities and what the current benchmarks are really evaluating.", "sentence_starts": [0]}
{"doc_id": "ACL_23_P_697", "wnd_id": "ACL_23_P_697-2", "entity_mentions": [{"id": "ACL_23_P_697-2-E0", "text": "We", "start": 0, "end": 1, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_697-2-E1", "text": "these benchmarks have serious limitations affecting the comparison between humans and PLMs", "start": 3, "end": 15, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_697-2-E2", "text": "recommendations for fairer and more transparent benchmarks", "start": 17, "end": 24, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_697-2-E3", "text": "these benchmarks have serious limitations affecting the comparison between humans and PLMs", "start": 3, "end": 15, "entity_type": "UNK", "mention_type": "UNK"}], "relation_mentions": [], "event_mentions": [{"event_type": "Results/Findings", "id": "ACL_23_P_697-2-EV0", "trigger": {"text": "show", "start": 1, "end": 2}, "arguments": [{"entity_id": "ACL_23_P_697-2-E0", "text": "We", "role": "Agent"}, {"entity_id": "ACL_23_P_697-2-E1", "text": "these benchmarks have serious limitations affecting the comparison between humans and PLMs", "role": "Results"}, {"entity_id": "ACL_23_P_697-2-E2", "text": "recommendations for fairer and more transparent benchmarks", "role": "Implications"}, {"entity_id": "ACL_23_P_697-2-E3", "text": "these benchmarks have serious limitations affecting the comparison between humans and PLMs", "role": "PrimaryObject"}]}], "entity_coreference": [], "event_coreference": [], "tokens": ["We", "show", "that", "these", "benchmarks", "have", "serious", "limitations", "affecting", "the", "comparison", "between", "humans", "and", "PLMs", "and", "provide", "recommendations", "for", "fairer", "and", "more", "transparent", "benchmarks."], "pieces": ["We", "show", "that", "these", "bench", "marks", "have", "serious", "lim", "itations", "aff", "ect", "ing", "the", "com", "par", "ison", "between", "humans", "and", "PL", "Ms", "and", "prov", "ide", "recomm", "end", "ations", "for", "f", "aire", "r", "and", "more", "trans", "parent", "bench", "marks", "."], "token_lens": [1, 1, 1, 1, 2, 1, 1, 2, 3, 1, 3, 1, 1, 1, 2, 1, 2, 3, 1, 3, 1, 1, 2, 3], "sentence": "We show that these benchmarks have serious limitations affecting the comparison between humans and PLMs and provide recommendations for fairer and more transparent benchmarks.", "sentence_starts": [0]}
{"doc_id": "ACL_23_P_392", "wnd_id": "ACL_23_P_392-0", "entity_mentions": [{"id": "ACL_23_P_392-0-E0", "text": "We", "start": 62, "end": 63, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_392-0-E1", "text": "Among the remarkable emergent capabilities of large language models (LMs) is free-text rationalization; beyond certain scale, large LMs are capable of generating seemingly useful rationalizations, which in turn, can dramatically enhance their performances on leaderboards.", "start": 0, "end": 35, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_392-0-E2", "text": "This phenomenon raises a question: can machine generated rationales also be useful for humans, especially when lay humans try to answer questions based on those machine rationales", "start": 35, "end": 62, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_392-0-E3", "text": "expensive to estimate with human studies", "start": 75, "end": 81, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_392-0-E4", "text": "Existing metrics like task performance of the LM generating the rationales or similarity between generated and gold rationales are not good indicators of their human utility", "start": 81, "end": 107, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_392-0-E5", "text": "While we observe that certain properties of rationales like conciseness and novelty are correlated with their human utility, estimating them without human involvement is challenging", "start": 107, "end": 132, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_392-0-E6", "text": "human utility of existing rationales is far from satisfactory", "start": 65, "end": 74, "entity_type": "UNK", "mention_type": "UNK"}], "relation_mentions": [], "event_mentions": [{"event_type": "Background/Introduction", "id": "ACL_23_P_392-0-EV0", "trigger": {"text": "observe", "start": 63, "end": 64}, "arguments": [{"entity_id": "ACL_23_P_392-0-E0", "text": "We", "role": "Agent"}, {"entity_id": "ACL_23_P_392-0-E1", "text": "Among the remarkable emergent capabilities of large language models (LMs) is free-text rationalization; beyond certain scale, large LMs are capable of generating seemingly useful rationalizations, which in turn, can dramatically enhance their performances on leaderboards.", "role": "Context"}, {"entity_id": "ACL_23_P_392-0-E2", "text": "This phenomenon raises a question: can machine generated rationales also be useful for humans, especially when lay humans try to answer questions based on those machine rationales", "role": "Context"}, {"entity_id": "ACL_23_P_392-0-E3", "text": "expensive to estimate with human studies", "role": "Challenge"}, {"entity_id": "ACL_23_P_392-0-E4", "text": "Existing metrics like task performance of the LM generating the rationales or similarity between generated and gold rationales are not good indicators of their human utility", "role": "Challenge"}, {"entity_id": "ACL_23_P_392-0-E5", "text": "While we observe that certain properties of rationales like conciseness and novelty are correlated with their human utility, estimating them without human involvement is challenging", "role": "Challenge"}, {"entity_id": "ACL_23_P_392-0-E6", "text": "human utility of existing rationales is far from satisfactory", "role": "PrimaryObject"}]}], "entity_coreference": [], "event_coreference": [], "tokens": ["Among", "the", "remarkable", "emergent", "capabilities", "of", "large", "language", "models", "(LMs)", "is", "free-text", "rationalization;", "beyond", "certain", "scale,", "large", "LMs", "are", "capable", "of", "generating", "seemingly", "useful", "rationalizations,", "which", "in", "turn,", "can", "dramatically", "enhance", "their", "performances", "on", "leaderboards.", "This", "phenomenon", "raises", "a", "question:", "can", "machine", "generated", "rationales", "also", "be", "useful", "for", "humans,", "especially", "when", "lay", "humans", "try", "to", "answer", "questions", "based", "on", "those", "machine", "rationales?", "We", "observe", "that", "human", "utility", "of", "existing", "rationales", "is", "far", "from", "satisfactory", "and", "expensive", "to", "estimate", "with", "human", "studies.", "Existing", "metrics", "like", "task", "performance", "of", "the", "LM", "generating", "the", "rationales", "or", "similarity", "between", "generated", "and", "gold", "rationales", "are", "not", "good", "indicators", "of", "their", "human", "utility.", "While", "we", "observe", "that", "certain", "properties", "of", "rationales", "like", "conciseness", "and", "novelty", "are", "correlated", "with", "their", "human", "utility,", "estimating", "them", "without", "human", "involvement", "is", "challenging."], "pieces": ["Among", "the", "rem", "arkable", "em", "erg", "ent", "cap", "abilities", "of", "large", "language", "models", "(", "L", "Ms", ")", "is", "free", "-", "text", "rational", "ization", ";", "be", "yond", "certain", "scale", ",", "large", "L", "Ms", "are", "cap", "able", "of", "gener", "ating", "se", "em", "ingly", "use", "ful", "rational", "izations", ",", "which", "in", "turn", ",", "can", "d", "ram", "atically", "enh", "ance", "their", "per", "form", "ances", "on", "leader", "boards", ".", "This", "phen", "omen", "on", "ra", "ises", "a", "question", ":", "can", "machine", "generated", "rational", "es", "also", "be", "use", "ful", "for", "humans", ",", "especially", "when", "lay", "humans", "try", "to", "answer", "quest", "ions", "based", "on", "those", "machine", "rational", "es", "?", "We", "ob", "ser", "ve", "that", "human", "ut", "ility", "of", "existing", "rational", "es", "is", "far", "from", "s", "atisf", "actory", "and", "expensive", "to", "est", "imate", "with", "human", "stud", "ies", ".", "Ex", "isting", "met", "rics", "like", "task", "performance", "of", "the", "LM", "gener", "ating", "the", "rational", "es", "or", "similar", "ity", "between", "generated", "and", "gold", "rational", "es", "are", "not", "good", "ind", "icators", "of", "their", "human", "ut", "ility", ".", "While", "we", "ob", "ser", "ve", "that", "certain", "properties", "of", "rational", "es", "like", "con", "c", "is", "eness", "and", "no", "vel", "ty", "are", "cor", "related", "with", "their", "human", "ut", "ility", ",", "est", "imating", "them", "without", "human", "inv", "olve", "ment", "is", "chall", "eng", "ing", "."], "token_lens": [1, 1, 2, 3, 2, 1, 1, 1, 1, 4, 1, 3, 3, 2, 1, 2, 1, 2, 1, 2, 1, 2, 3, 2, 3, 1, 1, 2, 1, 3, 2, 1, 3, 1, 3, 1, 3, 2, 1, 2, 1, 1, 1, 2, 1, 1, 2, 1, 2, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 3, 1, 3, 1, 1, 2, 1, 1, 2, 1, 1, 1, 3, 1, 1, 1, 2, 1, 1, 3, 2, 2, 1, 1, 1, 1, 1, 1, 2, 1, 2, 1, 2, 1, 1, 1, 1, 2, 1, 1, 1, 2, 1, 1, 1, 3, 1, 1, 3, 1, 1, 1, 1, 2, 1, 4, 1, 3, 1, 2, 1, 1, 1, 3, 2, 1, 1, 1, 3, 1, 4], "sentence": "Among the remarkable emergent capabilities of large language models (LMs) is free-text rationalization; beyond certain scale, large LMs are capable of generating seemingly useful rationalizations, which in turn, can dramatically enhance their performances on leaderboards. This phenomenon raises a question: can machine generated rationales also be useful for humans, especially when lay humans try to answer questions based on those machine rationales? We observe that human utility of existing rationales is far from satisfactory and expensive to estimate with human studies. Existing metrics like task performance of the LM generating the rationales or similarity between generated and gold rationales are not good indicators of their human utility. While we observe that certain properties of rationales like conciseness and novelty are correlated with their human utility, estimating them without human involvement is challenging.", "sentence_starts": [0]}
{"doc_id": "ACL_23_P_392", "wnd_id": "ACL_23_P_392-1", "entity_mentions": [{"id": "ACL_23_P_392-1-E0", "text": "we", "start": 0, "end": 1, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_392-1-E1", "text": "We also translate this finding into an automated score, Gen-U, that we propose, which can help improve LMs\u2019 ability to generate rationales with better human utility, while maintaining most of its task performance", "start": 23, "end": 56, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_392-1-E2", "text": "its human utility", "start": 16, "end": 19, "entity_type": "UNK", "mention_type": "UNK"}], "relation_mentions": [], "event_mentions": [{"event_type": "Methods/Approach", "id": "ACL_23_P_392-1-EV0", "trigger": {"text": "measure", "start": 15, "end": 16}, "arguments": [{"entity_id": "ACL_23_P_392-1-E0", "text": "we", "role": "Agent"}, {"entity_id": "ACL_23_P_392-1-E1", "text": "We also translate this finding into an automated score, Gen-U, that we propose, which can help improve LMs\u2019 ability to generate rationales with better human utility, while maintaining most of its task performance", "role": "Method"}, {"entity_id": "ACL_23_P_392-1-E2", "text": "its human utility", "role": "PrimaryObject"}]}], "entity_coreference": [], "event_coreference": [], "tokens": ["We", "show", "that,", "by", "estimating", "a", "rationale\u2019s", "helpfulness", "in", "answering", "similar", "unseen", "instances,", "we", "can", "measure", "its", "human", "utility", "to", "a", "better", "extent.", "We", "also", "translate", "this", "finding", "into", "an", "automated", "score,", "Gen-U,", "that", "we", "propose,", "which", "can", "help", "improve", "LMs\u2019", "ability", "to", "generate", "rationales", "with", "better", "human", "utility,", "while", "maintaining", "most", "of", "its", "task", "performance."], "pieces": ["We", "show", "that", ",", "by", "est", "imating", "a", "rational", "e", "\u00e2\u0122", "\u013b", "s", "help", "fulness", "in", "ans", "w", "ering", "similar", "un", "seen", "inst", "ances", ",", "we", "can", "me", "asure", "its", "human", "ut", "ility", "to", "a", "better", "ext", "ent", ".", "We", "also", "trans", "late", "this", "finding", "into", "an", "aut", "om", "ated", "score", ",", "Gen", "-", "U", ",", "that", "we", "pro", "pose", ",", "which", "can", "help", "improve", "L", "Ms", "\u00e2\u0122", "\u013b", "ability", "to", "gener", "ate", "rational", "es", "with", "better", "human", "ut", "ility", ",", "while", "m", "aint", "aining", "most", "of", "its", "task", "performance", "."], "token_lens": [1, 1, 2, 1, 2, 1, 5, 2, 1, 3, 1, 2, 3, 1, 1, 2, 1, 1, 2, 1, 1, 1, 3, 1, 1, 2, 1, 1, 1, 1, 3, 2, 4, 1, 1, 3, 1, 1, 1, 1, 4, 1, 1, 2, 2, 1, 1, 1, 3, 1, 3, 1, 1, 1, 1, 2], "sentence": "We show that, by estimating a rationale\u2019s helpfulness in answering similar unseen instances, we can measure its human utility to a better extent. We also translate this finding into an automated score, Gen-U, that we propose, which can help improve LMs\u2019 ability to generate rationales with better human utility, while maintaining most of its task performance.", "sentence_starts": [0]}
{"doc_id": "ACL_23_P_12", "wnd_id": "ACL_23_P_12-0", "entity_mentions": [{"id": "ACL_23_P_12-0-E0", "text": "we", "start": 5, "end": 6, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_12-0-E1", "text": "These structures underlie complex anaphoric and agreement relations at the interface of syntax and semantics, allowing us to study lexically-guided antecedent retrieval processes", "start": 40, "end": 63, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_12-0-E2", "text": "to correctly identify control dependencies in Spanish sentences such as \u2018Jos\u00e9 le prometi\u00f3/orden\u00f3 a Mar\u00eda ser ordenado/a\u2019 (\u2018Joseph promised/ordered Mary to be tidy\u2019)", "start": 17, "end": 40, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_12-0-E3", "text": "the ability of humans", "start": 7, "end": 11, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_12-0-E4", "text": "several pre-trained masked language models", "start": 12, "end": 17, "entity_type": "UNK", "mention_type": "UNK"}], "relation_mentions": [], "event_mentions": [{"event_type": "Background/Introduction", "id": "ACL_23_P_12-0-EV0", "trigger": {"text": "compare", "start": 6, "end": 7}, "arguments": [{"entity_id": "ACL_23_P_12-0-E0", "text": "we", "role": "Agent"}, {"entity_id": "ACL_23_P_12-0-E1", "text": "These structures underlie complex anaphoric and agreement relations at the interface of syntax and semantics, allowing us to study lexically-guided antecedent retrieval processes", "role": "Context"}, {"entity_id": "ACL_23_P_12-0-E2", "text": "to correctly identify control dependencies in Spanish sentences such as \u2018Jos\u00e9 le prometi\u00f3/orden\u00f3 a Mar\u00eda ser ordenado/a\u2019 (\u2018Joseph promised/ordered Mary to be tidy\u2019)", "role": "Purpose"}, {"entity_id": "ACL_23_P_12-0-E3", "text": "the ability of humans", "role": "PrimaryObject"}, {"entity_id": "ACL_23_P_12-0-E4", "text": "several pre-trained masked language models", "role": "SecondaryObject"}]}], "entity_coreference": [], "event_coreference": [], "tokens": ["Using", "psycholinguistic", "and", "computational", "experiments", "we", "compare", "the", "ability", "of", "humans", "and", "several", "pre-trained", "masked", "language", "models", "to", "correctly", "identify", "control", "dependencies", "in", "Spanish", "sentences", "such", "as", "\u2018Jos\u00e9", "le", "prometi\u00f3/orden\u00f3", "a", "Mar\u00eda", "ser", "ordenado/a\u2019", "(\u2018Joseph", "promised/ordered", "Mary", "to", "be", "tidy\u2019).", "These", "structures", "underlie", "complex", "anaphoric", "and", "agreement", "relations", "at", "the", "interface", "of", "syntax", "and", "semantics,", "allowing", "us", "to", "study", "lexically-guided", "antecedent", "retrieval", "processes."], "pieces": ["Using", "psych", "ol", "ingu", "istic", "and", "com", "put", "ational", "exper", "iments", "we", "comp", "are", "the", "ability", "of", "humans", "and", "sever", "al", "pre", "-", "trained", "mask", "ed", "language", "models", "to", "correct", "ly", "ident", "ify", "control", "depend", "encies", "in", "Spanish", "sent", "ences", "such", "as", "\u00e2\u0122", "\u013a", "J", "os", "\u00c3\u00a9", "le", "prom", "et", "i", "\u00c3\u00b3", "/", "ord", "en", "\u00c3\u00b3", "a", "Mar", "\u00c3\u0143a", "ser", "ord", "en", "ado", "/", "a", "\u00e2\u0122", "\u013b", "(", "\u00e2\u0122", "\u013a", "Joseph", "prom", "ised", "/", "ordered", "Mary", "to", "be", "t", "idy", "\u00e2\u0122", "\u013b", ").", "These", "struct", "ures", "under", "lie", "complex", "an", "aph", "oric", "and", "ag", "reement", "relations", "at", "the", "interface", "of", "sy", "ntax", "and", "sem", "antics", ",", "all", "owing", "us", "to", "study", "lex", "ically", "-", "guided", "ant", "ec", "ed", "ent", "ret", "ri", "eval", "process", "es", "."], "token_lens": [1, 4, 1, 3, 2, 1, 2, 1, 1, 1, 1, 1, 2, 3, 2, 1, 1, 1, 2, 2, 1, 2, 1, 1, 2, 1, 1, 5, 1, 8, 1, 2, 1, 7, 4, 4, 1, 1, 1, 5, 1, 2, 2, 1, 3, 1, 2, 1, 1, 1, 1, 1, 2, 1, 3, 2, 1, 1, 1, 4, 4, 3, 3], "sentence": "Using psycholinguistic and computational experiments we compare the ability of humans and several pre-trained masked language models to correctly identify control dependencies in Spanish sentences such as \u2018Jos\u00e9 le prometi\u00f3/orden\u00f3 a Mar\u00eda ser ordenado/a\u2019 (\u2018Joseph promised/ordered Mary to be tidy\u2019). These structures underlie complex anaphoric and agreement relations at the interface of syntax and semantics, allowing us to study lexically-guided antecedent retrieval processes.", "sentence_starts": [0]}
{"doc_id": "ACL_23_P_12", "wnd_id": "ACL_23_P_12-1", "entity_mentions": [{"id": "ACL_23_P_12-1-E0", "text": "Our results", "start": 0, "end": 2, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_12-1-E1", "text": "language models often fail to identify the correct antecedent in non-adjacent dependencies", "start": 13, "end": 25, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_12-1-E2", "text": "Additional experiments on Galician reinforce these conclusions", "start": 30, "end": 37, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_12-1-E3", "text": "language models often fail to identify the correct antecedent in non-adjacent dependencies", "start": 13, "end": 25, "entity_type": "UNK", "mention_type": "UNK"}], "relation_mentions": [], "event_mentions": [{"event_type": "Results/Findings", "id": "ACL_23_P_12-1-EV0", "trigger": {"text": "show", "start": 2, "end": 3}, "arguments": [{"entity_id": "ACL_23_P_12-1-E0", "text": "Our results", "role": "Agent"}, {"entity_id": "ACL_23_P_12-1-E1", "text": "language models often fail to identify the correct antecedent in non-adjacent dependencies", "role": "Results"}, {"entity_id": "ACL_23_P_12-1-E2", "text": "Additional experiments on Galician reinforce these conclusions", "role": "Results"}, {"entity_id": "ACL_23_P_12-1-E3", "text": "language models often fail to identify the correct antecedent in non-adjacent dependencies", "role": "PrimaryObject"}]}], "entity_coreference": [], "event_coreference": [], "tokens": ["Our", "results", "show", "that", "while", "humans", "correctly", "identify", "the", "(un)acceptability", "of", "the", "strings,", "language", "models", "often", "fail", "to", "identify", "the", "correct", "antecedent", "in", "non-adjacent", "dependencies,", "showing", "their", "reliance", "on", "linearity.", "Additional", "experiments", "on", "Galician", "reinforce", "these", "conclusions."], "pieces": ["Our", "results", "show", "that", "while", "humans", "correct", "ly", "ident", "ify", "the", "(", "un", ")", "accept", "ability", "of", "the", "strings", ",", "language", "models", "often", "fail", "to", "ident", "ify", "the", "correct", "ant", "ec", "ed", "ent", "in", "non", "-", "adj", "acent", "depend", "encies", ",", "sh", "owing", "their", "rel", "iance", "on", "linear", "ity", ".", "Additional", "exper", "iments", "on", "Gal", "ician", "re", "in", "force", "these", "con", "clusions", "."], "token_lens": [1, 1, 1, 1, 1, 1, 2, 2, 1, 5, 1, 1, 2, 1, 1, 1, 1, 1, 2, 1, 1, 4, 1, 4, 3, 2, 1, 2, 1, 3, 1, 2, 1, 2, 3, 1, 3], "sentence": "Our results show that while humans correctly identify the (un)acceptability of the strings, language models often fail to identify the correct antecedent in non-adjacent dependencies, showing their reliance on linearity. Additional experiments on Galician reinforce these conclusions.", "sentence_starts": [0]}
{"doc_id": "ACL_23_P_12", "wnd_id": "ACL_23_P_12-2", "entity_mentions": [{"id": "ACL_23_P_12-2-E0", "text": "Our findings", "start": 0, "end": 2, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_12-2-E1", "text": "for psycholinguistic theories of anaphor resolution", "start": 19, "end": 25, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_12-2-E2", "text": "equally valuable", "start": 3, "end": 5, "entity_type": "UNK", "mention_type": "UNK"}], "relation_mentions": [], "event_mentions": [{"event_type": "Conclusions/Implications", "id": "ACL_23_P_12-2-EV0", "trigger": {"text": "are", "start": 2, "end": 3}, "arguments": [{"entity_id": "ACL_23_P_12-2-E0", "text": "Our findings", "role": "Agent"}, {"entity_id": "ACL_23_P_12-2-E1", "text": "for psycholinguistic theories of anaphor resolution", "role": "Implications"}, {"entity_id": "ACL_23_P_12-2-E2", "text": "equally valuable", "role": "PrimaryObject"}]}], "entity_coreference": [], "event_coreference": [], "tokens": ["Our", "findings", "are", "equally", "valuable", "for", "the", "evaluation", "of", "language", "models\u2019", "ability", "to", "capture", "linguistic", "generalizations,", "as", "well", "as", "for", "psycholinguistic", "theories", "of", "anaphor", "resolution."], "pieces": ["Our", "find", "ings", "are", "equ", "ally", "val", "uable", "for", "the", "eval", "uation", "of", "language", "models", "\u00e2\u0122", "\u013b", "ability", "to", "capt", "ure", "ling", "u", "istic", "general", "izations", ",", "as", "well", "as", "for", "psych", "ol", "ingu", "istic", "the", "ories", "of", "an", "aph", "or", "resolution", "."], "token_lens": [1, 2, 1, 2, 2, 1, 1, 2, 1, 1, 3, 1, 1, 2, 3, 3, 1, 1, 1, 1, 4, 2, 1, 3, 2], "sentence": "Our findings are equally valuable for the evaluation of language models\u2019 ability to capture linguistic generalizations, as well as for psycholinguistic theories of anaphor resolution.", "sentence_starts": [0]}
{"doc_id": "ACL_23_P_183", "wnd_id": "ACL_23_P_183-0", "entity_mentions": [{"id": "ACL_23_P_183-0-E0", "text": "presenting the same news headline to all readers", "start": 30, "end": 38, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_183-0-E1", "text": "The potential choices for news article headlines are enormous, and finding the right balance between conveying the essential message and capturing the reader\u2019s attention is key to effective headlining", "start": 0, "end": 29, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_183-0-E2", "text": "because it does not take into account the different preferences and interests of diverse readers, who may be confused about why a particular article has been recommended to them and do not see a clear connection between their interests and the recommended article", "start": 42, "end": 85, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_183-0-E3", "text": "a suboptimal strategy", "start": 39, "end": 42, "entity_type": "UNK", "mention_type": "UNK"}], "relation_mentions": [], "event_mentions": [{"event_type": "Background/Introduction", "id": "ACL_23_P_183-0-EV0", "trigger": {"text": "is", "start": 24, "end": 25}, "arguments": [{"entity_id": "ACL_23_P_183-0-E0", "text": "presenting the same news headline to all readers", "role": "Agent"}, {"entity_id": "ACL_23_P_183-0-E1", "text": "The potential choices for news article headlines are enormous, and finding the right balance between conveying the essential message and capturing the reader\u2019s attention is key to effective headlining", "role": "Context"}, {"entity_id": "ACL_23_P_183-0-E2", "text": "because it does not take into account the different preferences and interests of diverse readers, who may be confused about why a particular article has been recommended to them and do not see a clear connection between their interests and the recommended article", "role": "Analysis"}, {"entity_id": "ACL_23_P_183-0-E3", "text": "a suboptimal strategy", "role": "PrimaryObject"}]}], "entity_coreference": [], "event_coreference": [], "tokens": ["The", "potential", "choices", "for", "news", "article", "headlines", "are", "enormous,", "and", "finding", "the", "right", "balance", "between", "conveying", "the", "essential", "message", "and", "capturing", "the", "reader\u2019s", "attention", "is", "key", "to", "effective", "headlining.", "However,", "presenting", "the", "same", "news", "headline", "to", "all", "readers", "is", "a", "suboptimal", "strategy,", "because", "it", "does", "not", "take", "into", "account", "the", "different", "preferences", "and", "interests", "of", "diverse", "readers,", "who", "may", "be", "confused", "about", "why", "a", "particular", "article", "has", "been", "recommended", "to", "them", "and", "do", "not", "see", "a", "clear", "connection", "between", "their", "interests", "and", "the", "recommended", "article."], "pieces": ["The", "pot", "ential", "cho", "ices", "for", "news", "article", "head", "lines", "are", "en", "orm", "ous", ",", "and", "finding", "the", "right", "balance", "between", "con", "ve", "ying", "the", "essential", "message", "and", "capt", "uring", "the", "reader", "\u00e2\u0122", "\u013b", "s", "att", "ention", "is", "key", "to", "effective", "head", "lining", ".", "However", ",", "present", "ing", "the", "same", "news", "head", "line", "to", "all", "read", "ers", "is", "a", "sub", "opt", "imal", "str", "ategy", ",", "because", "it", "does", "not", "take", "into", "account", "the", "different", "pre", "f", "erences", "and", "interest", "s", "of", "d", "iverse", "read", "ers", ",", "who", "may", "be", "conf", "used", "about", "why", "a", "part", "icular", "article", "has", "been", "recomm", "ended", "to", "them", "and", "do", "not", "see", "a", "clear", "connection", "between", "their", "interest", "s", "and", "the", "recomm", "ended", "article", "."], "token_lens": [1, 2, 2, 1, 1, 1, 2, 1, 4, 1, 1, 1, 1, 1, 1, 3, 1, 1, 1, 1, 2, 1, 4, 2, 1, 1, 1, 1, 3, 2, 2, 1, 1, 1, 2, 1, 1, 2, 1, 1, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 3, 1, 2, 1, 2, 3, 1, 1, 1, 2, 1, 1, 1, 2, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 2, 2], "sentence": "The potential choices for news article headlines are enormous, and finding the right balance between conveying the essential message and capturing the reader\u2019s attention is key to effective headlining. However, presenting the same news headline to all readers is a suboptimal strategy, because it does not take into account the different preferences and interests of diverse readers, who may be confused about why a particular article has been recommended to them and do not see a clear connection between their interests and the recommended article.", "sentence_starts": [0]}
{"doc_id": "ACL_23_P_183", "wnd_id": "ACL_23_P_183-1", "entity_mentions": [{"id": "ACL_23_P_183-1-E0", "text": "we", "start": 3, "end": 4, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_183-1-E1", "text": "a combination of automated and human evaluation methods to determine user preference for personalized headlines", "start": 21, "end": 36, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_183-1-E2", "text": "Our framework utilizes a learnable relevance function to assign personalized signature phrases to users based on their reading histories, which are then used to personalize headline generation", "start": 36, "end": 63, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_183-1-E3", "text": "a novel framework that addresses these challenges", "start": 5, "end": 12, "entity_type": "UNK", "mention_type": "UNK"}], "relation_mentions": [], "event_mentions": [{"event_type": "Methods/Approach", "id": "ACL_23_P_183-1-EV0", "trigger": {"text": "present", "start": 4, "end": 5}, "arguments": [{"entity_id": "ACL_23_P_183-1-E0", "text": "we", "role": "Agent"}, {"entity_id": "ACL_23_P_183-1-E1", "text": "a combination of automated and human evaluation methods to determine user preference for personalized headlines", "role": "Method"}, {"entity_id": "ACL_23_P_183-1-E2", "text": "Our framework utilizes a learnable relevance function to assign personalized signature phrases to users based on their reading histories, which are then used to personalize headline generation", "role": "Method"}, {"entity_id": "ACL_23_P_183-1-E3", "text": "a novel framework that addresses these challenges", "role": "PrimaryObject"}]}], "entity_coreference": [], "event_coreference": [], "tokens": ["In", "this", "paper,", "we", "present", "a", "novel", "framework", "that", "addresses", "these", "challenges", "by", "incorporating", "user", "profiling", "to", "generate", "personalized", "headlines,", "and", "a", "combination", "of", "automated", "and", "human", "evaluation", "methods", "to", "determine", "user", "preference", "for", "personalized", "headlines.", "Our", "framework", "utilizes", "a", "learnable", "relevance", "function", "to", "assign", "personalized", "signature", "phrases", "to", "users", "based", "on", "their", "reading", "histories,", "which", "are", "then", "used", "to", "personalize", "headline", "generation."], "pieces": ["In", "this", "paper", ",", "we", "present", "a", "no", "vel", "framework", "that", "add", "resses", "these", "chall", "enges", "by", "inc", "orpor", "ating", "user", "prof", "iling", "to", "gener", "ate", "personal", "ized", "head", "lines", ",", "and", "a", "comb", "ination", "of", "aut", "om", "ated", "and", "human", "eval", "uation", "method", "s", "to", "d", "eter", "mine", "user", "pre", "ference", "for", "personal", "ized", "head", "lines", ".", "Our", "framework", "util", "izes", "a", "learn", "able", "re", "lev", "ance", "function", "to", "ass", "ign", "personal", "ized", "sign", "ature", "ph", "r", "ases", "to", "users", "based", "on", "their", "reading", "hist", "ories", ",", "which", "are", "then", "used", "to", "personal", "ize", "head", "line", "generation", "."], "token_lens": [1, 1, 2, 1, 1, 1, 2, 1, 1, 2, 1, 2, 1, 3, 1, 2, 1, 2, 2, 3, 1, 1, 2, 1, 3, 1, 1, 2, 2, 1, 3, 1, 2, 1, 2, 3, 1, 1, 2, 1, 2, 3, 1, 1, 2, 2, 2, 3, 1, 1, 1, 1, 1, 1, 3, 1, 1, 1, 1, 1, 2, 2, 2], "sentence": "In this paper, we present a novel framework that addresses these challenges by incorporating user profiling to generate personalized headlines, and a combination of automated and human evaluation methods to determine user preference for personalized headlines. Our framework utilizes a learnable relevance function to assign personalized signature phrases to users based on their reading histories, which are then used to personalize headline generation.", "sentence_starts": [0]}
{"doc_id": "ACL_23_P_183", "wnd_id": "ACL_23_P_183-2", "entity_mentions": [{"id": "ACL_23_P_183-2-E0", "text": "we", "start": 3, "end": 4, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_183-2-E1", "text": "effectiveness of our proposed framework in generating personalized headlines that meet the needs of a diverse audience", "start": 6, "end": 23, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_183-2-E2", "text": "the effectiveness", "start": 5, "end": 7, "entity_type": "UNK", "mention_type": "UNK"}], "relation_mentions": [], "event_mentions": [{"event_type": "Results/Findings", "id": "ACL_23_P_183-2-EV0", "trigger": {"text": "demonstrate", "start": 4, "end": 5}, "arguments": [{"entity_id": "ACL_23_P_183-2-E0", "text": "we", "role": "Agent"}, {"entity_id": "ACL_23_P_183-2-E1", "text": "effectiveness of our proposed framework in generating personalized headlines that meet the needs of a diverse audience", "role": "Results"}, {"entity_id": "ACL_23_P_183-2-E2", "text": "the effectiveness", "role": "PrimaryObject"}]}], "entity_coreference": [], "event_coreference": [], "tokens": ["Through", "extensive", "evaluation,", "we", "demonstrate", "the", "effectiveness", "of", "our", "proposed", "framework", "in", "generating", "personalized", "headlines", "that", "meet", "the", "needs", "of", "a", "diverse", "audience."], "pieces": ["Through", "ext", "ensive", "eval", "uation", ",", "we", "demon", "strate", "the", "effect", "iveness", "of", "our", "prop", "osed", "framework", "in", "gener", "ating", "personal", "ized", "head", "lines", "that", "meet", "the", "needs", "of", "a", "d", "iverse", "aud", "ience", "."], "token_lens": [1, 2, 3, 1, 2, 1, 2, 1, 1, 2, 1, 1, 2, 2, 2, 1, 1, 1, 1, 1, 1, 2, 3], "sentence": "Through extensive evaluation, we demonstrate the effectiveness of our proposed framework in generating personalized headlines that meet the needs of a diverse audience.", "sentence_starts": [0]}
{"doc_id": "ACL_23_P_183", "wnd_id": "ACL_23_P_183-3", "entity_mentions": [{"id": "ACL_23_P_183-3-E0", "text": "Our framework", "start": 0, "end": 2, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_183-3-E1", "text": "the efficacy", "start": 7, "end": 9, "entity_type": "UNK", "mention_type": "UNK"}], "relation_mentions": [], "event_mentions": [{"event_type": "Conclusions/Implications", "id": "ACL_23_P_183-3-EV0", "trigger": {"text": "has the potential to improve", "start": 2, "end": 7}, "arguments": [{"entity_id": "ACL_23_P_183-3-E0", "text": "Our framework", "role": "Agent"}, {"entity_id": "ACL_23_P_183-3-E1", "text": "the efficacy", "role": "PrimaryObject"}]}], "entity_coreference": [], "event_coreference": [], "tokens": ["Our", "framework", "has", "the", "potential", "to", "improve", "the", "efficacy", "of", "news", "recommendations", "and", "facilitate", "creation", "of", "personalized", "content."], "pieces": ["Our", "framework", "has", "the", "pot", "ential", "to", "improve", "the", "effic", "acy", "of", "news", "recomm", "end", "ations", "and", "fac", "ilit", "ate", "creation", "of", "personal", "ized", "content", "."], "token_lens": [1, 1, 1, 1, 2, 1, 1, 1, 2, 1, 1, 3, 1, 3, 1, 1, 2, 2], "sentence": "Our framework has the potential to improve the efficacy of news recommendations and facilitate creation of personalized content.", "sentence_starts": [0]}
{"doc_id": "ACL_23_P_386", "wnd_id": "ACL_23_P_386-0", "entity_mentions": [{"id": "ACL_23_P_386-0-E0", "text": "Fact-checking real-world claims", "start": 0, "end": 3, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_386-0-E1", "text": "collecting multiple pieces of evidence and applying complex multi-step reasoning", "start": 5, "end": 15, "entity_type": "UNK", "mention_type": "UNK"}], "relation_mentions": [], "event_mentions": [{"event_type": "Background/Introduction", "id": "ACL_23_P_386-0-EV0", "trigger": {"text": "requires", "start": 4, "end": 5}, "arguments": [{"entity_id": "ACL_23_P_386-0-E0", "text": "Fact-checking real-world claims", "role": "Agent"}, {"entity_id": "ACL_23_P_386-0-E1", "text": "collecting multiple pieces of evidence and applying complex multi-step reasoning", "role": "PrimaryObject"}]}], "entity_coreference": [], "event_coreference": [], "tokens": ["Fact-checking", "real-world", "claims", "often", "requires", "collecting", "multiple", "pieces", "of", "evidence", "and", "applying", "complex", "multi-step", "reasoning."], "pieces": ["Fact", "-", "checking", "real", "-", "world", "claim", "s", "often", "requires", "collect", "ing", "multiple", "pieces", "of", "evidence", "and", "app", "lying", "complex", "multi", "-", "step", "reason", "ing", "."], "token_lens": [3, 3, 2, 1, 1, 2, 1, 1, 1, 1, 1, 2, 1, 3, 3], "sentence": "Fact-checking real-world claims often requires collecting multiple pieces of evidence and applying complex multi-step reasoning.", "sentence_starts": [0]}
{"doc_id": "ACL_23_P_386", "wnd_id": "ACL_23_P_386-1", "entity_mentions": [{"id": "ACL_23_P_386-1-E0", "text": "we", "start": 3, "end": 4, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_386-1-E1", "text": "We first leverage the in-context learning ability of large language models to generate reasoning programs to guide the verification process", "start": 30, "end": 50, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_386-1-E2", "text": "we execute the program by delegating each sub-task to the corresponding sub-task handler", "start": 51, "end": 64, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_386-1-E3", "text": "This process makes our model both explanatory and data-efficient, providing clear explanations of its reasoning process and requiring minimal training data", "start": 64, "end": 85, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_386-1-E4", "text": "Program-Guided Fact-Checking (ProgramFC)", "start": 5, "end": 8, "entity_type": "UNK", "mention_type": "UNK"}], "relation_mentions": [], "event_mentions": [{"event_type": "Methods/Approach", "id": "ACL_23_P_386-1-EV0", "trigger": {"text": "present", "start": 4, "end": 5}, "arguments": [{"entity_id": "ACL_23_P_386-1-E0", "text": "we", "role": "Agent"}, {"entity_id": "ACL_23_P_386-1-E1", "text": "We first leverage the in-context learning ability of large language models to generate reasoning programs to guide the verification process", "role": "Method"}, {"entity_id": "ACL_23_P_386-1-E2", "text": "we execute the program by delegating each sub-task to the corresponding sub-task handler", "role": "Method"}, {"entity_id": "ACL_23_P_386-1-E3", "text": "This process makes our model both explanatory and data-efficient, providing clear explanations of its reasoning process and requiring minimal training data", "role": "Results"}, {"entity_id": "ACL_23_P_386-1-E4", "text": "Program-Guided Fact-Checking (ProgramFC)", "role": "PrimaryObject"}]}], "entity_coreference": [], "event_coreference": [], "tokens": ["In", "this", "paper,", "we", "present", "Program-Guided", "Fact-Checking", "(ProgramFC),", "a", "novel", "fact-checking", "model", "that", "decomposes", "complex", "claims", "into", "simpler", "sub-tasks", "that", "can", "be", "solved", "using", "a", "shared", "library", "of", "specialized", "functions.", "We", "first", "leverage", "the", "in-context", "learning", "ability", "of", "large", "language", "models", "to", "generate", "reasoning", "programs", "to", "guide", "the", "verification", "process.", "Afterward,", "we", "execute", "the", "program", "by", "delegating", "each", "sub-task", "to", "the", "corresponding", "sub-task", "handler.", "This", "process", "makes", "our", "model", "both", "explanatory", "and", "data-efficient,", "providing", "clear", "explanations", "of", "its", "reasoning", "process", "and", "requiring", "minimal", "training", "data."], "pieces": ["In", "this", "paper", ",", "we", "present", "Program", "-", "Gu", "ided", "Fact", "-", "Check", "ing", "(", "Program", "FC", "),", "a", "no", "vel", "fact", "-", "checking", "model", "that", "dec", "om", "poses", "complex", "claim", "s", "into", "sim", "pler", "sub", "-", "t", "asks", "that", "can", "be", "s", "olved", "using", "a", "shared", "library", "of", "special", "ized", "fun", "ctions", ".", "We", "first", "le", "verage", "the", "in", "-", "context", "learning", "ability", "of", "large", "language", "models", "to", "gener", "ate", "reason", "ing", "program", "s", "to", "guide", "the", "ver", "ification", "process", ".", "After", "ward", ",", "we", "execute", "the", "program", "by", "de", "leg", "ating", "each", "sub", "-", "task", "to", "the", "cor", "respond", "ing", "sub", "-", "task", "handler", ".", "This", "process", "makes", "our", "model", "both", "ex", "plan", "atory", "and", "data", "-", "efficient", ",", "prov", "iding", "clear", "ex", "plan", "ations", "of", "its", "reason", "ing", "process", "and", "requ", "iring", "min", "imal", "training", "data", "."], "token_lens": [1, 1, 2, 1, 1, 4, 4, 4, 1, 2, 3, 1, 1, 3, 1, 2, 1, 2, 4, 1, 1, 1, 2, 1, 1, 1, 1, 1, 2, 3, 1, 1, 2, 1, 3, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 1, 1, 1, 2, 2, 3, 1, 1, 1, 1, 1, 3, 1, 3, 1, 1, 3, 3, 2, 1, 1, 1, 1, 1, 1, 3, 1, 4, 2, 1, 3, 1, 1, 2, 1, 1, 2, 2, 1, 2], "sentence": "In this paper, we present Program-Guided Fact-Checking (ProgramFC), a novel fact-checking model that decomposes complex claims into simpler sub-tasks that can be solved using a shared library of specialized functions. We first leverage the in-context learning ability of large language models to generate reasoning programs to guide the verification process. Afterward, we execute the program by delegating each sub-task to the corresponding sub-task handler. This process makes our model both explanatory and data-efficient, providing clear explanations of its reasoning process and requiring minimal training data.", "sentence_starts": [0]}
{"doc_id": "ACL_23_P_386", "wnd_id": "ACL_23_P_386-2", "entity_mentions": [{"id": "ACL_23_P_386-2-E0", "text": "We", "start": 0, "end": 1, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_386-2-E1", "text": "it outperforms seven fact-checking baselines across different settings of evidence availability, with explicit output programs that benefit human debugging", "start": 11, "end": 30, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_386-2-E2", "text": "ProgramFC", "start": 2, "end": 3, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_386-2-E3", "text": "on two challenging fact-checking datasets", "start": 3, "end": 8, "entity_type": "UNK", "mention_type": "UNK"}], "relation_mentions": [], "event_mentions": [{"event_type": "Results/Findings", "id": "ACL_23_P_386-2-EV0", "trigger": {"text": "evaluate", "start": 1, "end": 2}, "arguments": [{"entity_id": "ACL_23_P_386-2-E0", "text": "We", "role": "Agent"}, {"entity_id": "ACL_23_P_386-2-E1", "text": "it outperforms seven fact-checking baselines across different settings of evidence availability, with explicit output programs that benefit human debugging", "role": "Results"}, {"entity_id": "ACL_23_P_386-2-E2", "text": "ProgramFC", "role": "PrimaryObject"}, {"entity_id": "ACL_23_P_386-2-E3", "text": "on two challenging fact-checking datasets", "role": "SecondaryObject"}]}], "entity_coreference": [], "event_coreference": [], "tokens": ["We", "evaluate", "ProgramFC", "on", "two", "challenging", "fact-checking", "datasets", "and", "show", "that", "it", "outperforms", "seven", "fact-checking", "baselines", "across", "different", "settings", "of", "evidence", "availability,", "with", "explicit", "output", "programs", "that", "benefit", "human", "debugging."], "pieces": ["We", "evaluate", "Program", "FC", "on", "two", "chall", "eng", "ing", "fact", "-", "checking", "dat", "as", "ets", "and", "show", "that", "it", "out", "per", "forms", "seven", "fact", "-", "checking", "bas", "elines", "ac", "ross", "different", "settings", "of", "evidence", "availability", ",", "with", "expl", "icit", "output", "program", "s", "that", "benefit", "human", "debug", "ging", "."], "token_lens": [1, 1, 2, 1, 1, 3, 3, 3, 1, 1, 1, 1, 3, 1, 3, 2, 2, 1, 1, 1, 1, 2, 1, 2, 1, 2, 1, 1, 1, 3], "sentence": "We evaluate ProgramFC on two challenging fact-checking datasets and show that it outperforms seven fact-checking baselines across different settings of evidence availability, with explicit output programs that benefit human debugging.", "sentence_starts": [0]}
{"doc_id": "ACL_23_P_866", "wnd_id": "ACL_23_P_866-0", "entity_mentions": [{"id": "ACL_23_P_866-0-E0", "text": "The ability of commonsense reasoning (CR)", "start": 0, "end": 6, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_866-0-E1", "text": "Despite the rapid advancement of NMT and the use of pretraining to enhance NMT models", "start": 19, "end": 34, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_866-0-E2", "text": "research on CR in NMT is still in its infancy, leaving much to be explored in terms of effectively training NMT models with high CR abilities and devising accurate automatic evaluation metrics", "start": 34, "end": 66, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_866-0-E3", "text": "whether a neural machine translation (NMT) model can move beyond pattern recognition", "start": 7, "end": 19, "entity_type": "UNK", "mention_type": "UNK"}], "relation_mentions": [], "event_mentions": [{"event_type": "Background/Introduction", "id": "ACL_23_P_866-0-EV0", "trigger": {"text": "decides", "start": 6, "end": 7}, "arguments": [{"entity_id": "ACL_23_P_866-0-E0", "text": "The ability of commonsense reasoning (CR)", "role": "Agent"}, {"entity_id": "ACL_23_P_866-0-E1", "text": "Despite the rapid advancement of NMT and the use of pretraining to enhance NMT models", "role": "Context"}, {"entity_id": "ACL_23_P_866-0-E2", "text": "research on CR in NMT is still in its infancy, leaving much to be explored in terms of effectively training NMT models with high CR abilities and devising accurate automatic evaluation metrics", "role": "Challenge"}, {"entity_id": "ACL_23_P_866-0-E3", "text": "whether a neural machine translation (NMT) model can move beyond pattern recognition", "role": "PrimaryObject"}]}], "entity_coreference": [], "event_coreference": [], "tokens": ["The", "ability", "of", "commonsense", "reasoning", "(CR)", "decides", "whether", "a", "neural", "machine", "translation", "(NMT)", "model", "can", "move", "beyond", "pattern", "recognition.", "Despite", "the", "rapid", "advancement", "of", "NMT", "and", "the", "use", "of", "pretraining", "to", "enhance", "NMT", "models,", "research", "on", "CR", "in", "NMT", "is", "still", "in", "its", "infancy,", "leaving", "much", "to", "be", "explored", "in", "terms", "of", "effectively", "training", "NMT", "models", "with", "high", "CR", "abilities", "and", "devising", "accurate", "automatic", "evaluation", "metrics."], "pieces": ["The", "ability", "of", "comm", "onsense", "reason", "ing", "(", "CR", ")", "dec", "ides", "whether", "a", "ne", "ural", "machine", "translation", "(", "N", "MT", ")", "model", "can", "move", "be", "yond", "pattern", "recogn", "ition", ".", "Despite", "the", "rap", "id", "ad", "vance", "ment", "of", "N", "MT", "and", "the", "use", "of", "pret", "raining", "to", "enh", "ance", "N", "MT", "models", ",", "research", "on", "CR", "in", "N", "MT", "is", "still", "in", "its", "inf", "ancy", ",", "le", "aving", "much", "to", "be", "expl", "ored", "in", "terms", "of", "effect", "ively", "training", "N", "MT", "models", "with", "high", "CR", "abilities", "and", "dev", "ising", "acc", "urate", "automatic", "eval", "uation", "met", "rics", "."], "token_lens": [1, 1, 1, 2, 2, 3, 2, 1, 1, 2, 1, 1, 4, 1, 1, 1, 2, 1, 3, 1, 1, 2, 3, 1, 2, 1, 1, 1, 1, 2, 1, 2, 2, 2, 1, 1, 1, 1, 2, 1, 1, 1, 1, 3, 2, 1, 1, 1, 2, 1, 1, 1, 2, 1, 2, 1, 1, 1, 1, 1, 1, 2, 2, 1, 2, 3], "sentence": "The ability of commonsense reasoning (CR) decides whether a neural machine translation (NMT) model can move beyond pattern recognition. Despite the rapid advancement of NMT and the use of pretraining to enhance NMT models, research on CR in NMT is still in its infancy, leaving much to be explored in terms of effectively training NMT models with high CR abilities and devising accurate automatic evaluation metrics.", "sentence_starts": [0]}
{"doc_id": "ACL_23_P_866", "wnd_id": "ACL_23_P_866-1", "entity_mentions": [{"id": "ACL_23_P_866-1-E0", "text": "This paper", "start": 0, "end": 2, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_866-1-E1", "text": "For the training, we confirm the effectiveness of incorporating pretrained knowledge into NMT models and subsequently utilizing these models as robust testbeds for investigating CR in NMT", "start": 15, "end": 42, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_866-1-E2", "text": "For the evaluation, we propose a novel entity-aware evaluation method that takes into account both the NMT candidate and important entities in the candidate, which is more aligned with human judgement", "start": 42, "end": 73, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_866-1-E3", "text": "a comprehensive study", "start": 3, "end": 6, "entity_type": "UNK", "mention_type": "UNK"}], "relation_mentions": [], "event_mentions": [{"event_type": "Methods/Approach", "id": "ACL_23_P_866-1-EV0", "trigger": {"text": "presents", "start": 2, "end": 3}, "arguments": [{"entity_id": "ACL_23_P_866-1-E0", "text": "This paper", "role": "Agent"}, {"entity_id": "ACL_23_P_866-1-E1", "text": "For the training, we confirm the effectiveness of incorporating pretrained knowledge into NMT models and subsequently utilizing these models as robust testbeds for investigating CR in NMT", "role": "Method"}, {"entity_id": "ACL_23_P_866-1-E2", "text": "For the evaluation, we propose a novel entity-aware evaluation method that takes into account both the NMT candidate and important entities in the candidate, which is more aligned with human judgement", "role": "Method"}, {"entity_id": "ACL_23_P_866-1-E3", "text": "a comprehensive study", "role": "PrimaryObject"}]}], "entity_coreference": [], "event_coreference": [], "tokens": ["This", "paper", "presents", "a", "comprehensive", "study", "aimed", "at", "expanding", "the", "understanding", "of", "CR", "in", "NMT.", "For", "the", "training,", "we", "confirm", "the", "effectiveness", "of", "incorporating", "pretrained", "knowledge", "into", "NMT", "models", "and", "subsequently", "utilizing", "these", "models", "as", "robust", "testbeds", "for", "investigating", "CR", "in", "NMT.", "For", "the", "evaluation,", "we", "propose", "a", "novel", "entity-aware", "evaluation", "method", "that", "takes", "into", "account", "both", "the", "NMT", "candidate", "and", "important", "entities", "in", "the", "candidate,", "which", "is", "more", "aligned", "with", "human", "judgement."], "pieces": ["This", "paper", "p", "resents", "a", "com", "pre", "hens", "ive", "study", "aim", "ed", "at", "exp", "anding", "the", "under", "standing", "of", "CR", "in", "N", "MT", ".", "For", "the", "training", ",", "we", "conf", "irm", "the", "effect", "iveness", "of", "inc", "orpor", "ating", "pret", "rained", "knowledge", "into", "N", "MT", "models", "and", "sub", "sequently", "util", "izing", "these", "models", "as", "rob", "ust", "test", "bed", "s", "for", "invest", "igating", "CR", "in", "N", "MT", ".", "For", "the", "eval", "uation", ",", "we", "pro", "pose", "a", "no", "vel", "entity", "-", "aware", "eval", "uation", "method", "that", "t", "akes", "into", "account", "both", "the", "N", "MT", "cand", "idate", "and", "important", "ent", "ities", "in", "the", "cand", "idate", ",", "which", "is", "more", "aligned", "with", "human", "jud", "gement", "."], "token_lens": [1, 1, 2, 1, 4, 1, 2, 1, 2, 1, 2, 1, 1, 1, 3, 1, 1, 2, 1, 2, 1, 2, 1, 3, 2, 1, 1, 2, 1, 1, 2, 2, 1, 1, 1, 2, 3, 1, 2, 1, 1, 3, 1, 1, 3, 1, 2, 1, 2, 3, 2, 1, 1, 2, 1, 1, 1, 1, 2, 2, 1, 1, 2, 1, 1, 3, 1, 1, 1, 1, 1, 1, 3], "sentence": "This paper presents a comprehensive study aimed at expanding the understanding of CR in NMT. For the training, we confirm the effectiveness of incorporating pretrained knowledge into NMT models and subsequently utilizing these models as robust testbeds for investigating CR in NMT. For the evaluation, we propose a novel entity-aware evaluation method that takes into account both the NMT candidate and important entities in the candidate, which is more aligned with human judgement.", "sentence_starts": [0]}
{"doc_id": "ACL_23_P_866", "wnd_id": "ACL_23_P_866-2", "entity_mentions": [{"id": "ACL_23_P_866-2-E0", "text": "we", "start": 8, "end": 9, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_866-2-E1", "text": "Based on the strong testbed and evaluation methods,", "start": 0, "end": 8, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_866-2-E2", "text": "suggest directions for further unlabeled data utilization and model design", "start": 20, "end": 30, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_866-2-E3", "text": "challenges", "start": 10, "end": 11, "entity_type": "UNK", "mention_type": "UNK"}], "relation_mentions": [], "event_mentions": [{"event_type": "Results/Findings", "id": "ACL_23_P_866-2-EV0", "trigger": {"text": "identify", "start": 9, "end": 10}, "arguments": [{"entity_id": "ACL_23_P_866-2-E0", "text": "we", "role": "Agent"}, {"entity_id": "ACL_23_P_866-2-E1", "text": "Based on the strong testbed and evaluation methods,", "role": "Context"}, {"entity_id": "ACL_23_P_866-2-E2", "text": "suggest directions for further unlabeled data utilization and model design", "role": "Implications"}, {"entity_id": "ACL_23_P_866-2-E3", "text": "challenges", "role": "PrimaryObject"}]}], "entity_coreference": [], "event_coreference": [], "tokens": ["Based", "on", "the", "strong", "testbed", "and", "evaluation", "methods,", "we", "identify", "challenges", "in", "training", "NMT", "models", "with", "high", "CR", "abilities", "and", "suggest", "directions", "for", "further", "unlabeled", "data", "utilization", "and", "model", "design."], "pieces": ["Based", "on", "the", "strong", "test", "bed", "and", "eval", "uation", "method", "s", ",", "we", "ident", "ify", "chall", "enges", "in", "training", "N", "MT", "models", "with", "high", "CR", "abilities", "and", "suggest", "direct", "ions", "for", "f", "urther", "un", "label", "ed", "data", "util", "ization", "and", "model", "design", "."], "token_lens": [1, 1, 1, 1, 2, 1, 2, 3, 1, 2, 2, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 2, 1, 2, 3, 1, 2, 1, 1, 2], "sentence": "Based on the strong testbed and evaluation methods, we identify challenges in training NMT models with high CR abilities and suggest directions for further unlabeled data utilization and model design.", "sentence_starts": [0]}
{"doc_id": "ACL_23_P_866", "wnd_id": "ACL_23_P_866-3", "entity_mentions": [{"id": "ACL_23_P_866-3-E0", "text": "We", "start": 0, "end": 1, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_866-3-E1", "text": "that our methods and findings", "start": 2, "end": 7, "entity_type": "UNK", "mention_type": "UNK"}], "relation_mentions": [], "event_mentions": [{"event_type": "Conclusions/Implications", "id": "ACL_23_P_866-3-EV0", "trigger": {"text": "hope", "start": 1, "end": 2}, "arguments": [{"entity_id": "ACL_23_P_866-3-E0", "text": "We", "role": "Agent"}, {"entity_id": "ACL_23_P_866-3-E1", "text": "that our methods and findings", "role": "PrimaryObject"}]}], "entity_coreference": [], "event_coreference": [], "tokens": ["We", "hope", "that", "our", "methods", "and", "findings", "will", "contribute", "to", "advancing", "the", "research", "of", "CR", "in", "NMT."], "pieces": ["We", "h", "ope", "that", "our", "method", "s", "and", "find", "ings", "will", "cont", "ribute", "to", "adv", "ancing", "the", "research", "of", "CR", "in", "N", "MT", "."], "token_lens": [1, 2, 1, 1, 2, 1, 2, 1, 2, 1, 2, 1, 1, 1, 1, 1, 3], "sentence": "We hope that our methods and findings will contribute to advancing the research of CR in NMT.", "sentence_starts": [0]}
{"doc_id": "ACL_23_P_377", "wnd_id": "ACL_23_P_377-0", "entity_mentions": [{"id": "ACL_23_P_377-0-E0", "text": "A series of datasets and models", "start": 0, "end": 6, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_377-0-E1", "text": "Dialogue summaries, however, have been under explored", "start": 19, "end": 26, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_377-0-E2", "text": "for summaries", "start": 9, "end": 11, "entity_type": "UNK", "mention_type": "UNK"}], "relation_mentions": [], "event_mentions": [{"event_type": "Background/Introduction", "id": "ACL_23_P_377-0-EV0", "trigger": {"text": "have been proposed", "start": 6, "end": 9}, "arguments": [{"entity_id": "ACL_23_P_377-0-E0", "text": "A series of datasets and models", "role": "Agent"}, {"entity_id": "ACL_23_P_377-0-E1", "text": "Dialogue summaries, however, have been under explored", "role": "Challenge"}, {"entity_id": "ACL_23_P_377-0-E2", "text": "for summaries", "role": "PrimaryObject"}]}], "entity_coreference": [], "event_coreference": [], "tokens": ["A", "series", "of", "datasets", "and", "models", "have", "been", "proposed", "for", "summaries", "generated", "for", "well-formatted", "documents", "such", "as", "news", "articles.", "Dialogue", "summaries,", "however,", "have", "been", "under", "explored."], "pieces": ["A", "series", "of", "dat", "as", "ets", "and", "models", "have", "been", "prop", "osed", "for", "s", "umm", "aries", "generated", "for", "well", "-", "form", "atted", "doc", "uments", "such", "as", "news", "articles", ".", "Dialogue", "s", "umm", "aries", ",", "how", "ever", ",", "have", "been", "under", "expl", "ored", "."], "token_lens": [1, 1, 1, 3, 1, 1, 1, 1, 2, 1, 3, 1, 1, 4, 2, 1, 1, 1, 2, 1, 4, 3, 1, 1, 1, 3], "sentence": "A series of datasets and models have been proposed for summaries generated for well-formatted documents such as news articles. Dialogue summaries, however, have been under explored.", "sentence_starts": [0]}
{"doc_id": "ACL_23_P_377", "wnd_id": "ACL_23_P_377-1", "entity_mentions": [{"id": "ACL_23_P_377-1-E0", "text": "we", "start": 3, "end": 4, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_377-1-E1", "text": "We define fine-grained factual error detection as a sentence-level multi-label classification problem, and weevaluate two state-of-the-art (SOTA) models on our dataset", "start": 15, "end": 36, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_377-1-E2", "text": "We further propose an unsupervised model ENDERANKER via candidate ranking using pretrained encoder-decoder models", "start": 53, "end": 67, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_377-1-E3", "text": "Both models yield sub-optimal results, with a macro-averaged F1 score of around 0.25 over 6 error classes", "start": 36, "end": 53, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_377-1-E4", "text": "the first dataset", "start": 5, "end": 8, "entity_type": "UNK", "mention_type": "UNK"}], "relation_mentions": [], "event_mentions": [{"event_type": "Methods/Approach", "id": "ACL_23_P_377-1-EV0", "trigger": {"text": "present", "start": 4, "end": 5}, "arguments": [{"entity_id": "ACL_23_P_377-1-E0", "text": "we", "role": "Agent"}, {"entity_id": "ACL_23_P_377-1-E1", "text": "We define fine-grained factual error detection as a sentence-level multi-label classification problem, and weevaluate two state-of-the-art (SOTA) models on our dataset", "role": "Method"}, {"entity_id": "ACL_23_P_377-1-E2", "text": "We further propose an unsupervised model ENDERANKER via candidate ranking using pretrained encoder-decoder models", "role": "Method"}, {"entity_id": "ACL_23_P_377-1-E3", "text": "Both models yield sub-optimal results, with a macro-averaged F1 score of around 0.25 over 6 error classes", "role": "Results"}, {"entity_id": "ACL_23_P_377-1-E4", "text": "the first dataset", "role": "PrimaryObject"}]}], "entity_coreference": [], "event_coreference": [], "tokens": ["In", "this", "paper,", "we", "present", "the", "first", "dataset", "with", "fine-grained", "factual", "error", "annotations", "named", "DIASUMFACT.", "We", "define", "fine-grained", "factual", "error", "detection", "as", "a", "sentence-level", "multi-label", "classification", "problem,", "and", "weevaluate", "two", "state-of-the-art", "(SOTA)", "models", "on", "our", "dataset.", "Both", "models", "yield", "sub-optimal", "results,", "with", "a", "macro-averaged", "F1", "score", "of", "around", "0.25", "over", "6", "error", "classes.", "We", "further", "propose", "an", "unsupervised", "model", "ENDERANKER", "via", "candidate", "ranking", "using", "pretrained", "encoder-decoder", "models."], "pieces": ["In", "this", "paper", ",", "we", "present", "the", "first", "dat", "as", "et", "with", "fine", "-", "gr", "ained", "fact", "ual", "error", "annot", "ations", "named", "DI", "AS", "UM", "F", "ACT", ".", "We", "define", "fine", "-", "gr", "ained", "fact", "ual", "error", "det", "ection", "as", "a", "sent", "ence", "-", "level", "multi", "-", "label", "class", "ification", "problem", ",", "and", "we", "evaluate", "two", "state", "-", "of", "-", "the", "-", "art", "(", "S", "OTA", ")", "models", "on", "our", "dat", "as", "et", ".", "Both", "models", "y", "ield", "sub", "-", "opt", "imal", "results", ",", "with", "a", "mac", "ro", "-", "aver", "aged", "F", "1", "score", "of", "around", "0", ".", "25", "over", "6", "error", "classes", ".", "We", "f", "urther", "pro", "pose", "an", "un", "super", "vised", "model", "END", "ER", "ANK", "ER", "via", "cand", "idate", "ranking", "using", "pret", "rained", "enc", "oder", "-", "dec", "oder", "models", "."], "token_lens": [1, 1, 2, 1, 1, 1, 1, 3, 1, 4, 2, 1, 2, 1, 6, 1, 1, 4, 2, 1, 2, 1, 1, 4, 3, 2, 2, 1, 2, 1, 7, 4, 1, 1, 1, 4, 1, 1, 2, 4, 2, 1, 1, 5, 2, 1, 1, 1, 3, 1, 1, 1, 2, 1, 2, 2, 1, 3, 1, 4, 1, 2, 1, 1, 2, 5, 2], "sentence": "In this paper, we present the first dataset with fine-grained factual error annotations named DIASUMFACT. We define fine-grained factual error detection as a sentence-level multi-label classification problem, and weevaluate two state-of-the-art (SOTA) models on our dataset. Both models yield sub-optimal results, with a macro-averaged F1 score of around 0.25 over 6 error classes. We further propose an unsupervised model ENDERANKER via candidate ranking using pretrained encoder-decoder models.", "sentence_starts": [0]}
{"doc_id": "ACL_23_P_377", "wnd_id": "ACL_23_P_377-2", "entity_mentions": [{"id": "ACL_23_P_377-2-E0", "text": "Our model", "start": 0, "end": 2, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_377-2-E1", "text": "These observations confirm the challenges in detecting factual errors from dialogue summaries", "start": 13, "end": 25, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_377-2-E2", "text": " call for further studies, for which our dataset and results offer a solid foundation.", "start": 26, "end": 40, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_377-2-E3", "text": "the SOTA models", "start": 6, "end": 9, "entity_type": "UNK", "mention_type": "UNK"}], "relation_mentions": [], "event_mentions": [{"event_type": "Results/Findings", "id": "ACL_23_P_377-2-EV0", "trigger": {"text": "performs on par with", "start": 2, "end": 6}, "arguments": [{"entity_id": "ACL_23_P_377-2-E0", "text": "Our model", "role": "Agent"}, {"entity_id": "ACL_23_P_377-2-E1", "text": "These observations confirm the challenges in detecting factual errors from dialogue summaries", "role": "Results"}, {"entity_id": "ACL_23_P_377-2-E2", "text": " call for further studies, for which our dataset and results offer a solid foundation.", "role": "Implications"}, {"entity_id": "ACL_23_P_377-2-E3", "text": "the SOTA models", "role": "PrimaryObject"}]}], "entity_coreference": [], "event_coreference": [], "tokens": ["Our", "model", "performs", "on", "par", "with", "the", "SOTA", "models", "while", "requiring", "fewer", "resources.", "These", "observations", "confirm", "the", "challenges", "in", "detecting", "factual", "errors", "from", "dialogue", "summaries,", "which", "call", "for", "further", "studies,", "for", "which", "our", "dataset", "and", "results", "offer", "a", "solid", "foundation."], "pieces": ["Our", "model", "per", "forms", "on", "par", "with", "the", "S", "OTA", "models", "while", "requ", "iring", "few", "er", "resources", ".", "These", "ob", "serv", "ations", "conf", "irm", "the", "chall", "enges", "in", "det", "ect", "ing", "fact", "ual", "errors", "from", "dial", "ogue", "s", "umm", "aries", ",", "which", "call", "for", "f", "urther", "stud", "ies", ",", "for", "which", "our", "dat", "as", "et", "and", "results", "offer", "a", "solid", "foundation", "."], "token_lens": [1, 1, 2, 1, 1, 1, 1, 2, 1, 1, 2, 2, 2, 1, 3, 2, 1, 2, 1, 3, 2, 1, 1, 2, 4, 1, 1, 1, 2, 3, 1, 1, 1, 3, 1, 1, 1, 1, 1, 2], "sentence": "Our model performs on par with the SOTA models while requiring fewer resources. These observations confirm the challenges in detecting factual errors from dialogue summaries, which call for further studies, for which our dataset and results offer a solid foundation.", "sentence_starts": [0]}
{"doc_id": "ACL_23_P_147", "wnd_id": "ACL_23_P_147-0", "entity_mentions": [{"id": "ACL_23_P_147-0-E0", "text": "Zero-shot-CoT", "start": 52, "end": 53, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_147-0-E1", "text": "Large language models (LLMs) have recently been shown to deliver impressive performance in various NLP tasks", "start": 0, "end": 16, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_147-0-E2", "text": "To eliminate the manual efforts", "start": 47, "end": 52, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_147-0-E3", "text": "To tackle multi-step reasoning tasks, Few-shot chain-of-thought (CoT) prompting includes a few manually crafted step-by-step reasoning demonstrations which enable LLMs to explicitly generate reasoning steps and improve their reasoning task accuracy", "start": 16, "end": 47, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_147-0-E4", "text": "Despite the success of Zero-shot-CoT, it still suffers from three pitfalls: calculation errors, missing-step errors, and semantic misunderstanding errors", "start": 70, "end": 89, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_147-0-E5", "text": "the target problem statement", "start": 54, "end": 58, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_147-0-E6", "text": "with \u201cLet\u2019s think step by step\u201d", "start": 58, "end": 64, "entity_type": "UNK", "mention_type": "UNK"}], "relation_mentions": [], "event_mentions": [{"event_type": "Background/Introduction", "id": "ACL_23_P_147-0-EV0", "trigger": {"text": "concatenates", "start": 53, "end": 54}, "arguments": [{"entity_id": "ACL_23_P_147-0-E0", "text": "Zero-shot-CoT", "role": "Agent"}, {"entity_id": "ACL_23_P_147-0-E1", "text": "Large language models (LLMs) have recently been shown to deliver impressive performance in various NLP tasks", "role": "Context"}, {"entity_id": "ACL_23_P_147-0-E2", "text": "To eliminate the manual efforts", "role": "Purpose"}, {"entity_id": "ACL_23_P_147-0-E3", "text": "To tackle multi-step reasoning tasks, Few-shot chain-of-thought (CoT) prompting includes a few manually crafted step-by-step reasoning demonstrations which enable LLMs to explicitly generate reasoning steps and improve their reasoning task accuracy", "role": "Method"}, {"entity_id": "ACL_23_P_147-0-E4", "text": "Despite the success of Zero-shot-CoT, it still suffers from three pitfalls: calculation errors, missing-step errors, and semantic misunderstanding errors", "role": "Challenge"}, {"entity_id": "ACL_23_P_147-0-E5", "text": "the target problem statement", "role": "PrimaryObject"}, {"entity_id": "ACL_23_P_147-0-E6", "text": "with \u201cLet\u2019s think step by step\u201d", "role": "SecondaryObject"}]}], "entity_coreference": [], "event_coreference": [], "tokens": ["Large", "language", "models", "(LLMs)", "have", "recently", "been", "shown", "to", "deliver", "impressive", "performance", "in", "various", "NLP", "tasks.", "To", "tackle", "multi-step", "reasoning", "tasks,", "Few-shot", "chain-of-thought", "(CoT)", "prompting", "includes", "a", "few", "manually", "crafted", "step-by-step", "reasoning", "demonstrations", "which", "enable", "LLMs", "to", "explicitly", "generate", "reasoning", "steps", "and", "improve", "their", "reasoning", "task", "accuracy.", "To", "eliminate", "the", "manual", "efforts,", "Zero-shot-CoT", "concatenates", "the", "target", "problem", "statement", "with", "\u201cLet\u2019s", "think", "step", "by", "step\u201d", "as", "an", "input", "prompt", "to", "LLMs.", "Despite", "the", "success", "of", "Zero-shot-CoT,", "it", "still", "suffers", "from", "three", "pitfalls:", "calculation", "errors,", "missing-step", "errors,", "and", "semantic", "misunderstanding", "errors."], "pieces": ["Large", "language", "models", "(", "LL", "Ms", ")", "have", "recent", "ly", "been", "shown", "to", "del", "iver", "imp", "ressive", "performance", "in", "var", "ious", "N", "LP", "t", "asks", ".", "To", "tackle", "multi", "-", "step", "reason", "ing", "t", "asks", ",", "Few", "-", "shot", "chain", "-", "of", "-", "thought", "(", "Co", "T", ")", "prom", "pt", "ing", "includes", "a", "few", "man", "ually", "crafted", "step", "-", "by", "-", "step", "reason", "ing", "demon", "str", "ations", "which", "enable", "LL", "Ms", "to", "expl", "icit", "ly", "gener", "ate", "reason", "ing", "steps", "and", "improve", "their", "reason", "ing", "task", "acc", "uracy", ".", "To", "el", "im", "inate", "the", "man", "ual", "eff", "orts", ",", "Zero", "-", "shot", "-", "Co", "T", "con", "cat", "en", "ates", "the", "target", "problem", "statement", "with", "\u00e2\u0122", "\u013e", "Let", "\u00e2\u0122", "\u013b", "s", "think", "step", "by", "step", "\u00e2\u0122", "\u013f", "as", "an", "input", "prom", "pt", "to", "LL", "Ms", ".", "Despite", "the", "success", "of", "Zero", "-", "shot", "-", "Co", "T", ",", "it", "still", "suff", "ers", "from", "three", "pit", "falls", ":", "cal", "culation", "errors", ",", "missing", "-", "step", "errors", ",", "and", "sem", "antic", "mis", "under", "standing", "errors", "."], "token_lens": [1, 1, 1, 4, 1, 2, 1, 1, 1, 2, 2, 1, 1, 2, 2, 3, 1, 1, 3, 2, 3, 3, 5, 4, 3, 1, 1, 1, 2, 1, 5, 2, 3, 1, 1, 2, 1, 3, 2, 2, 1, 1, 1, 1, 2, 1, 3, 1, 3, 1, 2, 3, 6, 4, 1, 1, 1, 1, 1, 6, 1, 1, 1, 3, 1, 1, 1, 2, 1, 3, 1, 1, 1, 1, 7, 1, 1, 2, 1, 1, 3, 2, 2, 3, 2, 1, 2, 3, 2], "sentence": "Large language models (LLMs) have recently been shown to deliver impressive performance in various NLP tasks. To tackle multi-step reasoning tasks, Few-shot chain-of-thought (CoT) prompting includes a few manually crafted step-by-step reasoning demonstrations which enable LLMs to explicitly generate reasoning steps and improve their reasoning task accuracy. To eliminate the manual efforts, Zero-shot-CoT concatenates the target problem statement with \u201cLet\u2019s think step by step\u201d as an input prompt to LLMs. Despite the success of Zero-shot-CoT, it still suffers from three pitfalls: calculation errors, missing-step errors, and semantic misunderstanding errors.", "sentence_starts": [0]}
{"doc_id": "ACL_23_P_147", "wnd_id": "ACL_23_P_147-1", "entity_mentions": [{"id": "ACL_23_P_147-1-E0", "text": "we", "start": 5, "end": 6, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_147-1-E1", "text": "To address the missing-step errors", "start": 0, "end": 5, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_147-1-E2", "text": "To address the calculation errors and improve the quality of generated reasoning steps", "start": 37, "end": 50, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_147-1-E3", "text": "we extend PS prompting with more detailed instructions and derive PS+ prompting", "start": 50, "end": 62, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_147-1-E4", "text": "It consists of two components: first, devising a plan to divide the entire task into smaller subtasks, and then carrying out the subtasks according to the plan", "start": 10, "end": 37, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_147-1-E5", "text": "Plan-and-Solve (PS) Prompting", "start": 7, "end": 10, "entity_type": "UNK", "mention_type": "UNK"}], "relation_mentions": [], "event_mentions": [{"event_type": "Methods/Approach", "id": "ACL_23_P_147-1-EV0", "trigger": {"text": "propose", "start": 6, "end": 7}, "arguments": [{"entity_id": "ACL_23_P_147-1-E0", "text": "we", "role": "Agent"}, {"entity_id": "ACL_23_P_147-1-E1", "text": "To address the missing-step errors", "role": "Purpose"}, {"entity_id": "ACL_23_P_147-1-E2", "text": "To address the calculation errors and improve the quality of generated reasoning steps", "role": "Purpose"}, {"entity_id": "ACL_23_P_147-1-E3", "text": "we extend PS prompting with more detailed instructions and derive PS+ prompting", "role": "Method"}, {"entity_id": "ACL_23_P_147-1-E4", "text": "It consists of two components: first, devising a plan to divide the entire task into smaller subtasks, and then carrying out the subtasks according to the plan", "role": "Method"}, {"entity_id": "ACL_23_P_147-1-E5", "text": "Plan-and-Solve (PS) Prompting", "role": "PrimaryObject"}]}], "entity_coreference": [], "event_coreference": [], "tokens": ["To", "address", "the", "missing-step", "errors,", "we", "propose", "Plan-and-Solve", "(PS)", "Prompting.", "It", "consists", "of", "two", "components:", "first,", "devising", "a", "plan", "to", "divide", "the", "entire", "task", "into", "smaller", "subtasks,", "and", "then", "carrying", "out", "the", "subtasks", "according", "to", "the", "plan.", "To", "address", "the", "calculation", "errors", "and", "improve", "the", "quality", "of", "generated", "reasoning", "steps,", "we", "extend", "PS", "prompting", "with", "more", "detailed", "instructions", "and", "derive", "PS+", "prompting."], "pieces": ["To", "address", "the", "missing", "-", "step", "errors", ",", "we", "pro", "pose", "Plan", "-", "and", "-", "S", "olve", "(", "PS", ")", "Prom", "pt", "ing", ".", "It", "cons", "ists", "of", "two", "comp", "onents", ":", "first", ",", "dev", "ising", "a", "plan", "to", "div", "ide", "the", "ent", "ire", "task", "into", "small", "er", "sub", "t", "asks", ",", "and", "then", "carry", "ing", "out", "the", "sub", "t", "asks", "according", "to", "the", "plan", ".", "To", "address", "the", "cal", "culation", "errors", "and", "improve", "the", "quality", "of", "generated", "reason", "ing", "steps", ",", "we", "ext", "end", "PS", "prom", "pt", "ing", "with", "more", "det", "ailed", "in", "struct", "ions", "and", "der", "ive", "PS", "+", "prom", "pt", "ing", "."], "token_lens": [1, 1, 1, 3, 2, 1, 2, 6, 3, 4, 1, 2, 1, 1, 3, 2, 2, 1, 1, 1, 2, 1, 2, 1, 1, 2, 4, 1, 1, 2, 1, 1, 3, 1, 1, 1, 2, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 2, 2, 1, 2, 1, 3, 1, 1, 2, 3, 1, 2, 2, 4], "sentence": "To address the missing-step errors, we propose Plan-and-Solve (PS) Prompting. It consists of two components: first, devising a plan to divide the entire task into smaller subtasks, and then carrying out the subtasks according to the plan. To address the calculation errors and improve the quality of generated reasoning steps, we extend PS prompting with more detailed instructions and derive PS+ prompting.", "sentence_starts": [0]}
{"doc_id": "ACL_23_P_147", "wnd_id": "ACL_23_P_147-2", "entity_mentions": [{"id": "ACL_23_P_147-2-E0", "text": "We", "start": 0, "end": 1, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_147-2-E1", "text": "on ten datasets across three reasoning problems", "start": 6, "end": 13, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_147-2-E2", "text": "comparable to or exceeds Zero-shot-Program-of-Thought Prompting", "start": 35, "end": 41, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_147-2-E3", "text": "comparable performance with 8-shot CoT prompting on the math reasoning problem", "start": 43, "end": 54, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_147-2-E4", "text": "The experimental results over GPT-3 show that our proposed zero-shot prompting consistently outperforms Zero-shot-CoT across all datasets by a large margin", "start": 13, "end": 34, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_147-2-E5", "text": "our proposed prompting strategy", "start": 2, "end": 6, "entity_type": "UNK", "mention_type": "UNK"}], "relation_mentions": [], "event_mentions": [{"event_type": "Results/Findings", "id": "ACL_23_P_147-2-EV0", "trigger": {"text": "evaluate", "start": 1, "end": 2}, "arguments": [{"entity_id": "ACL_23_P_147-2-E0", "text": "We", "role": "Agent"}, {"entity_id": "ACL_23_P_147-2-E1", "text": "on ten datasets across three reasoning problems", "role": "Context"}, {"entity_id": "ACL_23_P_147-2-E2", "text": "comparable to or exceeds Zero-shot-Program-of-Thought Prompting", "role": "Results"}, {"entity_id": "ACL_23_P_147-2-E3", "text": "comparable performance with 8-shot CoT prompting on the math reasoning problem", "role": "Results"}, {"entity_id": "ACL_23_P_147-2-E4", "text": "The experimental results over GPT-3 show that our proposed zero-shot prompting consistently outperforms Zero-shot-CoT across all datasets by a large margin", "role": "Results"}, {"entity_id": "ACL_23_P_147-2-E5", "text": "our proposed prompting strategy", "role": "PrimaryObject"}]}], "entity_coreference": [], "event_coreference": [], "tokens": ["We", "evaluate", "our", "proposed", "prompting", "strategy", "on", "ten", "datasets", "across", "three", "reasoning", "problems.", "The", "experimental", "results", "over", "GPT-3", "show", "that", "our", "proposed", "zero-shot", "prompting", "consistently", "outperforms", "Zero-shot-CoT", "across", "all", "datasets", "by", "a", "large", "margin,", "is", "comparable", "to", "or", "exceeds", "Zero-shot-Program-of-Thought", "Prompting,", "and", "has", "comparable", "performance", "with", "8-shot", "CoT", "prompting", "on", "the", "math", "reasoning", "problem."], "pieces": ["We", "evaluate", "our", "prop", "osed", "prom", "pt", "ing", "str", "ategy", "on", "ten", "dat", "as", "ets", "ac", "ross", "three", "reason", "ing", "pro", "blems", ".", "The", "exper", "imental", "results", "over", "G", "PT", "-", "3", "show", "that", "our", "prop", "osed", "zero", "-", "shot", "prom", "pt", "ing", "cons", "ist", "ently", "out", "per", "forms", "Zero", "-", "shot", "-", "Co", "T", "ac", "ross", "all", "dat", "as", "ets", "by", "a", "large", "margin", ",", "is", "com", "parable", "to", "or", "ex", "ceed", "s", "Zero", "-", "shot", "-", "Program", "-", "of", "-", "Th", "ought", "Prom", "pt", "ing", ",", "and", "has", "com", "parable", "performance", "with", "8", "-", "shot", "Co", "T", "prom", "pt", "ing", "on", "the", "math", "reason", "ing", "problem", "."], "token_lens": [1, 1, 1, 2, 3, 2, 1, 1, 3, 2, 1, 2, 3, 1, 2, 1, 1, 4, 1, 1, 1, 2, 3, 3, 3, 3, 6, 2, 1, 3, 1, 1, 1, 2, 1, 2, 1, 1, 3, 10, 4, 1, 1, 2, 1, 1, 3, 2, 3, 1, 1, 1, 2, 2], "sentence": "We evaluate our proposed prompting strategy on ten datasets across three reasoning problems. The experimental results over GPT-3 show that our proposed zero-shot prompting consistently outperforms Zero-shot-CoT across all datasets by a large margin, is comparable to or exceeds Zero-shot-Program-of-Thought Prompting, and has comparable performance with 8-shot CoT prompting on the math reasoning problem.", "sentence_starts": [0]}
{"doc_id": "ACL_23_P_111", "wnd_id": "ACL_23_P_111-0", "entity_mentions": [{"id": "ACL_23_P_111-0-E0", "text": "we", "start": 43, "end": 44, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_111-0-E1", "text": "It has been commonly observed that a teacher model with superior performance does not necessarily result in a stronger student", "start": 0, "end": 20, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_111-0-E2", "text": "to determine the impact of distillation from each training sample on the student\u2019s generalization ability", "start": 50, "end": 65, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_111-0-E3", "text": "In order to enhance the guidance of the teacher training process", "start": 32, "end": 43, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_111-0-E4", "text": "discrepancy between current teacher training practices and effective knowledge transfer", "start": 22, "end": 32, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_111-0-E5", "text": "the concept of distillation influence", "start": 45, "end": 50, "entity_type": "UNK", "mention_type": "UNK"}], "relation_mentions": [], "event_mentions": [{"event_type": "Background/Introduction", "id": "ACL_23_P_111-0-EV0", "trigger": {"text": "introduce", "start": 44, "end": 45}, "arguments": [{"entity_id": "ACL_23_P_111-0-E0", "text": "we", "role": "Agent"}, {"entity_id": "ACL_23_P_111-0-E1", "text": "It has been commonly observed that a teacher model with superior performance does not necessarily result in a stronger student", "role": "Context"}, {"entity_id": "ACL_23_P_111-0-E2", "text": "to determine the impact of distillation from each training sample on the student\u2019s generalization ability", "role": "Purpose"}, {"entity_id": "ACL_23_P_111-0-E3", "text": "In order to enhance the guidance of the teacher training process", "role": "Purpose"}, {"entity_id": "ACL_23_P_111-0-E4", "text": "discrepancy between current teacher training practices and effective knowledge transfer", "role": "Challenge"}, {"entity_id": "ACL_23_P_111-0-E5", "text": "the concept of distillation influence", "role": "PrimaryObject"}]}], "entity_coreference": [], "event_coreference": [], "tokens": ["It", "has", "been", "commonly", "observed", "that", "a", "teacher", "model", "with", "superior", "performance", "does", "not", "necessarily", "result", "in", "a", "stronger", "student,", "highlighting", "a", "discrepancy", "between", "current", "teacher", "training", "practices", "and", "effective", "knowledge", "transfer.", "In", "order", "to", "enhance", "the", "guidance", "of", "the", "teacher", "training", "process,", "we", "introduce", "the", "concept", "of", "distillation", "influence", "to", "determine", "the", "impact", "of", "distillation", "from", "each", "training", "sample", "on", "the", "student\u2019s", "generalization", "ability."], "pieces": ["It", "has", "been", "common", "ly", "ob", "served", "that", "a", "te", "acher", "model", "with", "super", "ior", "performance", "does", "not", "necess", "arily", "result", "in", "a", "strong", "er", "student", ",", "high", "lighting", "a", "disc", "rep", "ancy", "between", "current", "te", "acher", "training", "pract", "ices", "and", "effective", "knowledge", "transfer", ".", "In", "order", "to", "enh", "ance", "the", "gu", "id", "ance", "of", "the", "te", "acher", "training", "process", ",", "we", "introdu", "ce", "the", "concept", "of", "dist", "illation", "inf", "luence", "to", "d", "eter", "mine", "the", "impact", "of", "dist", "illation", "from", "each", "training", "sample", "on", "the", "student", "\u00e2\u0122", "\u013b", "s", "general", "ization", "ability", "."], "token_lens": [1, 1, 1, 2, 2, 1, 1, 2, 1, 1, 2, 1, 1, 1, 2, 1, 1, 1, 2, 2, 2, 1, 3, 1, 1, 2, 1, 2, 1, 1, 1, 2, 1, 1, 1, 2, 1, 3, 1, 1, 2, 1, 2, 1, 2, 1, 1, 1, 2, 2, 1, 3, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 4, 2, 2], "sentence": "It has been commonly observed that a teacher model with superior performance does not necessarily result in a stronger student, highlighting a discrepancy between current teacher training practices and effective knowledge transfer. In order to enhance the guidance of the teacher training process, we introduce the concept of distillation influence to determine the impact of distillation from each training sample on the student\u2019s generalization ability.", "sentence_starts": [0]}
{"doc_id": "ACL_23_P_111", "wnd_id": "ACL_23_P_111-1", "entity_mentions": [{"id": "ACL_23_P_111-1-E0", "text": "we", "start": 3, "end": 4, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_111-1-E1", "text": "By prioritizing samples that are likely to enhance the student\u2019s generalization ability", "start": 23, "end": 35, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_111-1-E2", "text": "our LGTM outperforms 10 common knowledge distillation baselines on 6 text classification tasks in the GLUE benchmark", "start": 35, "end": 52, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_111-1-E3", "text": "Learning Good Teacher Matters (LGTM)", "start": 5, "end": 10, "entity_type": "UNK", "mention_type": "UNK"}], "relation_mentions": [], "event_mentions": [{"event_type": "Methods/Approach", "id": "ACL_23_P_111-1-EV0", "trigger": {"text": "propose", "start": 4, "end": 5}, "arguments": [{"entity_id": "ACL_23_P_111-1-E0", "text": "we", "role": "Agent"}, {"entity_id": "ACL_23_P_111-1-E1", "text": "By prioritizing samples that are likely to enhance the student\u2019s generalization ability", "role": "Method"}, {"entity_id": "ACL_23_P_111-1-E2", "text": "our LGTM outperforms 10 common knowledge distillation baselines on 6 text classification tasks in the GLUE benchmark", "role": "Results"}, {"entity_id": "ACL_23_P_111-1-E3", "text": "Learning Good Teacher Matters (LGTM)", "role": "PrimaryObject"}]}], "entity_coreference": [], "event_coreference": [], "tokens": ["In", "this", "paper,", "we", "propose", "Learning", "Good", "Teacher", "Matters", "(LGTM),", "an", "efficient", "training", "technique", "for", "incorporating", "distillation", "influence", "into", "the", "teacher\u2019s", "learning", "process.", "By", "prioritizing", "samples", "that", "are", "likely", "to", "enhance", "the", "student\u2019s", "generalization", "ability,", "our", "LGTM", "outperforms", "10", "common", "knowledge", "distillation", "baselines", "on", "6", "text", "classification", "tasks", "in", "the", "GLUE", "benchmark."], "pieces": ["In", "this", "paper", ",", "we", "pro", "pose", "Learning", "Good", "Te", "acher", "Mat", "ters", "(", "LG", "TM", "),", "an", "efficient", "training", "techn", "ique", "for", "inc", "orpor", "ating", "dist", "illation", "inf", "luence", "into", "the", "te", "acher", "\u00e2\u0122", "\u013b", "s", "learning", "process", ".", "By", "pri", "or", "it", "izing", "s", "amples", "that", "are", "likely", "to", "enh", "ance", "the", "student", "\u00e2\u0122", "\u013b", "s", "general", "ization", "ability", ",", "our", "LG", "TM", "out", "per", "forms", "10", "common", "knowledge", "dist", "illation", "bas", "elines", "on", "6", "text", "class", "ification", "t", "asks", "in", "the", "GL", "UE", "bench", "mark", "."], "token_lens": [1, 1, 2, 1, 2, 1, 1, 2, 2, 4, 1, 1, 1, 2, 1, 3, 2, 2, 1, 1, 5, 1, 2, 1, 4, 2, 1, 1, 1, 1, 2, 1, 4, 2, 2, 1, 2, 3, 1, 1, 1, 2, 2, 1, 1, 1, 2, 2, 1, 1, 2, 3], "sentence": "In this paper, we propose Learning Good Teacher Matters (LGTM), an efficient training technique for incorporating distillation influence into the teacher\u2019s learning process. By prioritizing samples that are likely to enhance the student\u2019s generalization ability, our LGTM outperforms 10 common knowledge distillation baselines on 6 text classification tasks in the GLUE benchmark.", "sentence_starts": [0]}
{"doc_id": "ACL_23_P_619", "wnd_id": "ACL_23_P_619-0", "entity_mentions": [{"id": "ACL_23_P_619-0-E0", "text": "Most research on stylized image captioning", "start": 0, "end": 6, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_619-0-E1", "text": "unlike previous single-sentence captions whose style is mostly embodied in distinctive words or phrases", "start": 27, "end": 41, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_619-0-E2", "text": "real-world styles are likely to be implied at the syntactic and discourse levels", "start": 41, "end": 54, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_619-0-E3", "text": "style-specific captions", "start": 9, "end": 11, "entity_type": "UNK", "mention_type": "UNK"}], "relation_mentions": [], "event_mentions": [{"event_type": "Background/Introduction", "id": "ACL_23_P_619-0-EV0", "trigger": {"text": "aims to generate", "start": 6, "end": 9}, "arguments": [{"entity_id": "ACL_23_P_619-0-E0", "text": "Most research on stylized image captioning", "role": "Agent"}, {"entity_id": "ACL_23_P_619-0-E1", "text": "unlike previous single-sentence captions whose style is mostly embodied in distinctive words or phrases", "role": "Analysis"}, {"entity_id": "ACL_23_P_619-0-E2", "text": "real-world styles are likely to be implied at the syntactic and discourse levels", "role": "Challenge"}, {"entity_id": "ACL_23_P_619-0-E3", "text": "style-specific captions", "role": "PrimaryObject"}]}], "entity_coreference": [], "event_coreference": [], "tokens": ["Most", "research", "on", "stylized", "image", "captioning", "aims", "to", "generate", "style-specific", "captions", "using", "unpaired", "text,", "and", "has", "achieved", "impressive", "performance", "for", "simple", "styles", "like", "positive", "and", "negative.", "However,", "unlike", "previous", "single-sentence", "captions", "whose", "style", "is", "mostly", "embodied", "in", "distinctive", "words", "or", "phrases,", "real-world", "styles", "are", "likely", "to", "be", "implied", "at", "the", "syntactic", "and", "discourse", "levels."], "pieces": ["Most", "research", "on", "st", "yl", "ized", "image", "ca", "ption", "ing", "aim", "s", "to", "gener", "ate", "style", "-", "specific", "capt", "ions", "using", "un", "pa", "ired", "text", ",", "and", "has", "ach", "ieved", "imp", "ressive", "performance", "for", "simple", "styles", "like", "positive", "and", "negative", ".", "However", ",", "un", "like", "pre", "vious", "single", "-", "sent", "ence", "capt", "ions", "whose", "style", "is", "mostly", "emb", "odied", "in", "dist", "inct", "ive", "words", "or", "ph", "r", "ases", ",", "real", "-", "world", "styles", "are", "likely", "to", "be", "impl", "ied", "at", "the", "sy", "nt", "actic", "and", "disc", "ourse", "levels", "."], "token_lens": [1, 1, 1, 3, 1, 3, 2, 1, 2, 3, 2, 1, 3, 2, 1, 1, 2, 2, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 4, 2, 1, 1, 1, 1, 2, 1, 3, 1, 1, 4, 3, 1, 1, 1, 1, 1, 2, 1, 1, 3, 1, 2, 2], "sentence": "Most research on stylized image captioning aims to generate style-specific captions using unpaired text, and has achieved impressive performance for simple styles like positive and negative. However, unlike previous single-sentence captions whose style is mostly embodied in distinctive words or phrases, real-world styles are likely to be implied at the syntactic and discourse levels.", "sentence_starts": [0]}
{"doc_id": "ACL_23_P_619", "wnd_id": "ACL_23_P_619-1", "entity_mentions": [{"id": "ACL_23_P_619-1-E0", "text": "we", "start": 3, "end": 4, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_619-1-E1", "text": "We propose a multitasking memory-augmented framework called StyleVSG, which is jointly trained on factual visual storytelling data and unpaired style corpus, achieving a trade-off between style accuracy and visual relevance", "start": 29, "end": 59, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_619-1-E2", "text": "StyleVSG learns to reconstruct the stylistic story from roughly parallel visual inputs mined with the CLIP model, avoiding problems caused by random mapping in previous methods", "start": 64, "end": 90, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_619-1-E3", "text": "a memory module is designed to preserve the consistency and coherence of generated stories", "start": 91, "end": 105, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_619-1-E4", "text": "a new task of Stylized Visual Storytelling (SVST)", "start": 5, "end": 13, "entity_type": "UNK", "mention_type": "UNK"}], "relation_mentions": [], "event_mentions": [{"event_type": "Methods/Approach", "id": "ACL_23_P_619-1-EV0", "trigger": {"text": "introduce", "start": 4, "end": 5}, "arguments": [{"entity_id": "ACL_23_P_619-1-E0", "text": "we", "role": "Agent"}, {"entity_id": "ACL_23_P_619-1-E1", "text": "We propose a multitasking memory-augmented framework called StyleVSG, which is jointly trained on factual visual storytelling data and unpaired style corpus, achieving a trade-off between style accuracy and visual relevance", "role": "Method"}, {"entity_id": "ACL_23_P_619-1-E2", "text": "StyleVSG learns to reconstruct the stylistic story from roughly parallel visual inputs mined with the CLIP model, avoiding problems caused by random mapping in previous methods", "role": "Method"}, {"entity_id": "ACL_23_P_619-1-E3", "text": "a memory module is designed to preserve the consistency and coherence of generated stories", "role": "Method"}, {"entity_id": "ACL_23_P_619-1-E4", "text": "a new task of Stylized Visual Storytelling (SVST)", "role": "PrimaryObject"}]}], "entity_coreference": [], "event_coreference": [], "tokens": ["In", "this", "work,", "we", "introduce", "a", "new", "task", "of", "Stylized", "Visual", "Storytelling", "(SVST),", "which", "aims", "to", "describe", "a", "photo", "stream", "with", "stylized", "stories", "that", "are", "more", "expressive", "and", "attractive.", "We", "propose", "a", "multitasking", "memory-augmented", "framework", "called", "StyleVSG,", "which", "is", "jointly", "trained", "on", "factual", "visual", "storytelling", "data", "and", "unpaired", "style", "corpus,", "achieving", "a", "trade-off", "between", "style", "accuracy", "and", "visual", "relevance.", "Particularly", "for", "unpaired", "stylized", "text,", "StyleVSG", "learns", "to", "reconstruct", "the", "stylistic", "story", "from", "roughly", "parallel", "visual", "inputs", "mined", "with", "the", "CLIP", "model,", "avoiding", "problems", "caused", "by", "random", "mapping", "in", "previous", "methods.", "Furthermore,", "a", "memory", "module", "is", "designed", "to", "preserve", "the", "consistency", "and", "coherence", "of", "generated", "stories."], "pieces": ["In", "this", "work", ",", "we", "introdu", "ce", "a", "new", "task", "of", "Sty", "l", "ized", "Visual", "Story", "telling", "(", "S", "V", "ST", "),", "which", "aim", "s", "to", "desc", "ribe", "a", "photo", "stream", "with", "st", "yl", "ized", "stories", "that", "are", "more", "exp", "ressive", "and", "att", "ractive", ".", "We", "pro", "pose", "a", "mult", "it", "asking", "memory", "-", "au", "gment", "ed", "framework", "called", "Style", "VS", "G", ",", "which", "is", "j", "oint", "ly", "trained", "on", "fact", "ual", "visual", "story", "telling", "data", "and", "un", "pa", "ired", "style", "cor", "p", "us", ",", "ach", "ieving", "a", "trade", "-", "off", "between", "style", "acc", "uracy", "and", "visual", "re", "lev", "ance", ".", "Part", "icularly", "for", "un", "pa", "ired", "st", "yl", "ized", "text", ",", "Style", "VS", "G", "learn", "s", "to", "re", "construct", "the", "st", "yl", "istic", "story", "from", "rough", "ly", "par", "allel", "visual", "input", "s", "min", "ed", "with", "the", "CL", "IP", "model", ",", "avoid", "ing", "pro", "blems", "ca", "used", "by", "random", "m", "apping", "in", "pre", "vious", "method", "s", ".", "Furthermore", ",", "a", "memory", "module", "is", "designed", "to", "pres", "erve", "the", "cons", "ist", "ency", "and", "co", "herence", "of", "generated", "stories", "."], "token_lens": [1, 1, 2, 1, 2, 1, 1, 1, 1, 3, 1, 2, 5, 1, 2, 1, 2, 1, 1, 1, 1, 3, 1, 1, 1, 1, 2, 1, 3, 1, 2, 1, 3, 5, 1, 1, 4, 1, 1, 3, 1, 1, 2, 1, 2, 1, 1, 3, 1, 4, 2, 1, 3, 1, 1, 2, 1, 1, 4, 2, 1, 3, 3, 2, 3, 2, 1, 2, 1, 3, 1, 1, 2, 2, 1, 2, 2, 1, 1, 2, 2, 2, 2, 2, 1, 1, 2, 1, 2, 3, 2, 1, 1, 1, 1, 1, 1, 2, 1, 3, 1, 2, 1, 1, 2], "sentence": "In this work, we introduce a new task of Stylized Visual Storytelling (SVST), which aims to describe a photo stream with stylized stories that are more expressive and attractive. We propose a multitasking memory-augmented framework called StyleVSG, which is jointly trained on factual visual storytelling data and unpaired style corpus, achieving a trade-off between style accuracy and visual relevance. Particularly for unpaired stylized text, StyleVSG learns to reconstruct the stylistic story from roughly parallel visual inputs mined with the CLIP model, avoiding problems caused by random mapping in previous methods. Furthermore, a memory module is designed to preserve the consistency and coherence of generated stories.", "sentence_starts": [0]}
{"doc_id": "ACL_23_P_619", "wnd_id": "ACL_23_P_619-2", "entity_mentions": [{"id": "ACL_23_P_619-2-E0", "text": "Experiments", "start": 0, "end": 1, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_619-2-E1", "text": "our method can generate attractive and coherent stories with different styles such as fairy tale, romance, and humor", "start": 3, "end": 21, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_619-2-E2", "text": "The overall performance of our StyleVSG surpasses state-of-the-art methods on both automatic and human evaluation metrics", "start": 21, "end": 37, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_619-2-E3", "text": "our method can generate attractive and coherent stories with different styles such as fairy tale, romance, and humor", "start": 3, "end": 21, "entity_type": "UNK", "mention_type": "UNK"}], "relation_mentions": [], "event_mentions": [{"event_type": "Results/Findings", "id": "ACL_23_P_619-2-EV0", "trigger": {"text": "show", "start": 1, "end": 2}, "arguments": [{"entity_id": "ACL_23_P_619-2-E0", "text": "Experiments", "role": "Agent"}, {"entity_id": "ACL_23_P_619-2-E1", "text": "our method can generate attractive and coherent stories with different styles such as fairy tale, romance, and humor", "role": "Results"}, {"entity_id": "ACL_23_P_619-2-E2", "text": "The overall performance of our StyleVSG surpasses state-of-the-art methods on both automatic and human evaluation metrics", "role": "Results"}, {"entity_id": "ACL_23_P_619-2-E3", "text": "our method can generate attractive and coherent stories with different styles such as fairy tale, romance, and humor", "role": "PrimaryObject"}]}], "entity_coreference": [], "event_coreference": [], "tokens": ["Experiments", "show", "that", "our", "method", "can", "generate", "attractive", "and", "coherent", "stories", "with", "different", "styles", "such", "as", "fairy", "tale,", "romance,", "and", "humor.", "The", "overall", "performance", "of", "our", "StyleVSG", "surpasses", "state-of-the-art", "methods", "on", "both", "automatic", "and", "human", "evaluation", "metrics."], "pieces": ["Exper", "iments", "show", "that", "our", "method", "can", "gener", "ate", "att", "ractive", "and", "co", "herent", "stories", "with", "different", "styles", "such", "as", "f", "airy", "tale", ",", "rom", "ance", ",", "and", "hum", "or", ".", "The", "over", "all", "performance", "of", "our", "Style", "VS", "G", "sur", "pass", "es", "state", "-", "of", "-", "the", "-", "art", "method", "s", "on", "both", "automatic", "and", "human", "eval", "uation", "met", "rics", "."], "token_lens": [2, 1, 1, 1, 1, 1, 2, 2, 1, 2, 1, 1, 1, 1, 1, 1, 2, 2, 3, 1, 3, 1, 2, 1, 1, 1, 3, 3, 7, 2, 1, 1, 1, 1, 1, 2, 3], "sentence": "Experiments show that our method can generate attractive and coherent stories with different styles such as fairy tale, romance, and humor. The overall performance of our StyleVSG surpasses state-of-the-art methods on both automatic and human evaluation metrics.", "sentence_starts": [0]}
{"doc_id": "ACL_23_P_380", "wnd_id": "ACL_23_P_380-0", "entity_mentions": [{"id": "ACL_23_P_380-0-E0", "text": "this paper", "start": 35, "end": 37, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_380-0-E1", "text": "Grammatical error correction (GEC) can be divided into sequence-to-edit (Seq2Edit) and sequence-to-sequence (Seq2Seq) frameworks, both of which have their pros and cons", "start": 0, "end": 22, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_380-0-E2", "text": "To utilize the strengths and make up for the shortcomings of these frameworks", "start": 22, "end": 35, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_380-0-E3", "text": "a novel method, TemplateGEC", "start": 38, "end": 42, "entity_type": "UNK", "mention_type": "UNK"}], "relation_mentions": [], "event_mentions": [{"event_type": "Background/Introduction", "id": "ACL_23_P_380-0-EV0", "trigger": {"text": "proposes", "start": 37, "end": 38}, "arguments": [{"entity_id": "ACL_23_P_380-0-E0", "text": "this paper", "role": "Agent"}, {"entity_id": "ACL_23_P_380-0-E1", "text": "Grammatical error correction (GEC) can be divided into sequence-to-edit (Seq2Edit) and sequence-to-sequence (Seq2Seq) frameworks, both of which have their pros and cons", "role": "Context"}, {"entity_id": "ACL_23_P_380-0-E2", "text": "To utilize the strengths and make up for the shortcomings of these frameworks", "role": "Purpose"}, {"entity_id": "ACL_23_P_380-0-E3", "text": "a novel method, TemplateGEC", "role": "PrimaryObject"}]}], "entity_coreference": [], "event_coreference": [], "tokens": ["Grammatical", "error", "correction", "(GEC)", "can", "be", "divided", "into", "sequence-to-edit", "(Seq2Edit)", "and", "sequence-to-sequence", "(Seq2Seq)", "frameworks,", "both", "of", "which", "have", "their", "pros", "and", "cons.", "To", "utilize", "the", "strengths", "and", "make", "up", "for", "the", "shortcomings", "of", "these", "frameworks,", "this", "paper", "proposes", "a", "novel", "method,", "TemplateGEC,", "which", "capitalizes", "on", "the", "capabilities", "of", "both", "Seq2Edit", "and", "Seq2Seq", "frameworks", "in", "error", "detection", "and", "correction", "respectively."], "pieces": ["G", "ram", "matical", "error", "cor", "rection", "(", "G", "EC", ")", "can", "be", "div", "ided", "into", "sequence", "-", "to", "-", "edit", "(", "Se", "q", "2", "Edit", ")", "and", "sequence", "-", "to", "-", "sequence", "(", "Se", "q", "2", "Se", "q", ")", "fram", "eworks", ",", "both", "of", "which", "have", "their", "pro", "s", "and", "cons", ".", "To", "util", "ize", "the", "stre", "ng", "ths", "and", "make", "up", "for", "the", "short", "comings", "of", "these", "fram", "eworks", ",", "this", "paper", "pro", "poses", "a", "no", "vel", "method", ",", "Template", "G", "EC", ",", "which", "capital", "izes", "on", "the", "cap", "abilities", "of", "both", "Se", "q", "2", "Edit", "and", "Se", "q", "2", "Se", "q", "fram", "eworks", "in", "error", "det", "ection", "and", "cor", "rection", "respect", "ively", "."], "token_lens": [3, 1, 2, 4, 1, 1, 2, 1, 5, 6, 1, 5, 7, 3, 1, 1, 1, 1, 1, 2, 1, 2, 1, 2, 1, 3, 1, 1, 1, 1, 1, 2, 1, 1, 3, 1, 1, 2, 1, 2, 2, 4, 1, 2, 1, 1, 2, 1, 1, 4, 1, 5, 2, 1, 1, 2, 1, 2, 3], "sentence": "Grammatical error correction (GEC) can be divided into sequence-to-edit (Seq2Edit) and sequence-to-sequence (Seq2Seq) frameworks, both of which have their pros and cons. To utilize the strengths and make up for the shortcomings of these frameworks, this paper proposes a novel method, TemplateGEC, which capitalizes on the capabilities of both Seq2Edit and Seq2Seq frameworks in error detection and correction respectively.", "sentence_starts": [0]}
{"doc_id": "ACL_23_P_380", "wnd_id": "ACL_23_P_380-1", "entity_mentions": [{"id": "ACL_23_P_380-1-E0", "text": "TemplateGEC", "start": 0, "end": 1, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_380-1-E1", "text": "A Seq2Seq model is employed to enforce consistency between the predictions of different templates by utilizing consistency learning", "start": 16, "end": 34, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_380-1-E2", "text": "the detection labels from a Seq2Edit model", "start": 2, "end": 9, "entity_type": "UNK", "mention_type": "UNK"}], "relation_mentions": [], "event_mentions": [{"event_type": "Methods/Approach", "id": "ACL_23_P_380-1-EV0", "trigger": {"text": "utilizes", "start": 1, "end": 2}, "arguments": [{"entity_id": "ACL_23_P_380-1-E0", "text": "TemplateGEC", "role": "Agent"}, {"entity_id": "ACL_23_P_380-1-E1", "text": "A Seq2Seq model is employed to enforce consistency between the predictions of different templates by utilizing consistency learning", "role": "Method"}, {"entity_id": "ACL_23_P_380-1-E2", "text": "the detection labels from a Seq2Edit model", "role": "PrimaryObject"}]}], "entity_coreference": [], "event_coreference": [], "tokens": ["TemplateGEC", "utilizes", "the", "detection", "labels", "from", "a", "Seq2Edit", "model,", "to", "construct", "the", "template", "as", "the", "input.", "A", "Seq2Seq", "model", "is", "employed", "to", "enforce", "consistency", "between", "the", "predictions", "of", "different", "templates", "by", "utilizing", "consistency", "learning."], "pieces": ["Template", "G", "EC", "util", "izes", "the", "det", "ection", "lab", "els", "from", "a", "Se", "q", "2", "Edit", "model", ",", "to", "construct", "the", "template", "as", "the", "input", ".", "A", "Se", "q", "2", "Se", "q", "model", "is", "employed", "to", "en", "force", "cons", "ist", "ency", "between", "the", "pred", "ictions", "of", "different", "tem", "plates", "by", "util", "izing", "cons", "ist", "ency", "learning", "."], "token_lens": [3, 2, 1, 2, 2, 1, 1, 4, 2, 1, 1, 1, 1, 1, 1, 2, 1, 5, 1, 1, 1, 1, 2, 3, 1, 1, 2, 1, 1, 2, 1, 2, 3, 2], "sentence": "TemplateGEC utilizes the detection labels from a Seq2Edit model, to construct the template as the input. A Seq2Seq model is employed to enforce consistency between the predictions of different templates by utilizing consistency learning.", "sentence_starts": [0]}
{"doc_id": "ACL_23_P_380", "wnd_id": "ACL_23_P_380-2", "entity_mentions": [{"id": "ACL_23_P_380-2-E0", "text": "Experimental results", "start": 0, "end": 2, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_380-2-E1", "text": "Experimental results on the Chinese NLPCC18, English BEA19 and CoNLL14 benchmarks", "start": 0, "end": 11, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_380-2-E2", "text": "the effectiveness and robustness of TemplateGEC", "start": 12, "end": 18, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_380-2-E3", "text": "Further analysis reveals the potential of our method in performing human-in-the-loop GEC", "start": 18, "end": 30, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_380-2-E4", "text": "the effectiveness and robustness of TemplateGEC", "start": 12, "end": 18, "entity_type": "UNK", "mention_type": "UNK"}], "relation_mentions": [], "event_mentions": [{"event_type": "Results/Findings", "id": "ACL_23_P_380-2-EV0", "trigger": {"text": "show", "start": 11, "end": 12}, "arguments": [{"entity_id": "ACL_23_P_380-2-E0", "text": "Experimental results", "role": "Agent"}, {"entity_id": "ACL_23_P_380-2-E1", "text": "Experimental results on the Chinese NLPCC18, English BEA19 and CoNLL14 benchmarks", "role": "Context"}, {"entity_id": "ACL_23_P_380-2-E2", "text": "the effectiveness and robustness of TemplateGEC", "role": "Results"}, {"entity_id": "ACL_23_P_380-2-E3", "text": "Further analysis reveals the potential of our method in performing human-in-the-loop GEC", "role": "Results"}, {"entity_id": "ACL_23_P_380-2-E4", "text": "the effectiveness and robustness of TemplateGEC", "role": "PrimaryObject"}]}], "entity_coreference": [], "event_coreference": [], "tokens": ["Experimental", "results", "on", "the", "Chinese", "NLPCC18,", "English", "BEA19", "and", "CoNLL14", "benchmarks", "show", "the", "effectiveness", "and", "robustness", "of", "TemplateGEC.", "Further", "analysis", "reveals", "the", "potential", "of", "our", "method", "in", "performing", "human-in-the-loop", "GEC."], "pieces": ["Exper", "imental", "results", "on", "the", "Chinese", "N", "LP", "CC", "18", ",", "English", "BE", "A", "19", "and", "Co", "N", "LL", "14", "bench", "marks", "show", "the", "effect", "iveness", "and", "rob", "ust", "ness", "of", "Template", "G", "EC", ".", "Further", "analysis", "reve", "als", "the", "pot", "ential", "of", "our", "method", "in", "performing", "human", "-", "in", "-", "the", "-", "loop", "G", "EC", "."], "token_lens": [2, 1, 1, 1, 1, 5, 1, 3, 1, 4, 2, 1, 1, 2, 1, 3, 1, 4, 1, 1, 2, 1, 2, 1, 1, 1, 1, 1, 7, 3], "sentence": "Experimental results on the Chinese NLPCC18, English BEA19 and CoNLL14 benchmarks show the effectiveness and robustness of TemplateGEC. Further analysis reveals the potential of our method in performing human-in-the-loop GEC.", "sentence_starts": [0]}
{"doc_id": "ACL_23_P_210", "wnd_id": "ACL_23_P_210-0", "entity_mentions": [{"id": "ACL_23_P_210-0-E0", "text": "Relation extraction (RE)", "start": 0, "end": 3, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_210-0-E1", "text": "extension to multilingual settings has been hindered by the lack of supervised resources comparable in size to large English datasets such as TACRED", "start": 11, "end": 34, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_210-0-E2", "text": "a fundamental task in information extraction", "start": 4, "end": 10, "entity_type": "UNK", "mention_type": "UNK"}], "relation_mentions": [], "event_mentions": [{"event_type": "Background/Introduction", "id": "ACL_23_P_210-0-EV0", "trigger": {"text": "is", "start": 3, "end": 4}, "arguments": [{"entity_id": "ACL_23_P_210-0-E0", "text": "Relation extraction (RE)", "role": "Agent"}, {"entity_id": "ACL_23_P_210-0-E1", "text": "extension to multilingual settings has been hindered by the lack of supervised resources comparable in size to large English datasets such as TACRED", "role": "Challenge"}, {"entity_id": "ACL_23_P_210-0-E2", "text": "a fundamental task in information extraction", "role": "PrimaryObject"}]}], "entity_coreference": [], "event_coreference": [], "tokens": ["Relation", "extraction", "(RE)", "is", "a", "fundamental", "task", "in", "information", "extraction,", "whose", "extension", "to", "multilingual", "settings", "has", "been", "hindered", "by", "the", "lack", "of", "supervised", "resources", "comparable", "in", "size", "to", "large", "English", "datasets", "such", "as", "TACRED", "(Zhang", "et", "al.,", "2017)."], "pieces": ["Rel", "ation", "ext", "raction", "(", "RE", ")", "is", "a", "fund", "amental", "task", "in", "information", "ext", "raction", ",", "whose", "ext", "ension", "to", "mult", "ilingual", "settings", "has", "been", "h", "ind", "ered", "by", "the", "l", "ack", "of", "super", "vised", "resources", "com", "parable", "in", "size", "to", "large", "English", "dat", "as", "ets", "such", "as", "T", "AC", "RED", "(", "Z", "hang", "et", "al", ".,", "2017", ")."], "token_lens": [2, 2, 3, 1, 1, 2, 1, 1, 1, 3, 1, 2, 1, 2, 1, 1, 1, 3, 1, 1, 2, 1, 2, 1, 2, 1, 1, 1, 1, 1, 3, 1, 1, 3, 3, 1, 2, 2], "sentence": "Relation extraction (RE) is a fundamental task in information extraction, whose extension to multilingual settings has been hindered by the lack of supervised resources comparable in size to large English datasets such as TACRED (Zhang et al., 2017).", "sentence_starts": [0]}
{"doc_id": "ACL_23_P_210", "wnd_id": "ACL_23_P_210-1", "entity_mentions": [{"id": "ACL_23_P_210-1-E0", "text": "we", "start": 4, "end": 5, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_210-1-E1", "text": "We analyze translation and annotation projection quality, identify error categories, and experimentally evaluate fine-tuned pretrained mono- and multilingual language models in common transfer learning scenarios", "start": 31, "end": 56, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_210-1-E2", "text": "the MultiTACRED dataset", "start": 6, "end": 9, "entity_type": "UNK", "mention_type": "UNK"}], "relation_mentions": [], "event_mentions": [{"event_type": "Methods/Approach", "id": "ACL_23_P_210-1-EV0", "trigger": {"text": "introduce", "start": 5, "end": 6}, "arguments": [{"entity_id": "ACL_23_P_210-1-E0", "text": "we", "role": "Agent"}, {"entity_id": "ACL_23_P_210-1-E1", "text": "We analyze translation and annotation projection quality, identify error categories, and experimentally evaluate fine-tuned pretrained mono- and multilingual language models in common transfer learning scenarios", "role": "Method"}, {"entity_id": "ACL_23_P_210-1-E2", "text": "the MultiTACRED dataset", "role": "PrimaryObject"}]}], "entity_coreference": [], "event_coreference": [], "tokens": ["To", "address", "this", "gap,", "we", "introduce", "the", "MultiTACRED", "dataset,", "covering", "12", "typologically", "diverse", "languages", "from", "9", "language", "families,", "which", "is", "created", "by", "machine-translating", "TACRED", "instances", "and", "automatically", "projecting", "their", "entity", "annotations.", "We", "analyze", "translation", "and", "annotation", "projection", "quality,", "identify", "error", "categories,", "and", "experimentally", "evaluate", "fine-tuned", "pretrained", "mono-", "and", "multilingual", "language", "models", "in", "common", "transfer", "learning", "scenarios."], "pieces": ["To", "address", "this", "gap", ",", "we", "introdu", "ce", "the", "Multi", "T", "AC", "RED", "dat", "as", "et", ",", "cover", "ing", "12", "typ", "ologically", "d", "iverse", "l", "anguages", "from", "9", "language", "fam", "ilies", ",", "which", "is", "created", "by", "machine", "-", "trans", "l", "ating", "T", "AC", "RED", "inst", "ances", "and", "aut", "om", "atically", "project", "ing", "their", "entity", "annot", "ations", ".", "We", "analy", "ze", "translation", "and", "ann", "otation", "project", "ion", "quality", ",", "ident", "ify", "error", "c", "ategories", ",", "and", "exper", "iment", "ally", "evaluate", "fine", "-", "tun", "ed", "pret", "rained", "mon", "o", "-", "and", "mult", "ilingual", "language", "models", "in", "common", "transfer", "learning", "sc", "en", "arios", "."], "token_lens": [1, 1, 1, 2, 1, 2, 1, 4, 4, 2, 1, 2, 2, 2, 1, 1, 1, 3, 1, 1, 1, 1, 5, 3, 2, 1, 3, 2, 1, 1, 3, 1, 2, 1, 1, 2, 2, 2, 2, 1, 3, 1, 3, 1, 4, 2, 3, 1, 2, 1, 1, 1, 1, 1, 1, 4], "sentence": "To address this gap, we introduce the MultiTACRED dataset, covering 12 typologically diverse languages from 9 language families, which is created by machine-translating TACRED instances and automatically projecting their entity annotations. We analyze translation and annotation projection quality, identify error categories, and experimentally evaluate fine-tuned pretrained mono- and multilingual language models in common transfer learning scenarios.", "sentence_starts": [0]}
{"doc_id": "ACL_23_P_210", "wnd_id": "ACL_23_P_210-2", "entity_mentions": [{"id": "ACL_23_P_210-2-E0", "text": "Our analyses", "start": 0, "end": 2, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_210-2-E1", "text": "We find monolingual RE model performance to be comparable to the English original for many of the target languages", "start": 31, "end": 50, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_210-2-E2", "text": "multilingual models trained on a combination of English and target language data can outperform their monolingual counterparts.", "start": 52, "end": 69, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_210-2-E3", "text": "pronoun-dropping, compounding and inflection, that degrade dataset quality and RE model performance", "start": 96, "end": 108, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_210-2-E4", "text": "we also observe a variety of translation and annotation projection errors, both due to the MT systems and linguistic features of the target languages", "start": 70, "end": 94, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_210-2-E5", "text": "machine translation is a viable strategy to transfer RE instances", "start": 4, "end": 14, "entity_type": "UNK", "mention_type": "UNK"}], "relation_mentions": [], "event_mentions": [{"event_type": "Results/Findings", "id": "ACL_23_P_210-2-EV0", "trigger": {"text": "show", "start": 2, "end": 3}, "arguments": [{"entity_id": "ACL_23_P_210-2-E0", "text": "Our analyses", "role": "Agent"}, {"entity_id": "ACL_23_P_210-2-E1", "text": "We find monolingual RE model performance to be comparable to the English original for many of the target languages", "role": "Results"}, {"entity_id": "ACL_23_P_210-2-E2", "text": "multilingual models trained on a combination of English and target language data can outperform their monolingual counterparts.", "role": "Results"}, {"entity_id": "ACL_23_P_210-2-E3", "text": "pronoun-dropping, compounding and inflection, that degrade dataset quality and RE model performance", "role": "Analysis"}, {"entity_id": "ACL_23_P_210-2-E4", "text": "we also observe a variety of translation and annotation projection errors, both due to the MT systems and linguistic features of the target languages", "role": "Challenge"}, {"entity_id": "ACL_23_P_210-2-E5", "text": "machine translation is a viable strategy to transfer RE instances", "role": "PrimaryObject"}]}], "entity_coreference": [], "event_coreference": [], "tokens": ["Our", "analyses", "show", "that", "machine", "translation", "is", "a", "viable", "strategy", "to", "transfer", "RE", "instances,", "with", "native", "speakers", "judging", "more", "than", "83%", "of", "the", "translated", "instances", "to", "be", "linguistically", "and", "semantically", "acceptable.", "We", "find", "monolingual", "RE", "model", "performance", "to", "be", "comparable", "to", "the", "English", "original", "for", "many", "of", "the", "target", "languages,", "and", "that", "multilingual", "models", "trained", "on", "a", "combination", "of", "English", "and", "target", "language", "data", "can", "outperform", "their", "monolingual", "counterparts.", "However,", "we", "also", "observe", "a", "variety", "of", "translation", "and", "annotation", "projection", "errors,", "both", "due", "to", "the", "MT", "systems", "and", "linguistic", "features", "of", "the", "target", "languages,", "such", "as", "pronoun-dropping,", "compounding", "and", "inflection,", "that", "degrade", "dataset", "quality", "and", "RE", "model", "performance."], "pieces": ["Our", "an", "alyses", "show", "that", "machine", "translation", "is", "a", "v", "iable", "str", "ategy", "to", "transfer", "RE", "inst", "ances", ",", "with", "native", "spe", "akers", "jud", "ging", "more", "than", "83", "%", "of", "the", "trans", "lated", "inst", "ances", "to", "be", "ling", "u", "istically", "and", "sem", "antically", "acceptable", ".", "We", "find", "mon", "oling", "ual", "RE", "model", "performance", "to", "be", "com", "parable", "to", "the", "English", "original", "for", "many", "of", "the", "target", "l", "anguages", ",", "and", "that", "mult", "ilingual", "models", "trained", "on", "a", "comb", "ination", "of", "English", "and", "target", "language", "data", "can", "out", "per", "form", "their", "mon", "oling", "ual", "counter", "parts", ".", "However", ",", "we", "also", "ob", "ser", "ve", "a", "var", "iety", "of", "translation", "and", "ann", "otation", "project", "ion", "errors", ",", "both", "due", "to", "the", "MT", "system", "s", "and", "ling", "u", "istic", "features", "of", "the", "target", "l", "anguages", ",", "such", "as", "pron", "oun", "-", "dropping", ",", "comp", "ounding", "and", "inf", "lection", ",", "that", "deg", "rade", "dat", "as", "et", "quality", "and", "RE", "model", "performance", "."], "token_lens": [1, 2, 1, 1, 1, 1, 1, 1, 2, 2, 1, 1, 1, 3, 1, 1, 2, 2, 1, 1, 2, 1, 1, 2, 2, 1, 1, 3, 1, 2, 2, 1, 1, 3, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 3, 1, 1, 2, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 3, 1, 3, 3, 2, 1, 1, 3, 1, 2, 1, 1, 1, 2, 2, 2, 1, 1, 1, 1, 1, 2, 1, 3, 1, 1, 1, 1, 3, 1, 1, 5, 2, 1, 3, 1, 2, 3, 1, 1, 1, 1, 2], "sentence": "Our analyses show that machine translation is a viable strategy to transfer RE instances, with native speakers judging more than 83% of the translated instances to be linguistically and semantically acceptable. We find monolingual RE model performance to be comparable to the English original for many of the target languages, and that multilingual models trained on a combination of English and target language data can outperform their monolingual counterparts. However, we also observe a variety of translation and annotation projection errors, both due to the MT systems and linguistic features of the target languages, such as pronoun-dropping, compounding and inflection, that degrade dataset quality and RE model performance.", "sentence_starts": [0]}
{"doc_id": "ACL_23_P_222", "wnd_id": "ACL_23_P_222-0", "entity_mentions": [{"id": "ACL_23_P_222-0-E0", "text": "self-training", "start": 6, "end": 7, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_222-0-E1", "text": "to bridge the linguistic gap by training on pseudo-labeled target-language data", "start": 10, "end": 21, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_222-0-E2", "text": "due to sub-optimal performance on target languages, the pseudo labels are often noisy and limit the overall performance", "start": 22, "end": 40, "entity_type": "UNK", "mention_type": "UNK"}], "relation_mentions": [], "event_mentions": [{"event_type": "Background/Introduction", "id": "ACL_23_P_222-0-EV0", "trigger": {"text": "is commonly used", "start": 7, "end": 10}, "arguments": [{"entity_id": "ACL_23_P_222-0-E0", "text": "self-training", "role": "Agent"}, {"entity_id": "ACL_23_P_222-0-E1", "text": "to bridge the linguistic gap by training on pseudo-labeled target-language data", "role": "Purpose"}, {"entity_id": "ACL_23_P_222-0-E2", "text": "due to sub-optimal performance on target languages, the pseudo labels are often noisy and limit the overall performance", "role": "Challenge"}]}], "entity_coreference": [], "event_coreference": [], "tokens": ["In", "cross-lingual", "named", "entity", "recognition", "(NER),", "self-training", "is", "commonly", "used", "to", "bridge", "the", "linguistic", "gap", "by", "training", "on", "pseudo-labeled", "target-language", "data.", "However,", "due", "to", "sub-optimal", "performance", "on", "target", "languages,", "the", "pseudo", "labels", "are", "often", "noisy", "and", "limit", "the", "overall", "performance."], "pieces": ["In", "cross", "-", "ling", "ual", "named", "entity", "recogn", "ition", "(", "NER", "),", "self", "-", "training", "is", "common", "ly", "used", "to", "bridge", "the", "ling", "u", "istic", "gap", "by", "training", "on", "pse", "udo", "-", "label", "ed", "target", "-", "language", "data", ".", "However", ",", "due", "to", "sub", "-", "opt", "imal", "performance", "on", "target", "l", "anguages", ",", "the", "pse", "udo", "lab", "els", "are", "often", "no", "isy", "and", "limit", "the", "over", "all", "performance", "."], "token_lens": [1, 4, 1, 1, 2, 3, 3, 1, 2, 1, 1, 1, 1, 3, 1, 1, 1, 1, 5, 3, 2, 2, 1, 1, 4, 1, 1, 1, 3, 1, 2, 2, 1, 1, 2, 1, 1, 1, 2, 2], "sentence": "In cross-lingual named entity recognition (NER), self-training is commonly used to bridge the linguistic gap by training on pseudo-labeled target-language data. However, due to sub-optimal performance on target languages, the pseudo labels are often noisy and limit the overall performance.", "sentence_starts": [0]}
{"doc_id": "ACL_23_P_222", "wnd_id": "ACL_23_P_222-1", "entity_mentions": [{"id": "ACL_23_P_222-1-E0", "text": "we", "start": 3, "end": 4, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_222-1-E1", "text": "Our proposed method, namely ContProto mainly comprises two components", "start": 23, "end": 32, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_222-1-E2", "text": "contrastive self-training", "start": 33, "end": 35, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_222-1-E3", "text": "prototype-based pseudo-labeling", "start": 37, "end": 39, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_222-1-E4", "text": "contrastive self-training facilitates span classification by separating clusters of different classes, and enhances cross-lingual transferability by producing closely-aligned representations between the source and target language", "start": 40, "end": 65, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_222-1-E5", "text": "prototype-based pseudo-labeling effectively improves the accuracy of pseudo labels during training", "start": 66, "end": 77, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_222-1-E6", "text": "self-training for cross-lingual NER", "start": 7, "end": 11, "entity_type": "UNK", "mention_type": "UNK"}], "relation_mentions": [], "event_mentions": [{"event_type": "Methods/Approach", "id": "ACL_23_P_222-1-EV0", "trigger": {"text": "aim to improve", "start": 4, "end": 7}, "arguments": [{"entity_id": "ACL_23_P_222-1-E0", "text": "we", "role": "Agent"}, {"entity_id": "ACL_23_P_222-1-E1", "text": "Our proposed method, namely ContProto mainly comprises two components", "role": "Method"}, {"entity_id": "ACL_23_P_222-1-E2", "text": "contrastive self-training", "role": "Method"}, {"entity_id": "ACL_23_P_222-1-E3", "text": "prototype-based pseudo-labeling", "role": "Method"}, {"entity_id": "ACL_23_P_222-1-E4", "text": "contrastive self-training facilitates span classification by separating clusters of different classes, and enhances cross-lingual transferability by producing closely-aligned representations between the source and target language", "role": "Method"}, {"entity_id": "ACL_23_P_222-1-E5", "text": "prototype-based pseudo-labeling effectively improves the accuracy of pseudo labels during training", "role": "Method"}, {"entity_id": "ACL_23_P_222-1-E6", "text": "self-training for cross-lingual NER", "role": "PrimaryObject"}]}], "entity_coreference": [], "event_coreference": [], "tokens": ["In", "this", "work,", "we", "aim", "to", "improve", "self-training", "for", "cross-lingual", "NER", "by", "combining", "representation", "learning", "and", "pseudo", "label", "refinement", "in", "one", "coherent", "framework.", "Our", "proposed", "method,", "namely", "ContProto", "mainly", "comprises", "two", "components:", "(1)", "contrastive", "self-training", "and", "(2)", "prototype-based", "pseudo-labeling.", "Our", "contrastive", "self-training", "facilitates", "span", "classification", "by", "separating", "clusters", "of", "different", "classes,", "and", "enhances", "cross-lingual", "transferability", "by", "producing", "closely-aligned", "representations", "between", "the", "source", "and", "target", "language.", "Meanwhile,", "prototype-based", "pseudo-labeling", "effectively", "improves", "the", "accuracy", "of", "pseudo", "labels", "during", "training."], "pieces": ["In", "this", "work", ",", "we", "aim", "to", "improve", "self", "-", "training", "for", "cross", "-", "ling", "ual", "NER", "by", "comb", "ining", "represent", "ation", "learning", "and", "pse", "udo", "label", "ref", "inement", "in", "one", "co", "herent", "framework", ".", "Our", "prop", "osed", "method", ",", "name", "ly", "Cont", "Pro", "to", "main", "ly", "com", "prises", "two", "comp", "onents", ":", "(", "1", ")", "cont", "rast", "ive", "self", "-", "training", "and", "(", "2", ")", "prototype", "-", "based", "pse", "udo", "-", "label", "ing", ".", "Our", "cont", "rast", "ive", "self", "-", "training", "fac", "ilit", "ates", "span", "class", "ification", "by", "separ", "ating", "cl", "usters", "of", "different", "classes", ",", "and", "enh", "ances", "cross", "-", "ling", "ual", "transfer", "ability", "by", "producing", "close", "ly", "-", "aligned", "represent", "ations", "between", "the", "source", "and", "target", "language", ".", "Meanwhile", ",", "prototype", "-", "based", "pse", "udo", "-", "label", "ing", "effect", "ively", "impro", "ves", "the", "acc", "uracy", "of", "pse", "udo", "lab", "els", "during", "training", "."], "token_lens": [1, 1, 2, 1, 1, 1, 1, 3, 1, 4, 1, 1, 2, 2, 1, 1, 2, 1, 2, 1, 1, 2, 2, 1, 2, 2, 2, 3, 2, 2, 1, 3, 3, 3, 3, 1, 3, 3, 6, 1, 3, 3, 3, 1, 2, 1, 2, 2, 1, 1, 2, 1, 2, 4, 2, 1, 1, 4, 2, 1, 1, 1, 1, 1, 2, 2, 3, 5, 2, 2, 1, 2, 1, 2, 2, 1, 2], "sentence": "In this work, we aim to improve self-training for cross-lingual NER by combining representation learning and pseudo label refinement in one coherent framework. Our proposed method, namely ContProto mainly comprises two components: (1) contrastive self-training and (2) prototype-based pseudo-labeling. Our contrastive self-training facilitates span classification by separating clusters of different classes, and enhances cross-lingual transferability by producing closely-aligned representations between the source and target language. Meanwhile, prototype-based pseudo-labeling effectively improves the accuracy of pseudo labels during training.", "sentence_starts": [0]}
{"doc_id": "ACL_23_P_222", "wnd_id": "ACL_23_P_222-2", "entity_mentions": [{"id": "ACL_23_P_222-2-E0", "text": "We", "start": 0, "end": 1, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_222-2-E1", "text": "ContProto", "start": 2, "end": 3, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_222-2-E2", "text": "on multiple transfer pairs", "start": 3, "end": 7, "entity_type": "UNK", "mention_type": "UNK"}], "relation_mentions": [], "event_mentions": [{"event_type": "Results/Findings", "id": "ACL_23_P_222-2-EV0", "trigger": {"text": "evaluate", "start": 1, "end": 2}, "arguments": [{"entity_id": "ACL_23_P_222-2-E0", "text": "We", "role": "Agent"}, {"entity_id": "ACL_23_P_222-2-E1", "text": "ContProto", "role": "PrimaryObject"}, {"entity_id": "ACL_23_P_222-2-E2", "text": "on multiple transfer pairs", "role": "SecondaryObject"}]}], "entity_coreference": [], "event_coreference": [], "tokens": ["We", "evaluate", "ContProto", "on", "multiple", "transfer", "pairs,", "and", "experimental", "results", "show", "our", "method", "brings", "substantial", "improvements", "over", "current", "state-of-the-art", "methods."], "pieces": ["We", "evaluate", "Cont", "Pro", "to", "on", "multiple", "transfer", "p", "airs", ",", "and", "exper", "imental", "results", "show", "our", "method", "br", "ings", "sub", "stantial", "improve", "ments", "over", "current", "state", "-", "of", "-", "the", "-", "art", "method", "s", "."], "token_lens": [1, 1, 3, 1, 1, 1, 3, 1, 2, 1, 1, 1, 1, 2, 2, 2, 1, 1, 7, 3], "sentence": "We evaluate ContProto on multiple transfer pairs, and experimental results show our method brings substantial improvements over current state-of-the-art methods.", "sentence_starts": [0]}
{"doc_id": "ACL_23_P_726", "wnd_id": "ACL_23_P_726-0", "entity_mentions": [{"id": "ACL_23_P_726-0-E0", "text": "We", "start": 27, "end": 28, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_726-0-E1", "text": "Languages differ in how they divide up the world into concepts and words", "start": 0, "end": 13, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_726-0-E2", "text": "aligning concepts in a parallel corpus", "start": 37, "end": 43, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_726-0-E3", "text": "these differences", "start": 29, "end": 31, "entity_type": "UNK", "mention_type": "UNK"}], "relation_mentions": [], "event_mentions": [{"event_type": "Background/Introduction", "id": "ACL_23_P_726-0-EV0", "trigger": {"text": "investigate", "start": 28, "end": 29}, "arguments": [{"entity_id": "ACL_23_P_726-0-E0", "text": "We", "role": "Agent"}, {"entity_id": "ACL_23_P_726-0-E1", "text": "Languages differ in how they divide up the world into concepts and words", "role": "Context"}, {"entity_id": "ACL_23_P_726-0-E2", "text": "aligning concepts in a parallel corpus", "role": "Method"}, {"entity_id": "ACL_23_P_726-0-E3", "text": "these differences", "role": "PrimaryObject"}]}], "entity_coreference": [], "event_coreference": [], "tokens": ["Languages", "differ", "in", "how", "they", "divide", "up", "the", "world", "into", "concepts", "and", "words;", "e.g.,", "in", "contrast", "to", "English,", "Swahili", "has", "a", "single", "concept", "for", "\u2018belly\u2019", "and", "\u2018womb\u2019.", "We", "investigate", "these", "differences", "in", "conceptualization", "across", "1,335", "languages", "by", "aligning", "concepts", "in", "a", "parallel", "corpus."], "pieces": ["L", "anguages", "diff", "er", "in", "how", "they", "div", "ide", "up", "the", "world", "into", "concept", "s", "and", "words", ";", "e", ".", "g", ".,", "in", "cont", "rast", "to", "English", ",", "Sw", "ah", "ili", "has", "a", "single", "concept", "for", "\u00e2\u0122", "\u013a", "b", "elly", "\u00e2\u0122", "\u013b", "and", "\u00e2\u0122", "\u013a", "w", "omb", "\u00e2\u0122", "\u013b", ".", "We", "invest", "igate", "these", "diff", "erences", "in", "concept", "ual", "ization", "ac", "ross", "1", ",", "335", "l", "anguages", "by", "align", "ing", "concept", "s", "in", "a", "par", "allel", "cor", "p", "us", "."], "token_lens": [2, 2, 1, 1, 1, 2, 1, 1, 1, 1, 2, 1, 2, 4, 1, 2, 1, 2, 3, 1, 1, 1, 1, 1, 6, 1, 7, 1, 2, 1, 2, 1, 3, 2, 3, 2, 1, 2, 2, 1, 1, 2, 4], "sentence": "Languages differ in how they divide up the world into concepts and words; e.g., in contrast to English, Swahili has a single concept for \u2018belly\u2019 and \u2018womb\u2019. We investigate these differences in conceptualization across 1,335 languages by aligning concepts in a parallel corpus.", "sentence_starts": [0]}
{"doc_id": "ACL_23_P_726", "wnd_id": "ACL_23_P_726-1", "entity_mentions": [{"id": "ACL_23_P_726-1-E0", "text": "we", "start": 3, "end": 4, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_726-1-E1", "text": "detailed linguistic analysis across all languages for one concept (\u2018bird\u2019)", "start": 27, "end": 37, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_726-1-E2", "text": "an evaluation on gold standard data for 32 Swadesh concepts", "start": 38, "end": 48, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_726-1-E3", "text": "crosslingual stability of a concept", "start": 72, "end": 77, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_726-1-E4", "text": "conceptualization pattern for 83 concepts", "start": 101, "end": 106, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_726-1-E5", "text": "similarity measure on these representations", "start": 109, "end": 114, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_726-1-E6", "text": "concreteness predicts stability", "start": 91, "end": 94, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_726-1-E7", "text": "Conceptualizer has good alignment accuracy", "start": 51, "end": 56, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_726-1-E8", "text": "the potential of research on conceptualization in NLP", "start": 58, "end": 66, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_726-1-E9", "text": "Conceptualizer", "start": 5, "end": 6, "entity_type": "UNK", "mention_type": "UNK"}], "relation_mentions": [], "event_mentions": [{"event_type": "Methods/Approach", "id": "ACL_23_P_726-1-EV0", "trigger": {"text": "propose", "start": 4, "end": 5}, "arguments": [{"entity_id": "ACL_23_P_726-1-E0", "text": "we", "role": "Agent"}, {"entity_id": "ACL_23_P_726-1-E1", "text": "detailed linguistic analysis across all languages for one concept (\u2018bird\u2019)", "role": "Method"}, {"entity_id": "ACL_23_P_726-1-E2", "text": "an evaluation on gold standard data for 32 Swadesh concepts", "role": "Method"}, {"entity_id": "ACL_23_P_726-1-E3", "text": "crosslingual stability of a concept", "role": "Method"}, {"entity_id": "ACL_23_P_726-1-E4", "text": "conceptualization pattern for 83 concepts", "role": "Method"}, {"entity_id": "ACL_23_P_726-1-E5", "text": "similarity measure on these representations", "role": "Method"}, {"entity_id": "ACL_23_P_726-1-E6", "text": "concreteness predicts stability", "role": "Results"}, {"entity_id": "ACL_23_P_726-1-E7", "text": "Conceptualizer has good alignment accuracy", "role": "Results"}, {"entity_id": "ACL_23_P_726-1-E8", "text": "the potential of research on conceptualization in NLP", "role": "Results"}, {"entity_id": "ACL_23_P_726-1-E9", "text": "Conceptualizer", "role": "PrimaryObject"}]}], "entity_coreference": [], "event_coreference": [], "tokens": ["To", "this", "end,", "we", "propose", "Conceptualizer,", "a", "method", "that", "creates", "a", "bipartite", "directed", "alignment", "graph", "between", "source", "language", "concepts", "and", "sets", "of", "target", "language", "strings.", "In", "a", "detailed", "linguistic", "analysis", "across", "all", "languages", "for", "one", "concept", "(\u2018bird\u2019)", "and", "an", "evaluation", "on", "gold", "standard", "data", "for", "32", "Swadesh", "concepts,", "we", "show", "that", "Conceptualizer", "has", "good", "alignment", "accuracy.", "We", "demonstrate", "the", "potential", "of", "research", "on", "conceptualization", "in", "NLP", "with", "two", "experiments.", "(1)", "We", "define", "crosslingual", "stability", "of", "a", "concept", "as", "the", "degree", "to", "which", "it", "has", "1-1", "correspondences", "across", "languages,", "and", "show", "that", "concreteness", "predicts", "stability.", "(2)", "We", "represent", "each", "language", "by", "its", "conceptualization", "pattern", "for", "83", "concepts,", "and", "define", "a", "similarity", "measure", "on", "these", "representations."], "pieces": ["To", "this", "end", ",", "we", "pro", "pose", "Con", "cept", "ual", "izer", ",", "a", "method", "that", "creat", "es", "a", "b", "ip", "art", "ite", "directed", "al", "ignment", "graph", "between", "source", "language", "concept", "s", "and", "sets", "of", "target", "language", "strings", ".", "In", "a", "det", "ailed", "ling", "u", "istic", "analysis", "ac", "ross", "all", "l", "anguages", "for", "one", "concept", "(", "\u00e2\u0122", "\u013a", "bird", "\u00e2\u0122", "\u013b", ")", "and", "an", "eval", "uation", "on", "gold", "standard", "data", "for", "32", "Sw", "adesh", "concept", "s", ",", "we", "show", "that", "Con", "cept", "ual", "izer", "has", "good", "al", "ignment", "acc", "uracy", ".", "We", "demon", "strate", "the", "pot", "ential", "of", "research", "on", "concept", "ual", "ization", "in", "N", "LP", "with", "two", "exper", "iments", ".", "(", "1", ")", "We", "define", "cross", "ling", "ual", "st", "ability", "of", "a", "concept", "as", "the", "degree", "to", "which", "it", "has", "1", "-", "1", "cor", "respond", "ences", "ac", "ross", "l", "anguages", ",", "and", "show", "that", "con", "c", "ret", "eness", "pred", "icts", "st", "ability", ".", "(", "2", ")", "We", "represent", "each", "language", "by", "its", "concept", "ual", "ization", "pattern", "for", "83", "concept", "s", ",", "and", "define", "a", "similar", "ity", "me", "asure", "on", "these", "represent", "ations", "."], "token_lens": [1, 1, 2, 1, 2, 5, 1, 1, 1, 2, 1, 4, 1, 2, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 2, 1, 1, 2, 3, 1, 2, 1, 2, 1, 1, 1, 7, 1, 1, 2, 1, 1, 1, 1, 1, 1, 2, 3, 1, 1, 1, 4, 1, 1, 2, 3, 1, 2, 1, 2, 1, 1, 1, 3, 1, 2, 1, 1, 3, 3, 1, 1, 3, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 3, 3, 2, 3, 1, 1, 1, 4, 2, 3, 3, 1, 1, 1, 1, 1, 1, 3, 1, 1, 1, 3, 1, 1, 1, 2, 2, 1, 1, 3], "sentence": "To this end, we propose Conceptualizer, a method that creates a bipartite directed alignment graph between source language concepts and sets of target language strings. In a detailed linguistic analysis across all languages for one concept (\u2018bird\u2019) and an evaluation on gold standard data for 32 Swadesh concepts, we show that Conceptualizer has good alignment accuracy. We demonstrate the potential of research on conceptualization in NLP with two experiments. (1) We define crosslingual stability of a concept as the degree to which it has 1-1 correspondences across languages, and show that concreteness predicts stability. (2) We represent each language by its conceptualization pattern for 83 concepts, and define a similarity measure on these representations.", "sentence_starts": [0]}
{"doc_id": "ACL_23_P_726", "wnd_id": "ACL_23_P_726-2", "entity_mentions": [{"id": "ACL_23_P_726-2-E0", "text": "we", "start": 27, "end": 28, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_726-2-E1", "text": "languages", "start": 9, "end": 10, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_726-2-E2", "text": "to their correct family", "start": 31, "end": 35, "entity_type": "UNK", "mention_type": "UNK"}], "relation_mentions": [], "event_mentions": [{"event_type": "Results/Findings", "id": "ACL_23_P_726-2-EV0", "trigger": {"text": "assign", "start": 29, "end": 30}, "arguments": [{"entity_id": "ACL_23_P_726-2-E0", "text": "we", "role": "Agent"}, {"entity_id": "ACL_23_P_726-2-E1", "text": "languages", "role": "PrimaryObject"}, {"entity_id": "ACL_23_P_726-2-E2", "text": "to their correct family", "role": "SecondaryObject"}]}], "entity_coreference": [], "event_coreference": [], "tokens": ["The", "resulting", "measure", "for", "the", "conceptual", "similarity", "between", "two", "languages", "is", "complementary", "to", "standard", "genealogical,", "typological,", "and", "surface", "similarity", "measures.", "For", "four", "out", "of", "six", "language", "families,", "we", "can", "assign", "languages", "to", "their", "correct", "family", "based", "on", "conceptual", "similarity", "with", "accuracies", "between", "54%", "and", "87%."], "pieces": ["The", "result", "ing", "me", "asure", "for", "the", "concept", "ual", "similar", "ity", "between", "two", "l", "anguages", "is", "com", "plement", "ary", "to", "standard", "g", "ene", "alog", "ical", ",", "typ", "ological", ",", "and", "surface", "similar", "ity", "measures", ".", "For", "four", "out", "of", "six", "language", "fam", "ilies", ",", "we", "can", "ass", "ign", "l", "anguages", "to", "their", "correct", "family", "based", "on", "concept", "ual", "similar", "ity", "with", "acc", "ur", "acies", "between", "54", "%", "and", "87", "%."], "token_lens": [1, 2, 2, 1, 1, 2, 2, 1, 1, 2, 1, 3, 1, 1, 5, 3, 1, 1, 2, 2, 1, 1, 1, 1, 1, 1, 3, 1, 1, 2, 2, 1, 1, 1, 1, 1, 1, 2, 2, 1, 3, 1, 2, 1, 2], "sentence": "The resulting measure for the conceptual similarity between two languages is complementary to standard genealogical, typological, and surface similarity measures. For four out of six language families, we can assign languages to their correct family based on conceptual similarity with accuracies between 54% and 87%.", "sentence_starts": [0]}
{"doc_id": "ACL_23_P_790", "wnd_id": "ACL_23_P_790-0", "entity_mentions": [{"id": "ACL_23_P_790-0-E0", "text": "The out-of-vocabulary (OOV) words", "start": 0, "end": 4, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_790-0-E1", "text": "Prior OOV word embedding learning methods failed to model complex word formation well", "start": 17, "end": 30, "entity_type": "UNK", "mention_type": "UNK"}], "relation_mentions": [], "event_mentions": [{"event_type": "Background/Introduction", "id": "ACL_23_P_790-0-EV0", "trigger": {"text": "are difficult to represent", "start": 4, "end": 8}, "arguments": [{"entity_id": "ACL_23_P_790-0-E0", "text": "The out-of-vocabulary (OOV) words", "role": "Agent"}, {"entity_id": "ACL_23_P_790-0-E1", "text": "Prior OOV word embedding learning methods failed to model complex word formation well", "role": "Challenge"}]}], "entity_coreference": [], "event_coreference": [], "tokens": ["The", "out-of-vocabulary", "(OOV)", "words", "are", "difficult", "to", "represent", "while", "critical", "to", "the", "performance", "of", "embedding-based", "downstream", "models.", "Prior", "OOV", "word", "embedding", "learning", "methods", "failed", "to", "model", "complex", "word", "formation", "well."], "pieces": ["The", "out", "-", "of", "-", "voc", "abulary", "(", "OO", "V", ")", "words", "are", "diff", "icult", "to", "represent", "while", "critical", "to", "the", "performance", "of", "embed", "ding", "-", "based", "down", "stream", "models", ".", "Prior", "OO", "V", "word", "embed", "ding", "learning", "method", "s", "failed", "to", "model", "complex", "word", "formation", "well", "."], "token_lens": [1, 6, 4, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 4, 2, 2, 1, 2, 1, 2, 1, 2, 1, 1, 1, 1, 1, 1, 2], "sentence": "The out-of-vocabulary (OOV) words are difficult to represent while critical to the performance of embedding-based downstream models. Prior OOV word embedding learning methods failed to model complex word formation well.", "sentence_starts": [0]}
{"doc_id": "ACL_23_P_790", "wnd_id": "ACL_23_P_790-1", "entity_mentions": [{"id": "ACL_23_P_790-1-E0", "text": "we", "start": 3, "end": 4, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_790-1-E1", "text": "We first build a Word Relationship Graph (WRG) based on word formation and associate OOV words with their semantically relevant words, which can mine the relational information inside word structures", "start": 18, "end": 48, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_790-1-E2", "text": "Subsequently, our GRM can infer high-quality embeddings for OOV words through passing and aggregating semantic attributes and relational information in the WRG, regardless of contextual richness", "start": 48, "end": 74, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_790-1-E3", "text": "a novel graph-based relation mining method", "start": 5, "end": 11, "entity_type": "UNK", "mention_type": "UNK"}], "relation_mentions": [], "event_mentions": [{"event_type": "Methods/Approach", "id": "ACL_23_P_790-1-EV0", "trigger": {"text": "propose", "start": 4, "end": 5}, "arguments": [{"entity_id": "ACL_23_P_790-1-E0", "text": "we", "role": "Agent"}, {"entity_id": "ACL_23_P_790-1-E1", "text": "We first build a Word Relationship Graph (WRG) based on word formation and associate OOV words with their semantically relevant words, which can mine the relational information inside word structures", "role": "Method"}, {"entity_id": "ACL_23_P_790-1-E2", "text": "Subsequently, our GRM can infer high-quality embeddings for OOV words through passing and aggregating semantic attributes and relational information in the WRG, regardless of contextual richness", "role": "Method"}, {"entity_id": "ACL_23_P_790-1-E3", "text": "a novel graph-based relation mining method", "role": "PrimaryObject"}]}], "entity_coreference": [], "event_coreference": [], "tokens": ["In", "this", "paper,", "we", "propose", "a", "novel", "graph-based", "relation", "mining", "method,", "namely", "GRM,", "for", "OOV", "word", "embedding", "learning.", "We", "first", "build", "a", "Word", "Relationship", "Graph", "(WRG)", "based", "on", "word", "formation", "and", "associate", "OOV", "words", "with", "their", "semantically", "relevant", "words,", "which", "can", "mine", "the", "relational", "information", "inside", "word", "structures.", "Subsequently,", "our", "GRM", "can", "infer", "high-quality", "embeddings", "for", "OOV", "words", "through", "passing", "and", "aggregating", "semantic", "attributes", "and", "relational", "information", "in", "the", "WRG,", "regardless", "of", "contextual", "richness."], "pieces": ["In", "this", "paper", ",", "we", "pro", "pose", "a", "no", "vel", "graph", "-", "based", "relation", "mining", "method", ",", "name", "ly", "GR", "M", ",", "for", "OO", "V", "word", "embed", "ding", "learning", ".", "We", "first", "build", "a", "Word", "Relations", "hip", "Graph", "(", "WR", "G", ")", "based", "on", "word", "formation", "and", "ass", "ociate", "OO", "V", "words", "with", "their", "sem", "antically", "relevant", "words", ",", "which", "can", "mine", "the", "rel", "ational", "information", "inside", "word", "struct", "ures", ".", "Sub", "sequently", ",", "our", "GR", "M", "can", "in", "fer", "high", "-", "quality", "embed", "d", "ings", "for", "OO", "V", "words", "through", "pass", "ing", "and", "agg", "reg", "ating", "sem", "antic", "att", "ributes", "and", "rel", "ational", "information", "in", "the", "WR", "G", ",", "reg", "ardless", "of", "context", "ual", "rich", "ness", "."], "token_lens": [1, 1, 2, 1, 2, 1, 2, 3, 1, 1, 2, 2, 3, 1, 2, 1, 2, 2, 1, 1, 1, 1, 1, 2, 1, 4, 1, 1, 1, 1, 1, 2, 2, 1, 1, 1, 2, 1, 2, 1, 1, 1, 1, 2, 1, 1, 1, 3, 3, 1, 2, 1, 2, 3, 3, 1, 2, 1, 1, 2, 1, 3, 2, 2, 1, 2, 1, 1, 1, 3, 2, 1, 2, 3], "sentence": "In this paper, we propose a novel graph-based relation mining method, namely GRM, for OOV word embedding learning. We first build a Word Relationship Graph (WRG) based on word formation and associate OOV words with their semantically relevant words, which can mine the relational information inside word structures. Subsequently, our GRM can infer high-quality embeddings for OOV words through passing and aggregating semantic attributes and relational information in the WRG, regardless of contextual richness.", "sentence_starts": [0]}
{"doc_id": "ACL_23_P_790", "wnd_id": "ACL_23_P_790-2", "entity_mentions": [{"id": "ACL_23_P_790-2-E0", "text": "Extensive experiments", "start": 0, "end": 2, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_790-2-E1", "text": "on both intrinsic and downstream tasks when faced with OOV words", "start": 10, "end": 21, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_790-2-E2", "text": "our model significantly outperforms state-of-the-art baselines", "start": 4, "end": 10, "entity_type": "UNK", "mention_type": "UNK"}], "relation_mentions": [], "event_mentions": [{"event_type": "Results/Findings", "id": "ACL_23_P_790-2-EV0", "trigger": {"text": "demonstrate", "start": 2, "end": 3}, "arguments": [{"entity_id": "ACL_23_P_790-2-E0", "text": "Extensive experiments", "role": "Agent"}, {"entity_id": "ACL_23_P_790-2-E1", "text": "on both intrinsic and downstream tasks when faced with OOV words", "role": "Context"}, {"entity_id": "ACL_23_P_790-2-E2", "text": "our model significantly outperforms state-of-the-art baselines", "role": "PrimaryObject"}]}], "entity_coreference": [], "event_coreference": [], "tokens": ["Extensive", "experiments", "demonstrate", "that", "our", "model", "significantly", "outperforms", "state-of-the-art", "baselines", "on", "both", "intrinsic", "and", "downstream", "tasks", "when", "faced", "with", "OOV", "words."], "pieces": ["Ext", "ensive", "exper", "iments", "demon", "strate", "that", "our", "model", "sign", "ificantly", "out", "per", "forms", "state", "-", "of", "-", "the", "-", "art", "bas", "elines", "on", "both", "int", "r", "ins", "ic", "and", "down", "stream", "t", "asks", "when", "faced", "with", "OO", "V", "words", "."], "token_lens": [2, 2, 2, 1, 1, 1, 2, 3, 7, 2, 1, 1, 4, 1, 2, 2, 1, 1, 1, 2, 2], "sentence": "Extensive experiments demonstrate that our model significantly outperforms state-of-the-art baselines on both intrinsic and downstream tasks when faced with OOV words.", "sentence_starts": [0]}
{"doc_id": "ACL_23_P_803", "wnd_id": "ACL_23_P_803-0", "entity_mentions": [{"id": "ACL_23_P_803-0-E0", "text": "Dynamic networks", "start": 0, "end": 2, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_803-0-E1", "text": "The common practice in implementing dynamic networks is to convert the given static layers into fully dynamic ones where all parameters are dynamic (at least within a single layer) and vary with the input.", "start": 29, "end": 63, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_803-0-E2", "text": "such a fully dynamic setting may cause redundant parameters and high deployment costs, limiting the applicability of dynamic networks to a broader range of tasks and models", "start": 64, "end": 91, "entity_type": "UNK", "mention_type": "UNK"}], "relation_mentions": [], "event_mentions": [{"event_type": "Background/Introduction", "id": "ACL_23_P_803-0-EV0", "trigger": {"text": "have been extensively explored", "start": 12, "end": 16}, "arguments": [{"entity_id": "ACL_23_P_803-0-E0", "text": "Dynamic networks", "role": "Agent"}, {"entity_id": "ACL_23_P_803-0-E1", "text": "The common practice in implementing dynamic networks is to convert the given static layers into fully dynamic ones where all parameters are dynamic (at least within a single layer) and vary with the input.", "role": "Context"}, {"entity_id": "ACL_23_P_803-0-E2", "text": "such a fully dynamic setting may cause redundant parameters and high deployment costs, limiting the applicability of dynamic networks to a broader range of tasks and models", "role": "Challenge"}]}], "entity_coreference": [], "event_coreference": [], "tokens": ["Dynamic", "networks,", "e.g.,", "Dynamic", "Convolution", "(DY-Conv)", "and", "the", "Mixture", "of", "Experts", "(MoE),", "have", "been", "extensively", "explored", "as", "they", "can", "considerably", "improve", "the", "model\u2019s", "representation", "power", "with", "acceptable", "computational", "cost.", "The", "common", "practice", "in", "implementing", "dynamic", "networks", "is", "to", "convert", "the", "given", "static", "layers", "into", "fully", "dynamic", "ones", "where", "all", "parameters", "are", "dynamic", "(at", "least", "within", "a", "single", "layer)", "and", "vary", "with", "the", "input.", "However,", "such", "a", "fully", "dynamic", "setting", "may", "cause", "redundant", "parameters", "and", "high", "deployment", "costs,", "limiting", "the", "applicability", "of", "dynamic", "networks", "to", "a", "broader", "range", "of", "tasks", "and", "models."], "pieces": ["Dynamic", "net", "works", ",", "e", ".", "g", ".,", "Dynamic", "Con", "v", "olution", "(", "D", "Y", "-", "Con", "v", ")", "and", "the", "M", "ixture", "of", "Experts", "(", "Mo", "E", "),", "have", "been", "ext", "ensive", "ly", "expl", "ored", "as", "they", "can", "consider", "ably", "improve", "the", "model", "\u00e2\u0122", "\u013b", "s", "represent", "ation", "power", "with", "acceptable", "com", "put", "ational", "cost", ".", "The", "common", "practice", "in", "im", "plement", "ing", "d", "ynamic", "net", "works", "is", "to", "con", "vert", "the", "given", "static", "l", "ayers", "into", "fully", "d", "ynamic", "ones", "where", "all", "param", "eters", "are", "d", "ynamic", "(", "at", "le", "ast", "within", "a", "single", "layer", ")", "and", "v", "ary", "with", "the", "input", ".", "However", ",", "such", "a", "fully", "d", "ynamic", "setting", "may", "cause", "red", "und", "ant", "param", "eters", "and", "high", "de", "ploy", "ment", "cost", "s", ",", "lim", "iting", "the", "app", "lic", "ability", "of", "d", "ynamic", "net", "works", "to", "a", "bro", "ader", "range", "of", "t", "asks", "and", "models", "."], "token_lens": [1, 3, 4, 1, 3, 7, 1, 1, 2, 1, 1, 4, 1, 1, 3, 2, 1, 1, 1, 2, 1, 1, 4, 2, 1, 1, 1, 3, 2, 1, 1, 1, 1, 3, 2, 2, 1, 1, 2, 1, 1, 1, 2, 1, 1, 2, 1, 1, 1, 2, 1, 2, 2, 2, 1, 1, 1, 2, 1, 2, 1, 1, 2, 2, 1, 1, 1, 2, 1, 1, 1, 3, 2, 1, 1, 3, 3, 2, 1, 3, 1, 2, 2, 1, 1, 2, 1, 1, 2, 1, 2], "sentence": "Dynamic networks, e.g., Dynamic Convolution (DY-Conv) and the Mixture of Experts (MoE), have been extensively explored as they can considerably improve the model\u2019s representation power with acceptable computational cost. The common practice in implementing dynamic networks is to convert the given static layers into fully dynamic ones where all parameters are dynamic (at least within a single layer) and vary with the input. However, such a fully dynamic setting may cause redundant parameters and high deployment costs, limiting the applicability of dynamic networks to a broader range of tasks and models.", "sentence_starts": [0]}
{"doc_id": "ACL_23_P_803", "wnd_id": "ACL_23_P_803-1", "entity_mentions": [{"id": "ACL_23_P_803-1-E0", "text": "The main contributions of our work", "start": 0, "end": 6, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_803-1-E1", "text": "proposing a partially dynamic network, namely PAD-Net, to transform the redundant dynamic parameters into static ones", "start": 15, "end": 31, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_803-1-E2", "text": "we further design Iterative Mode Partition to partition dynamic and static parameters efficiently", "start": 32, "end": 45, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_803-1-E3", "text": "challenging the basic commonsense", "start": 7, "end": 11, "entity_type": "UNK", "mention_type": "UNK"}], "relation_mentions": [], "event_mentions": [{"event_type": "Methods/Approach", "id": "ACL_23_P_803-1-EV0", "trigger": {"text": "are", "start": 6, "end": 7}, "arguments": [{"entity_id": "ACL_23_P_803-1-E0", "text": "The main contributions of our work", "role": "Agent"}, {"entity_id": "ACL_23_P_803-1-E1", "text": "proposing a partially dynamic network, namely PAD-Net, to transform the redundant dynamic parameters into static ones", "role": "Method"}, {"entity_id": "ACL_23_P_803-1-E2", "text": "we further design Iterative Mode Partition to partition dynamic and static parameters efficiently", "role": "Method"}, {"entity_id": "ACL_23_P_803-1-E3", "text": "challenging the basic commonsense", "role": "PrimaryObject"}]}], "entity_coreference": [], "event_coreference": [], "tokens": ["The", "main", "contributions", "of", "our", "work", "are", "challenging", "the", "basic", "commonsense", "in", "dynamic", "networks", "and", "proposing", "a", "partially", "dynamic", "network,", "namely", "PAD-Net,", "to", "transform", "the", "redundant", "dynamic", "parameters", "into", "static", "ones.", "Also,", "we", "further", "design", "Iterative", "Mode", "Partition", "to", "partition", "dynamic", "and", "static", "parameters", "efficiently."], "pieces": ["The", "main", "cont", "ribut", "ions", "of", "our", "work", "are", "chall", "eng", "ing", "the", "basic", "comm", "onsense", "in", "d", "ynamic", "net", "works", "and", "pro", "posing", "a", "part", "ially", "d", "ynamic", "network", ",", "name", "ly", "P", "AD", "-", "Net", ",", "to", "transform", "the", "red", "und", "ant", "d", "ynamic", "param", "eters", "into", "static", "ones", ".", "Also", ",", "we", "f", "urther", "design", "Iter", "ative", "Mode", "Part", "ition", "to", "part", "ition", "d", "ynamic", "and", "static", "param", "eters", "efficient", "ly", "."], "token_lens": [1, 1, 3, 1, 1, 1, 1, 3, 1, 1, 2, 1, 2, 2, 1, 2, 1, 2, 2, 2, 2, 5, 1, 1, 1, 3, 2, 2, 1, 1, 2, 2, 1, 2, 1, 2, 1, 2, 1, 2, 2, 1, 1, 2, 3], "sentence": "The main contributions of our work are challenging the basic commonsense in dynamic networks and proposing a partially dynamic network, namely PAD-Net, to transform the redundant dynamic parameters into static ones. Also, we further design Iterative Mode Partition to partition dynamic and static parameters efficiently.", "sentence_starts": [0]}
{"doc_id": "ACL_23_P_803", "wnd_id": "ACL_23_P_803-2", "entity_mentions": [{"id": "ACL_23_P_803-2-E0", "text": "Our method", "start": 0, "end": 2, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_803-2-E1", "text": "we surpass the fully dynamic networks by +0.7% top-1 acc with only 30% dynamic parameters for ResNet-50 and +1.9% average score in language understanding with only 50% dynamic parameters for BERT", "start": 26, "end": 57, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_803-2-E2", "text": "large-scale experiments with two typical advanced dynamic architectures", "start": 6, "end": 14, "entity_type": "UNK", "mention_type": "UNK"}], "relation_mentions": [], "event_mentions": [{"event_type": "Results/Findings", "id": "ACL_23_P_803-2-EV0", "trigger": {"text": "is comprehensively supported by", "start": 2, "end": 6}, "arguments": [{"entity_id": "ACL_23_P_803-2-E0", "text": "Our method", "role": "Agent"}, {"entity_id": "ACL_23_P_803-2-E1", "text": "we surpass the fully dynamic networks by +0.7% top-1 acc with only 30% dynamic parameters for ResNet-50 and +1.9% average score in language understanding with only 50% dynamic parameters for BERT", "role": "Results"}, {"entity_id": "ACL_23_P_803-2-E2", "text": "large-scale experiments with two typical advanced dynamic architectures", "role": "PrimaryObject"}]}], "entity_coreference": [], "event_coreference": [], "tokens": ["Our", "method", "is", "comprehensively", "supported", "by", "large-scale", "experiments", "with", "two", "typical", "advanced", "dynamic", "architectures,", "i.e.,", "DY-Conv", "and", "MoE,", "on", "both", "image", "classification", "and", "GLUE", "benchmarks.", "Encouragingly,", "we", "surpass", "the", "fully", "dynamic", "networks", "by", "+0.7%", "top-1", "acc", "with", "only", "30%", "dynamic", "parameters", "for", "ResNet-50", "and", "+1.9%", "average", "score", "in", "language", "understanding", "with", "only", "50%", "dynamic", "parameters", "for", "BERT."], "pieces": ["Our", "method", "is", "com", "pre", "hens", "ively", "supported", "by", "large", "-", "scale", "exper", "iments", "with", "two", "typ", "ical", "adv", "anced", "d", "ynamic", "arch", "itect", "ures", ",", "i", ".", "e", ".,", "D", "Y", "-", "Con", "v", "and", "Mo", "E", ",", "on", "both", "image", "class", "ification", "and", "GL", "UE", "bench", "marks", ".", "Enc", "our", "aging", "ly", ",", "we", "sur", "pass", "the", "fully", "d", "ynamic", "net", "works", "by", "+", "0", ".", "7", "%", "top", "-", "1", "acc", "with", "only", "30", "%", "d", "ynamic", "param", "eters", "for", "Res", "Net", "-", "50", "and", "+", "1", ".", "9", "%", "average", "score", "in", "language", "under", "standing", "with", "only", "50", "%", "d", "ynamic", "param", "eters", "for", "BER", "T", "."], "token_lens": [1, 1, 1, 4, 1, 1, 3, 2, 1, 1, 2, 2, 2, 4, 4, 5, 1, 3, 1, 1, 1, 2, 1, 2, 3, 5, 1, 2, 1, 1, 2, 2, 1, 5, 3, 1, 1, 1, 2, 2, 2, 1, 4, 1, 5, 1, 1, 1, 1, 2, 1, 1, 2, 2, 2, 1, 3], "sentence": "Our method is comprehensively supported by large-scale experiments with two typical advanced dynamic architectures, i.e., DY-Conv and MoE, on both image classification and GLUE benchmarks. Encouragingly, we surpass the fully dynamic networks by +0.7% top-1 acc with only 30% dynamic parameters for ResNet-50 and +1.9% average score in language understanding with only 50% dynamic parameters for BERT.", "sentence_starts": [0]}
{"doc_id": "ACL_23_P_241", "wnd_id": "ACL_23_P_241-0", "entity_mentions": [{"id": "ACL_23_P_241-0-E0", "text": "Commonsense reasoning", "start": 0, "end": 2, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_241-0-E1", "text": "We take the first step by focusing on event commonsense that considers events and their relations, and is crucial in both dialogues and general commonsense reasoning", "start": 28, "end": 54, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_241-0-E2", "text": "evaluating commonsense in dialogue systems is still an open challenge", "start": 18, "end": 28, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_241-0-E3", "text": "omnipresent in human communications", "start": 3, "end": 7, "entity_type": "UNK", "mention_type": "UNK"}], "relation_mentions": [], "event_mentions": [{"event_type": "Background/Introduction", "id": "ACL_23_P_241-0-EV0", "trigger": {"text": "is", "start": 2, "end": 3}, "arguments": [{"entity_id": "ACL_23_P_241-0-E0", "text": "Commonsense reasoning", "role": "Agent"}, {"entity_id": "ACL_23_P_241-0-E1", "text": "We take the first step by focusing on event commonsense that considers events and their relations, and is crucial in both dialogues and general commonsense reasoning", "role": "Method"}, {"entity_id": "ACL_23_P_241-0-E2", "text": "evaluating commonsense in dialogue systems is still an open challenge", "role": "Challenge"}, {"entity_id": "ACL_23_P_241-0-E3", "text": "omnipresent in human communications", "role": "PrimaryObject"}]}], "entity_coreference": [], "event_coreference": [], "tokens": ["Commonsense", "reasoning", "is", "omnipresent", "in", "human", "communications", "and", "thus", "is", "an", "important", "feature", "for", "open-domain", "dialogue", "systems.", "However,", "evaluating", "commonsense", "in", "dialogue", "systems", "is", "still", "an", "open", "challenge.", "We", "take", "the", "first", "step", "by", "focusing", "on", "event", "commonsense", "that", "considers", "events", "and", "their", "relations,", "and", "is", "crucial", "in", "both", "dialogues", "and", "general", "commonsense", "reasoning."], "pieces": ["Comm", "onsense", "reason", "ing", "is", "om", "n", "ip", "resent", "in", "human", "communications", "and", "thus", "is", "an", "important", "feature", "for", "open", "-", "domain", "dial", "ogue", "system", "s", ".", "However", ",", "eval", "uating", "comm", "onsense", "in", "dial", "ogue", "system", "s", "is", "still", "an", "open", "chall", "enge", ".", "We", "take", "the", "first", "step", "by", "f", "ocusing", "on", "event", "comm", "onsense", "that", "cons", "iders", "events", "and", "their", "relations", ",", "and", "is", "cru", "cial", "in", "both", "dial", "og", "ues", "and", "general", "comm", "onsense", "reason", "ing", "."], "token_lens": [2, 2, 1, 4, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 3, 2, 3, 2, 2, 2, 1, 2, 2, 1, 1, 1, 1, 3, 1, 1, 1, 1, 1, 1, 2, 1, 1, 2, 1, 2, 1, 1, 1, 2, 1, 1, 2, 1, 1, 3, 1, 1, 2, 3], "sentence": "Commonsense reasoning is omnipresent in human communications and thus is an important feature for open-domain dialogue systems. However, evaluating commonsense in dialogue systems is still an open challenge. We take the first step by focusing on event commonsense that considers events and their relations, and is crucial in both dialogues and general commonsense reasoning.", "sentence_starts": [0]}
{"doc_id": "ACL_23_P_241", "wnd_id": "ACL_23_P_241-1", "entity_mentions": [{"id": "ACL_23_P_241-1-E0", "text": "We", "start": 0, "end": 1, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_241-1-E1", "text": "ACCENT first extracts event-relation tuples from a dialogue", "start": 14, "end": 22, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_241-1-E2", "text": "evaluates the response by scoring the tuples in terms of their compatibility with the CSKB", "start": 24, "end": 39, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_241-1-E3", "text": "ACCENT", "start": 2, "end": 3, "entity_type": "UNK", "mention_type": "UNK"}], "relation_mentions": [], "event_mentions": [{"event_type": "Methods/Approach", "id": "ACL_23_P_241-1-EV0", "trigger": {"text": "propose", "start": 1, "end": 2}, "arguments": [{"entity_id": "ACL_23_P_241-1-E0", "text": "We", "role": "Agent"}, {"entity_id": "ACL_23_P_241-1-E1", "text": "ACCENT first extracts event-relation tuples from a dialogue", "role": "Method"}, {"entity_id": "ACL_23_P_241-1-E2", "text": "evaluates the response by scoring the tuples in terms of their compatibility with the CSKB", "role": "Method"}, {"entity_id": "ACL_23_P_241-1-E3", "text": "ACCENT", "role": "PrimaryObject"}]}], "entity_coreference": [], "event_coreference": [], "tokens": ["We", "propose", "ACCENT,", "an", "event", "commonsense", "evaluation", "metric", "empowered", "by", "commonsense", "knowledge", "bases", "(CSKBs).", "ACCENT", "first", "extracts", "event-relation", "tuples", "from", "a", "dialogue,", "and", "then", "evaluates", "the", "response", "by", "scoring", "the", "tuples", "in", "terms", "of", "their", "compatibility", "with", "the", "CSKB."], "pieces": ["We", "pro", "pose", "ACC", "ENT", ",", "an", "event", "comm", "onsense", "eval", "uation", "met", "ric", "em", "powered", "by", "comm", "onsense", "knowledge", "b", "ases", "(", "CS", "KB", "s", ").", "ACC", "ENT", "first", "ext", "ract", "s", "event", "-", "relation", "tu", "ples", "from", "a", "dial", "ogue", ",", "and", "then", "eval", "uates", "the", "response", "by", "scoring", "the", "tu", "ples", "in", "terms", "of", "their", "comp", "atibility", "with", "the", "CS", "KB", "."], "token_lens": [1, 2, 3, 1, 1, 2, 2, 2, 2, 1, 2, 1, 2, 5, 2, 1, 3, 3, 2, 1, 1, 3, 1, 1, 2, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 2, 1, 1, 3], "sentence": "We propose ACCENT, an event commonsense evaluation metric empowered by commonsense knowledge bases (CSKBs). ACCENT first extracts event-relation tuples from a dialogue, and then evaluates the response by scoring the tuples in terms of their compatibility with the CSKB.", "sentence_starts": [0]}
{"doc_id": "ACL_23_P_241", "wnd_id": "ACL_23_P_241-2", "entity_mentions": [{"id": "ACL_23_P_241-2-E0", "text": "we", "start": 3, "end": 4, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_241-2-E1", "text": "ACCENT is an efficient metric for event commonsense evaluation", "start": 19, "end": 28, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_241-2-E2", "text": "achieves higher correlations with human judgments than existing baselines", "start": 29, "end": 38, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_241-2-E3", "text": "the first public event commonsense evaluation dataset", "start": 5, "end": 12, "entity_type": "UNK", "mention_type": "UNK"}], "relation_mentions": [], "event_mentions": [{"event_type": "Results/Findings", "id": "ACL_23_P_241-2-EV0", "trigger": {"text": "construct", "start": 4, "end": 5}, "arguments": [{"entity_id": "ACL_23_P_241-2-E0", "text": "we", "role": "Agent"}, {"entity_id": "ACL_23_P_241-2-E1", "text": "ACCENT is an efficient metric for event commonsense evaluation", "role": "Results"}, {"entity_id": "ACL_23_P_241-2-E2", "text": "achieves higher correlations with human judgments than existing baselines", "role": "Results"}, {"entity_id": "ACL_23_P_241-2-E3", "text": "the first public event commonsense evaluation dataset", "role": "PrimaryObject"}]}], "entity_coreference": [], "event_coreference": [], "tokens": ["To", "evaluate", "ACCENT,", "we", "construct", "the", "first", "public", "event", "commonsense", "evaluation", "dataset", "for", "open-domain", "dialogues.", "Our", "experiments", "show", "that", "ACCENT", "is", "an", "efficient", "metric", "for", "event", "commonsense", "evaluation,", "which", "achieves", "higher", "correlations", "with", "human", "judgments", "than", "existing", "baselines."], "pieces": ["To", "evaluate", "ACC", "ENT", ",", "we", "construct", "the", "first", "public", "event", "comm", "onsense", "eval", "uation", "dat", "as", "et", "for", "open", "-", "domain", "dial", "og", "ues", ".", "Our", "exper", "iments", "show", "that", "ACC", "ENT", "is", "an", "efficient", "met", "ric", "for", "event", "comm", "onsense", "eval", "uation", ",", "which", "ach", "ieves", "higher", "cor", "relations", "with", "human", "jud", "gments", "than", "existing", "bas", "elines", "."], "token_lens": [1, 1, 3, 1, 1, 1, 1, 1, 1, 2, 2, 3, 1, 3, 4, 1, 2, 1, 1, 2, 1, 1, 1, 2, 1, 1, 2, 3, 1, 2, 1, 2, 1, 1, 2, 1, 1, 3], "sentence": "To evaluate ACCENT, we construct the first public event commonsense evaluation dataset for open-domain dialogues. Our experiments show that ACCENT is an efficient metric for event commonsense evaluation, which achieves higher correlations with human judgments than existing baselines.", "sentence_starts": [0]}
{"doc_id": "ACL_23_P_554", "wnd_id": "ACL_23_P_554-0", "entity_mentions": [{"id": "ACL_23_P_554-0-E0", "text": "Adversarial attacks", "start": 53, "end": 55, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_554-0-E1", "text": "Reasoning has been a central topic in artificial intelligence from the beginning", "start": 0, "end": 12, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_554-0-E2", "text": "The recent progress made on distributed representation and neural networks continues to improve the state-of-the-art performance of natural language inference", "start": 12, "end": 32, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_554-0-E3", "text": "it remains an open question whether the models perform real reasoning to reach their conclusions or rely on spurious correlations", "start": 33, "end": 53, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_554-0-E4", "text": "an important tool", "start": 59, "end": 62, "entity_type": "UNK", "mention_type": "UNK"}], "relation_mentions": [], "event_mentions": [{"event_type": "Background/Introduction", "id": "ACL_23_P_554-0-EV0", "trigger": {"text": "have proven to be", "start": 55, "end": 59}, "arguments": [{"entity_id": "ACL_23_P_554-0-E0", "text": "Adversarial attacks", "role": "Agent"}, {"entity_id": "ACL_23_P_554-0-E1", "text": "Reasoning has been a central topic in artificial intelligence from the beginning", "role": "Context"}, {"entity_id": "ACL_23_P_554-0-E2", "text": "The recent progress made on distributed representation and neural networks continues to improve the state-of-the-art performance of natural language inference", "role": "Context"}, {"entity_id": "ACL_23_P_554-0-E3", "text": "it remains an open question whether the models perform real reasoning to reach their conclusions or rely on spurious correlations", "role": "Challenge"}, {"entity_id": "ACL_23_P_554-0-E4", "text": "an important tool", "role": "PrimaryObject"}]}], "entity_coreference": [], "event_coreference": [], "tokens": ["Reasoning", "has", "been", "a", "central", "topic", "in", "artificial", "intelligence", "from", "the", "beginning.", "The", "recent", "progress", "made", "on", "distributed", "representation", "and", "neural", "networks", "continues", "to", "improve", "the", "state-of-the-art", "performance", "of", "natural", "language", "inference.", "However,", "it", "remains", "an", "open", "question", "whether", "the", "models", "perform", "real", "reasoning", "to", "reach", "their", "conclusions", "or", "rely", "on", "spurious", "correlations.", "Adversarial", "attacks", "have", "proven", "to", "be", "an", "important", "tool", "to", "help", "evaluate", "the", "Achilles\u2019", "heel", "of", "the", "victim", "models."], "pieces": ["Reason", "ing", "has", "been", "a", "central", "topic", "in", "art", "ificial", "intelligence", "from", "the", "begin", "ning", ".", "The", "recent", "progress", "made", "on", "dist", "ributed", "represent", "ation", "and", "ne", "ural", "net", "works", "contin", "ues", "to", "improve", "the", "state", "-", "of", "-", "the", "-", "art", "performance", "of", "natural", "language", "in", "ference", ".", "However", ",", "it", "rem", "ains", "an", "open", "question", "whether", "the", "models", "per", "form", "real", "reason", "ing", "to", "reach", "their", "con", "clusions", "or", "rely", "on", "sp", "urious", "cor", "relations", ".", "Ad", "vers", "arial", "attacks", "have", "proven", "to", "be", "an", "important", "tool", "to", "help", "evaluate", "the", "A", "ch", "illes", "\u00e2\u0122", "\u013b", "he", "el", "of", "the", "vict", "im", "models", "."], "token_lens": [2, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 3, 1, 1, 1, 1, 1, 2, 2, 1, 2, 2, 2, 1, 1, 1, 7, 1, 1, 1, 1, 3, 2, 1, 2, 1, 1, 1, 1, 1, 1, 2, 1, 2, 1, 1, 1, 2, 1, 1, 1, 2, 3, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 5, 2, 1, 1, 2, 2], "sentence": "Reasoning has been a central topic in artificial intelligence from the beginning. The recent progress made on distributed representation and neural networks continues to improve the state-of-the-art performance of natural language inference. However, it remains an open question whether the models perform real reasoning to reach their conclusions or rely on spurious correlations. Adversarial attacks have proven to be an important tool to help evaluate the Achilles\u2019 heel of the victim models.", "sentence_starts": [0]}
{"doc_id": "ACL_23_P_554", "wnd_id": "ACL_23_P_554-1", "entity_mentions": [{"id": "ACL_23_P_554-1-E0", "text": "we", "start": 3, "end": 4, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_554-1-E1", "text": "We propose NatLogAttack to perform systematic attacks centring around natural logic, a classical logic formalism that is traceable back to Aristotle\u2019s syllogism and has been closely developed for natural language inference", "start": 16, "end": 47, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_554-1-E2", "text": "The proposed framework renders both label-preserving and label-flipping attacks", "start": 47, "end": 56, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_554-1-E3", "text": "the fundamental problem", "start": 5, "end": 8, "entity_type": "UNK", "mention_type": "UNK"}], "relation_mentions": [], "event_mentions": [{"event_type": "Methods/Approach", "id": "ACL_23_P_554-1-EV0", "trigger": {"text": "explore", "start": 4, "end": 5}, "arguments": [{"entity_id": "ACL_23_P_554-1-E0", "text": "we", "role": "Agent"}, {"entity_id": "ACL_23_P_554-1-E1", "text": "We propose NatLogAttack to perform systematic attacks centring around natural logic, a classical logic formalism that is traceable back to Aristotle\u2019s syllogism and has been closely developed for natural language inference", "role": "Method"}, {"entity_id": "ACL_23_P_554-1-E2", "text": "The proposed framework renders both label-preserving and label-flipping attacks", "role": "Method"}, {"entity_id": "ACL_23_P_554-1-E3", "text": "the fundamental problem", "role": "PrimaryObject"}]}], "entity_coreference": [], "event_coreference": [], "tokens": ["In", "this", "study,", "we", "explore", "the", "fundamental", "problem", "of", "developing", "attack", "models", "based", "on", "logic", "formalism.", "We", "propose", "NatLogAttack", "to", "perform", "systematic", "attacks", "centring", "around", "natural", "logic,", "a", "classical", "logic", "formalism", "that", "is", "traceable", "back", "to", "Aristotle\u2019s", "syllogism", "and", "has", "been", "closely", "developed", "for", "natural", "language", "inference.", "The", "proposed", "framework", "renders", "both", "label-preserving", "and", "label-flipping", "attacks."], "pieces": ["In", "this", "study", ",", "we", "expl", "ore", "the", "fund", "amental", "problem", "of", "develop", "ing", "attack", "models", "based", "on", "log", "ic", "form", "al", "ism", ".", "We", "pro", "pose", "Nat", "Log", "Attack", "to", "per", "form", "system", "atic", "attacks", "cent", "ring", "around", "natural", "log", "ic", ",", "a", "class", "ical", "log", "ic", "form", "al", "ism", "that", "is", "trace", "able", "back", "to", "A", "rist", "otle", "\u00e2\u0122", "\u013b", "s", "sy", "ll", "og", "ism", "and", "has", "been", "close", "ly", "developed", "for", "natural", "language", "in", "ference", ".", "The", "prop", "osed", "framework", "rend", "ers", "both", "label", "-", "pres", "erving", "and", "label", "-", "fl", "ipping", "attacks", "."], "token_lens": [1, 1, 2, 1, 2, 1, 2, 1, 1, 2, 1, 1, 1, 1, 2, 4, 1, 2, 3, 1, 2, 2, 1, 2, 1, 1, 3, 1, 2, 2, 3, 1, 1, 2, 1, 1, 6, 4, 1, 1, 1, 2, 1, 1, 1, 1, 3, 1, 2, 1, 2, 1, 4, 1, 4, 2], "sentence": "In this study, we explore the fundamental problem of developing attack models based on logic formalism. We propose NatLogAttack to perform systematic attacks centring around natural logic, a classical logic formalism that is traceable back to Aristotle\u2019s syllogism and has been closely developed for natural language inference. The proposed framework renders both label-preserving and label-flipping attacks.", "sentence_starts": [0]}
{"doc_id": "ACL_23_P_554", "wnd_id": "ACL_23_P_554-2", "entity_mentions": [{"id": "ACL_23_P_554-2-E0", "text": "We", "start": 0, "end": 1, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_554-2-E1", "text": "compared to the existing attack models, NatLogAttack generates better adversarial examples with fewer visits to the victim models", "start": 3, "end": 21, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_554-2-E2", "text": "The victim models are found to be more vulnerable under the label-flipping setting", "start": 21, "end": 34, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_554-2-E3", "text": "compared to the existing attack models, NatLogAttack generates better adversarial examples with fewer visits to the victim models", "start": 3, "end": 21, "entity_type": "UNK", "mention_type": "UNK"}], "relation_mentions": [], "event_mentions": [{"event_type": "Results/Findings", "id": "ACL_23_P_554-2-EV0", "trigger": {"text": "show", "start": 1, "end": 2}, "arguments": [{"entity_id": "ACL_23_P_554-2-E0", "text": "We", "role": "Agent"}, {"entity_id": "ACL_23_P_554-2-E1", "text": "compared to the existing attack models, NatLogAttack generates better adversarial examples with fewer visits to the victim models", "role": "Results"}, {"entity_id": "ACL_23_P_554-2-E2", "text": "The victim models are found to be more vulnerable under the label-flipping setting", "role": "Results"}, {"entity_id": "ACL_23_P_554-2-E3", "text": "compared to the existing attack models, NatLogAttack generates better adversarial examples with fewer visits to the victim models", "role": "PrimaryObject"}]}], "entity_coreference": [], "event_coreference": [], "tokens": ["We", "show", "that", "compared", "to", "the", "existing", "attack", "models,", "NatLogAttack", "generates", "better", "adversarial", "examples", "with", "fewer", "visits", "to", "the", "victim", "models.", "The", "victim", "models", "are", "found", "to", "be", "more", "vulnerable", "under", "the", "label-flipping", "setting."], "pieces": ["We", "show", "that", "comp", "ared", "to", "the", "existing", "attack", "models", ",", "Nat", "Log", "Attack", "gener", "ates", "better", "ad", "vers", "arial", "ex", "amples", "with", "few", "er", "vis", "its", "to", "the", "vict", "im", "models", ".", "The", "vict", "im", "models", "are", "found", "to", "be", "more", "v", "ulnerable", "under", "the", "label", "-", "fl", "ipping", "setting", "."], "token_lens": [1, 1, 1, 2, 1, 1, 1, 1, 2, 3, 2, 1, 3, 2, 1, 2, 2, 1, 1, 2, 2, 1, 2, 1, 1, 1, 1, 1, 1, 2, 1, 1, 4, 2], "sentence": "We show that compared to the existing attack models, NatLogAttack generates better adversarial examples with fewer visits to the victim models. The victim models are found to be more vulnerable under the label-flipping setting.", "sentence_starts": [0]}
{"doc_id": "ACL_23_P_554", "wnd_id": "ACL_23_P_554-3", "entity_mentions": [{"id": "ACL_23_P_554-3-E0", "text": "NatLogAttack", "start": 0, "end": 1, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_554-3-E1", "text": "we hope more logic-based attacks will be further explored for understanding the desired property of reasoning", "start": 18, "end": 34, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_554-3-E2", "text": "a tool", "start": 2, "end": 4, "entity_type": "UNK", "mention_type": "UNK"}], "relation_mentions": [], "event_mentions": [{"event_type": "Conclusions/Implications", "id": "ACL_23_P_554-3-EV0", "trigger": {"text": "provides", "start": 1, "end": 2}, "arguments": [{"entity_id": "ACL_23_P_554-3-E0", "text": "NatLogAttack", "role": "Agent"}, {"entity_id": "ACL_23_P_554-3-E1", "text": "we hope more logic-based attacks will be further explored for understanding the desired property of reasoning", "role": "Implications"}, {"entity_id": "ACL_23_P_554-3-E2", "text": "a tool", "role": "PrimaryObject"}]}], "entity_coreference": [], "event_coreference": [], "tokens": ["NatLogAttack", "provides", "a", "tool", "to", "probe", "the", "existing", "and", "future", "NLI", "models\u2019", "capacity", "from", "a", "key", "viewpoint", "and", "we", "hope", "more", "logic-based", "attacks", "will", "be", "further", "explored", "for", "understanding", "the", "desired", "property", "of", "reasoning."], "pieces": ["Nat", "Log", "Attack", "prov", "ides", "a", "tool", "to", "pro", "be", "the", "existing", "and", "future", "N", "LI", "models", "\u00e2\u0122", "\u013b", "capacity", "from", "a", "key", "view", "point", "and", "we", "h", "ope", "more", "log", "ic", "-", "based", "attacks", "will", "be", "f", "urther", "expl", "ored", "for", "under", "standing", "the", "des", "ired", "property", "of", "reason", "ing", "."], "token_lens": [3, 2, 1, 1, 1, 2, 1, 1, 1, 1, 2, 3, 1, 1, 1, 1, 2, 1, 1, 2, 1, 4, 1, 1, 1, 2, 2, 1, 2, 1, 2, 1, 1, 3], "sentence": "NatLogAttack provides a tool to probe the existing and future NLI models\u2019 capacity from a key viewpoint and we hope more logic-based attacks will be further explored for understanding the desired property of reasoning.", "sentence_starts": [0]}
{"doc_id": "ACL_23_P_606", "wnd_id": "ACL_23_P_606-0", "entity_mentions": [{"id": "ACL_23_P_606-0-E0", "text": "Extracting generalized and robust representations", "start": 0, "end": 5, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_606-0-E1", "text": "a major challenge", "start": 6, "end": 9, "entity_type": "UNK", "mention_type": "UNK"}], "relation_mentions": [], "event_mentions": [{"event_type": "Background/Introduction", "id": "ACL_23_P_606-0-EV0", "trigger": {"text": "is", "start": 5, "end": 6}, "arguments": [{"entity_id": "ACL_23_P_606-0-E0", "text": "Extracting generalized and robust representations", "role": "Agent"}, {"entity_id": "ACL_23_P_606-0-E1", "text": "a major challenge", "role": "PrimaryObject"}]}], "entity_coreference": [], "event_coreference": [], "tokens": ["Extracting", "generalized", "and", "robust", "representations", "is", "a", "major", "challenge", "in", "emotion", "recognition", "in", "conversations", "(ERC)."], "pieces": ["Ext", "ract", "ing", "general", "ized", "and", "rob", "ust", "represent", "ations", "is", "a", "major", "chall", "enge", "in", "em", "otion", "recogn", "ition", "in", "con", "vers", "ations", "(", "ERC", ")."], "token_lens": [3, 2, 1, 2, 2, 1, 1, 1, 2, 1, 2, 2, 1, 3, 3], "sentence": "Extracting generalized and robust representations is a major challenge in emotion recognition in conversations (ERC).", "sentence_starts": [0]}
{"doc_id": "ACL_23_P_606", "wnd_id": "ACL_23_P_606-1", "entity_mentions": [{"id": "ACL_23_P_606-1-E0", "text": "we", "start": 3, "end": 4, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_606-1-E1", "text": "SACL applies contrast-aware adversarial training to generate worst-case samples and uses joint class-spread contrastive learning to extract structured representations", "start": 21, "end": 40, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_606-1-E2", "text": "It can effectively utilize label-level feature consistency and retain fine-grained intra-class features", "start": 40, "end": 52, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_606-1-E3", "text": "To avoid the negative impact of adversarial perturbations on context-dependent data, we design a contextual adversarial training (CAT) strategy to learn more diverse features from context and enhance the model\u2019s context robustness", "start": 52, "end": 84, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_606-1-E4", "text": "Under the framework with CAT, we develop a sequence-based SACL-LSTM to learn label-consistent and context-robust features for ERC", "start": 84, "end": 102, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_606-1-E5", "text": "a supervised adversarial contrastive learning (SACL) framework", "start": 5, "end": 12, "entity_type": "UNK", "mention_type": "UNK"}], "relation_mentions": [], "event_mentions": [{"event_type": "Methods/Approach", "id": "ACL_23_P_606-1-EV0", "trigger": {"text": "propose", "start": 4, "end": 5}, "arguments": [{"entity_id": "ACL_23_P_606-1-E0", "text": "we", "role": "Agent"}, {"entity_id": "ACL_23_P_606-1-E1", "text": "SACL applies contrast-aware adversarial training to generate worst-case samples and uses joint class-spread contrastive learning to extract structured representations", "role": "Method"}, {"entity_id": "ACL_23_P_606-1-E2", "text": "It can effectively utilize label-level feature consistency and retain fine-grained intra-class features", "role": "Method"}, {"entity_id": "ACL_23_P_606-1-E3", "text": "To avoid the negative impact of adversarial perturbations on context-dependent data, we design a contextual adversarial training (CAT) strategy to learn more diverse features from context and enhance the model\u2019s context robustness", "role": "Method"}, {"entity_id": "ACL_23_P_606-1-E4", "text": "Under the framework with CAT, we develop a sequence-based SACL-LSTM to learn label-consistent and context-robust features for ERC", "role": "Method"}, {"entity_id": "ACL_23_P_606-1-E5", "text": "a supervised adversarial contrastive learning (SACL) framework", "role": "PrimaryObject"}]}], "entity_coreference": [], "event_coreference": [], "tokens": ["To", "address", "this,", "we", "propose", "a", "supervised", "adversarial", "contrastive", "learning", "(SACL)", "framework", "for", "learning", "class-spread", "structured", "representations", "in", "a", "supervised", "manner.", "SACL", "applies", "contrast-aware", "adversarial", "training", "to", "generate", "worst-case", "samples", "and", "uses", "joint", "class-spread", "contrastive", "learning", "to", "extract", "structured", "representations.", "It", "can", "effectively", "utilize", "label-level", "feature", "consistency", "and", "retain", "fine-grained", "intra-class", "features.", "To", "avoid", "the", "negative", "impact", "of", "adversarial", "perturbations", "on", "context-dependent", "data,", "we", "design", "a", "contextual", "adversarial", "training", "(CAT)", "strategy", "to", "learn", "more", "diverse", "features", "from", "context", "and", "enhance", "the", "model\u2019s", "context", "robustness.", "Under", "the", "framework", "with", "CAT,", "we", "develop", "a", "sequence-based", "SACL-LSTM", "to", "learn", "label-consistent", "and", "context-robust", "features", "for", "ERC."], "pieces": ["To", "address", "this", ",", "we", "pro", "pose", "a", "super", "vised", "ad", "vers", "arial", "cont", "rast", "ive", "learning", "(", "S", "AC", "L", ")", "framework", "for", "learning", "class", "-", "spread", "struct", "ured", "represent", "ations", "in", "a", "super", "vised", "man", "ner", ".", "S", "AC", "L", "app", "lies", "cont", "rast", "-", "aware", "ad", "vers", "arial", "training", "to", "gener", "ate", "worst", "-", "case", "s", "amples", "and", "uses", "j", "oint", "class", "-", "spread", "cont", "rast", "ive", "learning", "to", "ext", "ract", "struct", "ured", "represent", "ations", ".", "It", "can", "effect", "ively", "util", "ize", "label", "-", "level", "feature", "cons", "ist", "ency", "and", "ret", "ain", "fine", "-", "gr", "ained", "int", "ra", "-", "class", "features", ".", "To", "avoid", "the", "negative", "impact", "of", "ad", "vers", "arial", "pert", "urb", "ations", "on", "context", "-", "dependent", "data", ",", "we", "design", "a", "context", "ual", "ad", "vers", "arial", "training", "(", "C", "AT", ")", "str", "ategy", "to", "learn", "more", "d", "iverse", "features", "from", "context", "and", "enh", "ance", "the", "model", "\u00e2\u0122", "\u013b", "s", "context", "rob", "ust", "ness", ".", "Under", "the", "framework", "with", "C", "AT", ",", "we", "develop", "a", "sequence", "-", "based", "S", "AC", "L", "-", "L", "ST", "M", "to", "learn", "label", "-", "cons", "istent", "and", "context", "-", "rob", "ust", "features", "for", "ERC", "."], "token_lens": [1, 1, 2, 1, 2, 1, 2, 3, 3, 1, 5, 1, 1, 1, 3, 2, 2, 1, 1, 2, 3, 3, 2, 4, 3, 1, 1, 2, 3, 2, 1, 1, 2, 3, 3, 1, 1, 2, 2, 3, 1, 1, 2, 2, 3, 1, 3, 1, 2, 4, 4, 2, 1, 1, 1, 1, 1, 1, 3, 3, 1, 3, 2, 1, 1, 1, 2, 3, 1, 4, 2, 1, 1, 1, 2, 1, 1, 1, 1, 2, 1, 4, 1, 4, 1, 1, 1, 1, 3, 1, 1, 1, 3, 7, 1, 1, 4, 1, 4, 1, 1, 2], "sentence": "To address this, we propose a supervised adversarial contrastive learning (SACL) framework for learning class-spread structured representations in a supervised manner. SACL applies contrast-aware adversarial training to generate worst-case samples and uses joint class-spread contrastive learning to extract structured representations. It can effectively utilize label-level feature consistency and retain fine-grained intra-class features. To avoid the negative impact of adversarial perturbations on context-dependent data, we design a contextual adversarial training (CAT) strategy to learn more diverse features from context and enhance the model\u2019s context robustness. Under the framework with CAT, we develop a sequence-based SACL-LSTM to learn label-consistent and context-robust features for ERC.", "sentence_starts": [0]}
{"doc_id": "ACL_23_P_606", "wnd_id": "ACL_23_P_606-2", "entity_mentions": [{"id": "ACL_23_P_606-2-E0", "text": "Experiments on three datasets", "start": 0, "end": 4, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_606-2-E1", "text": "SACL-LSTM achieves state-of-the-art performance on ERC", "start": 6, "end": 12, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_606-2-E2", "text": "Extended experiments prove the effectiveness of SACL and CAT", "start": 12, "end": 21, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_606-2-E3", "text": "SACL-LSTM achieves state-of-the-art performance on ERC", "start": 6, "end": 12, "entity_type": "UNK", "mention_type": "UNK"}], "relation_mentions": [], "event_mentions": [{"event_type": "Results/Findings", "id": "ACL_23_P_606-2-EV0", "trigger": {"text": "show", "start": 4, "end": 5}, "arguments": [{"entity_id": "ACL_23_P_606-2-E0", "text": "Experiments on three datasets", "role": "Agent"}, {"entity_id": "ACL_23_P_606-2-E1", "text": "SACL-LSTM achieves state-of-the-art performance on ERC", "role": "Results"}, {"entity_id": "ACL_23_P_606-2-E2", "text": "Extended experiments prove the effectiveness of SACL and CAT", "role": "Results"}, {"entity_id": "ACL_23_P_606-2-E3", "text": "SACL-LSTM achieves state-of-the-art performance on ERC", "role": "PrimaryObject"}]}], "entity_coreference": [], "event_coreference": [], "tokens": ["Experiments", "on", "three", "datasets", "show", "that", "SACL-LSTM", "achieves", "state-of-the-art", "performance", "on", "ERC.", "Extended", "experiments", "prove", "the", "effectiveness", "of", "SACL", "and", "CAT."], "pieces": ["Exper", "iments", "on", "three", "dat", "as", "ets", "show", "that", "S", "AC", "L", "-", "L", "ST", "M", "ach", "ieves", "state", "-", "of", "-", "the", "-", "art", "performance", "on", "ERC", ".", "Ext", "ended", "exper", "iments", "pro", "ve", "the", "effect", "iveness", "of", "S", "AC", "L", "and", "C", "AT", "."], "token_lens": [2, 1, 1, 3, 1, 1, 7, 2, 7, 1, 1, 2, 2, 2, 2, 1, 2, 1, 3, 1, 3], "sentence": "Experiments on three datasets show that SACL-LSTM achieves state-of-the-art performance on ERC. Extended experiments prove the effectiveness of SACL and CAT.", "sentence_starts": [0]}
{"doc_id": "ACL_23_P_420", "wnd_id": "ACL_23_P_420-0", "entity_mentions": [{"id": "ACL_23_P_420-0-E0", "text": "Weir", "start": 0, "end": 1, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_420-0-E1", "text": "The hierarchy is obtained using the mechanism of control", "start": 28, "end": 37, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_420-0-E2", "text": "L2 is obtained using a context-free grammar (CFG) whose derivations are controlled by another CFG", "start": 38, "end": 53, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_420-0-E3", "text": "a hierarchy of language classes", "start": 3, "end": 8, "entity_type": "UNK", "mention_type": "UNK"}], "relation_mentions": [], "event_mentions": [{"event_type": "Background/Introduction", "id": "ACL_23_P_420-0-EV0", "trigger": {"text": "defined", "start": 2, "end": 3}, "arguments": [{"entity_id": "ACL_23_P_420-0-E0", "text": "Weir", "role": "Agent"}, {"entity_id": "ACL_23_P_420-0-E1", "text": "The hierarchy is obtained using the mechanism of control", "role": "Method"}, {"entity_id": "ACL_23_P_420-0-E2", "text": "L2 is obtained using a context-free grammar (CFG) whose derivations are controlled by another CFG", "role": "Method"}, {"entity_id": "ACL_23_P_420-0-E3", "text": "a hierarchy of language classes", "role": "PrimaryObject"}]}], "entity_coreference": [], "event_coreference": [], "tokens": ["Weir", "has", "defined", "a", "hierarchy", "of", "language", "classes", "whose", "second", "member", "(L2)", "is", "generated", "by", "tree-adjoining", "grammars", "(TAG),", "linear", "indexed", "grammars", "(LIG),", "combinatory", "categorial", "grammars,", "and", "head", "grammars.", "The", "hierarchy", "is", "obtained", "using", "the", "mechanism", "of", "control,", "and", "L2", "is", "obtained", "using", "a", "context-free", "grammar", "(CFG)", "whose", "derivations", "are", "controlled", "by", "another", "CFG."], "pieces": ["We", "ir", "has", "defined", "a", "h", "ier", "archy", "of", "language", "classes", "whose", "second", "member", "(", "L", "2", ")", "is", "generated", "by", "tree", "-", "ad", "joining", "gram", "m", "ars", "(", "TAG", "),", "linear", "index", "ed", "gram", "m", "ars", "(", "L", "IG", "),", "com", "bin", "atory", "c", "ateg", "orial", "gram", "m", "ars", ",", "and", "head", "gram", "m", "ars", ".", "The", "h", "ier", "archy", "is", "ob", "tained", "using", "the", "me", "chan", "ism", "of", "control", ",", "and", "L", "2", "is", "ob", "tained", "using", "a", "context", "-", "free", "gram", "mar", "(", "CF", "G", ")", "whose", "der", "iv", "ations", "are", "controlled", "by", "another", "CF", "G", "."], "token_lens": [2, 1, 1, 1, 3, 1, 1, 1, 1, 1, 1, 4, 1, 1, 1, 4, 3, 3, 1, 2, 3, 4, 3, 3, 4, 1, 1, 4, 1, 3, 1, 2, 1, 1, 3, 1, 2, 1, 2, 1, 2, 1, 1, 3, 2, 4, 1, 3, 1, 1, 1, 1, 3], "sentence": "Weir has defined a hierarchy of language classes whose second member (L2) is generated by tree-adjoining grammars (TAG), linear indexed grammars (LIG), combinatory categorial grammars, and head grammars. The hierarchy is obtained using the mechanism of control, and L2 is obtained using a context-free grammar (CFG) whose derivations are controlled by another CFG.", "sentence_starts": [0]}
{"doc_id": "ACL_23_P_420", "wnd_id": "ACL_23_P_420-1", "entity_mentions": [{"id": "ACL_23_P_420-1-E0", "text": "We", "start": 0, "end": 1, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_420-1-E1", "text": "to give a definition of controllable pushdown automata (PDAs), called labeled distinguished PDAs", "start": 13, "end": 26, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_420-1-E2", "text": "three new characterizations of L2 as the class of languages generated by PDAs controlling PDAs, PDAs controlling CFGs, and CFGs controlling PDAs", "start": 28, "end": 50, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_420-1-E3", "text": "Weir\u2019s definition", "start": 2, "end": 4, "entity_type": "UNK", "mention_type": "UNK"}], "relation_mentions": [], "event_mentions": [{"event_type": "Methods/Approach", "id": "ACL_23_P_420-1-EV0", "trigger": {"text": "adapt", "start": 1, "end": 2}, "arguments": [{"entity_id": "ACL_23_P_420-1-E0", "text": "We", "role": "Agent"}, {"entity_id": "ACL_23_P_420-1-E1", "text": "to give a definition of controllable pushdown automata (PDAs), called labeled distinguished PDAs", "role": "Purpose"}, {"entity_id": "ACL_23_P_420-1-E2", "text": "three new characterizations of L2 as the class of languages generated by PDAs controlling PDAs, PDAs controlling CFGs, and CFGs controlling PDAs", "role": "Results"}, {"entity_id": "ACL_23_P_420-1-E3", "text": "Weir\u2019s definition", "role": "PrimaryObject"}]}], "entity_coreference": [], "event_coreference": [], "tokens": ["We", "adapt", "Weir\u2019s", "definition", "of", "a", "controllable", "CFG", "(called", "a", "labeled", "distinguished", "CFG)", "to", "give", "a", "definition", "of", "controllable", "pushdown", "automata", "(PDAs),", "called", "labeled", "distinguished", "PDAs.", "This", "yields", "three", "new", "characterizations", "of", "L2", "as", "the", "class", "of", "languages", "generated", "by", "PDAs", "controlling", "PDAs,", "PDAs", "controlling", "CFGs,", "and", "CFGs", "controlling", "PDAs."], "pieces": ["We", "adapt", "We", "ir", "\u00e2\u0122", "\u013b", "s", "definition", "of", "a", "cont", "roll", "able", "CF", "G", "(", "called", "a", "label", "ed", "dist", "inguished", "CF", "G", ")", "to", "give", "a", "definition", "of", "cont", "roll", "able", "push", "down", "aut", "om", "ata", "(", "PD", "As", "),", "called", "label", "ed", "dist", "inguished", "PD", "As", ".", "This", "y", "ield", "s", "three", "new", "character", "izations", "of", "L", "2", "as", "the", "class", "of", "l", "anguages", "generated", "by", "PD", "As", "cont", "rolling", "PD", "As", ",", "PD", "As", "cont", "rolling", "CF", "Gs", ",", "and", "CF", "Gs", "cont", "rolling", "PD", "As", "."], "token_lens": [1, 1, 5, 1, 1, 1, 3, 2, 2, 1, 2, 2, 3, 1, 1, 1, 1, 1, 3, 2, 3, 4, 1, 2, 2, 3, 1, 3, 1, 1, 2, 1, 2, 1, 1, 1, 1, 2, 1, 1, 2, 2, 3, 2, 2, 3, 1, 2, 2, 3], "sentence": "We adapt Weir\u2019s definition of a controllable CFG (called a labeled distinguished CFG) to give a definition of controllable pushdown automata (PDAs), called labeled distinguished PDAs. This yields three new characterizations of L2 as the class of languages generated by PDAs controlling PDAs, PDAs controlling CFGs, and CFGs controlling PDAs.", "sentence_starts": [0]}
{"doc_id": "ACL_23_P_420", "wnd_id": "ACL_23_P_420-2", "entity_mentions": [{"id": "ACL_23_P_420-2-E0", "text": "We", "start": 0, "end": 1, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_420-2-E1", "text": "using an even stricter notion of equivalence called d-strong equivalence", "start": 23, "end": 33, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_420-2-E2", "text": "these four formalisms are not only weakly equivalent but equivalent in a stricter sense that we call d-weak equivalence", "start": 3, "end": 22, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_420-2-E3", "text": "a CFG controlling a CFG is a TAG, a PDA controlling a PDA is an embedded PDA, and a PDA controlling a CFG is a LIG", "start": 39, "end": 65, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_420-2-E4", "text": "The fourth member of this family, a CFG controlling a PDA, does not correspond to any kind of automaton we know of, so we invent one and call it a Pushdown Adjoining Automaton (PAA)", "start": 65, "end": 99, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_420-2-E5", "text": "these four formalisms are not only weakly equivalent but equivalent in a stricter sense that we call d-weak equivalence", "start": 3, "end": 22, "entity_type": "UNK", "mention_type": "UNK"}], "relation_mentions": [], "event_mentions": [{"event_type": "Results/Findings", "id": "ACL_23_P_420-2-EV0", "trigger": {"text": "show", "start": 1, "end": 2}, "arguments": [{"entity_id": "ACL_23_P_420-2-E0", "text": "We", "role": "Agent"}, {"entity_id": "ACL_23_P_420-2-E1", "text": "using an even stricter notion of equivalence called d-strong equivalence", "role": "Method"}, {"entity_id": "ACL_23_P_420-2-E2", "text": "these four formalisms are not only weakly equivalent but equivalent in a stricter sense that we call d-weak equivalence", "role": "Results"}, {"entity_id": "ACL_23_P_420-2-E3", "text": "a CFG controlling a CFG is a TAG, a PDA controlling a PDA is an embedded PDA, and a PDA controlling a CFG is a LIG", "role": "Results"}, {"entity_id": "ACL_23_P_420-2-E4", "text": "The fourth member of this family, a CFG controlling a PDA, does not correspond to any kind of automaton we know of, so we invent one and call it a Pushdown Adjoining Automaton (PAA)", "role": "Results"}, {"entity_id": "ACL_23_P_420-2-E5", "text": "these four formalisms are not only weakly equivalent but equivalent in a stricter sense that we call d-weak equivalence", "role": "PrimaryObject"}]}], "entity_coreference": [], "event_coreference": [], "tokens": ["We", "show", "that", "these", "four", "formalisms", "are", "not", "only", "weakly", "equivalent", "but", "equivalent", "in", "a", "stricter", "sense", "that", "we", "call", "d-weak", "equivalence.", "Furthermore,", "using", "an", "even", "stricter", "notion", "of", "equivalence", "called", "d-strong", "equivalence,", "we", "make", "precise", "the", "intuition", "that", "a", "CFG", "controlling", "a", "CFG", "is", "a", "TAG,", "a", "PDA", "controlling", "a", "PDA", "is", "an", "embedded", "PDA,", "and", "a", "PDA", "controlling", "a", "CFG", "is", "a", "LIG.", "The", "fourth", "member", "of", "this", "family,", "a", "CFG", "controlling", "a", "PDA,", "does", "not", "correspond", "to", "any", "kind", "of", "automaton", "we", "know", "of,", "so", "we", "invent", "one", "and", "call", "it", "a", "Pushdown", "Adjoining", "Automaton", "(PAA)."], "pieces": ["We", "show", "that", "these", "four", "form", "al", "isms", "are", "not", "only", "weak", "ly", "equ", "ivalent", "but", "equ", "ivalent", "in", "a", "st", "ric", "ter", "sense", "that", "we", "call", "d", "-", "weak", "equ", "ival", "ence", ".", "Furthermore", ",", "using", "an", "even", "st", "ric", "ter", "not", "ion", "of", "equ", "ival", "ence", "called", "d", "-", "strong", "equ", "ival", "ence", ",", "we", "make", "pre", "cise", "the", "int", "u", "ition", "that", "a", "CF", "G", "cont", "rolling", "a", "CF", "G", "is", "a", "TAG", ",", "a", "P", "DA", "cont", "rolling", "a", "P", "DA", "is", "an", "embed", "ded", "P", "DA", ",", "and", "a", "P", "DA", "cont", "rolling", "a", "CF", "G", "is", "a", "L", "IG", ".", "The", "fourth", "member", "of", "this", "family", ",", "a", "CF", "G", "cont", "rolling", "a", "P", "DA", ",", "does", "not", "cor", "respond", "to", "any", "kind", "of", "aut", "om", "aton", "we", "know", "of", ",", "so", "we", "in", "vent", "one", "and", "call", "it", "a", "Push", "down", "Ad", "joining", "Autom", "aton", "(", "P", "AA", ")."], "token_lens": [1, 1, 1, 1, 1, 3, 1, 1, 1, 2, 2, 1, 2, 1, 1, 3, 1, 1, 1, 1, 3, 4, 2, 1, 1, 1, 3, 2, 1, 3, 1, 3, 4, 1, 1, 2, 1, 3, 1, 1, 2, 2, 1, 2, 1, 1, 2, 1, 2, 2, 1, 2, 1, 1, 2, 3, 1, 1, 2, 2, 1, 2, 1, 1, 3, 1, 1, 1, 1, 1, 2, 1, 2, 2, 1, 3, 1, 1, 2, 1, 1, 1, 1, 3, 1, 1, 2, 1, 1, 2, 1, 1, 1, 1, 1, 2, 2, 2, 4], "sentence": "We show that these four formalisms are not only weakly equivalent but equivalent in a stricter sense that we call d-weak equivalence. Furthermore, using an even stricter notion of equivalence called d-strong equivalence, we make precise the intuition that a CFG controlling a CFG is a TAG, a PDA controlling a PDA is an embedded PDA, and a PDA controlling a CFG is a LIG. The fourth member of this family, a CFG controlling a PDA, does not correspond to any kind of automaton we know of, so we invent one and call it a Pushdown Adjoining Automaton (PAA).", "sentence_starts": [0]}
{"doc_id": "ACL_23_P_216", "wnd_id": "ACL_23_P_216-0", "entity_mentions": [{"id": "ACL_23_P_216-0-E0", "text": "End-to-end Speech Translation (E2E ST)", "start": 0, "end": 5, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_216-0-E1", "text": "an ST model\u2019s performance closely correlates with its embedding similarity between speech and source transcript", "start": 32, "end": 47, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_216-0-E2", "text": "Existing ST methods perform poorly when only extremely small speech-text data are available for training", "start": 14, "end": 29, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_216-0-E3", "text": "source speech", "start": 9, "end": 11, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_216-0-E4", "text": "into target text", "start": 11, "end": 14, "entity_type": "UNK", "mention_type": "UNK"}], "relation_mentions": [], "event_mentions": [{"event_type": "Background/Introduction", "id": "ACL_23_P_216-0-EV0", "trigger": {"text": "aims to directly translate", "start": 5, "end": 9}, "arguments": [{"entity_id": "ACL_23_P_216-0-E0", "text": "End-to-end Speech Translation (E2E ST)", "role": "Agent"}, {"entity_id": "ACL_23_P_216-0-E1", "text": "an ST model\u2019s performance closely correlates with its embedding similarity between speech and source transcript", "role": "Context"}, {"entity_id": "ACL_23_P_216-0-E2", "text": "Existing ST methods perform poorly when only extremely small speech-text data are available for training", "role": "Challenge"}, {"entity_id": "ACL_23_P_216-0-E3", "text": "source speech", "role": "PrimaryObject"}, {"entity_id": "ACL_23_P_216-0-E4", "text": "into target text", "role": "SecondaryObject"}]}], "entity_coreference": [], "event_coreference": [], "tokens": ["End-to-end", "Speech", "Translation", "(E2E", "ST)", "aims", "to", "directly", "translate", "source", "speech", "into", "target", "text.", "Existing", "ST", "methods", "perform", "poorly", "when", "only", "extremely", "small", "speech-text", "data", "are", "available", "for", "training.", "We", "observe", "that", "an", "ST", "model\u2019s", "performance", "closely", "correlates", "with", "its", "embedding", "similarity", "between", "speech", "and", "source", "transcript."], "pieces": ["End", "-", "to", "-", "end", "Spe", "ech", "Translation", "(", "E", "2", "E", "ST", ")", "aim", "s", "to", "direct", "ly", "trans", "late", "source", "speech", "into", "target", "text", ".", "Ex", "isting", "ST", "method", "s", "per", "form", "poor", "ly", "when", "only", "extremely", "small", "speech", "-", "text", "data", "are", "available", "for", "training", ".", "We", "ob", "ser", "ve", "that", "an", "ST", "model", "\u00e2\u0122", "\u013b", "s", "performance", "close", "ly", "cor", "rel", "ates", "with", "its", "embed", "ding", "similar", "ity", "between", "speech", "and", "source", "trans", "cript", "."], "token_lens": [5, 2, 1, 4, 2, 2, 1, 2, 2, 1, 1, 1, 1, 2, 2, 1, 2, 2, 2, 1, 1, 1, 1, 3, 1, 1, 1, 1, 2, 1, 3, 1, 1, 1, 4, 1, 2, 3, 1, 1, 2, 2, 1, 1, 1, 1, 3], "sentence": "End-to-end Speech Translation (E2E ST) aims to directly translate source speech into target text. Existing ST methods perform poorly when only extremely small speech-text data are available for training. We observe that an ST model\u2019s performance closely correlates with its embedding similarity between speech and source transcript.", "sentence_starts": [0]}
{"doc_id": "ACL_23_P_216", "wnd_id": "ACL_23_P_216-1", "entity_mentions": [{"id": "ACL_23_P_216-1-E0", "text": "we", "start": 3, "end": 4, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_216-1-E1", "text": "bridging word-level representations for both speech and text modalities via contrastive learning", "start": 23, "end": 35, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_216-1-E2", "text": "Word-Aligned COntrastive learning (WACO)", "start": 5, "end": 9, "entity_type": "UNK", "mention_type": "UNK"}], "relation_mentions": [], "event_mentions": [{"event_type": "Methods/Approach", "id": "ACL_23_P_216-1-EV0", "trigger": {"text": "propose", "start": 4, "end": 5}, "arguments": [{"entity_id": "ACL_23_P_216-1-E0", "text": "we", "role": "Agent"}, {"entity_id": "ACL_23_P_216-1-E1", "text": "bridging word-level representations for both speech and text modalities via contrastive learning", "role": "Method"}, {"entity_id": "ACL_23_P_216-1-E2", "text": "Word-Aligned COntrastive learning (WACO)", "role": "PrimaryObject"}]}], "entity_coreference": [], "event_coreference": [], "tokens": ["In", "this", "paper,", "we", "propose", "Word-Aligned", "COntrastive", "learning", "(WACO),", "a", "simple", "and", "effective", "method", "for", "extremely", "low-resource", "speech-to-text", "translation.", "Our", "key", "idea", "is", "bridging", "word-level", "representations", "for", "both", "speech", "and", "text", "modalities", "via", "contrastive", "learning."], "pieces": ["In", "this", "paper", ",", "we", "pro", "pose", "Word", "-", "Al", "igned", "CO", "nt", "rast", "ive", "learning", "(", "W", "AC", "O", "),", "a", "simple", "and", "effective", "method", "for", "extremely", "low", "-", "resource", "speech", "-", "to", "-", "text", "translation", ".", "Our", "key", "ide", "a", "is", "brid", "ging", "word", "-", "level", "represent", "ations", "for", "both", "speech", "and", "text", "mod", "alities", "via", "cont", "rast", "ive", "learning", "."], "token_lens": [1, 1, 2, 1, 2, 4, 4, 1, 5, 1, 1, 1, 1, 1, 1, 1, 3, 5, 2, 1, 1, 2, 1, 2, 3, 2, 1, 1, 1, 1, 1, 2, 1, 3, 2], "sentence": "In this paper, we propose Word-Aligned COntrastive learning (WACO), a simple and effective method for extremely low-resource speech-to-text translation. Our key idea is bridging word-level representations for both speech and text modalities via contrastive learning.", "sentence_starts": [0]}
{"doc_id": "ACL_23_P_216", "wnd_id": "ACL_23_P_216-2", "entity_mentions": [{"id": "ACL_23_P_216-2-E0", "text": "We", "start": 0, "end": 1, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_216-2-E1", "text": "WACO outperforms the best baseline by 9+ BLEU points with only 1-hour parallel ST data", "start": 28, "end": 43, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_216-2-E2", "text": "WACO and other methods", "start": 2, "end": 6, "entity_type": "UNK", "mention_type": "UNK"}], "relation_mentions": [], "event_mentions": [{"event_type": "Results/Findings", "id": "ACL_23_P_216-2-EV0", "trigger": {"text": "evaluate", "start": 1, "end": 2}, "arguments": [{"entity_id": "ACL_23_P_216-2-E0", "text": "We", "role": "Agent"}, {"entity_id": "ACL_23_P_216-2-E1", "text": "WACO outperforms the best baseline by 9+ BLEU points with only 1-hour parallel ST data", "role": "Results"}, {"entity_id": "ACL_23_P_216-2-E2", "text": "WACO and other methods", "role": "PrimaryObject"}]}], "entity_coreference": [], "event_coreference": [], "tokens": ["We", "evaluate", "WACO", "and", "other", "methods", "on", "the", "MuST-C", "dataset,", "a", "widely", "used", "ST", "benchmark,", "and", "on", "a", "low-resource", "direction", "Maltese-English", "from", "IWSLT", "2023.", "Our", "experiments", "demonstrate", "that", "WACO", "outperforms", "the", "best", "baseline", "by", "9+", "BLEU", "points", "with", "only", "1-hour", "parallel", "ST", "data."], "pieces": ["We", "evaluate", "W", "AC", "O", "and", "other", "method", "s", "on", "the", "Mu", "ST", "-", "C", "dat", "as", "et", ",", "a", "wide", "ly", "used", "ST", "bench", "mark", ",", "and", "on", "a", "low", "-", "resource", "direction", "M", "alt", "ese", "-", "English", "from", "I", "W", "SL", "T", "20", "23", ".", "Our", "exper", "iments", "demon", "strate", "that", "W", "AC", "O", "out", "per", "forms", "the", "best", "bas", "eline", "by", "9", "+", "BLE", "U", "points", "with", "only", "1", "-", "hour", "par", "allel", "ST", "data", "."], "token_lens": [1, 1, 3, 1, 1, 2, 1, 1, 4, 4, 1, 2, 1, 1, 3, 1, 1, 1, 3, 1, 5, 1, 4, 3, 1, 2, 2, 1, 3, 3, 1, 1, 2, 1, 2, 2, 1, 1, 1, 3, 2, 1, 2], "sentence": "We evaluate WACO and other methods on the MuST-C dataset, a widely used ST benchmark, and on a low-resource direction Maltese-English from IWSLT 2023. Our experiments demonstrate that WACO outperforms the best baseline by 9+ BLEU points with only 1-hour parallel ST data.", "sentence_starts": [0]}
{"doc_id": "ACL_23_P_359", "wnd_id": "ACL_23_P_359-0", "entity_mentions": [{"id": "ACL_23_P_359-0-E0", "text": "Social biases and stereotypes", "start": 0, "end": 4, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_359-0-E1", "text": "as evidenced by the rich history of humanities and social science literature analyzing such biases in children's stories", "start": 17, "end": 35, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_359-0-E2", "text": "Because these analyses are often conducted manually and at a small scale", "start": 35, "end": 47, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_359-0-E3", "text": "such investigations can benefit from the use of more recent natural language processing (NLP) methods that examine social bias in models and data corpora", "start": 47, "end": 71, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_359-0-E4", "text": "our culture", "start": 7, "end": 9, "entity_type": "UNK", "mention_type": "UNK"}], "relation_mentions": [], "event_mentions": [{"event_type": "Background/Introduction", "id": "ACL_23_P_359-0-EV0", "trigger": {"text": "are embedded in", "start": 4, "end": 7}, "arguments": [{"entity_id": "ACL_23_P_359-0-E0", "text": "Social biases and stereotypes", "role": "Agent"}, {"entity_id": "ACL_23_P_359-0-E1", "text": "as evidenced by the rich history of humanities and social science literature analyzing such biases in children's stories", "role": "Analysis"}, {"entity_id": "ACL_23_P_359-0-E2", "text": "Because these analyses are often conducted manually and at a small scale", "role": "Analysis"}, {"entity_id": "ACL_23_P_359-0-E3", "text": "such investigations can benefit from the use of more recent natural language processing (NLP) methods that examine social bias in models and data corpora", "role": "Implications"}, {"entity_id": "ACL_23_P_359-0-E4", "text": "our culture", "role": "PrimaryObject"}]}], "entity_coreference": [], "event_coreference": [], "tokens": ["Social", "biases", "and", "stereotypes", "are", "embedded", "in", "our", "culture", "in", "part", "through", "their", "presence", "in", "our", "stories,", "as", "evidenced", "by", "the", "rich", "history", "of", "humanities", "and", "social", "science", "literature", "analyzing", "such", "biases", "in", "children's", "stories.", "Because", "these", "analyses", "are", "often", "conducted", "manually", "and", "at", "a", "small", "scale,", "such", "investigations", "can", "benefit", "from", "the", "use", "of", "more", "recent", "natural", "language", "processing", "(NLP)", "methods", "that", "examine", "social", "bias", "in", "models", "and", "data", "corpora."], "pieces": ["Social", "bi", "ases", "and", "st", "ere", "otypes", "are", "embed", "ded", "in", "our", "culture", "in", "part", "through", "their", "pres", "ence", "in", "our", "stories", ",", "as", "ev", "id", "enced", "by", "the", "rich", "history", "of", "human", "ities", "and", "social", "science", "liter", "ature", "analy", "zing", "such", "bi", "ases", "in", "children", "'s", "stories", ".", "Because", "these", "an", "alyses", "are", "often", "conduct", "ed", "man", "ually", "and", "at", "a", "small", "scale", ",", "such", "invest", "ig", "ations", "can", "benefit", "from", "the", "use", "of", "more", "recent", "natural", "language", "processing", "(", "N", "LP", ")", "method", "s", "that", "ex", "amine", "social", "b", "ias", "in", "models", "and", "data", "cor", "pora", "."], "token_lens": [1, 2, 1, 3, 1, 2, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 2, 1, 3, 1, 1, 1, 1, 1, 2, 1, 1, 1, 2, 2, 1, 2, 1, 2, 2, 1, 1, 2, 1, 1, 2, 2, 1, 1, 1, 1, 2, 1, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 4, 2, 1, 2, 1, 2, 1, 1, 1, 1, 3], "sentence": "Social biases and stereotypes are embedded in our culture in part through their presence in our stories, as evidenced by the rich history of humanities and social science literature analyzing such biases in children's stories. Because these analyses are often conducted manually and at a small scale, such investigations can benefit from the use of more recent natural language processing (NLP) methods that examine social bias in models and data corpora.", "sentence_starts": [0]}
{"doc_id": "ACL_23_P_359", "wnd_id": "ACL_23_P_359-1", "entity_mentions": [{"id": "ACL_23_P_359-1-E0", "text": "We", "start": 26, "end": 27, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_359-1-E1", "text": "Our work joins this interdisciplinary effort and makes a unique contribution by taking into account the event narrative structures when analyzing the social bias of stories", "start": 0, "end": 26, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_359-1-E2", "text": "We also present a verb-based event annotation scheme that can facilitate bias analysis by including categories such as those that align with traditional stereotypes", "start": 54, "end": 78, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_359-1-E3", "text": "a computational pipeline", "start": 28, "end": 31, "entity_type": "UNK", "mention_type": "UNK"}], "relation_mentions": [], "event_mentions": [{"event_type": "Methods/Approach", "id": "ACL_23_P_359-1-EV0", "trigger": {"text": "propose", "start": 27, "end": 28}, "arguments": [{"entity_id": "ACL_23_P_359-1-E0", "text": "We", "role": "Agent"}, {"entity_id": "ACL_23_P_359-1-E1", "text": "Our work joins this interdisciplinary effort and makes a unique contribution by taking into account the event narrative structures when analyzing the social bias of stories", "role": "Method"}, {"entity_id": "ACL_23_P_359-1-E2", "text": "We also present a verb-based event annotation scheme that can facilitate bias analysis by including categories such as those that align with traditional stereotypes", "role": "Method"}, {"entity_id": "ACL_23_P_359-1-E3", "text": "a computational pipeline", "role": "PrimaryObject"}]}], "entity_coreference": [], "event_coreference": [], "tokens": ["Our", "work", "joins", "this", "interdisciplinary", "effort", "and", "makes", "a", "unique", "contribution", "by", "taking", "into", "account", "the", "event", "narrative", "structures", "when", "analyzing", "the", "social", "bias", "of", "stories.", "We", "propose", "a", "computational", "pipeline", "that", "automatically", "extracts", "a", "story\u2019s", "temporal", "narrative", "verb-based", "event", "chain", "for", "each", "of", "its", "characters", "as", "well", "as", "character", "attributes", "such", "as", "gender.", "We", "also", "present", "a", "verb-based", "event", "annotation", "scheme", "that", "can", "facilitate", "bias", "analysis", "by", "including", "categories", "such", "as", "those", "that", "align", "with", "traditional", "stereotypes."], "pieces": ["Our", "work", "jo", "ins", "this", "inter", "disciplinary", "eff", "ort", "and", "makes", "a", "unique", "cont", "ribution", "by", "taking", "into", "account", "the", "event", "n", "arr", "ative", "struct", "ures", "when", "analy", "zing", "the", "social", "b", "ias", "of", "stories", ".", "We", "pro", "pose", "a", "com", "put", "ational", "p", "ip", "eline", "that", "aut", "om", "atically", "ext", "ract", "s", "a", "story", "\u00e2\u0122", "\u013b", "s", "tem", "poral", "n", "arr", "ative", "verb", "-", "based", "event", "chain", "for", "each", "of", "its", "char", "acters", "as", "well", "as", "character", "att", "ributes", "such", "as", "gender", ".", "We", "also", "present", "a", "verb", "-", "based", "event", "ann", "otation", "sche", "me", "that", "can", "fac", "ilit", "ate", "b", "ias", "analysis", "by", "including", "c", "ategories", "such", "as", "those", "that", "align", "with", "traditional", "st", "ere", "otypes", "."], "token_lens": [1, 1, 2, 1, 2, 2, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 3, 2, 1, 2, 1, 1, 2, 1, 2, 1, 2, 1, 3, 3, 1, 3, 3, 1, 4, 2, 3, 3, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 2, 1, 1, 2, 1, 1, 1, 1, 3, 1, 2, 2, 1, 1, 3, 2, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 4], "sentence": "Our work joins this interdisciplinary effort and makes a unique contribution by taking into account the event narrative structures when analyzing the social bias of stories. We propose a computational pipeline that automatically extracts a story\u2019s temporal narrative verb-based event chain for each of its characters as well as character attributes such as gender. We also present a verb-based event annotation scheme that can facilitate bias analysis by including categories such as those that align with traditional stereotypes.", "sentence_starts": [0]}
{"doc_id": "ACL_23_P_359", "wnd_id": "ACL_23_P_359-2", "entity_mentions": [{"id": "ACL_23_P_359-2-E0", "text": "we", "start": 10, "end": 11, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_359-2-E1", "text": "Through a case study analyzing gender bias in fairy tales", "start": 0, "end": 10, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_359-2-E2", "text": "our framework can reveal bias in not only the unigram verb-based events in which female and male characters participate but also in the temporal narrative order of such event participation", "start": 13, "end": 43, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_359-2-E3", "text": "our framework can reveal bias", "start": 13, "end": 18, "entity_type": "UNK", "mention_type": "UNK"}], "relation_mentions": [], "event_mentions": [{"event_type": "Results/Findings", "id": "ACL_23_P_359-2-EV0", "trigger": {"text": "demonstrate", "start": 11, "end": 12}, "arguments": [{"entity_id": "ACL_23_P_359-2-E0", "text": "we", "role": "Agent"}, {"entity_id": "ACL_23_P_359-2-E1", "text": "Through a case study analyzing gender bias in fairy tales", "role": "Method"}, {"entity_id": "ACL_23_P_359-2-E2", "text": "our framework can reveal bias in not only the unigram verb-based events in which female and male characters participate but also in the temporal narrative order of such event participation", "role": "Results"}, {"entity_id": "ACL_23_P_359-2-E3", "text": "our framework can reveal bias", "role": "PrimaryObject"}]}], "entity_coreference": [], "event_coreference": [], "tokens": ["Through", "a", "case", "study", "analyzing", "gender", "bias", "in", "fairy", "tales,", "we", "demonstrate", "that", "our", "framework", "can", "reveal", "bias", "in", "not", "only", "the", "unigram", "verb-based", "events", "in", "which", "female", "and", "male", "characters", "participate", "but", "also", "in", "the", "temporal", "narrative", "order", "of", "such", "event", "participation."], "pieces": ["Through", "a", "case", "study", "analy", "zing", "gender", "b", "ias", "in", "f", "airy", "t", "ales", ",", "we", "demon", "strate", "that", "our", "framework", "can", "reve", "al", "b", "ias", "in", "not", "only", "the", "un", "ig", "ram", "verb", "-", "based", "events", "in", "which", "female", "and", "male", "char", "acters", "particip", "ate", "but", "also", "in", "the", "tem", "poral", "n", "arr", "ative", "order", "of", "such", "event", "particip", "ation", "."], "token_lens": [1, 1, 1, 1, 2, 1, 2, 1, 2, 3, 1, 2, 1, 1, 1, 1, 2, 2, 1, 1, 1, 1, 3, 3, 1, 1, 1, 1, 1, 1, 2, 2, 1, 1, 1, 1, 2, 3, 1, 1, 1, 1, 3], "sentence": "Through a case study analyzing gender bias in fairy tales, we demonstrate that our framework can reveal bias in not only the unigram verb-based events in which female and male characters participate but also in the temporal narrative order of such event participation.", "sentence_starts": [0]}
{"doc_id": "ACL_23_P_900", "wnd_id": "ACL_23_P_900-0", "entity_mentions": [{"id": "ACL_23_P_900-0-E0", "text": "we", "start": 14, "end": 15, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_900-0-E1", "text": "Current image generation models struggle to reliably produce well-formed visual text,", "start": 0, "end": 11, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_900-0-E2", "text": "popular text-to-image models lack character-level input features, making it much harder to predict a word\u2019s visual makeup as a series of glyphs", "start": 20, "end": 42, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_900-0-E3", "text": "a key contributing factor", "start": 16, "end": 20, "entity_type": "UNK", "mention_type": "UNK"}], "relation_mentions": [], "event_mentions": [{"event_type": "Background/Introduction", "id": "ACL_23_P_900-0-EV0", "trigger": {"text": "investigate", "start": 15, "end": 16}, "arguments": [{"entity_id": "ACL_23_P_900-0-E0", "text": "we", "role": "Agent"}, {"entity_id": "ACL_23_P_900-0-E1", "text": "Current image generation models struggle to reliably produce well-formed visual text,", "role": "Context"}, {"entity_id": "ACL_23_P_900-0-E2", "text": "popular text-to-image models lack character-level input features, making it much harder to predict a word\u2019s visual makeup as a series of glyphs", "role": "Challenge"}, {"entity_id": "ACL_23_P_900-0-E3", "text": "a key contributing factor", "role": "PrimaryObject"}]}], "entity_coreference": [], "event_coreference": [], "tokens": ["Current", "image", "generation", "models", "struggle", "to", "reliably", "produce", "well-formed", "visual", "text.", "In", "this", "paper,", "we", "investigate", "a", "key", "contributing", "factor:", "popular", "text-to-image", "models", "lack", "character-level", "input", "features,", "making", "it", "much", "harder", "to", "predict", "a", "word\u2019s", "visual", "makeup", "as", "a", "series", "of", "glyphs."], "pieces": ["Current", "image", "generation", "models", "stru", "ggle", "to", "rel", "iably", "produ", "ce", "well", "-", "formed", "visual", "text", ".", "In", "this", "paper", ",", "we", "invest", "igate", "a", "key", "cont", "ribut", "ing", "factor", ":", "popular", "text", "-", "to", "-", "image", "models", "l", "ack", "character", "-", "level", "input", "features", ",", "making", "it", "much", "hard", "er", "to", "p", "redict", "a", "word", "\u00e2\u0122", "\u013b", "s", "visual", "make", "up", "as", "a", "series", "of", "gly", "ph", "s", "."], "token_lens": [1, 1, 1, 1, 2, 1, 2, 2, 3, 1, 2, 1, 1, 2, 1, 2, 1, 1, 3, 2, 1, 5, 1, 2, 3, 1, 2, 1, 1, 1, 2, 1, 2, 1, 4, 1, 2, 1, 1, 1, 1, 4], "sentence": "Current image generation models struggle to reliably produce well-formed visual text. In this paper, we investigate a key contributing factor: popular text-to-image models lack character-level input features, making it much harder to predict a word\u2019s visual makeup as a series of glyphs.", "sentence_starts": [0]}
{"doc_id": "ACL_23_P_900", "wnd_id": "ACL_23_P_900-1", "entity_mentions": [{"id": "ACL_23_P_900-1-E0", "text": "we", "start": 4, "end": 5, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_900-1-E1", "text": "To quantify this effect", "start": 0, "end": 4, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_900-1-E2", "text": "Applying our learnings to the visual domain, we train a suite of image generation models", "start": 34, "end": 49, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_900-1-E3", "text": "In the text-only domain, we find that character-aware models provide large gains on a novel spelling task (WikiSpell)", "start": 16, "end": 34, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_900-1-E4", "text": "character-aware variants outperform their character-blind counterparts across a range of novel text rendering tasks (our DrawText benchmark)", "start": 52, "end": 69, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_900-1-E5", "text": "a series of experiments", "start": 6, "end": 10, "entity_type": "UNK", "mention_type": "UNK"}], "relation_mentions": [], "event_mentions": [{"event_type": "Methods/Approach", "id": "ACL_23_P_900-1-EV0", "trigger": {"text": "conduct", "start": 5, "end": 6}, "arguments": [{"entity_id": "ACL_23_P_900-1-E0", "text": "we", "role": "Agent"}, {"entity_id": "ACL_23_P_900-1-E1", "text": "To quantify this effect", "role": "Purpose"}, {"entity_id": "ACL_23_P_900-1-E2", "text": "Applying our learnings to the visual domain, we train a suite of image generation models", "role": "Method"}, {"entity_id": "ACL_23_P_900-1-E3", "text": "In the text-only domain, we find that character-aware models provide large gains on a novel spelling task (WikiSpell)", "role": "Results"}, {"entity_id": "ACL_23_P_900-1-E4", "text": "character-aware variants outperform their character-blind counterparts across a range of novel text rendering tasks (our DrawText benchmark)", "role": "Results"}, {"entity_id": "ACL_23_P_900-1-E5", "text": "a series of experiments", "role": "PrimaryObject"}]}], "entity_coreference": [], "event_coreference": [], "tokens": ["To", "quantify", "this", "effect,", "we", "conduct", "a", "series", "of", "experiments", "comparing", "character-aware", "vs.", "character-blind", "text", "encoders.", "In", "the", "text-only", "domain,", "we", "find", "that", "character-aware", "models", "provide", "large", "gains", "on", "a", "novel", "spelling", "task", "(WikiSpell).", "Applying", "our", "learnings", "to", "the", "visual", "domain,", "we", "train", "a", "suite", "of", "image", "generation", "models,", "and", "show", "that", "character-aware", "variants", "outperform", "their", "character-blind", "counterparts", "across", "a", "range", "of", "novel", "text", "rendering", "tasks", "(our", "DrawText", "benchmark)."], "pieces": ["To", "quant", "ify", "this", "effect", ",", "we", "conduct", "a", "series", "of", "exper", "iments", "comp", "aring", "character", "-", "aware", "vs", ".", "character", "-", "blind", "text", "enc", "od", "ers", ".", "In", "the", "text", "-", "only", "domain", ",", "we", "find", "that", "character", "-", "aware", "models", "prov", "ide", "large", "g", "ains", "on", "a", "no", "vel", "spe", "lling", "task", "(", "Wiki", "Spell", ").", "App", "lying", "our", "learn", "ings", "to", "the", "visual", "domain", ",", "we", "train", "a", "su", "ite", "of", "image", "generation", "models", ",", "and", "show", "that", "character", "-", "aware", "vari", "ants", "out", "per", "form", "their", "character", "-", "blind", "counter", "parts", "ac", "ross", "a", "range", "of", "no", "vel", "text", "render", "ing", "t", "asks", "(", "our", "Draw", "Text", "bench", "mark", ")."], "token_lens": [1, 2, 1, 2, 1, 1, 1, 1, 1, 2, 2, 3, 2, 3, 1, 4, 1, 1, 3, 2, 1, 1, 1, 3, 1, 2, 1, 2, 1, 1, 2, 2, 1, 4, 2, 1, 2, 1, 1, 1, 2, 1, 1, 1, 2, 1, 1, 1, 2, 1, 1, 1, 3, 2, 3, 1, 3, 2, 2, 1, 1, 1, 2, 1, 2, 2, 2, 2, 3], "sentence": "To quantify this effect, we conduct a series of experiments comparing character-aware vs. character-blind text encoders. In the text-only domain, we find that character-aware models provide large gains on a novel spelling task (WikiSpell). Applying our learnings to the visual domain, we train a suite of image generation models, and show that character-aware variants outperform their character-blind counterparts across a range of novel text rendering tasks (our DrawText benchmark).", "sentence_starts": [0]}
{"doc_id": "ACL_23_P_900", "wnd_id": "ACL_23_P_900-2", "entity_mentions": [{"id": "ACL_23_P_900-2-E0", "text": "Our models", "start": 0, "end": 2, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_900-2-E1", "text": "a much higher state-of-the-art on visual spelling,", "start": 3, "end": 10, "entity_type": "UNK", "mention_type": "UNK"}], "relation_mentions": [], "event_mentions": [{"event_type": "Results/Findings", "id": "ACL_23_P_900-2-EV0", "trigger": {"text": "set", "start": 2, "end": 3}, "arguments": [{"entity_id": "ACL_23_P_900-2-E0", "text": "Our models", "role": "Agent"}, {"entity_id": "ACL_23_P_900-2-E1", "text": "a much higher state-of-the-art on visual spelling,", "role": "PrimaryObject"}]}], "entity_coreference": [], "event_coreference": [], "tokens": ["Our", "models", "set", "a", "much", "higher", "state-of-the-art", "on", "visual", "spelling,", "with", "30+", "point", "accuracy", "gains", "over", "competitors", "on", "rare", "words,", "despite", "training", "on", "far", "fewer", "examples."], "pieces": ["Our", "models", "set", "a", "much", "higher", "state", "-", "of", "-", "the", "-", "art", "on", "visual", "spe", "lling", ",", "with", "30", "+", "point", "acc", "uracy", "g", "ains", "over", "comp", "et", "itors", "on", "ra", "re", "words", ",", "despite", "training", "on", "far", "few", "er", "ex", "amples", "."], "token_lens": [1, 1, 1, 1, 1, 1, 7, 1, 1, 3, 1, 2, 1, 2, 2, 1, 3, 1, 2, 2, 1, 1, 1, 1, 2, 3], "sentence": "Our models set a much higher state-of-the-art on visual spelling, with 30+ point accuracy gains over competitors on rare words, despite training on far fewer examples.", "sentence_starts": [0]}
{"doc_id": "ACL_23_P_160", "wnd_id": "ACL_23_P_160-0", "entity_mentions": [{"id": "ACL_23_P_160-0-E0", "text": "Methods to generate text from structured data", "start": 0, "end": 7, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_160-0-E1", "text": "seek an unsupervised approach to improve the faithfulness of output text", "start": 54, "end": 65, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_160-0-E2", "text": "such models can fail to produce output faithful to the input data, particularly on out-of-domain data", "start": 25, "end": 41, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_160-0-E3", "text": "Sufficient annotated data is often not available for specific domains", "start": 41, "end": 51, "entity_type": "UNK", "mention_type": "UNK"}], "relation_mentions": [], "event_mentions": [{"event_type": "Background/Introduction", "id": "ACL_23_P_160-0-EV0", "trigger": {"text": "have advanced", "start": 7, "end": 9}, "arguments": [{"entity_id": "ACL_23_P_160-0-E0", "text": "Methods to generate text from structured data", "role": "Agent"}, {"entity_id": "ACL_23_P_160-0-E1", "text": "seek an unsupervised approach to improve the faithfulness of output text", "role": "Purpose"}, {"entity_id": "ACL_23_P_160-0-E2", "text": "such models can fail to produce output faithful to the input data, particularly on out-of-domain data", "role": "Challenge"}, {"entity_id": "ACL_23_P_160-0-E3", "text": "Sufficient annotated data is often not available for specific domains", "role": "Challenge"}]}], "entity_coreference": [], "event_coreference": [], "tokens": ["Methods", "to", "generate", "text", "from", "structured", "data", "have", "advanced", "significantly", "in", "recent", "years,", "primarily", "due", "to", "fine-tuning", "of", "pre-trained", "language", "models", "on", "large", "datasets.", "However,", "such", "models", "can", "fail", "to", "produce", "output", "faithful", "to", "the", "input", "data,", "particularly", "on", "out-of-domain", "data.", "Sufficient", "annotated", "data", "is", "often", "not", "available", "for", "specific", "domains,", "leading", "us", "to", "seek", "an", "unsupervised", "approach", "to", "improve", "the", "faithfulness", "of", "output", "text."], "pieces": ["Methods", "to", "gener", "ate", "text", "from", "struct", "ured", "data", "have", "adv", "anced", "sign", "ificantly", "in", "recent", "years", ",", "prim", "arily", "due", "to", "fine", "-", "tun", "ing", "of", "pre", "-", "trained", "language", "models", "on", "large", "dat", "as", "ets", ".", "However", ",", "such", "models", "can", "fail", "to", "produ", "ce", "output", "faith", "ful", "to", "the", "input", "data", ",", "particularly", "on", "out", "-", "of", "-", "domain", "data", ".", "S", "ufficient", "annot", "ated", "data", "is", "often", "not", "available", "for", "specific", "dom", "ains", ",", "leading", "us", "to", "seek", "an", "un", "super", "vised", "appro", "ach", "to", "improve", "the", "faith", "fulness", "of", "output", "text", "."], "token_lens": [1, 1, 2, 1, 1, 2, 1, 1, 2, 2, 1, 1, 2, 2, 1, 1, 4, 1, 3, 1, 1, 1, 1, 4, 2, 1, 1, 1, 1, 1, 2, 1, 2, 1, 1, 1, 2, 1, 1, 5, 2, 2, 2, 1, 1, 1, 1, 1, 1, 1, 3, 1, 1, 1, 1, 1, 3, 2, 1, 1, 1, 2, 1, 1, 2], "sentence": "Methods to generate text from structured data have advanced significantly in recent years, primarily due to fine-tuning of pre-trained language models on large datasets. However, such models can fail to produce output faithful to the input data, particularly on out-of-domain data. Sufficient annotated data is often not available for specific domains, leading us to seek an unsupervised approach to improve the faithfulness of output text.", "sentence_starts": [0]}
{"doc_id": "ACL_23_P_160", "wnd_id": "ACL_23_P_160-1", "entity_mentions": [{"id": "ACL_23_P_160-1-E0", "text": "we", "start": 17, "end": 18, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_160-1-E1", "text": "Cycle training uses two models which are inverses of each other", "start": 27, "end": 38, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_160-1-E2", "text": "one that generates text from structured data", "start": 38, "end": 45, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_160-1-E3", "text": "one which generates the structured data from natural language text", "start": 46, "end": 56, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_160-1-E4", "text": "Since the problem is fundamentally one of consistency between the representations of the structured data and text", "start": 0, "end": 17, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_160-1-E5", "text": "the effectiveness of cycle training in this work", "start": 19, "end": 27, "entity_type": "UNK", "mention_type": "UNK"}], "relation_mentions": [], "event_mentions": [{"event_type": "Methods/Approach", "id": "ACL_23_P_160-1-EV0", "trigger": {"text": "evaluate", "start": 18, "end": 19}, "arguments": [{"entity_id": "ACL_23_P_160-1-E0", "text": "we", "role": "Agent"}, {"entity_id": "ACL_23_P_160-1-E1", "text": "Cycle training uses two models which are inverses of each other", "role": "Method"}, {"entity_id": "ACL_23_P_160-1-E2", "text": "one that generates text from structured data", "role": "Method"}, {"entity_id": "ACL_23_P_160-1-E3", "text": "one which generates the structured data from natural language text", "role": "Method"}, {"entity_id": "ACL_23_P_160-1-E4", "text": "Since the problem is fundamentally one of consistency between the representations of the structured data and text", "role": "Analysis"}, {"entity_id": "ACL_23_P_160-1-E5", "text": "the effectiveness of cycle training in this work", "role": "PrimaryObject"}]}], "entity_coreference": [], "event_coreference": [], "tokens": ["Since", "the", "problem", "is", "fundamentally", "one", "of", "consistency", "between", "the", "representations", "of", "the", "structured", "data", "and", "text,", "we", "evaluate", "the", "effectiveness", "of", "cycle", "training", "in", "this", "work.", "Cycle", "training", "uses", "two", "models", "which", "are", "inverses", "of", "each", "other:", "one", "that", "generates", "text", "from", "structured", "data,", "and", "one", "which", "generates", "the", "structured", "data", "from", "natural", "language", "text."], "pieces": ["Since", "the", "problem", "is", "fund", "ament", "ally", "one", "of", "cons", "ist", "ency", "between", "the", "represent", "ations", "of", "the", "struct", "ured", "data", "and", "text", ",", "we", "evaluate", "the", "effect", "iveness", "of", "cycle", "training", "in", "this", "work", ".", "Cy", "cle", "training", "uses", "two", "models", "which", "are", "in", "vers", "es", "of", "each", "other", ":", "one", "that", "gener", "ates", "text", "from", "struct", "ured", "data", ",", "and", "one", "which", "gener", "ates", "the", "struct", "ured", "data", "from", "natural", "language", "text", "."], "token_lens": [1, 1, 1, 1, 3, 1, 1, 3, 1, 1, 2, 1, 1, 2, 1, 1, 2, 1, 1, 1, 2, 1, 1, 1, 1, 1, 2, 2, 1, 1, 1, 1, 1, 1, 3, 1, 1, 2, 1, 1, 2, 1, 1, 2, 2, 1, 1, 1, 2, 1, 2, 1, 1, 1, 1, 2], "sentence": "Since the problem is fundamentally one of consistency between the representations of the structured data and text, we evaluate the effectiveness of cycle training in this work. Cycle training uses two models which are inverses of each other: one that generates text from structured data, and one which generates the structured data from natural language text.", "sentence_starts": [0]}
{"doc_id": "ACL_23_P_160", "wnd_id": "ACL_23_P_160-2", "entity_mentions": [{"id": "ACL_23_P_160-2-E0", "text": "We", "start": 0, "end": 1, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_160-2-E1", "text": "when initialized with a small amount of supervised data (100 samples in our case)", "start": 5, "end": 19, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_160-2-E2", "text": "We perform extensive empirical analysis with automated evaluation metrics and a newly designed human evaluation schema to reveal different cycle training strategies\u2019 effectiveness of reducing various types of generation errors", "start": 41, "end": 71, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_160-2-E3", "text": "same performance as fully supervised approaches for the data-to-text generation task on the WebNLG, E2E, WTQ, and WSQL datasets", "start": 22, "end": 41, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_160-2-E4", "text": "cycle training", "start": 3, "end": 5, "entity_type": "UNK", "mention_type": "UNK"}], "relation_mentions": [], "event_mentions": [{"event_type": "Results/Findings", "id": "ACL_23_P_160-2-EV0", "trigger": {"text": "show", "start": 1, "end": 2}, "arguments": [{"entity_id": "ACL_23_P_160-2-E0", "text": "We", "role": "Agent"}, {"entity_id": "ACL_23_P_160-2-E1", "text": "when initialized with a small amount of supervised data (100 samples in our case)", "role": "Context"}, {"entity_id": "ACL_23_P_160-2-E2", "text": "We perform extensive empirical analysis with automated evaluation metrics and a newly designed human evaluation schema to reveal different cycle training strategies\u2019 effectiveness of reducing various types of generation errors", "role": "Method"}, {"entity_id": "ACL_23_P_160-2-E3", "text": "same performance as fully supervised approaches for the data-to-text generation task on the WebNLG, E2E, WTQ, and WSQL datasets", "role": "Results"}, {"entity_id": "ACL_23_P_160-2-E4", "text": "cycle training", "role": "PrimaryObject"}]}], "entity_coreference": [], "event_coreference": [], "tokens": ["We", "show", "that", "cycle", "training,", "when", "initialized", "with", "a", "small", "amount", "of", "supervised", "data", "(100", "samples", "in", "our", "case),", "achieves", "nearly", "the", "same", "performance", "as", "fully", "supervised", "approaches", "for", "the", "data-to-text", "generation", "task", "on", "the", "WebNLG,", "E2E,", "WTQ,", "and", "WSQL", "datasets.", "We", "perform", "extensive", "empirical", "analysis", "with", "automated", "evaluation", "metrics", "and", "a", "newly", "designed", "human", "evaluation", "schema", "to", "reveal", "different", "cycle", "training", "strategies\u2019", "effectiveness", "of", "reducing", "various", "types", "of", "generation", "errors."], "pieces": ["We", "show", "that", "cycle", "training", ",", "when", "initialized", "with", "a", "small", "amount", "of", "super", "vised", "data", "(", "100", "s", "amples", "in", "our", "case", "),", "ach", "ieves", "n", "early", "the", "same", "performance", "as", "fully", "super", "vised", "appro", "aches", "for", "the", "data", "-", "to", "-", "text", "generation", "task", "on", "the", "Web", "NL", "G", ",", "E", "2", "E", ",", "WT", "Q", ",", "and", "W", "SQL", "dat", "as", "ets", ".", "We", "per", "form", "ext", "ensive", "em", "pir", "ical", "analysis", "with", "aut", "om", "ated", "eval", "uation", "met", "rics", "and", "a", "new", "ly", "designed", "human", "eval", "uation", "sche", "ma", "to", "reve", "al", "different", "cycle", "training", "str", "ateg", "ies", "\u00e2\u0122", "\u013b", "effect", "iveness", "of", "red", "ucing", "var", "ious", "types", "of", "generation", "errors", "."], "token_lens": [1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 2, 1, 2, 2, 1, 1, 2, 2, 2, 1, 1, 1, 1, 1, 2, 2, 1, 1, 5, 1, 1, 1, 1, 4, 4, 3, 1, 2, 4, 1, 2, 2, 3, 1, 1, 3, 2, 2, 1, 1, 2, 1, 1, 2, 2, 1, 2, 1, 1, 1, 5, 2, 1, 2, 2, 1, 1, 1, 2], "sentence": "We show that cycle training, when initialized with a small amount of supervised data (100 samples in our case), achieves nearly the same performance as fully supervised approaches for the data-to-text generation task on the WebNLG, E2E, WTQ, and WSQL datasets. We perform extensive empirical analysis with automated evaluation metrics and a newly designed human evaluation schema to reveal different cycle training strategies\u2019 effectiveness of reducing various types of generation errors.", "sentence_starts": [0]}
{"doc_id": "ACL_23_P_668", "wnd_id": "ACL_23_P_668-0", "entity_mentions": [{"id": "ACL_23_P_668-0-E0", "text": "Health-related speech datasets", "start": 0, "end": 3, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_668-0-E1", "text": "This makes it difficult to leverage them to effectively support healthcare goals", "start": 10, "end": 22, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_668-0-E2", "text": "Robust transfer of linguistic features across different datasets orbiting the same goal carries potential to address this concern", "start": 22, "end": 40, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_668-0-E3", "text": "often small and varied in focus", "start": 4, "end": 10, "entity_type": "UNK", "mention_type": "UNK"}], "relation_mentions": [], "event_mentions": [{"event_type": "Background/Introduction", "id": "ACL_23_P_668-0-EV0", "trigger": {"text": "are", "start": 3, "end": 4}, "arguments": [{"entity_id": "ACL_23_P_668-0-E0", "text": "Health-related speech datasets", "role": "Agent"}, {"entity_id": "ACL_23_P_668-0-E1", "text": "This makes it difficult to leverage them to effectively support healthcare goals", "role": "Challenge"}, {"entity_id": "ACL_23_P_668-0-E2", "text": "Robust transfer of linguistic features across different datasets orbiting the same goal carries potential to address this concern", "role": "Implications"}, {"entity_id": "ACL_23_P_668-0-E3", "text": "often small and varied in focus", "role": "PrimaryObject"}]}], "entity_coreference": [], "event_coreference": [], "tokens": ["Health-related", "speech", "datasets", "are", "often", "small", "and", "varied", "in", "focus.", "This", "makes", "it", "difficult", "to", "leverage", "them", "to", "effectively", "support", "healthcare", "goals.", "Robust", "transfer", "of", "linguistic", "features", "across", "different", "datasets", "orbiting", "the", "same", "goal", "carries", "potential", "to", "address", "this", "concern."], "pieces": ["Health", "-", "related", "speech", "dat", "as", "ets", "are", "often", "small", "and", "var", "ied", "in", "focus", ".", "This", "makes", "it", "diff", "icult", "to", "le", "verage", "them", "to", "effect", "ively", "support", "health", "care", "go", "als", ".", "Rob", "ust", "transfer", "of", "ling", "u", "istic", "features", "ac", "ross", "different", "dat", "as", "ets", "orb", "iting", "the", "same", "goal", "car", "ries", "pot", "ential", "to", "address", "this", "con", "cern", "."], "token_lens": [3, 1, 3, 1, 1, 1, 1, 2, 1, 2, 1, 1, 1, 2, 1, 2, 1, 1, 2, 1, 2, 3, 2, 1, 1, 3, 1, 2, 1, 3, 2, 1, 1, 1, 2, 2, 1, 1, 1, 3], "sentence": "Health-related speech datasets are often small and varied in focus. This makes it difficult to leverage them to effectively support healthcare goals. Robust transfer of linguistic features across different datasets orbiting the same goal carries potential to address this concern.", "sentence_starts": [0]}
{"doc_id": "ACL_23_P_668", "wnd_id": "ACL_23_P_668-1", "entity_mentions": [{"id": "ACL_23_P_668-1-E0", "text": "we", "start": 4, "end": 5, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_668-1-E1", "text": "to evaluate generalizability across diverse datasets for a common task: dementia detection", "start": 16, "end": 28, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_668-1-E2", "text": "domain adaptation (DA) techniques", "start": 7, "end": 11, "entity_type": "UNK", "mention_type": "UNK"}], "relation_mentions": [], "event_mentions": [{"event_type": "Methods/Approach", "id": "ACL_23_P_668-1-EV0", "trigger": {"text": "experiment with", "start": 5, "end": 7}, "arguments": [{"entity_id": "ACL_23_P_668-1-E0", "text": "we", "role": "Agent"}, {"entity_id": "ACL_23_P_668-1-E1", "text": "to evaluate generalizability across diverse datasets for a common task: dementia detection", "role": "Purpose"}, {"entity_id": "ACL_23_P_668-1-E2", "text": "domain adaptation (DA) techniques", "role": "PrimaryObject"}]}], "entity_coreference": [], "event_coreference": [], "tokens": ["To", "test", "this", "hypothesis,", "we", "experiment", "with", "domain", "adaptation", "(DA)", "techniques", "on", "heterogeneous", "spoken", "language", "data", "to", "evaluate", "generalizability", "across", "diverse", "datasets", "for", "a", "common", "task:", "dementia", "detection."], "pieces": ["To", "test", "this", "hyp", "ot", "hesis", ",", "we", "exper", "iment", "with", "domain", "adapt", "ation", "(", "DA", ")", "techn", "iques", "on", "heter", "ogeneous", "spoken", "language", "data", "to", "evaluate", "general", "iz", "ability", "ac", "ross", "d", "iverse", "dat", "as", "ets", "for", "a", "common", "task", ":", "d", "ement", "ia", "det", "ection", "."], "token_lens": [1, 1, 1, 4, 1, 2, 1, 1, 2, 3, 2, 1, 2, 1, 1, 1, 1, 1, 3, 2, 2, 3, 1, 1, 1, 2, 3, 3], "sentence": "To test this hypothesis, we experiment with domain adaptation (DA) techniques on heterogeneous spoken language data to evaluate generalizability across diverse datasets for a common task: dementia detection.", "sentence_starts": [0]}
{"doc_id": "ACL_23_P_668", "wnd_id": "ACL_23_P_668-2", "entity_mentions": [{"id": "ACL_23_P_668-2-E0", "text": "We", "start": 0, "end": 1, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_668-2-E1", "text": "The feature-augmented DA method achieves a 22% increase in accuracy adapting from a conversational to task-specific dataset compared to a jointly trained baseline", "start": 13, "end": 36, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_668-2-E2", "text": "adapted models exhibit better performance across conversational and task-oriented datasets.", "start": 3, "end": 13, "entity_type": "UNK", "mention_type": "UNK"}], "relation_mentions": [], "event_mentions": [{"event_type": "Results/Findings", "id": "ACL_23_P_668-2-EV0", "trigger": {"text": "find", "start": 1, "end": 2}, "arguments": [{"entity_id": "ACL_23_P_668-2-E0", "text": "We", "role": "Agent"}, {"entity_id": "ACL_23_P_668-2-E1", "text": "The feature-augmented DA method achieves a 22% increase in accuracy adapting from a conversational to task-specific dataset compared to a jointly trained baseline", "role": "Results"}, {"entity_id": "ACL_23_P_668-2-E2", "text": "adapted models exhibit better performance across conversational and task-oriented datasets.", "role": "PrimaryObject"}]}], "entity_coreference": [], "event_coreference": [], "tokens": ["We", "find", "that", "adapted", "models", "exhibit", "better", "performance", "across", "conversational", "and", "task-oriented", "datasets.", "The", "feature-augmented", "DA", "method", "achieves", "a", "22%", "increase", "in", "accuracy", "adapting", "from", "a", "conversational", "to", "task-specific", "dataset", "compared", "to", "a", "jointly", "trained", "baseline."], "pieces": ["We", "find", "that", "adapt", "ed", "models", "ex", "hibit", "better", "performance", "ac", "ross", "con", "vers", "ational", "and", "task", "-", "oriented", "dat", "as", "ets", ".", "The", "feature", "-", "au", "gment", "ed", "DA", "method", "ach", "ieves", "a", "22", "%", "incre", "ase", "in", "acc", "uracy", "adapt", "ing", "from", "a", "con", "vers", "ational", "to", "task", "-", "specific", "dat", "as", "et", "comp", "ared", "to", "a", "j", "oint", "ly", "trained", "bas", "eline", "."], "token_lens": [1, 1, 1, 2, 1, 2, 1, 1, 2, 3, 1, 3, 4, 1, 5, 1, 1, 2, 1, 2, 2, 1, 2, 2, 1, 1, 3, 1, 3, 3, 2, 1, 1, 3, 1, 3], "sentence": "We find that adapted models exhibit better performance across conversational and task-oriented datasets. The feature-augmented DA method achieves a 22% increase in accuracy adapting from a conversational to task-specific dataset compared to a jointly trained baseline.", "sentence_starts": [0]}
{"doc_id": "ACL_23_P_668", "wnd_id": "ACL_23_P_668-3", "entity_mentions": [{"id": "ACL_23_P_668-3-E0", "text": "This", "start": 0, "end": 1, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_668-3-E1", "text": "promising capacity of these techniques to allow for productive use of disparate data for a complex spoken language healthcare task", "start": 2, "end": 22, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_668-3-E2", "text": "promising capacity of these techniques", "start": 2, "end": 7, "entity_type": "UNK", "mention_type": "UNK"}], "relation_mentions": [], "event_mentions": [{"event_type": "Conclusions/Implications", "id": "ACL_23_P_668-3-EV0", "trigger": {"text": "suggests", "start": 1, "end": 2}, "arguments": [{"entity_id": "ACL_23_P_668-3-E0", "text": "This", "role": "Agent"}, {"entity_id": "ACL_23_P_668-3-E1", "text": "promising capacity of these techniques to allow for productive use of disparate data for a complex spoken language healthcare task", "role": "Implications"}, {"entity_id": "ACL_23_P_668-3-E2", "text": "promising capacity of these techniques", "role": "PrimaryObject"}]}], "entity_coreference": [], "event_coreference": [], "tokens": ["This", "suggests", "promising", "capacity", "of", "these", "techniques", "to", "allow", "for", "productive", "use", "of", "disparate", "data", "for", "a", "complex", "spoken", "language", "healthcare", "task."], "pieces": ["This", "suggest", "s", "prom", "ising", "capacity", "of", "these", "techn", "iques", "to", "allow", "for", "productive", "use", "of", "dis", "par", "ate", "data", "for", "a", "complex", "spoken", "language", "health", "care", "task", "."], "token_lens": [1, 2, 2, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 3, 1, 1, 1, 1, 1, 1, 2, 2], "sentence": "This suggests promising capacity of these techniques to allow for productive use of disparate data for a complex spoken language healthcare task.", "sentence_starts": [0]}
{"doc_id": "ACL_23_P_163", "wnd_id": "ACL_23_P_163-0", "entity_mentions": [{"id": "ACL_23_P_163-0-E0", "text": "The ingrained principles of fairness", "start": 0, "end": 5, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_163-0-E1", "text": "For example, misusing pronouns in a user interaction may cause ambiguity about the intended subject", "start": 47, "end": 62, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_163-0-E2", "text": "Absence of equitable and inclusive principles can hinder the formation of common ground, which in turn negatively impacts the overall performance of the system", "start": 23, "end": 47, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_163-0-E3", "text": "there is no comprehensive study of equitable text generation in dialogue", "start": 63, "end": 74, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_163-0-E4", "text": "user engagement, satisfaction, and task achievement", "start": 17, "end": 23, "entity_type": "UNK", "mention_type": "UNK"}], "relation_mentions": [], "event_mentions": [{"event_type": "Background/Introduction", "id": "ACL_23_P_163-0-EV0", "trigger": {"text": "are crucial for", "start": 14, "end": 17}, "arguments": [{"entity_id": "ACL_23_P_163-0-E0", "text": "The ingrained principles of fairness", "role": "Agent"}, {"entity_id": "ACL_23_P_163-0-E1", "text": "For example, misusing pronouns in a user interaction may cause ambiguity about the intended subject", "role": "Analysis"}, {"entity_id": "ACL_23_P_163-0-E2", "text": "Absence of equitable and inclusive principles can hinder the formation of common ground, which in turn negatively impacts the overall performance of the system", "role": "Challenge"}, {"entity_id": "ACL_23_P_163-0-E3", "text": "there is no comprehensive study of equitable text generation in dialogue", "role": "Challenge"}, {"entity_id": "ACL_23_P_163-0-E4", "text": "user engagement, satisfaction, and task achievement", "role": "PrimaryObject"}]}], "entity_coreference": [], "event_coreference": [], "tokens": ["The", "ingrained", "principles", "of", "fairness", "in", "a", "dialogue", "system\u2019s", "decision-making", "process", "and", "generated", "responses", "are", "crucial", "for", "user", "engagement,", "satisfaction,", "and", "task", "achievement.", "Absence", "of", "equitable", "and", "inclusive", "principles", "can", "hinder", "the", "formation", "of", "common", "ground,", "which", "in", "turn", "negatively", "impacts", "the", "overall", "performance", "of", "the", "system.", "For", "example,", "misusing", "pronouns", "in", "a", "user", "interaction", "may", "cause", "ambiguity", "about", "the", "intended", "subject.", "Yet,", "there", "is", "no", "comprehensive", "study", "of", "equitable", "text", "generation", "in", "dialogue."], "pieces": ["The", "ing", "rained", "pr", "in", "ciples", "of", "fair", "ness", "in", "a", "dial", "ogue", "system", "\u00e2\u0122", "\u013b", "s", "dec", "ision", "-", "making", "process", "and", "generated", "respons", "es", "are", "cru", "cial", "for", "user", "eng", "agement", ",", "s", "atisf", "action", ",", "and", "task", "ach", "ieve", "ment", ".", "Abs", "ence", "of", "equ", "itable", "and", "in", "clusive", "pr", "in", "ciples", "can", "h", "inder", "the", "formation", "of", "common", "ground", ",", "which", "in", "turn", "neg", "atively", "imp", "acts", "the", "over", "all", "performance", "of", "the", "system", ".", "For", "example", ",", "mis", "using", "pron", "oun", "s", "in", "a", "user", "inter", "action", "may", "cause", "amb", "ig", "uity", "about", "the", "int", "ended", "subject", ".", "Yet", ",", "there", "is", "no", "com", "pre", "hens", "ive", "study", "of", "equ", "itable", "text", "generation", "in", "dial", "ogue", "."], "token_lens": [1, 2, 3, 1, 2, 1, 1, 2, 4, 4, 1, 1, 1, 2, 1, 2, 1, 1, 3, 4, 1, 1, 4, 2, 1, 2, 1, 2, 3, 1, 2, 1, 1, 1, 1, 2, 1, 1, 1, 2, 2, 1, 2, 1, 1, 1, 2, 1, 2, 2, 3, 1, 1, 1, 2, 1, 1, 3, 1, 1, 2, 2, 2, 1, 1, 1, 4, 1, 1, 2, 1, 1, 1, 3], "sentence": "The ingrained principles of fairness in a dialogue system\u2019s decision-making process and generated responses are crucial for user engagement, satisfaction, and task achievement. Absence of equitable and inclusive principles can hinder the formation of common ground, which in turn negatively impacts the overall performance of the system. For example, misusing pronouns in a user interaction may cause ambiguity about the intended subject. Yet, there is no comprehensive study of equitable text generation in dialogue.", "sentence_starts": [0]}
{"doc_id": "ACL_23_P_163", "wnd_id": "ACL_23_P_163-1", "entity_mentions": [{"id": "ACL_23_P_163-1-E0", "text": "we", "start": 4, "end": 5, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_163-1-E1", "text": "We provide formal definitions of equity in text generation, and further, prove formal connections between learning human-likeness and learning equity: algorithms for improving equity ultimately reduce to algorithms for improving human-likeness (on augmented data)", "start": 14, "end": 48, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_163-1-E2", "text": "we also formulate reasonable conditions under which text generation algorithms can learn to generate equitable text without any modifications to the biased training data on which they learn", "start": 51, "end": 79, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_163-1-E3", "text": "theories of computational learning to study this problem", "start": 6, "end": 14, "entity_type": "UNK", "mention_type": "UNK"}], "relation_mentions": [], "event_mentions": [{"event_type": "Methods/Approach", "id": "ACL_23_P_163-1-EV0", "trigger": {"text": "use", "start": 5, "end": 6}, "arguments": [{"entity_id": "ACL_23_P_163-1-E0", "text": "we", "role": "Agent"}, {"entity_id": "ACL_23_P_163-1-E1", "text": "We provide formal definitions of equity in text generation, and further, prove formal connections between learning human-likeness and learning equity: algorithms for improving equity ultimately reduce to algorithms for improving human-likeness (on augmented data)", "role": "Method"}, {"entity_id": "ACL_23_P_163-1-E2", "text": "we also formulate reasonable conditions under which text generation algorithms can learn to generate equitable text without any modifications to the biased training data on which they learn", "role": "Method"}, {"entity_id": "ACL_23_P_163-1-E3", "text": "theories of computational learning to study this problem", "role": "PrimaryObject"}]}], "entity_coreference": [], "event_coreference": [], "tokens": ["Aptly,", "in", "this", "work,", "we", "use", "theories", "of", "computational", "learning", "to", "study", "this", "problem.", "We", "provide", "formal", "definitions", "of", "equity", "in", "text", "generation,", "and", "further,", "prove", "formal", "connections", "between", "learning", "human-likeness", "and", "learning", "equity:", "algorithms", "for", "improving", "equity", "ultimately", "reduce", "to", "algorithms", "for", "improving", "human-likeness", "(on", "augmented", "data).", "With", "this", "insight,", "we", "also", "formulate", "reasonable", "conditions", "under", "which", "text", "generation", "algorithms", "can", "learn", "to", "generate", "equitable", "text", "without", "any", "modifications", "to", "the", "biased", "training", "data", "on", "which", "they", "learn."], "pieces": ["A", "pt", "ly", ",", "in", "this", "work", ",", "we", "use", "the", "ories", "of", "com", "put", "ational", "learning", "to", "study", "this", "problem", ".", "We", "prov", "ide", "form", "al", "def", "initions", "of", "equ", "ity", "in", "text", "generation", ",", "and", "f", "urther", ",", "pro", "ve", "form", "al", "connect", "ions", "between", "learning", "human", "-", "lik", "eness", "and", "learning", "equ", "ity", ":", "al", "gorith", "ms", "for", "impro", "ving", "equ", "ity", "ult", "imately", "red", "uce", "to", "al", "gorith", "ms", "for", "impro", "ving", "human", "-", "lik", "eness", "(", "on", "au", "gment", "ed", "data", ").", "With", "this", "ins", "ight", ",", "we", "also", "form", "ulate", "reasonable", "cond", "itions", "under", "which", "text", "generation", "al", "gorith", "ms", "can", "learn", "to", "gener", "ate", "equ", "itable", "text", "without", "any", "mod", "ifications", "to", "the", "biased", "training", "data", "on", "which", "they", "learn", "."], "token_lens": [4, 1, 1, 2, 1, 1, 2, 1, 3, 1, 1, 1, 1, 2, 1, 2, 2, 2, 1, 2, 1, 1, 2, 1, 3, 2, 2, 2, 1, 1, 4, 1, 1, 3, 3, 1, 2, 2, 2, 2, 1, 3, 1, 2, 4, 2, 3, 2, 1, 1, 3, 1, 1, 2, 1, 2, 1, 1, 1, 1, 3, 1, 1, 1, 2, 2, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 2], "sentence": "Aptly, in this work, we use theories of computational learning to study this problem. We provide formal definitions of equity in text generation, and further, prove formal connections between learning human-likeness and learning equity: algorithms for improving equity ultimately reduce to algorithms for improving human-likeness (on augmented data). With this insight, we also formulate reasonable conditions under which text generation algorithms can learn to generate equitable text without any modifications to the biased training data on which they learn.", "sentence_starts": [0]}
{"doc_id": "ACL_23_P_163", "wnd_id": "ACL_23_P_163-2", "entity_mentions": [{"id": "ACL_23_P_163-2-E0", "text": "we", "start": 6, "end": 7, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_163-2-E1", "text": "To exemplify our theory in practice", "start": 0, "end": 6, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_163-2-E2", "text": "Our theory accurately predicts relative performance of multiple algorithms in generating equitable text as measured by both human and automated evaluation", "start": 27, "end": 48, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_163-2-E3", "text": "a group of algorithms", "start": 9, "end": 13, "entity_type": "UNK", "mention_type": "UNK"}], "relation_mentions": [], "event_mentions": [{"event_type": "Results/Findings", "id": "ACL_23_P_163-2-EV0", "trigger": {"text": "look at", "start": 7, "end": 9}, "arguments": [{"entity_id": "ACL_23_P_163-2-E0", "text": "we", "role": "Agent"}, {"entity_id": "ACL_23_P_163-2-E1", "text": "To exemplify our theory in practice", "role": "Context"}, {"entity_id": "ACL_23_P_163-2-E2", "text": "Our theory accurately predicts relative performance of multiple algorithms in generating equitable text as measured by both human and automated evaluation", "role": "Results"}, {"entity_id": "ACL_23_P_163-2-E3", "text": "a group of algorithms", "role": "PrimaryObject"}]}], "entity_coreference": [], "event_coreference": [], "tokens": ["To", "exemplify", "our", "theory", "in", "practice,", "we", "look", "at", "a", "group", "of", "algorithms", "for", "the", "GuessWhat?!", "visual", "dialogue", "game", "and,", "using", "this", "example,", "test", "our", "theory", "empirically.", "Our", "theory", "accurately", "predicts", "relative", "performance", "of", "multiple", "algorithms", "in", "generating", "equitable", "text", "as", "measured", "by", "both", "human", "and", "automated", "evaluation."], "pieces": ["To", "ex", "empl", "ify", "our", "the", "ory", "in", "practice", ",", "we", "look", "at", "a", "group", "of", "al", "gorith", "ms", "for", "the", "Gu", "ess", "What", "?!", "visual", "dial", "ogue", "game", "and", ",", "using", "this", "example", ",", "test", "our", "the", "ory", "em", "pir", "ically", ".", "Our", "the", "ory", "acc", "ur", "ately", "pred", "icts", "relative", "performance", "of", "multiple", "al", "gorith", "ms", "in", "gener", "ating", "equ", "itable", "text", "as", "me", "asured", "by", "both", "human", "and", "aut", "om", "ated", "eval", "uation", "."], "token_lens": [1, 3, 1, 2, 1, 2, 1, 1, 1, 1, 1, 1, 3, 1, 1, 4, 1, 2, 1, 2, 1, 1, 2, 1, 1, 2, 4, 1, 2, 3, 2, 1, 1, 1, 1, 3, 1, 2, 2, 1, 1, 2, 1, 1, 1, 1, 3, 3], "sentence": "To exemplify our theory in practice, we look at a group of algorithms for the GuessWhat?! visual dialogue game and, using this example, test our theory empirically. Our theory accurately predicts relative performance of multiple algorithms in generating equitable text as measured by both human and automated evaluation.", "sentence_starts": [0]}
{"doc_id": "ACL_23_P_811", "wnd_id": "ACL_23_P_811-0", "entity_mentions": [{"id": "ACL_23_P_811-0-E0", "text": "Two-Tower Vision-Language (VL) models", "start": 0, "end": 4, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_811-0-E1", "text": "Although the most advanced work improves performance by building bridges between encoders", "start": 13, "end": 25, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_811-0-E2", "text": "it suffers from ineffective layer-by-layer utilization of uni-modal representations and cannot flexibly exploit different levels of uni-modal semantic knowledge", "start": 25, "end": 44, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_811-0-E3", "text": "promising improvements on various downstream VL tasks", "start": 6, "end": 13, "entity_type": "UNK", "mention_type": "UNK"}], "relation_mentions": [], "event_mentions": [{"event_type": "Background/Introduction", "id": "ACL_23_P_811-0-EV0", "trigger": {"text": "have shown", "start": 4, "end": 6}, "arguments": [{"entity_id": "ACL_23_P_811-0-E0", "text": "Two-Tower Vision-Language (VL) models", "role": "Agent"}, {"entity_id": "ACL_23_P_811-0-E1", "text": "Although the most advanced work improves performance by building bridges between encoders", "role": "Context"}, {"entity_id": "ACL_23_P_811-0-E2", "text": "it suffers from ineffective layer-by-layer utilization of uni-modal representations and cannot flexibly exploit different levels of uni-modal semantic knowledge", "role": "Challenge"}, {"entity_id": "ACL_23_P_811-0-E3", "text": "promising improvements on various downstream VL tasks", "role": "PrimaryObject"}]}], "entity_coreference": [], "event_coreference": [], "tokens": ["Two-Tower", "Vision-Language", "(VL)", "models", "have", "shown", "promising", "improvements", "on", "various", "downstream", "VL", "tasks.", "Although", "the", "most", "advanced", "work", "improves", "performance", "by", "building", "bridges", "between", "encoders,", "it", "suffers", "from", "ineffective", "layer-by-layer", "utilization", "of", "uni-modal", "representations", "and", "cannot", "flexibly", "exploit", "different", "levels", "of", "uni-modal", "semantic", "knowledge."], "pieces": ["Two", "-", "T", "ower", "Vision", "-", "Language", "(", "VL", ")", "models", "have", "shown", "prom", "ising", "improve", "ments", "on", "var", "ious", "down", "stream", "VL", "t", "asks", ".", "Although", "the", "most", "adv", "anced", "work", "impro", "ves", "performance", "by", "building", "brid", "ges", "between", "enc", "od", "ers", ",", "it", "suff", "ers", "from", "ine", "ffect", "ive", "layer", "-", "by", "-", "layer", "util", "ization", "of", "uni", "-", "mod", "al", "represent", "ations", "and", "c", "annot", "flex", "ibly", "expl", "oit", "different", "levels", "of", "uni", "-", "mod", "al", "sem", "antic", "knowledge", "."], "token_lens": [4, 3, 3, 1, 1, 1, 2, 2, 1, 2, 2, 1, 3, 1, 1, 1, 2, 1, 2, 1, 1, 1, 2, 1, 4, 1, 2, 1, 3, 5, 2, 1, 4, 2, 1, 2, 2, 2, 1, 1, 1, 4, 2, 2], "sentence": "Two-Tower Vision-Language (VL) models have shown promising improvements on various downstream VL tasks. Although the most advanced work improves performance by building bridges between encoders, it suffers from ineffective layer-by-layer utilization of uni-modal representations and cannot flexibly exploit different levels of uni-modal semantic knowledge.", "sentence_starts": [0]}
{"doc_id": "ACL_23_P_811", "wnd_id": "ACL_23_P_811-1", "entity_mentions": [{"id": "ACL_23_P_811-1-E0", "text": "we", "start": 3, "end": 4, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_811-1-E1", "text": "The managers introduced in each cross-modal layer can adaptively aggregate uni-modal semantic knowledge to facilitate more comprehensive cross-modal alignment and fusion", "start": 24, "end": 45, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_811-1-E2", "text": "ManagerTower", "start": 5, "end": 6, "entity_type": "UNK", "mention_type": "UNK"}], "relation_mentions": [], "event_mentions": [{"event_type": "Methods/Approach", "id": "ACL_23_P_811-1-EV0", "trigger": {"text": "propose", "start": 4, "end": 5}, "arguments": [{"entity_id": "ACL_23_P_811-1-E0", "text": "we", "role": "Agent"}, {"entity_id": "ACL_23_P_811-1-E1", "text": "The managers introduced in each cross-modal layer can adaptively aggregate uni-modal semantic knowledge to facilitate more comprehensive cross-modal alignment and fusion", "role": "Method"}, {"entity_id": "ACL_23_P_811-1-E2", "text": "ManagerTower", "role": "PrimaryObject"}]}], "entity_coreference": [], "event_coreference": [], "tokens": ["In", "this", "work,", "we", "propose", "ManagerTower,", "a", "novel", "VL", "model", "architecture", "that", "gathers", "and", "combines", "the", "insights", "of", "pre-trained", "uni-modal", "experts", "at", "different", "levels.", "The", "managers", "introduced", "in", "each", "cross-modal", "layer", "can", "adaptively", "aggregate", "uni-modal", "semantic", "knowledge", "to", "facilitate", "more", "comprehensive", "cross-modal", "alignment", "and", "fusion."], "pieces": ["In", "this", "work", ",", "we", "pro", "pose", "Manager", "T", "ower", ",", "a", "no", "vel", "VL", "model", "arch", "itect", "ure", "that", "g", "ather", "s", "and", "comb", "ines", "the", "ins", "ights", "of", "pre", "-", "trained", "uni", "-", "mod", "al", "exper", "ts", "at", "different", "levels", ".", "The", "man", "agers", "introdu", "ced", "in", "each", "cross", "-", "mod", "al", "layer", "can", "adapt", "ively", "agg", "regate", "uni", "-", "mod", "al", "sem", "antic", "knowledge", "to", "fac", "ilit", "ate", "more", "com", "pre", "hens", "ive", "cross", "-", "mod", "al", "al", "ignment", "and", "f", "usion", "."], "token_lens": [1, 1, 2, 1, 2, 4, 1, 2, 1, 1, 3, 1, 3, 1, 2, 1, 2, 1, 3, 4, 2, 1, 1, 2, 1, 2, 2, 1, 1, 4, 1, 1, 2, 2, 4, 2, 1, 1, 3, 1, 4, 4, 2, 1, 3], "sentence": "In this work, we propose ManagerTower, a novel VL model architecture that gathers and combines the insights of pre-trained uni-modal experts at different levels. The managers introduced in each cross-modal layer can adaptively aggregate uni-modal semantic knowledge to facilitate more comprehensive cross-modal alignment and fusion.", "sentence_starts": [0]}
{"doc_id": "ACL_23_P_811", "wnd_id": "ACL_23_P_811-2", "entity_mentions": [{"id": "ACL_23_P_811-2-E0", "text": "ManagerTower", "start": 0, "end": 1, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_811-2-E1", "text": "With only 4M VLP data, ManagerTower achieves superior performances on various downstream VL tasks, especially 79.15% accuracy on VQAv2 Test-Std, 86.56% IR@1 and 95.64% TR@1 on Flickr30K.", "start": 12, "end": 39, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_811-2-E2", "text": "previous strong baselines both with and without Vision-Language Pre-training (VLP).", "start": 2, "end": 12, "entity_type": "UNK", "mention_type": "UNK"}], "relation_mentions": [], "event_mentions": [{"event_type": "Results/Findings", "id": "ACL_23_P_811-2-EV0", "trigger": {"text": "outperforms", "start": 1, "end": 2}, "arguments": [{"entity_id": "ACL_23_P_811-2-E0", "text": "ManagerTower", "role": "Agent"}, {"entity_id": "ACL_23_P_811-2-E1", "text": "With only 4M VLP data, ManagerTower achieves superior performances on various downstream VL tasks, especially 79.15% accuracy on VQAv2 Test-Std, 86.56% IR@1 and 95.64% TR@1 on Flickr30K.", "role": "Results"}, {"entity_id": "ACL_23_P_811-2-E2", "text": "previous strong baselines both with and without Vision-Language Pre-training (VLP).", "role": "PrimaryObject"}]}], "entity_coreference": [], "event_coreference": [], "tokens": ["ManagerTower", "outperforms", "previous", "strong", "baselines", "both", "with", "and", "without", "Vision-Language", "Pre-training", "(VLP).", "With", "only", "4M", "VLP", "data,", "ManagerTower", "achieves", "superior", "performances", "on", "various", "downstream", "VL", "tasks,", "especially", "79.15%", "accuracy", "on", "VQAv2", "Test-Std,", "86.56%", "IR@1", "and", "95.64%", "TR@1", "on", "Flickr30K."], "pieces": ["Manager", "T", "ower", "out", "per", "forms", "pre", "vious", "strong", "bas", "elines", "both", "with", "and", "without", "Vision", "-", "Language", "Pre", "-", "training", "(", "V", "LP", ").", "With", "only", "4", "M", "V", "LP", "data", ",", "Manager", "T", "ower", "ach", "ieves", "super", "ior", "per", "form", "ances", "on", "var", "ious", "down", "stream", "VL", "t", "asks", ",", "especially", "79", ".", "15", "%", "acc", "uracy", "on", "V", "Q", "Av", "2", "Test", "-", "St", "d", ",", "86", ".", "56", "%", "IR", "@", "1", "and", "95", ".", "64", "%", "TR", "@", "1", "on", "Flickr", "30", "K", "."], "token_lens": [3, 3, 2, 1, 2, 1, 1, 1, 1, 3, 3, 4, 1, 1, 2, 2, 2, 3, 2, 2, 3, 1, 2, 2, 1, 3, 1, 4, 2, 1, 4, 5, 4, 3, 1, 4, 3, 1, 4], "sentence": "ManagerTower outperforms previous strong baselines both with and without Vision-Language Pre-training (VLP). With only 4M VLP data, ManagerTower achieves superior performances on various downstream VL tasks, especially 79.15% accuracy on VQAv2 Test-Std, 86.56% IR@1 and 95.64% TR@1 on Flickr30K.", "sentence_starts": [0]}
{"doc_id": "ACL_23_P_709", "wnd_id": "ACL_23_P_709-0", "entity_mentions": [{"id": "ACL_23_P_709-0-E0", "text": "Large pre-trained language models", "start": 0, "end": 4, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_709-0-E1", "text": "pre-trained language models may memorize a considerable fraction of their training data, leading to the privacy risk of information leakage", "start": 16, "end": 36, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_709-0-E2", "text": "impressive results across many tasks", "start": 5, "end": 10, "entity_type": "UNK", "mention_type": "UNK"}], "relation_mentions": [], "event_mentions": [{"event_type": "Background/Introduction", "id": "ACL_23_P_709-0-EV0", "trigger": {"text": "achieve", "start": 4, "end": 5}, "arguments": [{"entity_id": "ACL_23_P_709-0-E0", "text": "Large pre-trained language models", "role": "Agent"}, {"entity_id": "ACL_23_P_709-0-E1", "text": "pre-trained language models may memorize a considerable fraction of their training data, leading to the privacy risk of information leakage", "role": "Challenge"}, {"entity_id": "ACL_23_P_709-0-E2", "text": "impressive results across many tasks", "role": "PrimaryObject"}]}], "entity_coreference": [], "event_coreference": [], "tokens": ["Large", "pre-trained", "language", "models", "achieve", "impressive", "results", "across", "many", "tasks.", "However,", "recent", "works", "point", "out", "that", "pre-trained", "language", "models", "may", "memorize", "a", "considerable", "fraction", "of", "their", "training", "data,", "leading", "to", "the", "privacy", "risk", "of", "information", "leakage."], "pieces": ["Large", "pre", "-", "trained", "language", "models", "ach", "ieve", "imp", "ressive", "results", "ac", "ross", "many", "t", "asks", ".", "However", ",", "recent", "works", "point", "out", "that", "pre", "-", "trained", "language", "models", "may", "mem", "or", "ize", "a", "consider", "able", "f", "raction", "of", "their", "training", "data", ",", "leading", "to", "the", "priv", "acy", "risk", "of", "information", "le", "ak", "age", "."], "token_lens": [1, 3, 1, 1, 2, 2, 1, 2, 1, 3, 2, 1, 1, 1, 1, 1, 3, 1, 1, 1, 3, 1, 2, 2, 1, 1, 1, 2, 1, 1, 1, 2, 1, 1, 1, 4], "sentence": "Large pre-trained language models achieve impressive results across many tasks. However, recent works point out that pre-trained language models may memorize a considerable fraction of their training data, leading to the privacy risk of information leakage.", "sentence_starts": [0]}
{"doc_id": "ACL_23_P_709", "wnd_id": "ACL_23_P_709-1", "entity_mentions": [{"id": "ACL_23_P_709-1-E0", "text": "we", "start": 3, "end": 4, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_709-1-E1", "text": "To elicit memorization in the attacked model, we tune soft prompt embeddings while keeping the model fixed", "start": 37, "end": 54, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_709-1-E2", "text": "We further propose a smoothing loss that smooths the loss distribution of the suffix tokens to make it easier to sample the correct suffix", "start": 54, "end": 78, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_709-1-E3", "text": "In order to select the most probable suffix from a collection of sampled suffixes and estimate the prediction confidence, we propose a calibrated confidence estimation method, which normalizes the confidence of the generated suffixes with a local estimation", "start": 78, "end": 116, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_709-1-E4", "text": "a method ", "start": 5, "end": 7, "entity_type": "UNK", "mention_type": "UNK"}], "relation_mentions": [], "event_mentions": [{"event_type": "Methods/Approach", "id": "ACL_23_P_709-1-EV0", "trigger": {"text": "propose", "start": 4, "end": 5}, "arguments": [{"entity_id": "ACL_23_P_709-1-E0", "text": "we", "role": "Agent"}, {"entity_id": "ACL_23_P_709-1-E1", "text": "To elicit memorization in the attacked model, we tune soft prompt embeddings while keeping the model fixed", "role": "Method"}, {"entity_id": "ACL_23_P_709-1-E2", "text": "We further propose a smoothing loss that smooths the loss distribution of the suffix tokens to make it easier to sample the correct suffix", "role": "Method"}, {"entity_id": "ACL_23_P_709-1-E3", "text": "In order to select the most probable suffix from a collection of sampled suffixes and estimate the prediction confidence, we propose a calibrated confidence estimation method, which normalizes the confidence of the generated suffixes with a local estimation", "role": "Method"}, {"entity_id": "ACL_23_P_709-1-E4", "text": "a method ", "role": "PrimaryObject"}]}], "entity_coreference": [], "event_coreference": [], "tokens": ["In", "this", "paper,", "we", "propose", "a", "method", "named", "Ethicist", "for", "targeted", "training", "data", "extraction", "through", "loss", "smoothed", "soft", "prompting", "and", "calibrated", "confidence", "estimation,", "investigating", "how", "to", "recover", "the", "suffix", "in", "the", "training", "data", "when", "given", "a", "prefix.", "To", "elicit", "memorization", "in", "the", "attacked", "model,", "we", "tune", "soft", "prompt", "embeddings", "while", "keeping", "the", "model", "fixed.", "We", "further", "propose", "a", "smoothing", "loss", "that", "smooths", "the", "loss", "distribution", "of", "the", "suffix", "tokens", "to", "make", "it", "easier", "to", "sample", "the", "correct", "suffix.", "In", "order", "to", "select", "the", "most", "probable", "suffix", "from", "a", "collection", "of", "sampled", "suffixes", "and", "estimate", "the", "prediction", "confidence,", "we", "propose", "a", "calibrated", "confidence", "estimation", "method,", "which", "normalizes", "the", "confidence", "of", "the", "generated", "suffixes", "with", "a", "local", "estimation."], "pieces": ["In", "this", "paper", ",", "we", "pro", "pose", "a", "method", "named", "Eth", "icist", "for", "target", "ed", "training", "data", "ext", "raction", "through", "loss", "sm", "oot", "hed", "soft", "prom", "pt", "ing", "and", "cal", "ibr", "ated", "confidence", "est", "imation", ",", "invest", "igating", "how", "to", "re", "cover", "the", "suff", "ix", "in", "the", "training", "data", "when", "given", "a", "prefix", ".", "To", "el", "icit", "mem", "or", "ization", "in", "the", "att", "acked", "model", ",", "we", "t", "une", "soft", "prom", "pt", "embed", "d", "ings", "while", "keeping", "the", "model", "fixed", ".", "We", "f", "urther", "pro", "pose", "a", "sm", "oot", "hing", "loss", "that", "sm", "ooth", "s", "the", "loss", "dist", "ribution", "of", "the", "suff", "ix", "t", "ok", "ens", "to", "make", "it", "eas", "ier", "to", "sample", "the", "correct", "suff", "ix", ".", "In", "order", "to", "select", "the", "most", "pro", "bable", "suff", "ix", "from", "a", "collection", "of", "sam", "pled", "suff", "ix", "es", "and", "est", "imate", "the", "pred", "iction", "confidence", ",", "we", "pro", "pose", "a", "cal", "ibr", "ated", "confidence", "est", "imation", "method", ",", "which", "normal", "izes", "the", "confidence", "of", "the", "generated", "suff", "ix", "es", "with", "a", "local", "est", "imation", "."], "token_lens": [1, 1, 2, 1, 2, 1, 1, 1, 2, 1, 2, 1, 1, 2, 1, 1, 3, 1, 3, 1, 3, 1, 3, 2, 1, 1, 2, 1, 2, 1, 1, 1, 1, 1, 1, 1, 2, 1, 2, 3, 1, 1, 2, 2, 1, 2, 1, 2, 3, 1, 1, 1, 1, 2, 1, 2, 2, 1, 3, 1, 1, 3, 1, 1, 2, 1, 1, 2, 3, 1, 1, 1, 2, 1, 1, 1, 1, 3, 1, 1, 1, 1, 1, 1, 2, 2, 1, 1, 1, 1, 2, 3, 1, 2, 1, 2, 2, 1, 2, 1, 3, 1, 2, 2, 1, 2, 1, 1, 1, 1, 1, 3, 1, 1, 1, 3], "sentence": "In this paper, we propose a method named Ethicist for targeted training data extraction through loss smoothed soft prompting and calibrated confidence estimation, investigating how to recover the suffix in the training data when given a prefix. To elicit memorization in the attacked model, we tune soft prompt embeddings while keeping the model fixed. We further propose a smoothing loss that smooths the loss distribution of the suffix tokens to make it easier to sample the correct suffix. In order to select the most probable suffix from a collection of sampled suffixes and estimate the prediction confidence, we propose a calibrated confidence estimation method, which normalizes the confidence of the generated suffixes with a local estimation.", "sentence_starts": [0]}
{"doc_id": "ACL_23_P_709", "wnd_id": "ACL_23_P_709-2", "entity_mentions": [{"id": "ACL_23_P_709-2-E0", "text": "We", "start": 0, "end": 1, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_709-2-E1", "text": "We also investigate several factors influencing the data extraction performance, including decoding strategy, model scale, prefix length, and suffix length", "start": 15, "end": 35, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_709-2-E2", "text": "Ethicist significantly improves the extraction performance on a recently proposed public benchmark.", "start": 3, "end": 15, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_709-2-E3", "text": "Ethicist significantly improves the extraction performance on a recently proposed public benchmark", "start": 3, "end": 15, "entity_type": "UNK", "mention_type": "UNK"}], "relation_mentions": [], "event_mentions": [{"event_type": "Results/Findings", "id": "ACL_23_P_709-2-EV0", "trigger": {"text": "show", "start": 1, "end": 2}, "arguments": [{"entity_id": "ACL_23_P_709-2-E0", "text": "We", "role": "Agent"}, {"entity_id": "ACL_23_P_709-2-E1", "text": "We also investigate several factors influencing the data extraction performance, including decoding strategy, model scale, prefix length, and suffix length", "role": "Method"}, {"entity_id": "ACL_23_P_709-2-E2", "text": "Ethicist significantly improves the extraction performance on a recently proposed public benchmark.", "role": "Results"}, {"entity_id": "ACL_23_P_709-2-E3", "text": "Ethicist significantly improves the extraction performance on a recently proposed public benchmark", "role": "PrimaryObject"}]}], "entity_coreference": [], "event_coreference": [], "tokens": ["We", "show", "that", "Ethicist", "significantly", "improves", "the", "extraction", "performance", "on", "a", "recently", "proposed", "public", "benchmark.", "We", "also", "investigate", "several", "factors", "influencing", "the", "data", "extraction", "performance,", "including", "decoding", "strategy,", "model", "scale,", "prefix", "length,", "and", "suffix", "length."], "pieces": ["We", "show", "that", "Eth", "icist", "sign", "ificantly", "impro", "ves", "the", "ext", "raction", "performance", "on", "a", "recent", "ly", "prop", "osed", "public", "bench", "mark", ".", "We", "also", "invest", "igate", "sever", "al", "fact", "ors", "inf", "lu", "encing", "the", "data", "ext", "raction", "performance", ",", "including", "dec", "oding", "str", "ategy", ",", "model", "scale", ",", "prefix", "length", ",", "and", "suff", "ix", "length", "."], "token_lens": [1, 1, 1, 2, 2, 2, 1, 2, 1, 1, 1, 2, 2, 1, 3, 1, 1, 2, 2, 2, 3, 1, 1, 2, 2, 1, 2, 3, 1, 2, 1, 2, 1, 2, 2], "sentence": "We show that Ethicist significantly improves the extraction performance on a recently proposed public benchmark. We also investigate several factors influencing the data extraction performance, including decoding strategy, model scale, prefix length, and suffix length.", "sentence_starts": [0]}
{"doc_id": "ACL_23_P_373", "wnd_id": "ACL_23_P_373-0", "entity_mentions": [{"id": "ACL_23_P_373-0-E0", "text": "Text-based reinforcement learning agents", "start": 0, "end": 4, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_373-0-E1", "text": "neuro-symbolic methods, specifically those that leverage an intermediate formal representation, are gaining significant attention in language understanding tasks", "start": 29, "end": 47, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_373-0-E2", "text": "their advantages ranging from inherent interpretability, the lesser requirement of training data, and being generalizable in scenarios with unseen data", "start": 51, "end": 71, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_373-0-E3", "text": "neural network-based models with embeddings-based representation", "start": 7, "end": 13, "entity_type": "UNK", "mention_type": "UNK"}], "relation_mentions": [], "event_mentions": [{"event_type": "Background/Introduction", "id": "ACL_23_P_373-0-EV0", "trigger": {"text": "have predominantly been", "start": 4, "end": 7}, "arguments": [{"entity_id": "ACL_23_P_373-0-E0", "text": "Text-based reinforcement learning agents", "role": "Agent"}, {"entity_id": "ACL_23_P_373-0-E1", "text": "neuro-symbolic methods, specifically those that leverage an intermediate formal representation, are gaining significant attention in language understanding tasks", "role": "Context"}, {"entity_id": "ACL_23_P_373-0-E2", "text": "their advantages ranging from inherent interpretability, the lesser requirement of training data, and being generalizable in scenarios with unseen data", "role": "Analysis"}, {"entity_id": "ACL_23_P_373-0-E3", "text": "neural network-based models with embeddings-based representation", "role": "PrimaryObject"}]}], "entity_coreference": [], "event_coreference": [], "tokens": ["Text-based", "reinforcement", "learning", "agents", "have", "predominantly", "been", "neural", "network-based", "models", "with", "embeddings-based", "representation,", "learning", "uninterpretable", "policies", "that", "often", "do", "not", "generalize", "well", "to", "unseen", "games.", "On", "the", "other", "hand,", "neuro-symbolic", "methods,", "specifically", "those", "that", "leverage", "an", "intermediate", "formal", "representation,", "are", "gaining", "significant", "attention", "in", "language", "understanding", "tasks.", "This", "is", "because", "of", "their", "advantages", "ranging", "from", "inherent", "interpretability,", "the", "lesser", "requirement", "of", "training", "data,", "and", "being", "generalizable", "in", "scenarios", "with", "unseen", "data."], "pieces": ["Text", "-", "based", "re", "in", "forcement", "learning", "agents", "have", "pred", "omin", "antly", "been", "ne", "ural", "network", "-", "based", "models", "with", "embed", "d", "ings", "-", "based", "represent", "ation", ",", "learning", "un", "interpret", "able", "p", "olic", "ies", "that", "often", "do", "not", "general", "ize", "well", "to", "un", "seen", "games", ".", "On", "the", "other", "hand", ",", "ne", "uro", "-", "sy", "mb", "olic", "method", "s", ",", "specific", "ally", "those", "that", "le", "verage", "an", "inter", "mediate", "form", "al", "represent", "ation", ",", "are", "g", "aining", "significant", "att", "ention", "in", "language", "under", "standing", "t", "asks", ".", "This", "is", "because", "of", "their", "advant", "ages", "ranging", "from", "in", "herent", "interpret", "ability", ",", "the", "less", "er", "requ", "irement", "of", "training", "data", ",", "and", "being", "general", "izable", "in", "sc", "en", "arios", "with", "un", "seen", "data", "."], "token_lens": [3, 3, 1, 1, 1, 3, 1, 2, 3, 1, 1, 5, 3, 1, 3, 3, 1, 1, 1, 1, 2, 1, 1, 2, 2, 1, 1, 1, 2, 6, 3, 2, 1, 1, 2, 1, 2, 2, 3, 1, 2, 1, 2, 1, 1, 2, 3, 1, 1, 1, 1, 1, 2, 1, 1, 2, 3, 1, 2, 2, 1, 1, 2, 1, 1, 2, 1, 3, 1, 2, 2], "sentence": "Text-based reinforcement learning agents have predominantly been neural network-based models with embeddings-based representation, learning uninterpretable policies that often do not generalize well to unseen games. On the other hand, neuro-symbolic methods, specifically those that leverage an intermediate formal representation, are gaining significant attention in language understanding tasks. This is because of their advantages ranging from inherent interpretability, the lesser requirement of training data, and being generalizable in scenarios with unseen data.", "sentence_starts": [0]}
{"doc_id": "ACL_23_P_373", "wnd_id": "ACL_23_P_373-1", "entity_mentions": [{"id": "ACL_23_P_373-1-E0", "text": "we", "start": 4, "end": 5, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_373-1-E1", "text": "to learn abstract interpretable rules as policies", "start": 23, "end": 30, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_373-1-E2", "text": "a modular, NEuro-Symbolic Textual Agent (NESTA)", "start": 6, "end": 12, "entity_type": "UNK", "mention_type": "UNK"}], "relation_mentions": [], "event_mentions": [{"event_type": "Methods/Approach", "id": "ACL_23_P_373-1-EV0", "trigger": {"text": "propose", "start": 5, "end": 6}, "arguments": [{"entity_id": "ACL_23_P_373-1-E0", "text": "we", "role": "Agent"}, {"entity_id": "ACL_23_P_373-1-E1", "text": "to learn abstract interpretable rules as policies", "role": "Purpose"}, {"entity_id": "ACL_23_P_373-1-E2", "text": "a modular, NEuro-Symbolic Textual Agent (NESTA)", "role": "PrimaryObject"}]}], "entity_coreference": [], "event_coreference": [], "tokens": ["Therefore,", "in", "this", "paper,", "we", "propose", "a", "modular,", "NEuro-Symbolic", "Textual", "Agent", "(NESTA)", "that", "combines", "a", "generic", "semantic", "parser", "with", "a", "rule", "induction", "system", "to", "learn", "abstract", "interpretable", "rules", "as", "policies."], "pieces": ["Therefore", ",", "in", "this", "paper", ",", "we", "pro", "pose", "a", "mod", "ular", ",", "NE", "uro", "-", "Sy", "mb", "olic", "Text", "ual", "Agent", "(", "NES", "TA", ")", "that", "comb", "ines", "a", "generic", "sem", "antic", "parser", "with", "a", "rule", "ind", "uction", "system", "to", "learn", "ab", "stract", "interpret", "able", "rules", "as", "p", "olic", "ies", "."], "token_lens": [2, 1, 1, 2, 1, 2, 1, 3, 6, 2, 1, 4, 1, 2, 1, 1, 2, 1, 1, 1, 1, 2, 1, 1, 1, 2, 2, 1, 1, 4], "sentence": "Therefore, in this paper, we propose a modular, NEuro-Symbolic Textual Agent (NESTA) that combines a generic semantic parser with a rule induction system to learn abstract interpretable rules as policies.", "sentence_starts": [0]}
{"doc_id": "ACL_23_P_373", "wnd_id": "ACL_23_P_373-2", "entity_mentions": [{"id": "ACL_23_P_373-2-E0", "text": "Our experiments on established text-based game benchmarks", "start": 0, "end": 7, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_373-2-E1", "text": "the proposed NESTA method outperforms deep reinforcement learning-based techniques by achieving better generalization to unseen test games and learning from fewer training interactions", "start": 9, "end": 32, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_373-2-E2", "text": "the proposed NESTA method outperforms deep reinforcement learning-based techniques", "start": 9, "end": 18, "entity_type": "UNK", "mention_type": "UNK"}], "relation_mentions": [], "event_mentions": [{"event_type": "Results/Findings", "id": "ACL_23_P_373-2-EV0", "trigger": {"text": "show", "start": 7, "end": 8}, "arguments": [{"entity_id": "ACL_23_P_373-2-E0", "text": "Our experiments on established text-based game benchmarks", "role": "Agent"}, {"entity_id": "ACL_23_P_373-2-E1", "text": "the proposed NESTA method outperforms deep reinforcement learning-based techniques by achieving better generalization to unseen test games and learning from fewer training interactions", "role": "Results"}, {"entity_id": "ACL_23_P_373-2-E2", "text": "the proposed NESTA method outperforms deep reinforcement learning-based techniques", "role": "PrimaryObject"}]}], "entity_coreference": [], "event_coreference": [], "tokens": ["Our", "experiments", "on", "established", "text-based", "game", "benchmarks", "show", "that", "the", "proposed", "NESTA", "method", "outperforms", "deep", "reinforcement", "learning-based", "techniques", "by", "achieving", "better", "generalization", "to", "unseen", "test", "games", "and", "learning", "from", "fewer", "training", "interactions."], "pieces": ["Our", "exper", "iments", "on", "established", "text", "-", "based", "game", "bench", "marks", "show", "that", "the", "prop", "osed", "NES", "TA", "method", "out", "per", "forms", "deep", "re", "in", "forcement", "learning", "-", "based", "techn", "iques", "by", "ach", "ieving", "better", "general", "ization", "to", "un", "seen", "test", "games", "and", "learning", "from", "few", "er", "training", "inter", "actions", "."], "token_lens": [1, 2, 1, 1, 3, 1, 2, 1, 1, 1, 2, 2, 1, 3, 1, 3, 3, 2, 1, 2, 1, 2, 1, 2, 1, 1, 1, 1, 1, 2, 1, 3], "sentence": "Our experiments on established text-based game benchmarks show that the proposed NESTA method outperforms deep reinforcement learning-based techniques by achieving better generalization to unseen test games and learning from fewer training interactions.", "sentence_starts": [0]}
{"doc_id": "ACL_23_P_365", "wnd_id": "ACL_23_P_365-0", "entity_mentions": [{"id": "ACL_23_P_365-0-E0", "text": "previous studies", "start": 17, "end": 19, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_365-0-E1", "text": "Dense retrieval has shown promise in the first-stage retrieval process when trained on in-domain labeled datasets", "start": 0, "end": 16, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_365-0-E2", "text": "due to its weak modeling of domain-invariant and interpretable feature (i.e., matching signal between two texts, which is the essence of information retrieval)", "start": 31, "end": 54, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_365-0-E3", "text": "dense retrieval is hard to generalize to unseen domains", "start": 22, "end": 31, "entity_type": "UNK", "mention_type": "UNK"}], "relation_mentions": [], "event_mentions": [{"event_type": "Background/Introduction", "id": "ACL_23_P_365-0-EV0", "trigger": {"text": "found", "start": 20, "end": 21}, "arguments": [{"entity_id": "ACL_23_P_365-0-E0", "text": "previous studies", "role": "Agent"}, {"entity_id": "ACL_23_P_365-0-E1", "text": "Dense retrieval has shown promise in the first-stage retrieval process when trained on in-domain labeled datasets", "role": "Context"}, {"entity_id": "ACL_23_P_365-0-E2", "text": "due to its weak modeling of domain-invariant and interpretable feature (i.e., matching signal between two texts, which is the essence of information retrieval)", "role": "Analysis"}, {"entity_id": "ACL_23_P_365-0-E3", "text": "dense retrieval is hard to generalize to unseen domains", "role": "PrimaryObject"}]}], "entity_coreference": [], "event_coreference": [], "tokens": ["Dense", "retrieval", "has", "shown", "promise", "in", "the", "first-stage", "retrieval", "process", "when", "trained", "on", "in-domain", "labeled", "datasets.", "However,", "previous", "studies", "have", "found", "that", "dense", "retrieval", "is", "hard", "to", "generalize", "to", "unseen", "domains", "due", "to", "its", "weak", "modeling", "of", "domain-invariant", "and", "interpretable", "feature", "(i.e.,", "matching", "signal", "between", "two", "texts,", "which", "is", "the", "essence", "of", "information", "retrieval)."], "pieces": ["D", "ense", "ret", "ri", "eval", "has", "shown", "prom", "ise", "in", "the", "first", "-", "stage", "ret", "ri", "eval", "process", "when", "trained", "on", "in", "-", "domain", "label", "ed", "dat", "as", "ets", ".", "However", ",", "pre", "vious", "stud", "ies", "have", "found", "that", "d", "ense", "ret", "ri", "eval", "is", "hard", "to", "general", "ize", "to", "un", "seen", "dom", "ains", "due", "to", "its", "weak", "mod", "eling", "of", "domain", "-", "inv", "ari", "ant", "and", "interpret", "able", "feature", "(", "i", ".", "e", ".,", "match", "ing", "sign", "al", "between", "two", "text", "s", ",", "which", "is", "the", "ess", "ence", "of", "information", "ret", "ri", "eval", ")."], "token_lens": [2, 3, 1, 1, 2, 1, 1, 3, 3, 1, 1, 1, 1, 3, 2, 4, 2, 2, 2, 1, 1, 1, 2, 3, 1, 1, 1, 2, 1, 2, 2, 1, 1, 1, 1, 2, 1, 5, 1, 2, 1, 5, 2, 2, 1, 1, 3, 1, 1, 1, 2, 1, 1, 4], "sentence": "Dense retrieval has shown promise in the first-stage retrieval process when trained on in-domain labeled datasets. However, previous studies have found that dense retrieval is hard to generalize to unseen domains due to its weak modeling of domain-invariant and interpretable feature (i.e., matching signal between two texts, which is the essence of information retrieval).", "sentence_starts": [0]}
{"doc_id": "ACL_23_P_365", "wnd_id": "ACL_23_P_365-1", "entity_mentions": [{"id": "ACL_23_P_365-1-E0", "text": "we", "start": 3, "end": 4, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_365-1-E1", "text": "to improve the generalization of dense retrieval via capturing matching signal called BERM", "start": 8, "end": 21, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_365-1-E2", "text": "in BERM, a single passage is segmented into multiple units and two unit-level requirements are proposed for representation as the constraint in training to obtain the effective matching signal", "start": 35, "end": 64, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_365-1-E3", "text": "Unit-level view and balanced semantics make representation express the text in a fine-grained manner", "start": 77, "end": 91, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_365-1-E4", "text": "One is semantic unit balance and the other is essential matching unit extractability.", "start": 64, "end": 77, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_365-1-E5", "text": "Fully fine-grained expression and query-oriented saliency are two properties of the matching signal", "start": 21, "end": 34, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_365-1-E6", "text": "Essential matching unit extractability makes passage representation sensitive to the given query to extract the pure matching information from the passage containing complex context.", "start": 91, "end": 115, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_365-1-E7", "text": "a novel method", "start": 5, "end": 8, "entity_type": "UNK", "mention_type": "UNK"}], "relation_mentions": [], "event_mentions": [{"event_type": "Methods/Approach", "id": "ACL_23_P_365-1-EV0", "trigger": {"text": "propose", "start": 4, "end": 5}, "arguments": [{"entity_id": "ACL_23_P_365-1-E0", "text": "we", "role": "Agent"}, {"entity_id": "ACL_23_P_365-1-E1", "text": "to improve the generalization of dense retrieval via capturing matching signal called BERM", "role": "Purpose"}, {"entity_id": "ACL_23_P_365-1-E2", "text": "in BERM, a single passage is segmented into multiple units and two unit-level requirements are proposed for representation as the constraint in training to obtain the effective matching signal", "role": "Method"}, {"entity_id": "ACL_23_P_365-1-E3", "text": "Unit-level view and balanced semantics make representation express the text in a fine-grained manner", "role": "Method"}, {"entity_id": "ACL_23_P_365-1-E4", "text": "One is semantic unit balance and the other is essential matching unit extractability.", "role": "Method"}, {"entity_id": "ACL_23_P_365-1-E5", "text": "Fully fine-grained expression and query-oriented saliency are two properties of the matching signal", "role": "Method"}, {"entity_id": "ACL_23_P_365-1-E6", "text": "Essential matching unit extractability makes passage representation sensitive to the given query to extract the pure matching information from the passage containing complex context.", "role": "Method"}, {"entity_id": "ACL_23_P_365-1-E7", "text": "a novel method", "role": "PrimaryObject"}]}], "entity_coreference": [], "event_coreference": [], "tokens": ["In", "this", "paper,", "we", "propose", "a", "novel", "method", "to", "improve", "the", "generalization", "of", "dense", "retrieval", "via", "capturing", "matching", "signal", "called", "BERM.", "Fully", "fine-grained", "expression", "and", "query-oriented", "saliency", "are", "two", "properties", "of", "the", "matching", "signal.", "Thus,", "in", "BERM,", "a", "single", "passage", "is", "segmented", "into", "multiple", "units", "and", "two", "unit-level", "requirements", "are", "proposed", "for", "representation", "as", "the", "constraint", "in", "training", "to", "obtain", "the", "effective", "matching", "signal.", "One", "is", "semantic", "unit", "balance", "and", "the", "other", "is", "essential", "matching", "unit", "extractability.", "Unit-level", "view", "and", "balanced", "semantics", "make", "representation", "express", "the", "text", "in", "a", "fine-grained", "manner.", "Essential", "matching", "unit", "extractability", "makes", "passage", "representation", "sensitive", "to", "the", "given", "query", "to", "extract", "the", "pure", "matching", "information", "from", "the", "passage", "containing", "complex", "context."], "pieces": ["In", "this", "paper", ",", "we", "pro", "pose", "a", "no", "vel", "method", "to", "improve", "the", "general", "ization", "of", "d", "ense", "ret", "ri", "eval", "via", "capt", "uring", "match", "ing", "sign", "al", "called", "BER", "M", ".", "F", "ully", "fine", "-", "gr", "ained", "expression", "and", "query", "-", "oriented", "sal", "iency", "are", "two", "properties", "of", "the", "match", "ing", "sign", "al", ".", "Thus", ",", "in", "BER", "M", ",", "a", "single", "pass", "age", "is", "se", "gment", "ed", "into", "multiple", "units", "and", "two", "unit", "-", "level", "requ", "irements", "are", "prop", "osed", "for", "represent", "ation", "as", "the", "con", "str", "aint", "in", "training", "to", "ob", "tain", "the", "effective", "match", "ing", "sign", "al", ".", "One", "is", "sem", "antic", "unit", "balance", "and", "the", "other", "is", "essential", "match", "ing", "unit", "ext", "ract", "ability", ".", "Unit", "-", "level", "view", "and", "balanced", "sem", "antics", "make", "represent", "ation", "express", "the", "text", "in", "a", "fine", "-", "gr", "ained", "man", "ner", ".", "Ess", "ential", "match", "ing", "unit", "ext", "ract", "ability", "makes", "pass", "age", "represent", "ation", "sensitive", "to", "the", "given", "query", "to", "ext", "ract", "the", "pure", "match", "ing", "information", "from", "the", "pass", "age", "containing", "complex", "context", "."], "token_lens": [1, 1, 2, 1, 2, 1, 2, 1, 1, 1, 1, 2, 1, 2, 3, 1, 2, 2, 2, 1, 3, 2, 4, 1, 1, 3, 2, 1, 1, 1, 1, 1, 2, 3, 2, 1, 3, 1, 1, 2, 1, 3, 1, 1, 1, 1, 1, 3, 2, 1, 2, 1, 2, 1, 1, 3, 1, 1, 1, 2, 1, 1, 2, 3, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 2, 1, 4, 3, 1, 1, 1, 2, 1, 2, 1, 1, 1, 1, 1, 4, 3, 2, 2, 1, 3, 1, 2, 2, 1, 1, 1, 1, 1, 1, 2, 1, 1, 2, 1, 1, 1, 2, 1, 1, 2], "sentence": "In this paper, we propose a novel method to improve the generalization of dense retrieval via capturing matching signal called BERM. Fully fine-grained expression and query-oriented saliency are two properties of the matching signal. Thus, in BERM, a single passage is segmented into multiple units and two unit-level requirements are proposed for representation as the constraint in training to obtain the effective matching signal. One is semantic unit balance and the other is essential matching unit extractability. Unit-level view and balanced semantics make representation express the text in a fine-grained manner. Essential matching unit extractability makes passage representation sensitive to the given query to extract the pure matching information from the passage containing complex context.", "sentence_starts": [0]}
{"doc_id": "ACL_23_P_365", "wnd_id": "ACL_23_P_365-2", "entity_mentions": [{"id": "ACL_23_P_365-2-E0", "text": "Experiments on BEIR", "start": 0, "end": 3, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_365-2-E1", "text": "to improve its generalization ability without any additional inference overhead and target domain data", "start": 24, "end": 38, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_365-2-E2", "text": "our method can be effectively combined with different dense retrieval training methods", "start": 5, "end": 17, "entity_type": "UNK", "mention_type": "UNK"}], "relation_mentions": [], "event_mentions": [{"event_type": "Results/Findings", "id": "ACL_23_P_365-2-EV0", "trigger": {"text": "show", "start": 3, "end": 4}, "arguments": [{"entity_id": "ACL_23_P_365-2-E0", "text": "Experiments on BEIR", "role": "Agent"}, {"entity_id": "ACL_23_P_365-2-E1", "text": "to improve its generalization ability without any additional inference overhead and target domain data", "role": "Purpose"}, {"entity_id": "ACL_23_P_365-2-E2", "text": "our method can be effectively combined with different dense retrieval training methods", "role": "PrimaryObject"}]}], "entity_coreference": [], "event_coreference": [], "tokens": ["Experiments", "on", "BEIR", "show", "that", "our", "method", "can", "be", "effectively", "combined", "with", "different", "dense", "retrieval", "training", "methods", "(vanilla,", "hard", "negatives", "mining,", "and", "knowledge", "distillation)", "to", "improve", "its", "generalization", "ability", "without", "any", "additional", "inference", "overhead", "and", "target", "domain", "data."], "pieces": ["Exper", "iments", "on", "BE", "IR", "show", "that", "our", "method", "can", "be", "effect", "ively", "comb", "ined", "with", "different", "d", "ense", "ret", "ri", "eval", "training", "method", "s", "(", "van", "illa", ",", "hard", "neg", "atives", "mining", ",", "and", "knowledge", "dist", "illation", ")", "to", "improve", "its", "general", "ization", "ability", "without", "any", "add", "itional", "in", "ference", "over", "head", "and", "target", "domain", "data", "."], "token_lens": [2, 1, 2, 1, 1, 1, 1, 1, 1, 2, 2, 1, 1, 2, 3, 1, 2, 4, 1, 2, 2, 1, 1, 3, 1, 1, 1, 2, 1, 1, 1, 2, 2, 2, 1, 1, 1, 2], "sentence": "Experiments on BEIR show that our method can be effectively combined with different dense retrieval training methods (vanilla, hard negatives mining, and knowledge distillation) to improve its generalization ability without any additional inference overhead and target domain data.", "sentence_starts": [0]}
{"doc_id": "ACL_23_P_502", "wnd_id": "ACL_23_P_502-0", "entity_mentions": [{"id": "ACL_23_P_502-0-E0", "text": "Autoregressive language models", "start": 0, "end": 3, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_502-0-E1", "text": "minimizing the forward cross-entropy, which is equivalent to maximum likelihood estimation (MLE)", "start": 23, "end": 35, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_502-0-E2", "text": "minimizing the cross-entropy of the model distribution Q relative to the data distribution P", "start": 6, "end": 20, "entity_type": "UNK", "mention_type": "UNK"}], "relation_mentions": [], "event_mentions": [{"event_type": "Background/Introduction", "id": "ACL_23_P_502-0-EV0", "trigger": {"text": "are trained by", "start": 3, "end": 6}, "arguments": [{"entity_id": "ACL_23_P_502-0-E0", "text": "Autoregressive language models", "role": "Agent"}, {"entity_id": "ACL_23_P_502-0-E1", "text": "minimizing the forward cross-entropy, which is equivalent to maximum likelihood estimation (MLE)", "role": "Analysis"}, {"entity_id": "ACL_23_P_502-0-E2", "text": "minimizing the cross-entropy of the model distribution Q relative to the data distribution P", "role": "PrimaryObject"}]}], "entity_coreference": [], "event_coreference": [], "tokens": ["Autoregressive", "language", "models", "are", "trained", "by", "minimizing", "the", "cross-entropy", "of", "the", "model", "distribution", "Q", "relative", "to", "the", "data", "distribution", "P", "\u2013", "that", "is,", "minimizing", "the", "forward", "cross-entropy,", "which", "is", "equivalent", "to", "maximum", "likelihood", "estimation", "(MLE)."], "pieces": ["Aut", "ore", "gressive", "language", "models", "are", "trained", "by", "min", "im", "izing", "the", "cross", "-", "ent", "ropy", "of", "the", "model", "dist", "ribution", "Q", "relative", "to", "the", "data", "dist", "ribution", "P", "\u00e2\u0122\u0135", "that", "is", ",", "min", "im", "izing", "the", "forward", "cross", "-", "ent", "ropy", ",", "which", "is", "equ", "ivalent", "to", "maximum", "like", "lihood", "est", "imation", "(", "M", "LE", ")."], "token_lens": [3, 1, 1, 1, 1, 1, 3, 1, 4, 1, 1, 1, 2, 1, 1, 1, 1, 1, 2, 1, 1, 1, 2, 3, 1, 1, 5, 1, 1, 2, 1, 1, 2, 2, 4], "sentence": "Autoregressive language models are trained by minimizing the cross-entropy of the model distribution Q relative to the data distribution P \u2013 that is, minimizing the forward cross-entropy, which is equivalent to maximum likelihood estimation (MLE).", "sentence_starts": [0]}
{"doc_id": "ACL_23_P_502", "wnd_id": "ACL_23_P_502-1", "entity_mentions": [{"id": "ACL_23_P_502-1-E0", "text": "We", "start": 0, "end": 1, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_502-1-E1", "text": "We have observed that models trained in this way may \u201cover-generalize\u201d", "start": 0, "end": 11, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_502-1-E2", "text": "in the sense that they produce non-human-like text", "start": 11, "end": 19, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_502-1-E3", "text": "we believe that reverse cross-entropy, i.e., the cross-entropy of P relative to Q, is a better reflection of how a human would evaluate text generated by a model", "start": 20, "end": 48, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_502-1-E4", "text": "learning with MixCE", "start": 51, "end": 54, "entity_type": "UNK", "mention_type": "UNK"}], "relation_mentions": [], "event_mentions": [{"event_type": "Methods/Approach", "id": "ACL_23_P_502-1-EV0", "trigger": {"text": "propose", "start": 50, "end": 51}, "arguments": [{"entity_id": "ACL_23_P_502-1-E0", "text": "We", "role": "Agent"}, {"entity_id": "ACL_23_P_502-1-E1", "text": "We have observed that models trained in this way may \u201cover-generalize\u201d", "role": "Results"}, {"entity_id": "ACL_23_P_502-1-E2", "text": "in the sense that they produce non-human-like text", "role": "Analysis"}, {"entity_id": "ACL_23_P_502-1-E3", "text": "we believe that reverse cross-entropy, i.e., the cross-entropy of P relative to Q, is a better reflection of how a human would evaluate text generated by a model", "role": "Analysis"}, {"entity_id": "ACL_23_P_502-1-E4", "text": "learning with MixCE", "role": "PrimaryObject"}]}], "entity_coreference": [], "event_coreference": [], "tokens": ["We", "have", "observed", "that", "models", "trained", "in", "this", "way", "may", "\u201cover-generalize\u201d,", "in", "the", "sense", "that", "they", "produce", "non-human-like", "text.", "Moreover,", "we", "believe", "that", "reverse", "cross-entropy,", "i.e.,", "the", "cross-entropy", "of", "P", "relative", "to", "Q,", "is", "a", "better", "reflection", "of", "how", "a", "human", "would", "evaluate", "text", "generated", "by", "a", "model.", "Hence,", "we", "propose", "learning", "with", "MixCE,", "an", "objective", "that", "mixes", "the", "forward", "and", "reverse", "cross-entropies."], "pieces": ["We", "have", "ob", "served", "that", "models", "trained", "in", "this", "way", "may", "\u00e2\u0122", "\u013e", "over", "-", "general", "ize", "\u00e2\u0122", "\u013f", ",", "in", "the", "sense", "that", "they", "produ", "ce", "non", "-", "human", "-", "like", "text", ".", "Moreover", ",", "we", "bel", "ieve", "that", "reverse", "cross", "-", "ent", "ropy", ",", "i", ".", "e", ".,", "the", "cross", "-", "ent", "ropy", "of", "P", "relative", "to", "Q", ",", "is", "a", "better", "ref", "lection", "of", "how", "a", "human", "would", "evaluate", "text", "generated", "by", "a", "model", ".", "H", "ence", ",", "we", "pro", "pose", "learning", "with", "Mix", "CE", ",", "an", "object", "ive", "that", "mix", "es", "the", "forward", "and", "reverse", "cross", "-", "ent", "rop", "ies", "."], "token_lens": [1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 9, 1, 1, 1, 1, 1, 2, 5, 2, 2, 1, 2, 1, 1, 5, 4, 1, 4, 1, 1, 1, 1, 2, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 3, 1, 2, 1, 1, 3, 1, 2, 1, 2, 1, 1, 1, 1, 6], "sentence": "We have observed that models trained in this way may \u201cover-generalize\u201d, in the sense that they produce non-human-like text. Moreover, we believe that reverse cross-entropy, i.e., the cross-entropy of P relative to Q, is a better reflection of how a human would evaluate text generated by a model. Hence, we propose learning with MixCE, an objective that mixes the forward and reverse cross-entropies.", "sentence_starts": [0]}
{"doc_id": "ACL_23_P_502", "wnd_id": "ACL_23_P_502-2", "entity_mentions": [{"id": "ACL_23_P_502-2-E0", "text": "We", "start": 0, "end": 1, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_502-2-E1", "text": "the resulting models yield better generated text without complex decoding strategies", "start": 21, "end": 32, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_502-2-E2", "text": "models", "start": 2, "end": 3, "entity_type": "UNK", "mention_type": "UNK"}], "relation_mentions": [], "event_mentions": [{"event_type": "Results/Findings", "id": "ACL_23_P_502-2-EV0", "trigger": {"text": "evaluate", "start": 1, "end": 2}, "arguments": [{"entity_id": "ACL_23_P_502-2-E0", "text": "We", "role": "Agent"}, {"entity_id": "ACL_23_P_502-2-E1", "text": "the resulting models yield better generated text without complex decoding strategies", "role": "Results"}, {"entity_id": "ACL_23_P_502-2-E2", "text": "models", "role": "PrimaryObject"}]}], "entity_coreference": [], "event_coreference": [], "tokens": ["We", "evaluate", "models", "trained", "with", "this", "objective", "on", "synthetic", "data", "settings", "(where", "P", "is", "known)", "and", "real", "data,", "and", "show", "that", "the", "resulting", "models", "yield", "better", "generated", "text", "without", "complex", "decoding", "strategies."], "pieces": ["We", "evaluate", "models", "trained", "with", "this", "object", "ive", "on", "sy", "nt", "hetic", "data", "settings", "(", "where", "P", "is", "known", ")", "and", "real", "data", ",", "and", "show", "that", "the", "result", "ing", "models", "y", "ield", "better", "generated", "text", "without", "complex", "dec", "oding", "str", "ateg", "ies", "."], "token_lens": [1, 1, 1, 1, 1, 1, 2, 1, 3, 1, 1, 2, 1, 1, 2, 1, 1, 2, 1, 1, 1, 1, 2, 1, 2, 1, 1, 1, 1, 1, 2, 4], "sentence": "We evaluate models trained with this objective on synthetic data settings (where P is known) and real data, and show that the resulting models yield better generated text without complex decoding strategies.", "sentence_starts": [0]}
{"doc_id": "ACL_23_P_314", "wnd_id": "ACL_23_P_314-0", "entity_mentions": [{"id": "ACL_23_P_314-0-E0", "text": "current work", "start": 43, "end": 45, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_314-0-E1", "text": "Massively multilingual language models have displayed strong performance in zero-shot (ZS-XLT) and few-shot (FS-XLT) cross-lingual transfer setups", "start": 0, "end": 17, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_314-0-E2", "text": "models fine-tuned on task data in a source language are transferred without any or with only a few annotated instances to the target language(s)", "start": 18, "end": 42, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_314-0-E3", "text": "Such XLT setups require robust methods that do not depend on labeled target language data for validation and model selection", "start": 79, "end": 99, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_314-0-E4", "text": "This effectively violates the main assumptions of \u2018true\u2019 ZS-XLT and FS-XLT", "start": 68, "end": 79, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_314-0-E5", "text": "model performance", "start": 47, "end": 49, "entity_type": "UNK", "mention_type": "UNK"}], "relation_mentions": [], "event_mentions": [{"event_type": "Background/Introduction", "id": "ACL_23_P_314-0-EV0", "trigger": {"text": "typically overestimates", "start": 45, "end": 47}, "arguments": [{"entity_id": "ACL_23_P_314-0-E0", "text": "current work", "role": "Agent"}, {"entity_id": "ACL_23_P_314-0-E1", "text": "Massively multilingual language models have displayed strong performance in zero-shot (ZS-XLT) and few-shot (FS-XLT) cross-lingual transfer setups", "role": "Context"}, {"entity_id": "ACL_23_P_314-0-E2", "text": "models fine-tuned on task data in a source language are transferred without any or with only a few annotated instances to the target language(s)", "role": "Context"}, {"entity_id": "ACL_23_P_314-0-E3", "text": "Such XLT setups require robust methods that do not depend on labeled target language data for validation and model selection", "role": "Context"}, {"entity_id": "ACL_23_P_314-0-E4", "text": "This effectively violates the main assumptions of \u2018true\u2019 ZS-XLT and FS-XLT", "role": "Challenge"}, {"entity_id": "ACL_23_P_314-0-E5", "text": "model performance", "role": "PrimaryObject"}]}], "entity_coreference": [], "event_coreference": [], "tokens": ["Massively", "multilingual", "language", "models", "have", "displayed", "strong", "performance", "in", "zero-shot", "(ZS-XLT)", "and", "few-shot", "(FS-XLT)", "cross-lingual", "transfer", "setups,", "where", "models", "fine-tuned", "on", "task", "data", "in", "a", "source", "language", "are", "transferred", "without", "any", "or", "with", "only", "a", "few", "annotated", "instances", "to", "the", "target", "language(s).", "However,", "current", "work", "typically", "overestimates", "model", "performance", "as", "fine-tuned", "models", "are", "frequently", "evaluated", "at", "model", "checkpoints", "that", "generalize", "best", "to", "validation", "instances", "in", "the", "target", "languages.", "This", "effectively", "violates", "the", "main", "assumptions", "of", "\u2018true\u2019", "ZS-XLT", "and", "FS-XLT.", "Such", "XLT", "setups", "require", "robust", "methods", "that", "do", "not", "depend", "on", "labeled", "target", "language", "data", "for", "validation", "and", "model", "selection."], "pieces": ["Mass", "ively", "mult", "ilingual", "language", "models", "have", "display", "ed", "strong", "performance", "in", "zero", "-", "shot", "(", "Z", "S", "-", "X", "LT", ")", "and", "few", "-", "shot", "(", "FS", "-", "X", "LT", ")", "cross", "-", "ling", "ual", "transfer", "set", "ups", ",", "where", "models", "fine", "-", "tun", "ed", "on", "task", "data", "in", "a", "source", "language", "are", "trans", "ferred", "without", "any", "or", "with", "only", "a", "few", "annot", "ated", "inst", "ances", "to", "the", "target", "language", "(", "s", ").", "However", ",", "current", "work", "typically", "ove", "rest", "imates", "model", "performance", "as", "fine", "-", "tun", "ed", "models", "are", "f", "requently", "eval", "uated", "at", "model", "check", "points", "that", "general", "ize", "best", "to", "valid", "ation", "inst", "ances", "in", "the", "target", "l", "anguages", ".", "This", "effect", "ively", "viol", "ates", "the", "main", "ass", "um", "ptions", "of", "\u00e2\u0122", "\u013a", "true", "\u00e2\u0122", "\u013b", "Z", "S", "-", "X", "LT", "and", "FS", "-", "X", "LT", ".", "Such", "X", "LT", "set", "ups", "require", "rob", "ust", "method", "s", "that", "do", "not", "depend", "on", "label", "ed", "target", "language", "data", "for", "valid", "ation", "and", "model", "selection", "."], "token_lens": [2, 2, 1, 1, 1, 2, 1, 1, 1, 3, 7, 1, 3, 6, 4, 1, 3, 1, 1, 4, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 2, 2, 1, 1, 1, 4, 2, 1, 1, 1, 3, 1, 1, 1, 4, 1, 1, 2, 2, 1, 1, 2, 1, 2, 1, 1, 2, 2, 1, 1, 1, 3, 1, 2, 2, 1, 1, 3, 1, 5, 5, 1, 5, 1, 2, 2, 1, 2, 2, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 2, 1, 1, 2], "sentence": "Massively multilingual language models have displayed strong performance in zero-shot (ZS-XLT) and few-shot (FS-XLT) cross-lingual transfer setups, where models fine-tuned on task data in a source language are transferred without any or with only a few annotated instances to the target language(s). However, current work typically overestimates model performance as fine-tuned models are frequently evaluated at model checkpoints that generalize best to validation instances in the target languages. This effectively violates the main assumptions of \u2018true\u2019 ZS-XLT and FS-XLT. Such XLT setups require robust methods that do not depend on labeled target language data for validation and model selection.", "sentence_starts": [0]}
{"doc_id": "ACL_23_P_314", "wnd_id": "ACL_23_P_314-1", "entity_mentions": [{"id": "ACL_23_P_314-1-E0", "text": "we", "start": 13, "end": 14, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_314-1-E1", "text": "aiming to improve the robustness of \u2018true\u2019 ZS-XLT and FS-XLT,", "start": 3, "end": 13, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_314-1-E2", "text": "We conduct exhaustive ZS-XLT and FS-XLT experiments across higher-level semantic tasks (NLI, extractive QA) and lower-level token classification tasks (NER, POS)", "start": 30, "end": 51, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_314-1-E3", "text": "a simple and effective method", "start": 15, "end": 20, "entity_type": "UNK", "mention_type": "UNK"}], "relation_mentions": [], "event_mentions": [{"event_type": "Methods/Approach", "id": "ACL_23_P_314-1-EV0", "trigger": {"text": "propose", "start": 14, "end": 15}, "arguments": [{"entity_id": "ACL_23_P_314-1-E0", "text": "we", "role": "Agent"}, {"entity_id": "ACL_23_P_314-1-E1", "text": "aiming to improve the robustness of \u2018true\u2019 ZS-XLT and FS-XLT,", "role": "Purpose"}, {"entity_id": "ACL_23_P_314-1-E2", "text": "We conduct exhaustive ZS-XLT and FS-XLT experiments across higher-level semantic tasks (NLI, extractive QA) and lower-level token classification tasks (NER, POS)", "role": "Method"}, {"entity_id": "ACL_23_P_314-1-E3", "text": "a simple and effective method", "role": "PrimaryObject"}]}], "entity_coreference": [], "event_coreference": [], "tokens": ["In", "this", "work,", "aiming", "to", "improve", "the", "robustness", "of", "\u2018true\u2019", "ZS-XLT", "and", "FS-XLT,", "we", "propose", "a", "simple", "and", "effective", "method", "that", "averages", "different", "checkpoints", "(i.e.,", "model", "snapshots)", "during", "task", "fine-tuning.", "We", "conduct", "exhaustive", "ZS-XLT", "and", "FS-XLT", "experiments", "across", "higher-level", "semantic", "tasks", "(NLI,", "extractive", "QA)", "and", "lower-level", "token", "classification", "tasks", "(NER,", "POS)."], "pieces": ["In", "this", "work", ",", "aim", "ing", "to", "improve", "the", "rob", "ust", "ness", "of", "\u00e2\u0122", "\u013a", "true", "\u00e2\u0122", "\u013b", "Z", "S", "-", "X", "LT", "and", "FS", "-", "X", "LT", ",", "we", "pro", "pose", "a", "simple", "and", "effective", "method", "that", "aver", "ages", "different", "check", "points", "(", "i", ".", "e", ".,", "model", "snap", "shots", ")", "during", "task", "fine", "-", "tun", "ing", ".", "We", "conduct", "ex", "haust", "ive", "Z", "S", "-", "X", "LT", "and", "FS", "-", "X", "LT", "exper", "iments", "ac", "ross", "higher", "-", "level", "sem", "antic", "t", "asks", "(", "N", "LI", ",", "ext", "ractive", "Q", "A", ")", "and", "lower", "-", "level", "token", "class", "ification", "t", "asks", "(", "NER", ",", "POS", ")."], "token_lens": [1, 1, 2, 2, 1, 1, 1, 3, 1, 5, 5, 1, 5, 1, 2, 1, 1, 1, 1, 1, 1, 2, 1, 2, 5, 1, 3, 1, 1, 5, 1, 1, 3, 5, 1, 4, 2, 2, 3, 2, 2, 4, 2, 3, 1, 3, 1, 2, 2, 3, 2], "sentence": "In this work, aiming to improve the robustness of \u2018true\u2019 ZS-XLT and FS-XLT, we propose a simple and effective method that averages different checkpoints (i.e., model snapshots) during task fine-tuning. We conduct exhaustive ZS-XLT and FS-XLT experiments across higher-level semantic tasks (NLI, extractive QA) and lower-level token classification tasks (NER, POS).", "sentence_starts": [0]}
{"doc_id": "ACL_23_P_314", "wnd_id": "ACL_23_P_314-2", "entity_mentions": [{"id": "ACL_23_P_314-2-E0", "text": "We", "start": 37, "end": 38, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_314-2-E1", "text": "The results indicate that averaging model checkpoints yields systematic and consistent performance gains across diverse target languages in all tasks", "start": 0, "end": 20, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_314-2-E2", "text": "it simultaneously substantially desensitizes XLT to varying hyperparameter choices in the absence of target language validation", "start": 21, "end": 37, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_314-2-E3", "text": "checkpoint averaging benefits performance", "start": 41, "end": 45, "entity_type": "UNK", "mention_type": "UNK"}], "relation_mentions": [], "event_mentions": [{"event_type": "Results/Findings", "id": "ACL_23_P_314-2-EV0", "trigger": {"text": "show", "start": 39, "end": 40}, "arguments": [{"entity_id": "ACL_23_P_314-2-E0", "text": "We", "role": "Agent"}, {"entity_id": "ACL_23_P_314-2-E1", "text": "The results indicate that averaging model checkpoints yields systematic and consistent performance gains across diverse target languages in all tasks", "role": "Results"}, {"entity_id": "ACL_23_P_314-2-E2", "text": "it simultaneously substantially desensitizes XLT to varying hyperparameter choices in the absence of target language validation", "role": "Results"}, {"entity_id": "ACL_23_P_314-2-E3", "text": "checkpoint averaging benefits performance", "role": "PrimaryObject"}]}], "entity_coreference": [], "event_coreference": [], "tokens": ["The", "results", "indicate", "that", "averaging", "model", "checkpoints", "yields", "systematic", "and", "consistent", "performance", "gains", "across", "diverse", "target", "languages", "in", "all", "tasks.", "Importantly,", "it", "simultaneously", "substantially", "desensitizes", "XLT", "to", "varying", "hyperparameter", "choices", "in", "the", "absence", "of", "target", "language", "validation.", "We", "also", "show", "that", "checkpoint", "averaging", "benefits", "performance", "when", "further", "combined", "with", "run", "averaging", "(i.e.,", "averaging", "the", "parameters", "of", "models", "fine-tuned", "over", "independent", "runs)."], "pieces": ["The", "results", "ind", "icate", "that", "aver", "aging", "model", "check", "points", "y", "ield", "s", "system", "atic", "and", "cons", "istent", "performance", "g", "ains", "ac", "ross", "d", "iverse", "target", "l", "anguages", "in", "all", "t", "asks", ".", "Import", "antly", ",", "it", "sim", "ultane", "ously", "sub", "stant", "ially", "des", "ens", "itiz", "es", "X", "LT", "to", "v", "ary", "ing", "hyper", "param", "eter", "cho", "ices", "in", "the", "abs", "ence", "of", "target", "language", "valid", "ation", ".", "We", "also", "show", "that", "check", "point", "aver", "aging", "benef", "its", "performance", "when", "f", "urther", "comb", "ined", "with", "run", "aver", "aging", "(", "i", ".", "e", ".,", "aver", "aging", "the", "param", "eters", "of", "models", "fine", "-", "tun", "ed", "over", "independent", "runs", ")."], "token_lens": [1, 1, 2, 1, 2, 1, 2, 3, 2, 1, 2, 1, 2, 2, 2, 1, 2, 1, 1, 3, 3, 1, 3, 3, 4, 2, 1, 3, 3, 2, 1, 1, 2, 1, 1, 1, 3, 1, 1, 1, 1, 2, 2, 2, 1, 1, 2, 2, 1, 1, 2, 5, 2, 1, 2, 1, 1, 4, 1, 1, 2], "sentence": "The results indicate that averaging model checkpoints yields systematic and consistent performance gains across diverse target languages in all tasks. Importantly, it simultaneously substantially desensitizes XLT to varying hyperparameter choices in the absence of target language validation. We also show that checkpoint averaging benefits performance when further combined with run averaging (i.e., averaging the parameters of models fine-tuned over independent runs).", "sentence_starts": [0]}
{"doc_id": "ACL_23_P_96", "wnd_id": "ACL_23_P_96-0", "entity_mentions": [{"id": "ACL_23_P_96-0-E0", "text": "Emotional support conversation (ESC)", "start": 0, "end": 4, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_96-0-E1", "text": "Existing works stay at fitting grounded responses and responding strategies (e.g., question)", "start": 15, "end": 27, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_96-0-E2", "text": "ignore the effect on ES and lack explicit goals to guide emotional positive transition", "start": 28, "end": 42, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_96-0-E3", "text": "emotional support (ES)", "start": 7, "end": 10, "entity_type": "UNK", "mention_type": "UNK"}], "relation_mentions": [], "event_mentions": [{"event_type": "Background/Introduction", "id": "ACL_23_P_96-0-EV0", "trigger": {"text": "aims to provide", "start": 4, "end": 7}, "arguments": [{"entity_id": "ACL_23_P_96-0-E0", "text": "Emotional support conversation (ESC)", "role": "Agent"}, {"entity_id": "ACL_23_P_96-0-E1", "text": "Existing works stay at fitting grounded responses and responding strategies (e.g., question)", "role": "Context"}, {"entity_id": "ACL_23_P_96-0-E2", "text": "ignore the effect on ES and lack explicit goals to guide emotional positive transition", "role": "Challenge"}, {"entity_id": "ACL_23_P_96-0-E3", "text": "emotional support (ES)", "role": "PrimaryObject"}]}], "entity_coreference": [], "event_coreference": [], "tokens": ["Emotional", "support", "conversation", "(ESC)", "aims", "to", "provide", "emotional", "support", "(ES)", "to", "improve", "one\u2019s", "mental", "state.", "Existing", "works", "stay", "at", "fitting", "grounded", "responses", "and", "responding", "strategies", "(e.g.,", "question),", "which", "ignore", "the", "effect", "on", "ES", "and", "lack", "explicit", "goals", "to", "guide", "emotional", "positive", "transition."], "pieces": ["Em", "otional", "support", "con", "vers", "ation", "(", "ES", "C", ")", "aim", "s", "to", "prov", "ide", "em", "otional", "support", "(", "ES", ")", "to", "improve", "one", "\u00e2\u0122", "\u013b", "s", "mental", "state", ".", "Ex", "isting", "works", "stay", "at", "fitting", "ground", "ed", "respons", "es", "and", "respond", "ing", "str", "ateg", "ies", "(", "e", ".", "g", ".,", "question", "),", "which", "ignore", "the", "effect", "on", "ES", "and", "l", "ack", "expl", "icit", "go", "als", "to", "guide", "em", "otional", "positive", "trans", "ition", "."], "token_lens": [2, 1, 3, 4, 2, 1, 2, 2, 1, 3, 1, 1, 4, 1, 2, 2, 1, 1, 1, 1, 2, 2, 1, 2, 3, 5, 2, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 1, 1, 2, 1, 3], "sentence": "Emotional support conversation (ESC) aims to provide emotional support (ES) to improve one\u2019s mental state. Existing works stay at fitting grounded responses and responding strategies (e.g., question), which ignore the effect on ES and lack explicit goals to guide emotional positive transition.", "sentence_starts": [0]}
{"doc_id": "ACL_23_P_96", "wnd_id": "ACL_23_P_96-1", "entity_mentions": [{"id": "ACL_23_P_96-1-E0", "text": "we", "start": 3, "end": 4, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_96-1-E1", "text": "Addressing this task requires finely adjusting the elicitation intensity in ES as the conversation progresses while maintaining conversational goals like coherence", "start": 19, "end": 40, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_96-1-E2", "text": "we propose Supporter, a mixture-of-expert-based reinforcement learning model, and well design ES and dialogue coherence rewards to guide policy\u2019s learning for responding", "start": 43, "end": 65, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_96-1-E3", "text": "a new paradigm", "start": 5, "end": 8, "entity_type": "UNK", "mention_type": "UNK"}], "relation_mentions": [], "event_mentions": [{"event_type": "Methods/Approach", "id": "ACL_23_P_96-1-EV0", "trigger": {"text": "introduce", "start": 4, "end": 5}, "arguments": [{"entity_id": "ACL_23_P_96-1-E0", "text": "we", "role": "Agent"}, {"entity_id": "ACL_23_P_96-1-E1", "text": "Addressing this task requires finely adjusting the elicitation intensity in ES as the conversation progresses while maintaining conversational goals like coherence", "role": "Method"}, {"entity_id": "ACL_23_P_96-1-E2", "text": "we propose Supporter, a mixture-of-expert-based reinforcement learning model, and well design ES and dialogue coherence rewards to guide policy\u2019s learning for responding", "role": "Method"}, {"entity_id": "ACL_23_P_96-1-E3", "text": "a new paradigm", "role": "PrimaryObject"}]}], "entity_coreference": [], "event_coreference": [], "tokens": ["To", "this", "end,", "we", "introduce", "a", "new", "paradigm", "to", "formalize", "multi-turn", "ESC", "as", "a", "process", "of", "positive", "emotion", "elicitation.", "Addressing", "this", "task", "requires", "finely", "adjusting", "the", "elicitation", "intensity", "in", "ES", "as", "the", "conversation", "progresses", "while", "maintaining", "conversational", "goals", "like", "coherence.", "In", "this", "paper,", "we", "propose", "Supporter,", "a", "mixture-of-expert-based", "reinforcement", "learning", "model,", "and", "well", "design", "ES", "and", "dialogue", "coherence", "rewards", "to", "guide", "policy\u2019s", "learning", "for", "responding."], "pieces": ["To", "this", "end", ",", "we", "introdu", "ce", "a", "new", "par", "ad", "igm", "to", "form", "al", "ize", "multi", "-", "turn", "ES", "C", "as", "a", "process", "of", "positive", "em", "otion", "el", "icit", "ation", ".", "Add", "ressing", "this", "task", "requires", "fine", "ly", "adjust", "ing", "the", "el", "icit", "ation", "intensity", "in", "ES", "as", "the", "con", "vers", "ation", "progress", "es", "while", "m", "aint", "aining", "con", "vers", "ational", "go", "als", "like", "co", "herence", ".", "In", "this", "paper", ",", "we", "pro", "pose", "Supp", "orter", ",", "a", "m", "ixture", "-", "of", "-", "ex", "pert", "-", "based", "re", "in", "forcement", "learning", "model", ",", "and", "well", "design", "ES", "and", "dial", "ogue", "co", "herence", "re", "wards", "to", "guide", "policy", "\u00e2\u0122", "\u013b", "s", "learning", "for", "respond", "ing", "."], "token_lens": [1, 1, 2, 1, 2, 1, 1, 3, 1, 3, 3, 2, 1, 1, 1, 1, 1, 2, 4, 2, 1, 1, 1, 2, 2, 1, 3, 1, 1, 1, 1, 1, 3, 2, 1, 3, 3, 2, 1, 3, 1, 1, 2, 1, 2, 3, 1, 9, 3, 1, 2, 1, 1, 1, 1, 1, 2, 2, 2, 1, 1, 4, 1, 1, 3], "sentence": "To this end, we introduce a new paradigm to formalize multi-turn ESC as a process of positive emotion elicitation. Addressing this task requires finely adjusting the elicitation intensity in ES as the conversation progresses while maintaining conversational goals like coherence. In this paper, we propose Supporter, a mixture-of-expert-based reinforcement learning model, and well design ES and dialogue coherence rewards to guide policy\u2019s learning for responding.", "sentence_starts": [0]}
{"doc_id": "ACL_23_P_96", "wnd_id": "ACL_23_P_96-2", "entity_mentions": [{"id": "ACL_23_P_96-2-E0", "text": "Experiments", "start": 0, "end": 1, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_96-2-E1", "text": "the superiority", "start": 2, "end": 4, "entity_type": "UNK", "mention_type": "UNK"}], "relation_mentions": [], "event_mentions": [{"event_type": "Results/Findings", "id": "ACL_23_P_96-2-EV0", "trigger": {"text": "verify", "start": 1, "end": 2}, "arguments": [{"entity_id": "ACL_23_P_96-2-E0", "text": "Experiments", "role": "Agent"}, {"entity_id": "ACL_23_P_96-2-E1", "text": "the superiority", "role": "PrimaryObject"}]}], "entity_coreference": [], "event_coreference": [], "tokens": ["Experiments", "verify", "the", "superiority", "of", "Supporter", "in", "achieving", "positive", "emotion", "elicitation", "during", "responding", "while", "maintaining", "conversational", "goals", "including", "coherence."], "pieces": ["Exper", "iments", "ver", "ify", "the", "super", "ior", "ity", "of", "Supp", "orter", "in", "ach", "ieving", "positive", "em", "otion", "el", "icit", "ation", "during", "respond", "ing", "while", "m", "aint", "aining", "con", "vers", "ational", "go", "als", "including", "co", "herence", "."], "token_lens": [2, 2, 1, 3, 1, 2, 1, 2, 1, 2, 3, 1, 2, 1, 3, 3, 2, 1, 3], "sentence": "Experiments verify the superiority of Supporter in achieving positive emotion elicitation during responding while maintaining conversational goals including coherence.", "sentence_starts": [0]}
{"doc_id": "ACL_23_P_211", "wnd_id": "ACL_23_P_211-0", "entity_mentions": [{"id": "ACL_23_P_211-0-E0", "text": "Multilingual neural machine translation", "start": 0, "end": 4, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_211-0-E1", "text": "The set of all Pareto optimal solutions forms a Pareto frontier.", "start": 86, "end": 97, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_211-0-E2", "text": "Existing balancing training strategies are equivalent to a series of Pareto optimal solutions, which trade off on a Pareto frontierIn Pareto optimization, Pareto optimal solutions refer to solutions in which none of the objectives can be improved without sacrificing at least one of the other objectives", "start": 40, "end": 86, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_211-0-E3", "text": "the long-tailed distribution of multilingual corpora poses a challenge of Pareto optimization", "start": 12, "end": 24, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_211-0-E4", "text": "optimizing for some languages may come at the cost of degrading the performance of others", "start": 25, "end": 40, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_211-0-E5", "text": "remarkable progress", "start": 6, "end": 8, "entity_type": "UNK", "mention_type": "UNK"}], "relation_mentions": [], "event_mentions": [{"event_type": "Background/Introduction", "id": "ACL_23_P_211-0-EV0", "trigger": {"text": "has witnessed", "start": 4, "end": 6}, "arguments": [{"entity_id": "ACL_23_P_211-0-E0", "text": "Multilingual neural machine translation", "role": "Agent"}, {"entity_id": "ACL_23_P_211-0-E1", "text": "The set of all Pareto optimal solutions forms a Pareto frontier.", "role": "Context"}, {"entity_id": "ACL_23_P_211-0-E2", "text": "Existing balancing training strategies are equivalent to a series of Pareto optimal solutions, which trade off on a Pareto frontierIn Pareto optimization, Pareto optimal solutions refer to solutions in which none of the objectives can be improved without sacrificing at least one of the other objectives", "role": "Context"}, {"entity_id": "ACL_23_P_211-0-E3", "text": "the long-tailed distribution of multilingual corpora poses a challenge of Pareto optimization", "role": "Challenge"}, {"entity_id": "ACL_23_P_211-0-E4", "text": "optimizing for some languages may come at the cost of degrading the performance of others", "role": "Challenge"}, {"entity_id": "ACL_23_P_211-0-E5", "text": "remarkable progress", "role": "PrimaryObject"}]}], "entity_coreference": [], "event_coreference": [], "tokens": ["Multilingual", "neural", "machine", "translation", "has", "witnessed", "remarkable", "progress", "in", "recent", "years.", "However,", "the", "long-tailed", "distribution", "of", "multilingual", "corpora", "poses", "a", "challenge", "of", "Pareto", "optimization,", "i.e.,", "optimizing", "for", "some", "languages", "may", "come", "at", "the", "cost", "of", "degrading", "the", "performance", "of", "others.", "Existing", "balancing", "training", "strategies", "are", "equivalent", "to", "a", "series", "of", "Pareto", "optimal", "solutions,", "which", "trade", "off", "on", "a", "Pareto", "frontierIn", "Pareto", "optimization,", "Pareto", "optimal", "solutions", "refer", "to", "solutions", "in", "which", "none", "of", "the", "objectives", "can", "be", "improved", "without", "sacrificing", "at", "least", "one", "of", "the", "other", "objectives.", "The", "set", "of", "all", "Pareto", "optimal", "solutions", "forms", "a", "Pareto", "frontier."], "pieces": ["Mult", "ilingual", "ne", "ural", "machine", "translation", "has", "w", "itness", "ed", "rem", "arkable", "progress", "in", "recent", "years", ".", "However", ",", "the", "long", "-", "tailed", "dist", "ribution", "of", "mult", "ilingual", "cor", "pora", "poses", "a", "chall", "enge", "of", "P", "are", "to", "optim", "ization", ",", "i", ".", "e", ".,", "optim", "izing", "for", "some", "l", "anguages", "may", "come", "at", "the", "cost", "of", "deg", "r", "ading", "the", "performance", "of", "other", "s", ".", "Ex", "isting", "bal", "ancing", "training", "str", "ateg", "ies", "are", "equ", "ivalent", "to", "a", "series", "of", "P", "are", "to", "opt", "imal", "s", "olutions", ",", "which", "trade", "off", "on", "a", "P", "are", "to", "front", "ier", "In", "P", "are", "to", "optim", "ization", ",", "P", "are", "to", "opt", "imal", "s", "olutions", "re", "fer", "to", "s", "olutions", "in", "which", "none", "of", "the", "object", "ives", "can", "be", "impro", "ved", "without", "sac", "r", "ific", "ing", "at", "le", "ast", "one", "of", "the", "other", "object", "ives", ".", "The", "set", "of", "all", "P", "are", "to", "opt", "imal", "s", "olutions", "forms", "a", "P", "are", "to", "front", "ier", "."], "token_lens": [2, 2, 1, 1, 1, 3, 2, 1, 1, 1, 2, 2, 1, 3, 2, 1, 2, 2, 1, 1, 2, 1, 3, 3, 4, 2, 1, 1, 2, 1, 1, 1, 1, 1, 1, 3, 1, 1, 1, 3, 2, 2, 1, 3, 1, 2, 1, 1, 1, 1, 3, 2, 3, 1, 1, 1, 1, 1, 3, 3, 3, 3, 3, 2, 2, 2, 1, 2, 1, 1, 1, 1, 1, 2, 1, 1, 2, 1, 4, 1, 2, 1, 1, 1, 1, 3, 1, 1, 1, 1, 3, 2, 2, 1, 1, 3, 3], "sentence": "Multilingual neural machine translation has witnessed remarkable progress in recent years. However, the long-tailed distribution of multilingual corpora poses a challenge of Pareto optimization, i.e., optimizing for some languages may come at the cost of degrading the performance of others. Existing balancing training strategies are equivalent to a series of Pareto optimal solutions, which trade off on a Pareto frontierIn Pareto optimization, Pareto optimal solutions refer to solutions in which none of the objectives can be improved without sacrificing at least one of the other objectives. The set of all Pareto optimal solutions forms a Pareto frontier.", "sentence_starts": [0]}
{"doc_id": "ACL_23_P_211", "wnd_id": "ACL_23_P_211-1", "entity_mentions": [{"id": "ACL_23_P_211-1-E0", "text": "we", "start": 3, "end": 4, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_211-1-E1", "text": "we introduce a novel strategy to enable stronger communication between Pareto optimal solutions and broaden the applicability of our approach.", "start": 50, "end": 70, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_211-1-E2", "text": "Pareto-MD collaboratively trains two Pareto optimal solutions that favor different languages and allows them to learn from the strengths of each other via knowledge distillation", "start": 24, "end": 49, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_211-1-E3", "text": "a new training framework", "start": 5, "end": 9, "entity_type": "UNK", "mention_type": "UNK"}], "relation_mentions": [], "event_mentions": [{"event_type": "Methods/Approach", "id": "ACL_23_P_211-1-EV0", "trigger": {"text": "propose", "start": 4, "end": 5}, "arguments": [{"entity_id": "ACL_23_P_211-1-E0", "text": "we", "role": "Agent"}, {"entity_id": "ACL_23_P_211-1-E1", "text": "we introduce a novel strategy to enable stronger communication between Pareto optimal solutions and broaden the applicability of our approach.", "role": "Purpose"}, {"entity_id": "ACL_23_P_211-1-E2", "text": "Pareto-MD collaboratively trains two Pareto optimal solutions that favor different languages and allows them to learn from the strengths of each other via knowledge distillation", "role": "Method"}, {"entity_id": "ACL_23_P_211-1-E3", "text": "a new training framework", "role": "PrimaryObject"}]}], "entity_coreference": [], "event_coreference": [], "tokens": ["In", "this", "work,", "we", "propose", "a", "new", "training", "framework,", "Pareto", "Mutual", "Distillation", "(Pareto-MD),", "towards", "pushing", "the", "Pareto", "frontier", "outwards", "rather", "than", "making", "trade-offs.", "Specifically,", "Pareto-MD", "collaboratively", "trains", "two", "Pareto", "optimal", "solutions", "that", "favor", "different", "languages", "and", "allows", "them", "to", "learn", "from", "the", "strengths", "of", "each", "other", "via", "knowledge", "distillation.", "Furthermore,", "we", "introduce", "a", "novel", "strategy", "to", "enable", "stronger", "communication", "between", "Pareto", "optimal", "solutions", "and", "broaden", "the", "applicability", "of", "our", "approach."], "pieces": ["In", "this", "work", ",", "we", "pro", "pose", "a", "new", "training", "framework", ",", "P", "are", "to", "Mut", "ual", "Dist", "illation", "(", "P", "are", "to", "-", "MD", "),", "t", "ow", "ards", "p", "ushing", "the", "P", "are", "to", "front", "ier", "out", "wards", "rather", "than", "making", "trade", "-", "offs", ".", "Specifically", ",", "P", "are", "to", "-", "MD", "coll", "abor", "atively", "tr", "ains", "two", "P", "are", "to", "opt", "imal", "s", "olutions", "that", "f", "avor", "different", "l", "anguages", "and", "allows", "them", "to", "learn", "from", "the", "stre", "ng", "ths", "of", "each", "other", "via", "knowledge", "dist", "illation", ".", "Furthermore", ",", "we", "introdu", "ce", "a", "no", "vel", "str", "ategy", "to", "enable", "strong", "er", "communication", "between", "P", "are", "to", "opt", "imal", "s", "olutions", "and", "broad", "en", "the", "app", "lic", "ability", "of", "our", "appro", "ach", "."], "token_lens": [1, 1, 2, 1, 2, 1, 1, 1, 2, 3, 2, 2, 7, 3, 2, 1, 3, 2, 2, 1, 1, 1, 4, 2, 5, 3, 2, 1, 3, 2, 2, 1, 2, 1, 2, 1, 1, 1, 1, 1, 1, 1, 3, 1, 1, 1, 1, 1, 3, 2, 1, 2, 1, 2, 2, 1, 1, 2, 1, 1, 3, 2, 2, 1, 2, 1, 3, 1, 1, 3], "sentence": "In this work, we propose a new training framework, Pareto Mutual Distillation (Pareto-MD), towards pushing the Pareto frontier outwards rather than making trade-offs. Specifically, Pareto-MD collaboratively trains two Pareto optimal solutions that favor different languages and allows them to learn from the strengths of each other via knowledge distillation. Furthermore, we introduce a novel strategy to enable stronger communication between Pareto optimal solutions and broaden the applicability of our approach.", "sentence_starts": [0]}
{"doc_id": "ACL_23_P_211", "wnd_id": "ACL_23_P_211-2", "entity_mentions": [{"id": "ACL_23_P_211-2-E0", "text": "Experimental results on the widely-used WMT and TED datasets", "start": 0, "end": 9, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_211-2-E1", "text": "our method significantly pushes the Pareto frontier and outperforms baselines by up to +2.46 BLEU", "start": 11, "end": 26, "entity_type": "UNK", "mention_type": "UNK"}], "relation_mentions": [], "event_mentions": [{"event_type": "Results/Findings", "id": "ACL_23_P_211-2-EV0", "trigger": {"text": "show", "start": 9, "end": 10}, "arguments": [{"entity_id": "ACL_23_P_211-2-E0", "text": "Experimental results on the widely-used WMT and TED datasets", "role": "Agent"}, {"entity_id": "ACL_23_P_211-2-E1", "text": "our method significantly pushes the Pareto frontier and outperforms baselines by up to +2.46 BLEU", "role": "PrimaryObject"}]}], "entity_coreference": [], "event_coreference": [], "tokens": ["Experimental", "results", "on", "the", "widely-used", "WMT", "and", "TED", "datasets", "show", "that", "our", "method", "significantly", "pushes", "the", "Pareto", "frontier", "and", "outperforms", "baselines", "by", "up", "to", "+2.46", "BLEU."], "pieces": ["Exper", "imental", "results", "on", "the", "wide", "ly", "-", "used", "W", "MT", "and", "TED", "dat", "as", "ets", "show", "that", "our", "method", "sign", "ificantly", "p", "ushes", "the", "P", "are", "to", "front", "ier", "and", "out", "per", "forms", "bas", "elines", "by", "up", "to", "+", "2", ".", "46", "BLE", "U", "."], "token_lens": [2, 1, 1, 1, 4, 2, 1, 1, 3, 1, 1, 1, 1, 2, 2, 1, 3, 2, 1, 3, 2, 1, 1, 1, 4, 3], "sentence": "Experimental results on the widely-used WMT and TED datasets show that our method significantly pushes the Pareto frontier and outperforms baselines by up to +2.46 BLEU.", "sentence_starts": [0]}
{"doc_id": "ACL_23_P_367", "wnd_id": "ACL_23_P_367-0", "entity_mentions": [{"id": "ACL_23_P_367-0-E0", "text": "pretrained language models (PLMs)", "start": 1, "end": 5, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_367-0-E1", "text": "it remains an open question how much this ability comes from generalizable linguistic understanding versus surface-level lexical patterns.", "start": 16, "end": 34, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_367-0-E2", "text": "a wide range of language tasks", "start": 10, "end": 16, "entity_type": "UNK", "mention_type": "UNK"}], "relation_mentions": [], "event_mentions": [{"event_type": "Background/Introduction", "id": "ACL_23_P_367-0-EV0", "trigger": {"text": "can be prompted to perform", "start": 5, "end": 10}, "arguments": [{"entity_id": "ACL_23_P_367-0-E0", "text": "pretrained language models (PLMs)", "role": "Agent"}, {"entity_id": "ACL_23_P_367-0-E1", "text": "it remains an open question how much this ability comes from generalizable linguistic understanding versus surface-level lexical patterns.", "role": "Challenge"}, {"entity_id": "ACL_23_P_367-0-E2", "text": "a wide range of language tasks", "role": "PrimaryObject"}]}], "entity_coreference": [], "event_coreference": [], "tokens": ["Although", "pretrained", "language", "models", "(PLMs)", "can", "be", "prompted", "to", "perform", "a", "wide", "range", "of", "language", "tasks,", "it", "remains", "an", "open", "question", "how", "much", "this", "ability", "comes", "from", "generalizable", "linguistic", "understanding", "versus", "surface-level", "lexical", "patterns."], "pieces": ["Although", "pret", "rained", "language", "models", "(", "PL", "Ms", ")", "can", "be", "prom", "pt", "ed", "to", "per", "form", "a", "wide", "range", "of", "language", "t", "asks", ",", "it", "rem", "ains", "an", "open", "question", "how", "much", "this", "ability", "comes", "from", "general", "izable", "ling", "u", "istic", "under", "standing", "vers", "us", "surface", "-", "level", "lex", "ical", "pattern", "s", "."], "token_lens": [1, 2, 1, 1, 4, 1, 1, 3, 1, 2, 1, 1, 1, 1, 1, 3, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 3, 2, 2, 3, 2, 3], "sentence": "Although pretrained language models (PLMs) can be prompted to perform a wide range of language tasks, it remains an open question how much this ability comes from generalizable linguistic understanding versus surface-level lexical patterns.", "sentence_starts": [0]}
{"doc_id": "ACL_23_P_367", "wnd_id": "ACL_23_P_367-1", "entity_mentions": [{"id": "ACL_23_P_367-1-E0", "text": "we", "start": 3, "end": 4, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_367-1-E1", "text": "perform zero- and few-shot sequence tagging with autoregressive PLMs", "start": 17, "end": 26, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_367-1-E2", "text": "We evaluate this approach on part-of-speech tagging, named entity recognition, and sentence chunking,", "start": 26, "end": 39, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_367-1-E3", "text": "strong few-shot performance in all cases.", "start": 40, "end": 46, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_367-1-E4", "text": "a structured prompting approach", "start": 5, "end": 9, "entity_type": "UNK", "mention_type": "UNK"}], "relation_mentions": [], "event_mentions": [{"event_type": "Methods/Approach", "id": "ACL_23_P_367-1-EV0", "trigger": {"text": "present", "start": 4, "end": 5}, "arguments": [{"entity_id": "ACL_23_P_367-1-E0", "text": "we", "role": "Agent"}, {"entity_id": "ACL_23_P_367-1-E1", "text": "perform zero- and few-shot sequence tagging with autoregressive PLMs", "role": "Method"}, {"entity_id": "ACL_23_P_367-1-E2", "text": "We evaluate this approach on part-of-speech tagging, named entity recognition, and sentence chunking,", "role": "Method"}, {"entity_id": "ACL_23_P_367-1-E3", "text": "strong few-shot performance in all cases.", "role": "Results"}, {"entity_id": "ACL_23_P_367-1-E4", "text": "a structured prompting approach", "role": "PrimaryObject"}]}], "entity_coreference": [], "event_coreference": [], "tokens": ["To", "test", "this,", "we", "present", "a", "structured", "prompting", "approach", "for", "linguistic", "structured", "prediction", "tasks,", "allowing", "us", "to", "perform", "zero-", "and", "few-shot", "sequence", "tagging", "with", "autoregressive", "PLMs.", "We", "evaluate", "this", "approach", "on", "part-of-speech", "tagging,", "named", "entity", "recognition,", "and", "sentence", "chunking,", "demonstrating", "strong", "few-shot", "performance", "in", "all", "cases."], "pieces": ["To", "test", "this", ",", "we", "present", "a", "struct", "ured", "prom", "pt", "ing", "appro", "ach", "for", "ling", "u", "istic", "struct", "ured", "pred", "iction", "t", "asks", ",", "all", "owing", "us", "to", "per", "form", "zero", "-", "and", "few", "-", "shot", "sequence", "tag", "ging", "with", "aut", "ore", "gressive", "PL", "Ms", ".", "We", "evaluate", "this", "appro", "ach", "on", "part", "-", "of", "-", "speech", "tag", "ging", ",", "named", "entity", "recogn", "ition", ",", "and", "sent", "ence", "ch", "unk", "ing", ",", "demon", "str", "ating", "strong", "few", "-", "shot", "performance", "in", "all", "cases", "."], "token_lens": [1, 1, 2, 1, 1, 1, 2, 3, 2, 1, 3, 2, 2, 3, 2, 1, 1, 2, 2, 1, 3, 1, 2, 1, 3, 3, 1, 1, 1, 2, 1, 5, 3, 1, 1, 3, 1, 2, 4, 3, 1, 3, 1, 1, 1, 2], "sentence": "To test this, we present a structured prompting approach for linguistic structured prediction tasks, allowing us to perform zero- and few-shot sequence tagging with autoregressive PLMs. We evaluate this approach on part-of-speech tagging, named entity recognition, and sentence chunking, demonstrating strong few-shot performance in all cases.", "sentence_starts": [0]}
{"doc_id": "ACL_23_P_367", "wnd_id": "ACL_23_P_367-2", "entity_mentions": [{"id": "ACL_23_P_367-2-E0", "text": "We", "start": 0, "end": 1, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_367-2-E1", "text": "while PLMs contain significant prior knowledge of task labels due to task leakage into the pretraining corpus", "start": 4, "end": 21, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_367-2-E2", "text": "structured prompting can also retrieve linguistic structure with arbitrary labels", "start": 21, "end": 31, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_367-2-E3", "text": "the in-context learning ability and linguistic knowledge of PLMs generalizes beyond memorization of their training data", "start": 35, "end": 51, "entity_type": "UNK", "mention_type": "UNK"}], "relation_mentions": [], "event_mentions": [{"event_type": "Results/Findings", "id": "ACL_23_P_367-2-EV0", "trigger": {"text": "find", "start": 2, "end": 3}, "arguments": [{"entity_id": "ACL_23_P_367-2-E0", "text": "We", "role": "Agent"}, {"entity_id": "ACL_23_P_367-2-E1", "text": "while PLMs contain significant prior knowledge of task labels due to task leakage into the pretraining corpus", "role": "Context"}, {"entity_id": "ACL_23_P_367-2-E2", "text": "structured prompting can also retrieve linguistic structure with arbitrary labels", "role": "Results"}, {"entity_id": "ACL_23_P_367-2-E3", "text": "the in-context learning ability and linguistic knowledge of PLMs generalizes beyond memorization of their training data", "role": "Results"}]}], "entity_coreference": [], "event_coreference": [], "tokens": ["We", "also", "find", "that", "while", "PLMs", "contain", "significant", "prior", "knowledge", "of", "task", "labels", "due", "to", "task", "leakage", "into", "the", "pretraining", "corpus,", "structured", "prompting", "can", "also", "retrieve", "linguistic", "structure", "with", "arbitrary", "labels.", "These", "findings", "indicate", "that", "the", "in-context", "learning", "ability", "and", "linguistic", "knowledge", "of", "PLMs", "generalizes", "beyond", "memorization", "of", "their", "training", "data."], "pieces": ["We", "also", "find", "that", "while", "PL", "Ms", "cont", "ain", "significant", "pri", "or", "knowledge", "of", "task", "lab", "els", "due", "to", "task", "le", "ak", "age", "into", "the", "pret", "raining", "cor", "p", "us", ",", "struct", "ured", "prom", "pt", "ing", "can", "also", "ret", "rieve", "ling", "u", "istic", "st", "ructure", "with", "ar", "bit", "rary", "lab", "els", ".", "These", "find", "ings", "ind", "icate", "that", "the", "in", "-", "context", "learning", "ability", "and", "ling", "u", "istic", "knowledge", "of", "PL", "Ms", "general", "izes", "be", "yond", "mem", "or", "ization", "of", "their", "training", "data", "."], "token_lens": [1, 1, 1, 1, 1, 2, 2, 1, 2, 1, 1, 1, 2, 1, 1, 1, 3, 1, 1, 2, 4, 2, 3, 1, 1, 2, 3, 2, 1, 3, 3, 1, 2, 2, 1, 1, 3, 1, 1, 1, 3, 1, 1, 2, 2, 2, 3, 1, 1, 1, 2], "sentence": "We also find that while PLMs contain significant prior knowledge of task labels due to task leakage into the pretraining corpus, structured prompting can also retrieve linguistic structure with arbitrary labels. These findings indicate that the in-context learning ability and linguistic knowledge of PLMs generalizes beyond memorization of their training data.", "sentence_starts": [0]}
{"doc_id": "ACL_23_P_509", "wnd_id": "ACL_23_P_509-0", "entity_mentions": [{"id": "ACL_23_P_509-0-E0", "text": "Fine-tuning", "start": 0, "end": 1, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_509-0-E1", "text": "Most existing studies attribute it to catastrophic forgetting, and they retain the pre-trained knowledge indiscriminately without identifying what knowledge is transferable", "start": 37, "end": 58, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_509-0-E2", "text": "vanilla fine-tuning easily overfits the target data and degrades the generalization ability", "start": 25, "end": 37, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_509-0-E3", "text": "a simple and effective technique ", "start": 6, "end": 11, "entity_type": "UNK", "mention_type": "UNK"}], "relation_mentions": [], "event_mentions": [{"event_type": "Background/Introduction", "id": "ACL_23_P_509-0-EV0", "trigger": {"text": "has been proven to be", "start": 1, "end": 6}, "arguments": [{"entity_id": "ACL_23_P_509-0-E0", "text": "Fine-tuning", "role": "Agent"}, {"entity_id": "ACL_23_P_509-0-E1", "text": "Most existing studies attribute it to catastrophic forgetting, and they retain the pre-trained knowledge indiscriminately without identifying what knowledge is transferable", "role": "Context"}, {"entity_id": "ACL_23_P_509-0-E2", "text": "vanilla fine-tuning easily overfits the target data and degrades the generalization ability", "role": "Challenge"}, {"entity_id": "ACL_23_P_509-0-E3", "text": "a simple and effective technique ", "role": "PrimaryObject"}]}], "entity_coreference": [], "event_coreference": [], "tokens": ["Fine-tuning", "has", "been", "proven", "to", "be", "a", "simple", "and", "effective", "technique", "to", "transfer", "the", "learned", "knowledge", "of", "Pre-trained", "Language", "Models", "(PLMs)", "to", "downstream", "tasks.", "However,", "vanilla", "fine-tuning", "easily", "overfits", "the", "target", "data", "and", "degrades", "the", "generalization", "ability.", "Most", "existing", "studies", "attribute", "it", "to", "catastrophic", "forgetting,", "and", "they", "retain", "the", "pre-trained", "knowledge", "indiscriminately", "without", "identifying", "what", "knowledge", "is", "transferable."], "pieces": ["Fine", "-", "tun", "ing", "has", "been", "proven", "to", "be", "a", "simple", "and", "effective", "techn", "ique", "to", "transfer", "the", "learn", "ed", "knowledge", "of", "Pre", "-", "trained", "Language", "Mod", "els", "(", "PL", "Ms", ")", "to", "down", "stream", "t", "asks", ".", "However", ",", "van", "illa", "fine", "-", "tun", "ing", "eas", "ily", "over", "fits", "the", "target", "data", "and", "deg", "r", "ades", "the", "general", "ization", "ability", ".", "Most", "existing", "stud", "ies", "attribute", "it", "to", "cat", "ast", "rophic", "for", "getting", ",", "and", "they", "ret", "ain", "the", "pre", "-", "trained", "knowledge", "ind", "isc", "rim", "inately", "without", "ident", "ifying", "what", "knowledge", "is", "transfer", "able", "."], "token_lens": [4, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 2, 1, 1, 3, 1, 2, 4, 1, 2, 3, 2, 2, 4, 2, 2, 1, 1, 1, 1, 3, 1, 2, 2, 1, 1, 2, 1, 1, 1, 3, 3, 1, 1, 2, 1, 3, 1, 4, 1, 2, 1, 1, 1, 3], "sentence": "Fine-tuning has been proven to be a simple and effective technique to transfer the learned knowledge of Pre-trained Language Models (PLMs) to downstream tasks. However, vanilla fine-tuning easily overfits the target data and degrades the generalization ability. Most existing studies attribute it to catastrophic forgetting, and they retain the pre-trained knowledge indiscriminately without identifying what knowledge is transferable.", "sentence_starts": [0]}
{"doc_id": "ACL_23_P_509", "wnd_id": "ACL_23_P_509-1", "entity_mentions": [{"id": "ACL_23_P_509-1-E0", "text": "we", "start": 3, "end": 4, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_509-1-E1", "text": "we propose a unified objective for fine-tuning to retrieve the causality back", "start": 33, "end": 45, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_509-1-E2", "text": "the unified objective can be seen as the sum of the vanilla fine-tuning objective, which learns new knowledge from target data, and the causal objective, which preserves old knowledge from PLMs", "start": 46, "end": 77, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_509-1-E3", "text": "Since endowing models with commonsense is a long-standing challenge, we implement our method on commonsense QA with a proposed heuristic estimation to verify its effectiveness", "start": 90, "end": 115, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_509-1-E4", "text": "the crux of catastrophic forgetting lies in the missing causal effects from the pre-trained data", "start": 13, "end": 28, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_509-1-E5", "text": "our method is flexible and can mitigate negative transfer while preserving knowledge", "start": 78, "end": 90, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_509-1-E6", "text": "fine-tuning", "start": 5, "end": 6, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_509-1-E7", "text": "into a causal graph", "start": 6, "end": 10, "entity_type": "UNK", "mention_type": "UNK"}], "relation_mentions": [], "event_mentions": [{"event_type": "Methods/Approach", "id": "ACL_23_P_509-1-EV0", "trigger": {"text": "frame", "start": 4, "end": 5}, "arguments": [{"entity_id": "ACL_23_P_509-1-E0", "text": "we", "role": "Agent"}, {"entity_id": "ACL_23_P_509-1-E1", "text": "we propose a unified objective for fine-tuning to retrieve the causality back", "role": "Purpose"}, {"entity_id": "ACL_23_P_509-1-E2", "text": "the unified objective can be seen as the sum of the vanilla fine-tuning objective, which learns new knowledge from target data, and the causal objective, which preserves old knowledge from PLMs", "role": "Method"}, {"entity_id": "ACL_23_P_509-1-E3", "text": "Since endowing models with commonsense is a long-standing challenge, we implement our method on commonsense QA with a proposed heuristic estimation to verify its effectiveness", "role": "Method"}, {"entity_id": "ACL_23_P_509-1-E4", "text": "the crux of catastrophic forgetting lies in the missing causal effects from the pre-trained data", "role": "Results"}, {"entity_id": "ACL_23_P_509-1-E5", "text": "our method is flexible and can mitigate negative transfer while preserving knowledge", "role": "Results"}, {"entity_id": "ACL_23_P_509-1-E6", "text": "fine-tuning", "role": "PrimaryObject"}, {"entity_id": "ACL_23_P_509-1-E7", "text": "into a causal graph", "role": "SecondaryObject"}]}], "entity_coreference": [], "event_coreference": [], "tokens": ["Motivated", "by", "this,", "we", "frame", "fine-tuning", "into", "a", "causal", "graph", "and", "discover", "that", "the", "crux", "of", "catastrophic", "forgetting", "lies", "in", "the", "missing", "causal", "effects", "from", "the", "pre-trained", "data.", "Based", "on", "the", "causal", "view,", "we", "propose", "a", "unified", "objective", "for", "fine-tuning", "to", "retrieve", "the", "causality", "back.", "Intriguingly,", "the", "unified", "objective", "can", "be", "seen", "as", "the", "sum", "of", "the", "vanilla", "fine-tuning", "objective,", "which", "learns", "new", "knowledge", "from", "target", "data,", "and", "the", "causal", "objective,", "which", "preserves", "old", "knowledge", "from", "PLMs.", "Therefore,", "our", "method", "is", "flexible", "and", "can", "mitigate", "negative", "transfer", "while", "preserving", "knowledge.", "Since", "endowing", "models", "with", "commonsense", "is", "a", "long-standing", "challenge,", "we", "implement", "our", "method", "on", "commonsense", "QA", "with", "a", "proposed", "heuristic", "estimation", "to", "verify", "its", "effectiveness."], "pieces": ["Mot", "ivated", "by", "this", ",", "we", "frame", "fine", "-", "tun", "ing", "into", "a", "ca", "usal", "graph", "and", "d", "iscover", "that", "the", "cru", "x", "of", "cat", "ast", "rophic", "for", "getting", "lies", "in", "the", "missing", "ca", "usal", "effects", "from", "the", "pre", "-", "trained", "data", ".", "Based", "on", "the", "ca", "usal", "view", ",", "we", "pro", "pose", "a", "un", "ified", "object", "ive", "for", "fine", "-", "tun", "ing", "to", "ret", "rieve", "the", "ca", "us", "ality", "back", ".", "Int", "rig", "uing", "ly", ",", "the", "un", "ified", "object", "ive", "can", "be", "seen", "as", "the", "sum", "of", "the", "van", "illa", "fine", "-", "tun", "ing", "object", "ive", ",", "which", "learn", "s", "new", "knowledge", "from", "target", "data", ",", "and", "the", "ca", "usal", "object", "ive", ",", "which", "pres", "erves", "old", "knowledge", "from", "PL", "Ms", ".", "Therefore", ",", "our", "method", "is", "flex", "ible", "and", "can", "mit", "igate", "negative", "transfer", "while", "pres", "erving", "knowledge", ".", "Since", "end", "owing", "models", "with", "comm", "onsense", "is", "a", "long", "-", "standing", "chall", "enge", ",", "we", "im", "plement", "our", "method", "on", "comm", "onsense", "Q", "A", "with", "a", "prop", "osed", "he", "uristic", "est", "imation", "to", "ver", "ify", "its", "effect", "iveness", "."], "token_lens": [2, 1, 2, 1, 1, 4, 1, 1, 2, 1, 1, 2, 1, 1, 2, 1, 3, 2, 1, 1, 1, 1, 2, 1, 1, 1, 3, 2, 1, 1, 1, 2, 2, 1, 2, 1, 2, 2, 1, 4, 1, 2, 1, 3, 2, 5, 1, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 2, 4, 3, 1, 2, 1, 1, 1, 1, 2, 1, 1, 2, 3, 1, 2, 1, 1, 1, 3, 2, 1, 1, 1, 2, 1, 1, 2, 1, 1, 1, 2, 2, 1, 2, 1, 1, 2, 1, 1, 3, 3, 1, 2, 1, 1, 1, 2, 2, 1, 1, 2, 2, 2, 1, 2, 1, 3], "sentence": "Motivated by this, we frame fine-tuning into a causal graph and discover that the crux of catastrophic forgetting lies in the missing causal effects from the pre-trained data. Based on the causal view, we propose a unified objective for fine-tuning to retrieve the causality back. Intriguingly, the unified objective can be seen as the sum of the vanilla fine-tuning objective, which learns new knowledge from target data, and the causal objective, which preserves old knowledge from PLMs. Therefore, our method is flexible and can mitigate negative transfer while preserving knowledge. Since endowing models with commonsense is a long-standing challenge, we implement our method on commonsense QA with a proposed heuristic estimation to verify its effectiveness.", "sentence_starts": [0]}
{"doc_id": "ACL_23_P_509", "wnd_id": "ACL_23_P_509-2", "entity_mentions": [{"id": "ACL_23_P_509-2-E0", "text": "our method", "start": 3, "end": 5, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_509-2-E1", "text": "implemented as a plug-in module to inflate the performance of existing QA models", "start": 18, "end": 31, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_509-2-E2", "text": "state-of-the-art fine-tuning methods", "start": 6, "end": 9, "entity_type": "UNK", "mention_type": "UNK"}], "relation_mentions": [], "event_mentions": [{"event_type": "Results/Findings", "id": "ACL_23_P_509-2-EV0", "trigger": {"text": "outperforms", "start": 5, "end": 6}, "arguments": [{"entity_id": "ACL_23_P_509-2-E0", "text": "our method", "role": "Agent"}, {"entity_id": "ACL_23_P_509-2-E1", "text": "implemented as a plug-in module to inflate the performance of existing QA models", "role": "Method"}, {"entity_id": "ACL_23_P_509-2-E2", "text": "state-of-the-art fine-tuning methods", "role": "PrimaryObject"}]}], "entity_coreference": [], "event_coreference": [], "tokens": ["In", "the", "experiments,", "our", "method", "outperforms", "state-of-the-art", "fine-tuning", "methods", "on", "all", "six", "commonsense", "QA", "datasets", "and", "can", "be", "implemented", "as", "a", "plug-in", "module", "to", "inflate", "the", "performance", "of", "existing", "QA", "models."], "pieces": ["In", "the", "exper", "iments", ",", "our", "method", "out", "per", "forms", "state", "-", "of", "-", "the", "-", "art", "fine", "-", "tun", "ing", "method", "s", "on", "all", "six", "comm", "onsense", "Q", "A", "dat", "as", "ets", "and", "can", "be", "im", "ple", "mented", "as", "a", "plug", "-", "in", "module", "to", "in", "fl", "ate", "the", "performance", "of", "existing", "Q", "A", "models", "."], "token_lens": [1, 1, 3, 1, 1, 3, 7, 4, 2, 1, 1, 1, 2, 2, 3, 1, 1, 1, 3, 1, 1, 3, 1, 1, 3, 1, 1, 1, 1, 2, 2], "sentence": "In the experiments, our method outperforms state-of-the-art fine-tuning methods on all six commonsense QA datasets and can be implemented as a plug-in module to inflate the performance of existing QA models.", "sentence_starts": [0]}
{"doc_id": "ACL_23_P_316", "wnd_id": "ACL_23_P_316-0", "entity_mentions": [{"id": "ACL_23_P_316-0-E0", "text": "We", "start": 0, "end": 1, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_316-0-E1", "text": "Using the probabilistic linear context-free rewriting system (LCFRS) formalism, our approach fixes the rule structure in advance and focuses on parameter learning with maximum likelihood", "start": 12, "end": 37, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_316-0-E2", "text": "grammar induction", "start": 2, "end": 4, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_316-0-E3", "text": "with mildly context-sensitive grammars", "start": 4, "end": 8, "entity_type": "UNK", "mention_type": "UNK"}], "relation_mentions": [], "event_mentions": [{"event_type": "Background/Introduction", "id": "ACL_23_P_316-0-EV0", "trigger": {"text": "study", "start": 1, "end": 2}, "arguments": [{"entity_id": "ACL_23_P_316-0-E0", "text": "We", "role": "Agent"}, {"entity_id": "ACL_23_P_316-0-E1", "text": "Using the probabilistic linear context-free rewriting system (LCFRS) formalism, our approach fixes the rule structure in advance and focuses on parameter learning with maximum likelihood", "role": "Method"}, {"entity_id": "ACL_23_P_316-0-E2", "text": "grammar induction", "role": "PrimaryObject"}, {"entity_id": "ACL_23_P_316-0-E3", "text": "with mildly context-sensitive grammars", "role": "SecondaryObject"}]}], "entity_coreference": [], "event_coreference": [], "tokens": ["We", "study", "grammar", "induction", "with", "mildly", "context-sensitive", "grammars", "for", "unsupervised", "discontinuous", "parsing.", "Using", "the", "probabilistic", "linear", "context-free", "rewriting", "system", "(LCFRS)", "formalism,", "our", "approach", "fixes", "the", "rule", "structure", "in", "advance", "and", "focuses", "on", "parameter", "learning", "with", "maximum", "likelihood."], "pieces": ["We", "study", "gram", "mar", "ind", "uction", "with", "m", "ild", "ly", "context", "-", "sensitive", "gram", "m", "ars", "for", "un", "super", "vised", "disc", "ont", "in", "uous", "p", "ars", "ing", ".", "Using", "the", "pro", "b", "abil", "istic", "linear", "context", "-", "free", "rew", "rit", "ing", "system", "(", "LC", "F", "RS", ")", "form", "al", "ism", ",", "our", "appro", "ach", "fixes", "the", "rule", "st", "ructure", "in", "ad", "vance", "and", "f", "oc", "uses", "on", "param", "eter", "learning", "with", "maximum", "like", "lihood", "."], "token_lens": [1, 1, 2, 2, 1, 3, 3, 3, 1, 3, 4, 4, 1, 1, 4, 1, 3, 3, 1, 5, 4, 1, 2, 1, 1, 1, 2, 1, 2, 1, 3, 1, 2, 1, 1, 1, 3], "sentence": "We study grammar induction with mildly context-sensitive grammars for unsupervised discontinuous parsing. Using the probabilistic linear context-free rewriting system (LCFRS) formalism, our approach fixes the rule structure in advance and focuses on parameter learning with maximum likelihood.", "sentence_starts": [0]}
{"doc_id": "ACL_23_P_316", "wnd_id": "ACL_23_P_316-1", "entity_mentions": [{"id": "ACL_23_P_316-1-E0", "text": "we", "start": 11, "end": 12, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_316-1-E1", "text": "To reduce the computational complexity of both parsing and parameter estimation", "start": 0, "end": 11, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_316-1-E2", "text": "make use of tensor decomposition-based rank-space dynamic programming with an embedding-based parameterization of rule probabilities to scale up the number of nonterminals", "start": 51, "end": 73, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_316-1-E3", "text": "using a large number of nonterminals is beneficial", "start": 41, "end": 49, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_316-1-E4", "text": "the grammar formalism", "start": 13, "end": 16, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_316-1-E5", "text": "to LCFRS-2", "start": 16, "end": 18, "entity_type": "UNK", "mention_type": "UNK"}], "relation_mentions": [], "event_mentions": [{"event_type": "Methods/Approach", "id": "ACL_23_P_316-1-EV0", "trigger": {"text": "restrict", "start": 12, "end": 13}, "arguments": [{"entity_id": "ACL_23_P_316-1-E0", "text": "we", "role": "Agent"}, {"entity_id": "ACL_23_P_316-1-E1", "text": "To reduce the computational complexity of both parsing and parameter estimation", "role": "Purpose"}, {"entity_id": "ACL_23_P_316-1-E2", "text": "make use of tensor decomposition-based rank-space dynamic programming with an embedding-based parameterization of rule probabilities to scale up the number of nonterminals", "role": "Method"}, {"entity_id": "ACL_23_P_316-1-E3", "text": "using a large number of nonterminals is beneficial", "role": "Analysis"}, {"entity_id": "ACL_23_P_316-1-E4", "text": "the grammar formalism", "role": "PrimaryObject"}, {"entity_id": "ACL_23_P_316-1-E5", "text": "to LCFRS-2", "role": "SecondaryObject"}]}], "entity_coreference": [], "event_coreference": [], "tokens": ["To", "reduce", "the", "computational", "complexity", "of", "both", "parsing", "and", "parameter", "estimation,", "we", "restrict", "the", "grammar", "formalism", "to", "LCFRS-2", "(i.e.,", "binary", "LCFRS", "with", "fan-out", "two)", "and", "further", "discard", "rules", "that", "require", "O(l\u2076)", "time", "to", "parse,", "reducing", "inference", "to", "O(l\u2075).", "We", "find", "that", "using", "a", "large", "number", "of", "nonterminals", "is", "beneficial", "and", "thus", "make", "use", "of", "tensor", "decomposition-based", "rank-space", "dynamic", "programming", "with", "an", "embedding-based", "parameterization", "of", "rule", "probabilities", "to", "scale", "up", "the", "number", "of", "nonterminals."], "pieces": ["To", "red", "uce", "the", "com", "put", "ational", "complex", "ity", "of", "both", "p", "ars", "ing", "and", "param", "eter", "est", "imation", ",", "we", "rest", "rict", "the", "gram", "mar", "form", "al", "ism", "to", "LC", "F", "RS", "-", "2", "(", "i", ".", "e", ".,", "binary", "LC", "F", "RS", "with", "fan", "-", "out", "two", ")", "and", "f", "urther", "disc", "ard", "rules", "that", "require", "O", "(", "l", "\u00e2\u0123", "\u00b6", ")", "time", "to", "parse", ",", "red", "ucing", "in", "ference", "to", "O", "(", "l", "\u00e2\u0123", "\u00b5", ").", "We", "find", "that", "using", "a", "large", "number", "of", "non", "termin", "als", "is", "benef", "icial", "and", "thus", "make", "use", "of", "t", "ensor", "dec", "om", "position", "-", "based", "rank", "-", "space", "d", "ynamic", "program", "ming", "with", "an", "embed", "ding", "-", "based", "param", "eter", "ization", "of", "rule", "pro", "b", "abilities", "to", "scale", "up", "the", "number", "of", "non", "termin", "als", "."], "token_lens": [1, 2, 1, 3, 2, 1, 1, 3, 1, 2, 3, 1, 2, 1, 2, 3, 1, 5, 5, 1, 3, 1, 3, 2, 1, 2, 2, 1, 1, 1, 6, 1, 1, 2, 2, 2, 1, 6, 1, 1, 1, 1, 1, 1, 1, 1, 3, 1, 2, 1, 1, 1, 1, 1, 2, 5, 3, 2, 2, 1, 1, 4, 3, 1, 1, 3, 1, 1, 1, 1, 1, 1, 4], "sentence": "To reduce the computational complexity of both parsing and parameter estimation, we restrict the grammar formalism to LCFRS-2 (i.e., binary LCFRS with fan-out two) and further discard rules that require O(l\u2076) time to parse, reducing inference to O(l\u2075). We find that using a large number of nonterminals is beneficial and thus make use of tensor decomposition-based rank-space dynamic programming with an embedding-based parameterization of rule probabilities to scale up the number of nonterminals.", "sentence_starts": [0]}
{"doc_id": "ACL_23_P_316", "wnd_id": "ACL_23_P_316-2", "entity_mentions": [{"id": "ACL_23_P_316-2-E0", "text": "Experiments on German and Dutch", "start": 0, "end": 5, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_316-2-E1", "text": "our approach is able to induce linguistically meaningful trees with continuous and discontinuous structures.", "start": 7, "end": 21, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_316-2-E2", "text": "our approach is able to induce linguistically meaningful trees with continuous and discontinuous structures", "start": 7, "end": 21, "entity_type": "UNK", "mention_type": "UNK"}], "relation_mentions": [], "event_mentions": [{"event_type": "Results/Findings", "id": "ACL_23_P_316-2-EV0", "trigger": {"text": "show", "start": 5, "end": 6}, "arguments": [{"entity_id": "ACL_23_P_316-2-E0", "text": "Experiments on German and Dutch", "role": "Agent"}, {"entity_id": "ACL_23_P_316-2-E1", "text": "our approach is able to induce linguistically meaningful trees with continuous and discontinuous structures.", "role": "Results"}, {"entity_id": "ACL_23_P_316-2-E2", "text": "our approach is able to induce linguistically meaningful trees with continuous and discontinuous structures", "role": "PrimaryObject"}]}], "entity_coreference": [], "event_coreference": [], "tokens": ["Experiments", "on", "German", "and", "Dutch", "show", "that", "our", "approach", "is", "able", "to", "induce", "linguistically", "meaningful", "trees", "with", "continuous", "and", "discontinuous", "structures."], "pieces": ["Exper", "iments", "on", "German", "and", "Dutch", "show", "that", "our", "appro", "ach", "is", "able", "to", "ind", "uce", "ling", "u", "istically", "meaning", "ful", "t", "rees", "with", "contin", "uous", "and", "disc", "ont", "in", "uous", "struct", "ures", "."], "token_lens": [2, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 2, 3, 2, 2, 1, 2, 1, 4, 3], "sentence": "Experiments on German and Dutch show that our approach is able to induce linguistically meaningful trees with continuous and discontinuous structures.", "sentence_starts": [0]}
{"doc_id": "ACL_23_P_587", "wnd_id": "ACL_23_P_587-0", "entity_mentions": [{"id": "ACL_23_P_587-0-E0", "text": "Summarization models", "start": 0, "end": 2, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_587-0-E1", "text": "much of this work has focused on how to generate and optimize these sets", "start": 64, "end": 78, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_587-0-E2", "text": "recent work has added a calibration step, which exposes a model to its own ranked outputs to improve relevance or, in a separate line of work, contrasts positive and negative sets to improve faithfulness", "start": 28, "end": 62, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_587-0-E3", "text": "While effective, much of this work has focused on how to generate and optimize these sets. Less is known about why one setup is more effective than another", "start": 62, "end": 90, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_587-0-E4", "text": "text", "start": 4, "end": 5, "entity_type": "UNK", "mention_type": "UNK"}], "relation_mentions": [], "event_mentions": [{"event_type": "Background/Introduction", "id": "ACL_23_P_587-0-EV0", "trigger": {"text": "generate", "start": 3, "end": 4}, "arguments": [{"entity_id": "ACL_23_P_587-0-E0", "text": "Summarization models", "role": "Agent"}, {"entity_id": "ACL_23_P_587-0-E1", "text": "much of this work has focused on how to generate and optimize these sets", "role": "Context"}, {"entity_id": "ACL_23_P_587-0-E2", "text": "recent work has added a calibration step, which exposes a model to its own ranked outputs to improve relevance or, in a separate line of work, contrasts positive and negative sets to improve faithfulness", "role": "Context"}, {"entity_id": "ACL_23_P_587-0-E3", "text": "While effective, much of this work has focused on how to generate and optimize these sets. Less is known about why one setup is more effective than another", "role": "Challenge"}, {"entity_id": "ACL_23_P_587-0-E4", "text": "text", "role": "PrimaryObject"}]}], "entity_coreference": [], "event_coreference": [], "tokens": ["Summarization", "models", "often", "generate", "text", "that", "is", "poorly", "calibrated", "to", "quality", "metrics", "because", "they", "are", "trained", "to", "maximize", "the", "likelihood", "of", "a", "single", "reference", "(MLE).", "To", "address", "this,", "recent", "work", "has", "added", "a", "calibration", "step,", "which", "exposes", "a", "model", "to", "its", "own", "ranked", "outputs", "to", "improve", "relevance", "or,", "in", "a", "separate", "line", "of", "work,", "contrasts", "positive", "and", "negative", "sets", "to", "improve", "faithfulness.", "While", "effective,", "much", "of", "this", "work", "has", "focused", "on", "how", "to", "generate", "and", "optimize", "these", "sets.", "Less", "is", "known", "about", "why", "one", "setup", "is", "more", "effective", "than", "another."], "pieces": ["Sum", "mar", "ization", "models", "often", "gener", "ate", "text", "that", "is", "poor", "ly", "cal", "ibr", "ated", "to", "quality", "met", "rics", "because", "they", "are", "trained", "to", "max", "imize", "the", "like", "lihood", "of", "a", "single", "reference", "(", "M", "LE", ").", "To", "address", "this", ",", "recent", "work", "has", "added", "a", "cal", "ib", "ration", "step", ",", "which", "ex", "poses", "a", "model", "to", "its", "own", "ranked", "output", "s", "to", "improve", "re", "lev", "ance", "or", ",", "in", "a", "separ", "ate", "line", "of", "work", ",", "cont", "rast", "s", "positive", "and", "negative", "sets", "to", "improve", "faith", "fulness", ".", "While", "effective", ",", "much", "of", "this", "work", "has", "focused", "on", "how", "to", "gener", "ate", "and", "optim", "ize", "these", "sets", ".", "Less", "is", "known", "about", "why", "one", "setup", "is", "more", "effective", "than", "another", "."], "token_lens": [3, 1, 1, 2, 1, 1, 1, 2, 3, 1, 1, 2, 1, 1, 1, 1, 1, 2, 1, 2, 1, 1, 1, 1, 4, 1, 1, 2, 1, 1, 1, 1, 1, 3, 2, 1, 2, 1, 1, 1, 1, 1, 1, 2, 1, 1, 3, 2, 1, 1, 2, 1, 1, 2, 3, 1, 1, 1, 1, 1, 1, 3, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 2, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2], "sentence": "Summarization models often generate text that is poorly calibrated to quality metrics because they are trained to maximize the likelihood of a single reference (MLE). To address this, recent work has added a calibration step, which exposes a model to its own ranked outputs to improve relevance or, in a separate line of work, contrasts positive and negative sets to improve faithfulness. While effective, much of this work has focused on how to generate and optimize these sets. Less is known about why one setup is more effective than another.", "sentence_starts": [0]}
{"doc_id": "ACL_23_P_587", "wnd_id": "ACL_23_P_587-1", "entity_mentions": [{"id": "ACL_23_P_587-1-E0", "text": "we", "start": 3, "end": 4, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_587-1-E1", "text": "we form a large, diverse pool of candidates and systematically vary the subsets used for calibration fine-tuning", "start": 15, "end": 32, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_587-1-E2", "text": "Each selection strategy targets distinct aspects of the sets, such as lexical diversity or the size of the gap between positive and negatives", "start": 32, "end": 55, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_587-1-E3", "text": "the underlying characteristics of effective sets", "start": 5, "end": 11, "entity_type": "UNK", "mention_type": "UNK"}], "relation_mentions": [], "event_mentions": [{"event_type": "Methods/Approach", "id": "ACL_23_P_587-1-EV0", "trigger": {"text": "uncover", "start": 4, "end": 5}, "arguments": [{"entity_id": "ACL_23_P_587-1-E0", "text": "we", "role": "Agent"}, {"entity_id": "ACL_23_P_587-1-E1", "text": "we form a large, diverse pool of candidates and systematically vary the subsets used for calibration fine-tuning", "role": "Method"}, {"entity_id": "ACL_23_P_587-1-E2", "text": "Each selection strategy targets distinct aspects of the sets, such as lexical diversity or the size of the gap between positive and negatives", "role": "Method"}, {"entity_id": "ACL_23_P_587-1-E3", "text": "the underlying characteristics of effective sets", "role": "PrimaryObject"}]}], "entity_coreference": [], "event_coreference": [], "tokens": ["In", "this", "work,", "we", "uncover", "the", "underlying", "characteristics", "of", "effective", "sets.", "For", "each", "training", "instance,", "we", "form", "a", "large,", "diverse", "pool", "of", "candidates", "and", "systematically", "vary", "the", "subsets", "used", "for", "calibration", "fine-tuning.", "Each", "selection", "strategy", "targets", "distinct", "aspects", "of", "the", "sets,", "such", "as", "lexical", "diversity", "or", "the", "size", "of", "the", "gap", "between", "positive", "and", "negatives."], "pieces": ["In", "this", "work", ",", "we", "un", "cover", "the", "under", "lying", "character", "istics", "of", "effective", "sets", ".", "For", "each", "training", "instance", ",", "we", "form", "a", "large", ",", "d", "iverse", "pool", "of", "cand", "idates", "and", "system", "atically", "v", "ary", "the", "sub", "sets", "used", "for", "cal", "ib", "ration", "fine", "-", "tun", "ing", ".", "Each", "selection", "str", "ategy", "t", "arg", "ets", "dist", "inct", "as", "pects", "of", "the", "sets", ",", "such", "as", "lex", "ical", "d", "iversity", "or", "the", "size", "of", "the", "gap", "between", "positive", "and", "neg", "atives", "."], "token_lens": [1, 1, 2, 1, 2, 1, 2, 2, 1, 1, 2, 1, 1, 1, 2, 1, 1, 1, 2, 2, 1, 1, 2, 1, 2, 2, 1, 2, 1, 1, 3, 5, 1, 1, 2, 3, 2, 2, 1, 1, 2, 1, 1, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 3], "sentence": "In this work, we uncover the underlying characteristics of effective sets. For each training instance, we form a large, diverse pool of candidates and systematically vary the subsets used for calibration fine-tuning. Each selection strategy targets distinct aspects of the sets, such as lexical diversity or the size of the gap between positive and negatives.", "sentence_starts": [0]}
{"doc_id": "ACL_23_P_587", "wnd_id": "ACL_23_P_587-2", "entity_mentions": [{"id": "ACL_23_P_587-2-E0", "text": "we", "start": 13, "end": 14, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_587-2-E1", "text": "On three diverse scientific long-form summarization datasets (spanning biomedical, clinical, and chemical domains)", "start": 0, "end": 13, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_587-2-E2", "text": "for relevance calibration, the metric margin between candidates should be maximized and surprise", "start": 35, "end": 48, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_587-2-E3", "text": "the disagreement between model and metric defined candidate rankings \u2013 minimized", "start": 49, "end": 60, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_587-2-E4", "text": "faithfulness calibration is optimal", "start": 18, "end": 22, "entity_type": "UNK", "mention_type": "UNK"}], "relation_mentions": [], "event_mentions": [{"event_type": "Results/Findings", "id": "ACL_23_P_587-2-EV0", "trigger": {"text": "find,", "start": 14, "end": 15}, "arguments": [{"entity_id": "ACL_23_P_587-2-E0", "text": "we", "role": "Agent"}, {"entity_id": "ACL_23_P_587-2-E1", "text": "On three diverse scientific long-form summarization datasets (spanning biomedical, clinical, and chemical domains)", "role": "Context"}, {"entity_id": "ACL_23_P_587-2-E2", "text": "for relevance calibration, the metric margin between candidates should be maximized and surprise", "role": "Results"}, {"entity_id": "ACL_23_P_587-2-E3", "text": "the disagreement between model and metric defined candidate rankings \u2013 minimized", "role": "Results"}, {"entity_id": "ACL_23_P_587-2-E4", "text": "faithfulness calibration is optimal", "role": "PrimaryObject"}]}], "entity_coreference": [], "event_coreference": [], "tokens": ["On", "three", "diverse", "scientific", "long-form", "summarization", "datasets", "(spanning", "biomedical,", "clinical,", "and", "chemical", "domains),", "we", "find,", "among", "others,", "that", "faithfulness", "calibration", "is", "optimal", "when", "the", "negative", "sets", "are", "extractive", "and", "more", "likely", "to", "be", "generated,", "whereas", "for", "relevance", "calibration,", "the", "metric", "margin", "between", "candidates", "should", "be", "maximized", "and", "surprise", "\u2013", "the", "disagreement", "between", "model", "and", "metric", "defined", "candidate", "rankings", "\u2013", "minimized."], "pieces": ["On", "three", "d", "iverse", "scientific", "long", "-", "form", "sum", "mar", "ization", "dat", "as", "ets", "(", "span", "ning", "bi", "omedical", ",", "clinical", ",", "and", "chemical", "dom", "ains", "),", "we", "find", ",", "among", "other", "s", ",", "that", "faith", "fulness", "cal", "ib", "ration", "is", "opt", "imal", "when", "the", "negative", "sets", "are", "ext", "ractive", "and", "more", "likely", "to", "be", "generated", ",", "where", "as", "for", "re", "lev", "ance", "cal", "ib", "ration", ",", "the", "met", "ric", "margin", "between", "cand", "idates", "should", "be", "max", "im", "ized", "and", "sur", "prise", "\u00e2\u0122\u0135", "the", "dis", "ag", "reement", "between", "model", "and", "met", "ric", "defined", "cand", "idate", "rank", "ings", "\u00e2\u0122\u0135", "min", "im", "ized", "."], "token_lens": [1, 1, 2, 1, 3, 3, 3, 3, 3, 2, 1, 1, 3, 1, 2, 1, 3, 1, 2, 3, 1, 2, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 2, 2, 1, 3, 4, 1, 2, 1, 1, 2, 1, 1, 3, 1, 2, 1, 1, 3, 1, 1, 1, 2, 1, 2, 2, 1, 4], "sentence": "On three diverse scientific long-form summarization datasets (spanning biomedical, clinical, and chemical domains), we find, among others, that faithfulness calibration is optimal when the negative sets are extractive and more likely to be generated, whereas for relevance calibration, the metric margin between candidates should be maximized and surprise \u2013 the disagreement between model and metric defined candidate rankings \u2013 minimized.", "sentence_starts": [0]}
{"doc_id": "ACL_23_P_299", "wnd_id": "ACL_23_P_299-0", "entity_mentions": [{"id": "ACL_23_P_299-0-E0", "text": "personalized dialogue", "start": 1, "end": 3, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_299-0-E1", "text": "Existing personalized dialogue agents model persona profiles from three resources: sparse or dense persona descriptions and dialogue histories", "start": 12, "end": 30, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_299-0-E2", "text": "sparse structured persona attributes are explicit but uninformative", "start": 31, "end": 39, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_299-0-E3", "text": "dense persona texts contain rich persona descriptions with much noise", "start": 39, "end": 49, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_299-0-E4", "text": "dialogue history query is both noisy and uninformative for persona modeling", "start": 50, "end": 61, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_299-0-E5", "text": "the consistent relationship between dialogue generation and personality", "start": 4, "end": 12, "entity_type": "UNK", "mention_type": "UNK"}], "relation_mentions": [], "event_mentions": [{"event_type": "Background/Introduction", "id": "ACL_23_P_299-0-EV0", "trigger": {"text": "explores", "start": 3, "end": 4}, "arguments": [{"entity_id": "ACL_23_P_299-0-E0", "text": "personalized dialogue", "role": "Agent"}, {"entity_id": "ACL_23_P_299-0-E1", "text": "Existing personalized dialogue agents model persona profiles from three resources: sparse or dense persona descriptions and dialogue histories", "role": "Context"}, {"entity_id": "ACL_23_P_299-0-E2", "text": "sparse structured persona attributes are explicit but uninformative", "role": "Challenge"}, {"entity_id": "ACL_23_P_299-0-E3", "text": "dense persona texts contain rich persona descriptions with much noise", "role": "Challenge"}, {"entity_id": "ACL_23_P_299-0-E4", "text": "dialogue history query is both noisy and uninformative for persona modeling", "role": "Challenge"}, {"entity_id": "ACL_23_P_299-0-E5", "text": "the consistent relationship between dialogue generation and personality", "role": "PrimaryObject"}]}], "entity_coreference": [], "event_coreference": [], "tokens": ["The", "personalized", "dialogue", "explores", "the", "consistent", "relationship", "between", "dialogue", "generation", "and", "personality.", "Existing", "personalized", "dialogue", "agents", "model", "persona", "profiles", "from", "three", "resources:", "sparse", "or", "dense", "persona", "descriptions", "and", "dialogue", "histories.", "However,", "sparse", "structured", "persona", "attributes", "are", "explicit", "but", "uninformative,", "dense", "persona", "texts", "contain", "rich", "persona", "descriptions", "with", "much", "noise,", "and", "dialogue", "history", "query", "is", "both", "noisy", "and", "uninformative", "for", "persona", "modeling."], "pieces": ["The", "personal", "ized", "dial", "ogue", "expl", "ores", "the", "cons", "istent", "relations", "hip", "between", "dial", "ogue", "generation", "and", "person", "ality", ".", "Ex", "isting", "personal", "ized", "dial", "ogue", "agents", "model", "person", "a", "prof", "iles", "from", "three", "resources", ":", "s", "parse", "or", "d", "ense", "person", "a", "desc", "ript", "ions", "and", "dial", "ogue", "hist", "ories", ".", "However", ",", "s", "parse", "struct", "ured", "person", "a", "att", "ributes", "are", "expl", "icit", "but", "unin", "form", "ative", ",", "d", "ense", "person", "a", "text", "s", "cont", "ain", "rich", "person", "a", "desc", "ript", "ions", "with", "much", "no", "ise", ",", "and", "dial", "ogue", "history", "query", "is", "both", "no", "isy", "and", "unin", "form", "ative", "for", "person", "a", "mod", "eling", "."], "token_lens": [1, 2, 2, 2, 1, 2, 2, 1, 2, 1, 1, 3, 2, 2, 2, 1, 1, 2, 2, 1, 1, 2, 2, 1, 2, 2, 3, 1, 2, 3, 2, 2, 2, 2, 2, 1, 2, 1, 4, 2, 2, 2, 2, 1, 2, 3, 1, 1, 3, 1, 2, 1, 1, 1, 1, 2, 1, 3, 1, 2, 3], "sentence": "The personalized dialogue explores the consistent relationship between dialogue generation and personality. Existing personalized dialogue agents model persona profiles from three resources: sparse or dense persona descriptions and dialogue histories. However, sparse structured persona attributes are explicit but uninformative, dense persona texts contain rich persona descriptions with much noise, and dialogue history query is both noisy and uninformative for persona modeling.", "sentence_starts": [0]}
{"doc_id": "ACL_23_P_299", "wnd_id": "ACL_23_P_299-1", "entity_mentions": [{"id": "ACL_23_P_299-1-E0", "text": "we", "start": 3, "end": 4, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_299-1-E1", "text": "a Contrastive Latent Variable-based model (CLV) that clusters the dense persona descriptions into sparse categories, which are combined with the history query", "start": 21, "end": 43, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_299-1-E2", "text": "the advantages of the three resources", "start": 5, "end": 11, "entity_type": "UNK", "mention_type": "UNK"}], "relation_mentions": [], "event_mentions": [{"event_type": "Methods/Approach", "id": "ACL_23_P_299-1-EV0", "trigger": {"text": "combine", "start": 4, "end": 5}, "arguments": [{"entity_id": "ACL_23_P_299-1-E0", "text": "we", "role": "Agent"}, {"entity_id": "ACL_23_P_299-1-E1", "text": "a Contrastive Latent Variable-based model (CLV) that clusters the dense persona descriptions into sparse categories, which are combined with the history query", "role": "Method"}, {"entity_id": "ACL_23_P_299-1-E2", "text": "the advantages of the three resources", "role": "PrimaryObject"}]}], "entity_coreference": [], "event_coreference": [], "tokens": ["In", "this", "work,", "we", "combine", "the", "advantages", "of", "the", "three", "resources", "to", "obtain", "a", "richer", "and", "more", "accurate", "persona.", "We", "design", "a", "Contrastive", "Latent", "Variable-based", "model", "(CLV)", "that", "clusters", "the", "dense", "persona", "descriptions", "into", "sparse", "categories,", "which", "are", "combined", "with", "the", "history", "query", "to", "generate", "personalized", "responses."], "pieces": ["In", "this", "work", ",", "we", "comb", "ine", "the", "advant", "ages", "of", "the", "three", "resources", "to", "ob", "tain", "a", "ric", "her", "and", "more", "acc", "urate", "person", "a", ".", "We", "design", "a", "Cont", "rast", "ive", "Lat", "ent", "Variable", "-", "based", "model", "(", "CL", "V", ")", "that", "cl", "usters", "the", "d", "ense", "person", "a", "desc", "ript", "ions", "into", "s", "parse", "c", "ategories", ",", "which", "are", "comb", "ined", "with", "the", "history", "query", "to", "gener", "ate", "personal", "ized", "respons", "es", "."], "token_lens": [1, 1, 2, 1, 2, 1, 2, 1, 1, 1, 1, 1, 2, 1, 2, 1, 1, 2, 3, 1, 1, 1, 3, 2, 3, 1, 4, 1, 2, 1, 2, 2, 3, 1, 2, 3, 1, 1, 2, 1, 1, 1, 1, 1, 2, 2, 3], "sentence": "In this work, we combine the advantages of the three resources to obtain a richer and more accurate persona. We design a Contrastive Latent Variable-based model (CLV) that clusters the dense persona descriptions into sparse categories, which are combined with the history query to generate personalized responses.", "sentence_starts": [0]}
{"doc_id": "ACL_23_P_299", "wnd_id": "ACL_23_P_299-2", "entity_mentions": [{"id": "ACL_23_P_299-2-E0", "text": "Experimental results on Chinese and English datasets", "start": 0, "end": 7, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_299-2-E1", "text": "model\u2019s superiority in personalization", "start": 9, "end": 13, "entity_type": "UNK", "mention_type": "UNK"}], "relation_mentions": [], "event_mentions": [{"event_type": "Results/Findings", "id": "ACL_23_P_299-2-EV0", "trigger": {"text": "demonstrate", "start": 7, "end": 8}, "arguments": [{"entity_id": "ACL_23_P_299-2-E0", "text": "Experimental results on Chinese and English datasets", "role": "Agent"}, {"entity_id": "ACL_23_P_299-2-E1", "text": "model\u2019s superiority in personalization", "role": "PrimaryObject"}]}], "entity_coreference": [], "event_coreference": [], "tokens": ["Experimental", "results", "on", "Chinese", "and", "English", "datasets", "demonstrate", "our", "model\u2019s", "superiority", "in", "personalization."], "pieces": ["Exper", "imental", "results", "on", "Chinese", "and", "English", "dat", "as", "ets", "demon", "strate", "our", "model", "\u00e2\u0122", "\u013b", "s", "super", "ior", "ity", "in", "personal", "ization", "."], "token_lens": [2, 1, 1, 1, 1, 1, 3, 2, 1, 4, 3, 1, 3], "sentence": "Experimental results on Chinese and English datasets demonstrate our model\u2019s superiority in personalization.", "sentence_starts": [0]}
{"doc_id": "ACL_23_P_634", "wnd_id": "ACL_23_P_634-0", "entity_mentions": [{"id": "ACL_23_P_634-0-E0", "text": "Many text generation applications", "start": 0, "end": 4, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_634-0-E1", "text": "Previous work has developed various metrics that often depend on specific functions, such as natural language inference (NLI) or question answering (QA), trained on limited data", "start": 22, "end": 48, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_634-0-E2", "text": "Automatic evaluation of factual consistency is challenging", "start": 15, "end": 22, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_634-0-E3", "text": "Those metrics thus can hardly assess diverse factual inconsistencies (e.g., contradictions, hallucinations) that occur in varying inputs/outputs (e.g., sentences, documents) from different tasks", "start": 48, "end": 71, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_634-0-E4", "text": "the generated text", "start": 5, "end": 8, "entity_type": "UNK", "mention_type": "UNK"}], "relation_mentions": [], "event_mentions": [{"event_type": "Background/Introduction", "id": "ACL_23_P_634-0-EV0", "trigger": {"text": "require", "start": 4, "end": 5}, "arguments": [{"entity_id": "ACL_23_P_634-0-E0", "text": "Many text generation applications", "role": "Agent"}, {"entity_id": "ACL_23_P_634-0-E1", "text": "Previous work has developed various metrics that often depend on specific functions, such as natural language inference (NLI) or question answering (QA), trained on limited data", "role": "Context"}, {"entity_id": "ACL_23_P_634-0-E2", "text": "Automatic evaluation of factual consistency is challenging", "role": "Challenge"}, {"entity_id": "ACL_23_P_634-0-E3", "text": "Those metrics thus can hardly assess diverse factual inconsistencies (e.g., contradictions, hallucinations) that occur in varying inputs/outputs (e.g., sentences, documents) from different tasks", "role": "Challenge"}, {"entity_id": "ACL_23_P_634-0-E4", "text": "the generated text", "role": "PrimaryObject"}]}], "entity_coreference": [], "event_coreference": [], "tokens": ["Many", "text", "generation", "applications", "require", "the", "generated", "text", "to", "be", "factually", "consistent", "with", "input", "information.", "Automatic", "evaluation", "of", "factual", "consistency", "is", "challenging.", "Previous", "work", "has", "developed", "various", "metrics", "that", "often", "depend", "on", "specific", "functions,", "such", "as", "natural", "language", "inference", "(NLI)", "or", "question", "answering", "(QA),", "trained", "on", "limited", "data.", "Those", "metrics", "thus", "can", "hardly", "assess", "diverse", "factual", "inconsistencies", "(e.g.,", "contradictions,", "hallucinations)", "that", "occur", "in", "varying", "inputs/outputs", "(e.g.,", "sentences,", "documents)", "from", "different", "tasks."], "pieces": ["Many", "text", "generation", "app", "lic", "ations", "require", "the", "generated", "text", "to", "be", "fact", "ually", "cons", "istent", "with", "input", "information", ".", "Aut", "omatic", "eval", "uation", "of", "fact", "ual", "cons", "ist", "ency", "is", "chall", "eng", "ing", ".", "Previous", "work", "has", "developed", "var", "ious", "met", "rics", "that", "often", "depend", "on", "specific", "fun", "ctions", ",", "such", "as", "natural", "language", "in", "ference", "(", "N", "LI", ")", "or", "question", "ans", "w", "ering", "(", "Q", "A", "),", "trained", "on", "limited", "data", ".", "Those", "met", "rics", "thus", "can", "hard", "ly", "ass", "ess", "d", "iverse", "fact", "ual", "inc", "ons", "ist", "encies", "(", "e", ".", "g", ".,", "cont", "rad", "ictions", ",", "hall", "uc", "inations", ")", "that", "occ", "ur", "in", "v", "ary", "ing", "input", "s", "/", "output", "s", "(", "e", ".", "g", ".,", "sent", "ences", ",", "doc", "uments", ")", "from", "different", "t", "asks", "."], "token_lens": [1, 1, 1, 3, 1, 1, 1, 1, 1, 1, 2, 2, 1, 1, 2, 2, 2, 1, 2, 3, 1, 4, 1, 1, 1, 1, 2, 2, 1, 1, 1, 1, 1, 3, 1, 1, 1, 1, 2, 4, 1, 1, 3, 4, 1, 1, 1, 2, 1, 2, 1, 1, 2, 2, 2, 2, 4, 5, 4, 4, 1, 2, 1, 3, 5, 5, 3, 3, 1, 1, 3], "sentence": "Many text generation applications require the generated text to be factually consistent with input information. Automatic evaluation of factual consistency is challenging. Previous work has developed various metrics that often depend on specific functions, such as natural language inference (NLI) or question answering (QA), trained on limited data. Those metrics thus can hardly assess diverse factual inconsistencies (e.g., contradictions, hallucinations) that occur in varying inputs/outputs (e.g., sentences, documents) from different tasks.", "sentence_starts": [0]}
{"doc_id": "ACL_23_P_634", "wnd_id": "ACL_23_P_634-1", "entity_mentions": [{"id": "ACL_23_P_634-1-E0", "text": "we", "start": 3, "end": 4, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_634-1-E1", "text": "AlignScore is based on a general function of information alignment between two arbitrary text pieces", "start": 21, "end": 36, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_634-1-E2", "text": "Crucially, we develop a unified training framework of the alignment function by integrating a large diversity of data sources", "start": 36, "end": 55, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_634-1-E3", "text": "resulting in 4.7M training examples from 7 well-established tasks (NLI, QA, paraphrasing, fact verification, information retrieval, semantic similarity, and summarization)", "start": 55, "end": 75, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_634-1-E4", "text": "AlignScore", "start": 5, "end": 6, "entity_type": "UNK", "mention_type": "UNK"}], "relation_mentions": [], "event_mentions": [{"event_type": "Methods/Approach", "id": "ACL_23_P_634-1-EV0", "trigger": {"text": "propose", "start": 4, "end": 5}, "arguments": [{"entity_id": "ACL_23_P_634-1-E0", "text": "we", "role": "Agent"}, {"entity_id": "ACL_23_P_634-1-E1", "text": "AlignScore is based on a general function of information alignment between two arbitrary text pieces", "role": "Method"}, {"entity_id": "ACL_23_P_634-1-E2", "text": "Crucially, we develop a unified training framework of the alignment function by integrating a large diversity of data sources", "role": "Method"}, {"entity_id": "ACL_23_P_634-1-E3", "text": "resulting in 4.7M training examples from 7 well-established tasks (NLI, QA, paraphrasing, fact verification, information retrieval, semantic similarity, and summarization)", "role": "Results"}, {"entity_id": "ACL_23_P_634-1-E4", "text": "AlignScore", "role": "PrimaryObject"}]}], "entity_coreference": [], "event_coreference": [], "tokens": ["In", "this", "paper,", "we", "propose", "AlignScore,", "a", "new", "holistic", "metric", "that", "applies", "to", "a", "variety", "of", "factual", "inconsistency", "scenarios", "as", "above.", "AlignScore", "is", "based", "on", "a", "general", "function", "of", "information", "alignment", "between", "two", "arbitrary", "text", "pieces.", "Crucially,", "we", "develop", "a", "unified", "training", "framework", "of", "the", "alignment", "function", "by", "integrating", "a", "large", "diversity", "of", "data", "sources,", "resulting", "in", "4.7M", "training", "examples", "from", "7", "well-established", "tasks", "(NLI,", "QA,", "paraphrasing,", "fact", "verification,", "information", "retrieval,", "semantic", "similarity,", "and", "summarization)."], "pieces": ["In", "this", "paper", ",", "we", "pro", "pose", "Al", "ign", "Score", ",", "a", "new", "hol", "istic", "met", "ric", "that", "app", "lies", "to", "a", "var", "iety", "of", "fact", "ual", "inc", "ons", "ist", "ency", "sc", "en", "arios", "as", "above", ".", "Al", "ign", "Score", "is", "based", "on", "a", "general", "function", "of", "information", "al", "ignment", "between", "two", "ar", "bit", "rary", "text", "pieces", ".", "Cru", "cially", ",", "we", "develop", "a", "un", "ified", "training", "framework", "of", "the", "al", "ignment", "function", "by", "integ", "rating", "a", "large", "d", "iversity", "of", "data", "s", "ources", ",", "result", "ing", "in", "4", ".", "7", "M", "training", "ex", "amples", "from", "7", "well", "-", "established", "t", "asks", "(", "N", "LI", ",", "Q", "A", ",", "par", "aph", "r", "asing", ",", "fact", "ver", "ification", ",", "information", "ret", "ri", "eval", ",", "sem", "antic", "similar", "ity", ",", "and", "sum", "mar", "ization", ")."], "token_lens": [1, 1, 2, 1, 2, 4, 1, 1, 2, 2, 1, 2, 1, 1, 2, 1, 2, 4, 3, 1, 2, 3, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 3, 1, 2, 3, 1, 1, 1, 2, 1, 1, 1, 1, 2, 1, 1, 2, 1, 1, 2, 1, 1, 3, 2, 1, 4, 1, 2, 1, 1, 3, 2, 4, 3, 5, 1, 3, 1, 4, 2, 3, 1, 4], "sentence": "In this paper, we propose AlignScore, a new holistic metric that applies to a variety of factual inconsistency scenarios as above. AlignScore is based on a general function of information alignment between two arbitrary text pieces. Crucially, we develop a unified training framework of the alignment function by integrating a large diversity of data sources, resulting in 4.7M training examples from 7 well-established tasks (NLI, QA, paraphrasing, fact verification, information retrieval, semantic similarity, and summarization).", "sentence_starts": [0]}
{"doc_id": "ACL_23_P_634", "wnd_id": "ACL_23_P_634-2", "entity_mentions": [{"id": "ACL_23_P_634-2-E0", "text": "We", "start": 0, "end": 1, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_634-2-E1", "text": "AlignScore achieves substantial improvement over a wide range of previous metrics", "start": 23, "end": 34, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_634-2-E2", "text": "Moreover, AlignScore (355M parameters) matches or even outperforms metrics based on ChatGPT and GPT-4 that are orders of magnitude larger", "start": 34, "end": 54, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_634-2-E3", "text": "extensive experiments on large-scale benchmarks", "start": 2, "end": 7, "entity_type": "UNK", "mention_type": "UNK"}], "relation_mentions": [], "event_mentions": [{"event_type": "Results/Findings", "id": "ACL_23_P_634-2-EV0", "trigger": {"text": "conduct", "start": 1, "end": 2}, "arguments": [{"entity_id": "ACL_23_P_634-2-E0", "text": "We", "role": "Agent"}, {"entity_id": "ACL_23_P_634-2-E1", "text": "AlignScore achieves substantial improvement over a wide range of previous metrics", "role": "Results"}, {"entity_id": "ACL_23_P_634-2-E2", "text": "Moreover, AlignScore (355M parameters) matches or even outperforms metrics based on ChatGPT and GPT-4 that are orders of magnitude larger", "role": "Results"}, {"entity_id": "ACL_23_P_634-2-E3", "text": "extensive experiments on large-scale benchmarks", "role": "PrimaryObject"}]}], "entity_coreference": [], "event_coreference": [], "tokens": ["We", "conduct", "extensive", "experiments", "on", "large-scale", "benchmarks", "including", "22", "evaluation", "datasets,", "where", "19", "of", "the", "datasets", "were", "never", "seen", "in", "the", "alignment", "training.", "AlignScore", "achieves", "substantial", "improvement", "over", "a", "wide", "range", "of", "previous", "metrics.", "Moreover,", "AlignScore", "(355M", "parameters)", "matches", "or", "even", "outperforms", "metrics", "based", "on", "ChatGPT", "and", "GPT-4", "that", "are", "orders", "of", "magnitude", "larger."], "pieces": ["We", "conduct", "ext", "ensive", "exper", "iments", "on", "large", "-", "scale", "bench", "marks", "including", "22", "eval", "uation", "dat", "as", "ets", ",", "where", "19", "of", "the", "dat", "as", "ets", "were", "never", "seen", "in", "the", "al", "ignment", "training", ".", "Al", "ign", "Score", "ach", "ieves", "sub", "stantial", "improve", "ment", "over", "a", "wide", "range", "of", "pre", "vious", "met", "rics", ".", "Moreover", ",", "Al", "ign", "Score", "(", "355", "M", "param", "eters", ")", "mat", "ches", "or", "even", "out", "per", "forms", "met", "rics", "based", "on", "Chat", "G", "PT", "and", "G", "PT", "-", "4", "that", "are", "orders", "of", "m", "agn", "itude", "larg", "er", "."], "token_lens": [1, 1, 2, 2, 1, 3, 2, 1, 1, 2, 4, 1, 1, 1, 1, 3, 1, 1, 1, 1, 1, 2, 2, 3, 2, 2, 2, 1, 1, 1, 1, 1, 2, 3, 2, 3, 3, 3, 2, 1, 1, 3, 2, 1, 1, 3, 1, 4, 1, 1, 1, 1, 3, 3], "sentence": "We conduct extensive experiments on large-scale benchmarks including 22 evaluation datasets, where 19 of the datasets were never seen in the alignment training. AlignScore achieves substantial improvement over a wide range of previous metrics. Moreover, AlignScore (355M parameters) matches or even outperforms metrics based on ChatGPT and GPT-4 that are orders of magnitude larger.", "sentence_starts": [0]}
{"doc_id": "ACL_23_P_859", "wnd_id": "ACL_23_P_859-0", "entity_mentions": [{"id": "ACL_23_P_859-0-E0", "text": "Large language models (LLMs)", "start": 0, "end": 4, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_859-0-E1", "text": "a remarkable ability", "start": 15, "end": 18, "entity_type": "UNK", "mention_type": "UNK"}], "relation_mentions": [], "event_mentions": [{"event_type": "Background/Introduction", "id": "ACL_23_P_859-0-EV0", "trigger": {"text": "exhibit", "start": 14, "end": 15}, "arguments": [{"entity_id": "ACL_23_P_859-0-E0", "text": "Large language models (LLMs)", "role": "Agent"}, {"entity_id": "ACL_23_P_859-0-E1", "text": "a remarkable ability", "role": "PrimaryObject"}]}], "entity_coreference": [], "event_coreference": [], "tokens": ["Large", "language", "models", "(LLMs)", "that", "have", "been", "trained", "on", "multilingual", "but", "not", "parallel", "text", "exhibit", "a", "remarkable", "ability", "to", "translate", "between", "languages."], "pieces": ["Large", "language", "models", "(", "LL", "Ms", ")", "that", "have", "been", "trained", "on", "mult", "ilingual", "but", "not", "par", "allel", "text", "ex", "hibit", "a", "rem", "arkable", "ability", "to", "trans", "late", "between", "l", "anguages", "."], "token_lens": [1, 1, 1, 4, 1, 1, 1, 1, 1, 2, 1, 1, 2, 1, 2, 1, 2, 1, 1, 2, 1, 3], "sentence": "Large language models (LLMs) that have been trained on multilingual but not parallel text exhibit a remarkable ability to translate between languages.", "sentence_starts": [0]}
{"doc_id": "ACL_23_P_859", "wnd_id": "ACL_23_P_859-1", "entity_mentions": [{"id": "ACL_23_P_859-1-E0", "text": "We", "start": 0, "end": 1, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_859-1-E1", "text": "We investigate various strategies for choosing translation examples for few-shot prompting, concluding that example quality is the most important factor", "start": 28, "end": 48, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_859-1-E2", "text": "Using optimized prompts, we revisit previous assessments of PaLM\u2019s MT capabilities with more recent test sets, modern MT metrics, and human evaluation", "start": 48, "end": 70, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_859-1-E3", "text": "its performance, while impressive, still lags that of state-of-the-art supervised systems", "start": 73, "end": 84, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_859-1-E4", "text": "this ability", "start": 2, "end": 4, "entity_type": "UNK", "mention_type": "UNK"}], "relation_mentions": [], "event_mentions": [{"event_type": "Methods/Approach", "id": "ACL_23_P_859-1-EV0", "trigger": {"text": "probe", "start": 1, "end": 2}, "arguments": [{"entity_id": "ACL_23_P_859-1-E0", "text": "We", "role": "Agent"}, {"entity_id": "ACL_23_P_859-1-E1", "text": "We investigate various strategies for choosing translation examples for few-shot prompting, concluding that example quality is the most important factor", "role": "Method"}, {"entity_id": "ACL_23_P_859-1-E2", "text": "Using optimized prompts, we revisit previous assessments of PaLM\u2019s MT capabilities with more recent test sets, modern MT metrics, and human evaluation", "role": "Method"}, {"entity_id": "ACL_23_P_859-1-E3", "text": "its performance, while impressive, still lags that of state-of-the-art supervised systems", "role": "Results"}, {"entity_id": "ACL_23_P_859-1-E4", "text": "this ability", "role": "PrimaryObject"}]}], "entity_coreference": [], "event_coreference": [], "tokens": ["We", "probe", "this", "ability", "in", "an", "in-depth", "study", "of", "the", "pathways", "language", "model", "(PaLM),", "which", "has", "demonstrated", "the", "strongest", "machine", "translation", "(MT)", "performance", "among", "similarly-trained", "LLMs", "to", "date.", "We", "investigate", "various", "strategies", "for", "choosing", "translation", "examples", "for", "few-shot", "prompting,", "concluding", "that", "example", "quality", "is", "the", "most", "important", "factor.", "Using", "optimized", "prompts,", "we", "revisit", "previous", "assessments", "of", "PaLM\u2019s", "MT", "capabilities", "with", "more", "recent", "test", "sets,", "modern", "MT", "metrics,", "and", "human", "evaluation,", "and", "find", "that", "its", "performance,", "while", "impressive,", "still", "lags", "that", "of", "state-of-the-art", "supervised", "systems."], "pieces": ["We", "pro", "be", "this", "ability", "in", "an", "in", "-", "depth", "study", "of", "the", "path", "ways", "language", "model", "(", "Pa", "LM", "),", "which", "has", "demon", "str", "ated", "the", "strong", "est", "machine", "translation", "(", "MT", ")", "performance", "among", "similar", "ly", "-", "trained", "LL", "Ms", "to", "date", ".", "We", "invest", "igate", "var", "ious", "str", "ateg", "ies", "for", "cho", "osing", "translation", "ex", "amples", "for", "few", "-", "shot", "prom", "pt", "ing", ",", "con", "cluding", "that", "example", "quality", "is", "the", "most", "important", "factor", ".", "Using", "optim", "ized", "prom", "pt", "s", ",", "we", "re", "vis", "it", "pre", "vious", "ass", "ess", "ments", "of", "Pa", "LM", "\u00e2\u0122", "\u013b", "s", "MT", "cap", "abilities", "with", "more", "recent", "test", "sets", ",", "modern", "MT", "met", "rics", ",", "and", "human", "eval", "uation", ",", "and", "find", "that", "its", "performance", ",", "while", "imp", "ressive", ",", "still", "l", "ags", "that", "of", "state", "-", "of", "-", "the", "-", "art", "super", "vised", "system", "s", "."], "token_lens": [1, 2, 1, 1, 1, 1, 3, 1, 1, 1, 2, 1, 1, 4, 1, 1, 3, 1, 2, 1, 1, 3, 1, 1, 4, 2, 1, 2, 1, 2, 2, 3, 1, 2, 1, 2, 1, 3, 4, 2, 1, 1, 1, 1, 1, 1, 1, 2, 1, 2, 4, 1, 3, 2, 3, 1, 5, 1, 2, 1, 1, 1, 1, 2, 1, 1, 3, 1, 1, 3, 1, 1, 1, 1, 2, 1, 3, 1, 2, 1, 1, 7, 2, 3], "sentence": "We probe this ability in an in-depth study of the pathways language model (PaLM), which has demonstrated the strongest machine translation (MT) performance among similarly-trained LLMs to date. We investigate various strategies for choosing translation examples for few-shot prompting, concluding that example quality is the most important factor. Using optimized prompts, we revisit previous assessments of PaLM\u2019s MT capabilities with more recent test sets, modern MT metrics, and human evaluation, and find that its performance, while impressive, still lags that of state-of-the-art supervised systems.", "sentence_starts": [0]}
{"doc_id": "ACL_23_P_859", "wnd_id": "ACL_23_P_859-2", "entity_mentions": [{"id": "ACL_23_P_859-2-E0", "text": "We", "start": 0, "end": 1, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_859-2-E1", "text": "prospects for future work", "start": 16, "end": 20, "entity_type": "UNK", "mention_type": "UNK"}], "relation_mentions": [], "event_mentions": [{"event_type": "Conclusions/Implications", "id": "ACL_23_P_859-2-EV0", "trigger": {"text": "conclude", "start": 1, "end": 2}, "arguments": [{"entity_id": "ACL_23_P_859-2-E0", "text": "We", "role": "Agent"}, {"entity_id": "ACL_23_P_859-2-E1", "text": "prospects for future work", "role": "Implications"}]}], "entity_coreference": [], "event_coreference": [], "tokens": ["We", "conclude", "by", "providing", "an", "analysis", "of", "PaLM\u2019s", "MT", "output", "which", "reveals", "some", "interesting", "properties", "and", "prospects", "for", "future", "work."], "pieces": ["We", "con", "clude", "by", "prov", "iding", "an", "analysis", "of", "Pa", "LM", "\u00e2\u0122", "\u013b", "s", "MT", "output", "which", "reve", "als", "some", "interesting", "properties", "and", "pro", "spect", "s", "for", "future", "work", "."], "token_lens": [1, 2, 1, 2, 1, 1, 1, 5, 1, 1, 1, 2, 1, 1, 1, 1, 3, 1, 1, 2], "sentence": "We conclude by providing an analysis of PaLM\u2019s MT output which reveals some interesting properties and prospects for future work.", "sentence_starts": [0]}
{"doc_id": "ACL_23_P_657", "wnd_id": "ACL_23_P_657-0", "entity_mentions": [{"id": "ACL_23_P_657-0-E0", "text": "Second language acquisition (SLA) research", "start": 0, "end": 5, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_657-0-E1", "text": "Effects of such transfer can be positive (facilitating acquisition) or negative (impeding acquisition)", "start": 30, "end": 43, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_657-0-E2", "text": "NLP literature has not given enough attention to the phenomenon of negative transfer", "start": 46, "end": 59, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_657-0-E3", "text": "cross-linguistic transfer", "start": 8, "end": 10, "entity_type": "UNK", "mention_type": "UNK"}], "relation_mentions": [], "event_mentions": [{"event_type": "Background/Introduction", "id": "ACL_23_P_657-0-EV0", "trigger": {"text": "has extensively studied", "start": 5, "end": 8}, "arguments": [{"entity_id": "ACL_23_P_657-0-E0", "text": "Second language acquisition (SLA) research", "role": "Agent"}, {"entity_id": "ACL_23_P_657-0-E1", "text": "Effects of such transfer can be positive (facilitating acquisition) or negative (impeding acquisition)", "role": "Context"}, {"entity_id": "ACL_23_P_657-0-E2", "text": "NLP literature has not given enough attention to the phenomenon of negative transfer", "role": "Challenge"}, {"entity_id": "ACL_23_P_657-0-E3", "text": "cross-linguistic transfer", "role": "PrimaryObject"}]}], "entity_coreference": [], "event_coreference": [], "tokens": ["Second", "language", "acquisition", "(SLA)", "research", "has", "extensively", "studied", "cross-linguistic", "transfer,", "the", "influence", "of", "linguistic", "structure", "of", "a", "speaker\u2019s", "native", "language", "[L1]", "on", "the", "successful", "acquisition", "of", "a", "foreign", "language", "[L2].", "Effects", "of", "such", "transfer", "can", "be", "positive", "(facilitating", "acquisition)", "or", "negative", "(impeding", "acquisition).", "We", "find", "that", "NLP", "literature", "has", "not", "given", "enough", "attention", "to", "the", "phenomenon", "of", "negative", "transfer."], "pieces": ["Second", "language", "acqu", "isition", "(", "SL", "A", ")", "research", "has", "ext", "ensive", "ly", "stud", "ied", "cross", "-", "ling", "u", "istic", "transfer", ",", "the", "inf", "luence", "of", "ling", "u", "istic", "st", "ructure", "of", "a", "spe", "aker", "\u00e2\u0122", "\u013b", "s", "native", "language", "[", "L", "1", "]", "on", "the", "successful", "acqu", "isition", "of", "a", "foreign", "language", "[", "L", "2", "].", "Effects", "of", "such", "transfer", "can", "be", "positive", "(", "fac", "ilitating", "acqu", "isition", ")", "or", "negative", "(", "imp", "eding", "acqu", "isition", ").", "We", "find", "that", "N", "LP", "liter", "ature", "has", "not", "given", "enough", "att", "ention", "to", "the", "phen", "omen", "on", "of", "negative", "transfer", "."], "token_lens": [1, 1, 2, 4, 1, 1, 3, 2, 5, 2, 1, 2, 1, 3, 2, 1, 1, 5, 1, 1, 4, 1, 1, 1, 2, 1, 1, 1, 1, 4, 1, 1, 1, 1, 1, 1, 1, 3, 3, 1, 1, 3, 3, 1, 1, 1, 2, 2, 1, 1, 1, 1, 2, 1, 1, 3, 1, 1, 2], "sentence": "Second language acquisition (SLA) research has extensively studied cross-linguistic transfer, the influence of linguistic structure of a speaker\u2019s native language [L1] on the successful acquisition of a foreign language [L2]. Effects of such transfer can be positive (facilitating acquisition) or negative (impeding acquisition). We find that NLP literature has not given enough attention to the phenomenon of negative transfer.", "sentence_starts": [0]}
{"doc_id": "ACL_23_P_657", "wnd_id": "ACL_23_P_657-1", "entity_mentions": [{"id": "ACL_23_P_657-1-E0", "text": "we", "start": 13, "end": 14, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_657-1-E1", "text": "To understand patterns of both positive and negative transfer between L1 and L2", "start": 0, "end": 13, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_657-1-E2", "text": "we build a Multilingual Age Ordered CHILDES (MAO-CHILDES)", "start": 22, "end": 30, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_657-1-E3", "text": "a dataset consisting of 5 typologically diverse languages, i.e., German, French, Polish, Indonesian, and Japanese", "start": 31, "end": 46, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_657-1-E4", "text": "sequential second language acquisition in LMs", "start": 15, "end": 21, "entity_type": "UNK", "mention_type": "UNK"}], "relation_mentions": [], "event_mentions": [{"event_type": "Methods/Approach", "id": "ACL_23_P_657-1-EV0", "trigger": {"text": "model", "start": 14, "end": 15}, "arguments": [{"entity_id": "ACL_23_P_657-1-E0", "text": "we", "role": "Agent"}, {"entity_id": "ACL_23_P_657-1-E1", "text": "To understand patterns of both positive and negative transfer between L1 and L2", "role": "Purpose"}, {"entity_id": "ACL_23_P_657-1-E2", "text": "we build a Multilingual Age Ordered CHILDES (MAO-CHILDES)", "role": "Method"}, {"entity_id": "ACL_23_P_657-1-E3", "text": "a dataset consisting of 5 typologically diverse languages, i.e., German, French, Polish, Indonesian, and Japanese", "role": "Analysis"}, {"entity_id": "ACL_23_P_657-1-E4", "text": "sequential second language acquisition in LMs", "role": "PrimaryObject"}]}], "entity_coreference": [], "event_coreference": [], "tokens": ["To", "understand", "patterns", "of", "both", "positive", "and", "negative", "transfer", "between", "L1", "and", "L2,", "we", "model", "sequential", "second", "language", "acquisition", "in", "LMs.", "Further,", "we", "build", "a", "Multilingual", "Age", "Ordered", "CHILDES", "(MAO-CHILDES)", "\u2014", "a", "dataset", "consisting", "of", "5", "typologically", "diverse", "languages,", "i.e.,", "German,", "French,", "Polish,", "Indonesian,", "and", "Japanese", "\u2014", "to", "understand", "the", "degree", "to", "which", "native", "Child-Directed", "Speech", "(CDS)", "[L1]", "can", "help", "or", "conflict", "with", "English", "language", "acquisition", "[L2]."], "pieces": ["To", "under", "stand", "pattern", "s", "of", "both", "positive", "and", "negative", "transfer", "between", "L", "1", "and", "L", "2", ",", "we", "model", "sequ", "ential", "second", "language", "acqu", "isition", "in", "L", "Ms", ".", "Further", ",", "we", "build", "a", "Mult", "ilingual", "Age", "Ord", "ered", "CH", "ILD", "ES", "(", "MA", "O", "-", "CH", "ILD", "ES", ")", "\u00e2\u0122\u0136", "a", "dat", "as", "et", "cons", "isting", "of", "5", "typ", "ologically", "d", "iverse", "l", "anguages", ",", "i", ".", "e", ".,", "German", ",", "French", ",", "Pol", "ish", ",", "Ind", "ones", "ian", ",", "and", "Japanese", "\u00e2\u0122\u0136", "to", "under", "stand", "the", "degree", "to", "which", "native", "Child", "-", "Direct", "ed", "Spe", "ech", "(", "C", "DS", ")", "[", "L", "1", "]", "can", "help", "or", "conf", "lict", "with", "English", "language", "acqu", "isition", "[", "L", "2", "]."], "token_lens": [1, 2, 2, 1, 1, 1, 1, 1, 1, 1, 2, 1, 3, 1, 1, 2, 1, 1, 2, 1, 3, 2, 1, 1, 1, 2, 1, 2, 3, 8, 1, 1, 3, 2, 1, 1, 2, 2, 3, 4, 2, 2, 3, 4, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 4, 2, 4, 4, 1, 1, 1, 2, 1, 1, 1, 2, 4], "sentence": "To understand patterns of both positive and negative transfer between L1 and L2, we model sequential second language acquisition in LMs. Further, we build a Multilingual Age Ordered CHILDES (MAO-CHILDES) \u2014 a dataset consisting of 5 typologically diverse languages, i.e., German, French, Polish, Indonesian, and Japanese \u2014 to understand the degree to which native Child-Directed Speech (CDS) [L1] can help or conflict with English language acquisition [L2].", "sentence_starts": [0]}
{"doc_id": "ACL_23_P_657", "wnd_id": "ACL_23_P_657-2", "entity_mentions": [{"id": "ACL_23_P_657-2-E0", "text": "we", "start": 7, "end": 8, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_657-2-E1", "text": "To examine the impact of native CDS", "start": 0, "end": 7, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_657-2-E2", "text": "as in human SLA, language family distance predicts more negative transfer.", "start": 25, "end": 36, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_657-2-E3", "text": "conversational speech data shows greater facilitation for language acquisition than scripted speech data", "start": 40, "end": 53, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_657-2-E4", "text": "the TILT-based cross lingual transfer learning approach", "start": 9, "end": 16, "entity_type": "UNK", "mention_type": "UNK"}], "relation_mentions": [], "event_mentions": [{"event_type": "Results/Findings", "id": "ACL_23_P_657-2-EV0", "trigger": {"text": "use", "start": 8, "end": 9}, "arguments": [{"entity_id": "ACL_23_P_657-2-E0", "text": "we", "role": "Agent"}, {"entity_id": "ACL_23_P_657-2-E1", "text": "To examine the impact of native CDS", "role": "Purpose"}, {"entity_id": "ACL_23_P_657-2-E2", "text": "as in human SLA, language family distance predicts more negative transfer.", "role": "Results"}, {"entity_id": "ACL_23_P_657-2-E3", "text": "conversational speech data shows greater facilitation for language acquisition than scripted speech data", "role": "Results"}, {"entity_id": "ACL_23_P_657-2-E4", "text": "the TILT-based cross lingual transfer learning approach", "role": "PrimaryObject"}]}], "entity_coreference": [], "event_coreference": [], "tokens": ["To", "examine", "the", "impact", "of", "native", "CDS,", "we", "use", "the", "TILT-based", "cross", "lingual", "transfer", "learning", "approach", "established", "by", "Papadimitriou", "and", "Jurafsky", "(2020)", "and", "find", "that,", "as", "in", "human", "SLA,", "language", "family", "distance", "predicts", "more", "negative", "transfer.", "Additionally,", "we", "find", "that", "conversational", "speech", "data", "shows", "greater", "facilitation", "for", "language", "acquisition", "than", "scripted", "speech", "data."], "pieces": ["To", "ex", "amine", "the", "impact", "of", "native", "C", "DS", ",", "we", "use", "the", "T", "IL", "T", "-", "based", "cross", "ling", "ual", "transfer", "learning", "appro", "ach", "established", "by", "P", "ap", "ad", "im", "itri", "ou", "and", "J", "ur", "af", "sky", "(", "2020", ")", "and", "find", "that", ",", "as", "in", "human", "SL", "A", ",", "language", "family", "distance", "pred", "icts", "more", "negative", "transfer", ".", "Additionally", ",", "we", "find", "that", "con", "vers", "ational", "speech", "data", "shows", "great", "er", "fac", "ilitation", "for", "language", "acqu", "isition", "than", "script", "ed", "speech", "data", "."], "token_lens": [1, 2, 1, 1, 1, 1, 3, 1, 1, 1, 5, 1, 2, 1, 1, 2, 1, 1, 6, 1, 4, 3, 1, 1, 2, 1, 1, 1, 3, 1, 1, 1, 2, 1, 1, 2, 2, 1, 1, 1, 3, 1, 1, 1, 2, 2, 1, 1, 2, 1, 2, 1, 2], "sentence": "To examine the impact of native CDS, we use the TILT-based cross lingual transfer learning approach established by Papadimitriou and Jurafsky (2020) and find that, as in human SLA, language family distance predicts more negative transfer. Additionally, we find that conversational speech data shows greater facilitation for language acquisition than scripted speech data.", "sentence_starts": [0]}
{"doc_id": "ACL_23_P_657", "wnd_id": "ACL_23_P_657-3", "entity_mentions": [{"id": "ACL_23_P_657-3-E0", "text": "Our findings", "start": 0, "end": 2, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_657-3-E1", "text": "using our novel Transformer-based SLA models", "start": 6, "end": 12, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_657-3-E2", "text": "further research", "start": 4, "end": 6, "entity_type": "UNK", "mention_type": "UNK"}], "relation_mentions": [], "event_mentions": [{"event_type": "Conclusions/Implications", "id": "ACL_23_P_657-3-EV0", "trigger": {"text": "call for", "start": 2, "end": 4}, "arguments": [{"entity_id": "ACL_23_P_657-3-E0", "text": "Our findings", "role": "Agent"}, {"entity_id": "ACL_23_P_657-3-E1", "text": "using our novel Transformer-based SLA models", "role": "Method"}, {"entity_id": "ACL_23_P_657-3-E2", "text": "further research", "role": "PrimaryObject"}]}], "entity_coreference": [], "event_coreference": [], "tokens": ["Our", "findings", "call", "for", "further", "research", "using", "our", "novel", "Transformer-based", "SLA", "models", "and", "we", "would", "like", "to", "encourage", "it", "by", "releasing", "our", "code,", "data,", "and", "models."], "pieces": ["Our", "find", "ings", "call", "for", "f", "urther", "research", "using", "our", "no", "vel", "Trans", "former", "-", "based", "SL", "A", "models", "and", "we", "would", "like", "to", "enc", "ourage", "it", "by", "re", "leasing", "our", "code", ",", "data", ",", "and", "models", "."], "token_lens": [1, 2, 1, 1, 2, 1, 1, 1, 2, 4, 2, 1, 1, 1, 1, 1, 1, 2, 1, 1, 2, 1, 2, 2, 1, 2], "sentence": "Our findings call for further research using our novel Transformer-based SLA models and we would like to encourage it by releasing our code, data, and models.", "sentence_starts": [0]}
{"doc_id": "ACL_23_P_334", "wnd_id": "ACL_23_P_334-0", "entity_mentions": [{"id": "ACL_23_P_334-0-E0", "text": "progress", "start": 2, "end": 3, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_334-0-E1", "text": "e.g., replacing key question entities or shuffling table columns", "start": 30, "end": 39, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_334-0-E2", "text": "it\u2019s unclear whether, and to what extent existing Table QA models are robust to task-specific perturbations", "start": 14, "end": 30, "entity_type": "UNK", "mention_type": "UNK"}], "relation_mentions": [], "event_mentions": [{"event_type": "Background/Introduction", "id": "ACL_23_P_334-0-EV0", "trigger": {"text": "having been made", "start": 3, "end": 6}, "arguments": [{"entity_id": "ACL_23_P_334-0-E0", "text": "progress", "role": "Agent"}, {"entity_id": "ACL_23_P_334-0-E1", "text": "e.g., replacing key question entities or shuffling table columns", "role": "Analysis"}, {"entity_id": "ACL_23_P_334-0-E2", "text": "it\u2019s unclear whether, and to what extent existing Table QA models are robust to task-specific perturbations", "role": "Challenge"}]}], "entity_coreference": [], "event_coreference": [], "tokens": ["Despite", "significant", "progress", "having", "been", "made", "in", "question", "answering", "on", "tabular", "data", "(Table", "QA),", "it\u2019s", "unclear", "whether,", "and", "to", "what", "extent", "existing", "Table", "QA", "models", "are", "robust", "to", "task-specific", "perturbations,", "e.g.,", "replacing", "key", "question", "entities", "or", "shuffling", "table", "columns."], "pieces": ["Despite", "significant", "progress", "having", "been", "made", "in", "question", "ans", "w", "ering", "on", "tab", "ular", "data", "(", "Table", "Q", "A", "),", "it", "\u00e2\u0122", "\u013b", "s", "un", "clear", "whether", ",", "and", "to", "what", "ext", "ent", "existing", "Table", "Q", "A", "models", "are", "rob", "ust", "to", "task", "-", "specific", "pert", "urb", "ations", ",", "e", ".", "g", ".,", "repl", "acing", "key", "question", "ent", "ities", "or", "sh", "uff", "ling", "table", "column", "s", "."], "token_lens": [1, 1, 1, 1, 1, 1, 1, 1, 3, 1, 2, 1, 2, 3, 4, 2, 2, 1, 1, 1, 2, 1, 1, 2, 1, 1, 2, 1, 3, 4, 4, 2, 1, 1, 2, 1, 3, 1, 3], "sentence": "Despite significant progress having been made in question answering on tabular data (Table QA), it\u2019s unclear whether, and to what extent existing Table QA models are robust to task-specific perturbations, e.g., replacing key question entities or shuffling table columns.", "sentence_starts": [0]}
{"doc_id": "ACL_23_P_334", "wnd_id": "ACL_23_P_334-1", "entity_mentions": [{"id": "ACL_23_P_334-1-E0", "text": "we", "start": 9, "end": 10, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_334-1-E1", "text": "To systematically study the robustness of Table QA models", "start": 0, "end": 9, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_334-1-E2", "text": "a benchmark called RobuT", "start": 11, "end": 15, "entity_type": "UNK", "mention_type": "UNK"}], "relation_mentions": [], "event_mentions": [{"event_type": "Methods/Approach", "id": "ACL_23_P_334-1-EV0", "trigger": {"text": "propose", "start": 10, "end": 11}, "arguments": [{"entity_id": "ACL_23_P_334-1-E0", "text": "we", "role": "Agent"}, {"entity_id": "ACL_23_P_334-1-E1", "text": "To systematically study the robustness of Table QA models", "role": "Purpose"}, {"entity_id": "ACL_23_P_334-1-E2", "text": "a benchmark called RobuT", "role": "PrimaryObject"}]}], "entity_coreference": [], "event_coreference": [], "tokens": ["To", "systematically", "study", "the", "robustness", "of", "Table", "QA", "models,", "we", "propose", "a", "benchmark", "called", "RobuT,", "which", "builds", "upon", "existing", "Table", "QA", "datasets", "(WTQ,", "WikiSQL-Weak,", "and", "SQA)", "and", "includes", "human-annotated", "adversarial", "perturbations", "in", "terms", "of", "table", "header,", "table", "content,", "and", "question."], "pieces": ["To", "system", "atically", "study", "the", "rob", "ust", "ness", "of", "Table", "Q", "A", "models", ",", "we", "pro", "pose", "a", "bench", "mark", "called", "Rob", "u", "T", ",", "which", "build", "s", "upon", "existing", "Table", "Q", "A", "dat", "as", "ets", "(", "WT", "Q", ",", "Wiki", "SQL", "-", "Weak", ",", "and", "S", "Q", "A", ")", "and", "includes", "human", "-", "annot", "ated", "ad", "vers", "arial", "pert", "urb", "ations", "in", "terms", "of", "table", "header", ",", "table", "content", ",", "and", "question", "."], "token_lens": [1, 2, 1, 1, 3, 1, 1, 2, 2, 1, 2, 1, 2, 1, 4, 1, 2, 1, 1, 1, 2, 3, 4, 5, 1, 4, 1, 1, 4, 3, 3, 1, 1, 1, 1, 2, 1, 2, 1, 2], "sentence": "To systematically study the robustness of Table QA models, we propose a benchmark called RobuT, which builds upon existing Table QA datasets (WTQ, WikiSQL-Weak, and SQA) and includes human-annotated adversarial perturbations in terms of table header, table content, and question.", "sentence_starts": [0]}
{"doc_id": "ACL_23_P_334", "wnd_id": "ACL_23_P_334-2", "entity_mentions": [{"id": "ACL_23_P_334-2-E0", "text": "Our results", "start": 0, "end": 2, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_334-2-E1", "text": "both state-of-the-art Table QA models and large language models (e.g., GPT-3) with few-shot learning falter in these adversarial sets.", "start": 4, "end": 23, "entity_type": "UNK", "mention_type": "UNK"}], "relation_mentions": [], "event_mentions": [{"event_type": "Results/Findings", "id": "ACL_23_P_334-2-EV0", "trigger": {"text": "indicate", "start": 2, "end": 3}, "arguments": [{"entity_id": "ACL_23_P_334-2-E0", "text": "Our results", "role": "Agent"}, {"entity_id": "ACL_23_P_334-2-E1", "text": "both state-of-the-art Table QA models and large language models (e.g., GPT-3) with few-shot learning falter in these adversarial sets.", "role": "PrimaryObject"}]}], "entity_coreference": [], "event_coreference": [], "tokens": ["Our", "results", "indicate", "that", "both", "state-of-the-art", "Table", "QA", "models", "and", "large", "language", "models", "(e.g.,", "GPT-3)", "with", "few-shot", "learning", "falter", "in", "these", "adversarial", "sets."], "pieces": ["Our", "results", "ind", "icate", "that", "both", "state", "-", "of", "-", "the", "-", "art", "Table", "Q", "A", "models", "and", "large", "language", "models", "(", "e", ".", "g", ".,", "G", "PT", "-", "3", ")", "with", "few", "-", "shot", "learning", "fal", "ter", "in", "these", "ad", "vers", "arial", "sets", "."], "token_lens": [1, 1, 2, 1, 1, 7, 1, 2, 1, 1, 1, 1, 1, 5, 5, 1, 3, 1, 2, 1, 1, 3, 2], "sentence": "Our results indicate that both state-of-the-art Table QA models and large language models (e.g., GPT-3) with few-shot learning falter in these adversarial sets.", "sentence_starts": [0]}
{"doc_id": "ACL_23_P_334", "wnd_id": "ACL_23_P_334-3", "entity_mentions": [{"id": "ACL_23_P_334-3-E0", "text": "We", "start": 0, "end": 1, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_334-3-E1", "text": "significantly improves the robustness of Table QA models.", "start": 19, "end": 27, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_334-3-E2", "text": "this problem", "start": 4, "end": 6, "entity_type": "UNK", "mention_type": "UNK"}], "relation_mentions": [], "event_mentions": [{"event_type": "Conclusions/Implications", "id": "ACL_23_P_334-3-EV0", "trigger": {"text": "propose to address", "start": 1, "end": 4}, "arguments": [{"entity_id": "ACL_23_P_334-3-E0", "text": "We", "role": "Agent"}, {"entity_id": "ACL_23_P_334-3-E1", "text": "significantly improves the robustness of Table QA models.", "role": "Results"}, {"entity_id": "ACL_23_P_334-3-E2", "text": "this problem", "role": "PrimaryObject"}]}], "entity_coreference": [], "event_coreference": [], "tokens": ["We", "propose", "to", "address", "this", "problem", "by", "using", "large", "language", "models", "to", "generate", "adversarial", "examples", "to", "enhance", "training,", "which", "significantly", "improves", "the", "robustness", "of", "Table", "QA", "models."], "pieces": ["We", "pro", "pose", "to", "address", "this", "problem", "by", "using", "large", "language", "models", "to", "gener", "ate", "ad", "vers", "arial", "ex", "amples", "to", "enh", "ance", "training", ",", "which", "sign", "ificantly", "impro", "ves", "the", "rob", "ust", "ness", "of", "Table", "Q", "A", "models", "."], "token_lens": [1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 3, 2, 1, 2, 2, 1, 2, 2, 1, 3, 1, 1, 2, 2], "sentence": "We propose to address this problem by using large language models to generate adversarial examples to enhance training, which significantly improves the robustness of Table QA models.", "sentence_starts": [0]}
{"doc_id": "ACL_23_P_725", "wnd_id": "ACL_23_P_725-0", "entity_mentions": [{"id": "ACL_23_P_725-0-E0", "text": "Backdoor attacks", "start": 0, "end": 2, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_725-0-E1", "text": "By providing poisoned training data, the adversary can embed a \u201cbackdoor\u201d into the victim model, which allows input instances satisfying certain textual patterns (e.g., containing a keyword) to be predicted as a target label of the adversary\u2019s choice", "start": 10, "end": 48, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_725-0-E2", "text": "an emerging threat", "start": 4, "end": 7, "entity_type": "UNK", "mention_type": "UNK"}], "relation_mentions": [], "event_mentions": [{"event_type": "Background/Introduction", "id": "ACL_23_P_725-0-EV0", "trigger": {"text": "become", "start": 3, "end": 4}, "arguments": [{"entity_id": "ACL_23_P_725-0-E0", "text": "Backdoor attacks", "role": "Agent"}, {"entity_id": "ACL_23_P_725-0-E1", "text": "By providing poisoned training data, the adversary can embed a \u201cbackdoor\u201d into the victim model, which allows input instances satisfying certain textual patterns (e.g., containing a keyword) to be predicted as a target label of the adversary\u2019s choice", "role": "Context"}, {"entity_id": "ACL_23_P_725-0-E2", "text": "an emerging threat", "role": "PrimaryObject"}]}], "entity_coreference": [], "event_coreference": [], "tokens": ["Backdoor", "attacks", "have", "become", "an", "emerging", "threat", "to", "NLP", "systems.", "By", "providing", "poisoned", "training", "data,", "the", "adversary", "can", "embed", "a", "\u201cbackdoor\u201d", "into", "the", "victim", "model,", "which", "allows", "input", "instances", "satisfying", "certain", "textual", "patterns", "(e.g.,", "containing", "a", "keyword)", "to", "be", "predicted", "as", "a", "target", "label", "of", "the", "adversary\u2019s", "choice."], "pieces": ["Back", "door", "attacks", "have", "bec", "ome", "an", "emer", "ging", "threat", "to", "N", "LP", "system", "s", ".", "By", "prov", "iding", "po", "ison", "ed", "training", "data", ",", "the", "ad", "vers", "ary", "can", "embed", "a", "\u00e2\u0122", "\u013e", "back", "door", "\u00e2\u0122", "\u013f", "into", "the", "vict", "im", "model", ",", "which", "allows", "input", "inst", "ances", "s", "atisf", "ying", "certain", "text", "ual", "pattern", "s", "(", "e", ".", "g", ".,", "containing", "a", "key", "word", ")", "to", "be", "pred", "icted", "as", "a", "target", "label", "of", "the", "ad", "vers", "ary", "\u00e2\u0122", "\u013b", "s", "choice", "."], "token_lens": [2, 1, 1, 2, 1, 2, 1, 1, 2, 3, 1, 2, 3, 1, 2, 1, 3, 1, 1, 1, 6, 1, 1, 2, 2, 1, 1, 1, 2, 3, 1, 2, 2, 5, 1, 1, 3, 1, 1, 2, 1, 1, 1, 1, 1, 1, 6, 2], "sentence": "Backdoor attacks have become an emerging threat to NLP systems. By providing poisoned training data, the adversary can embed a \u201cbackdoor\u201d into the victim model, which allows input instances satisfying certain textual patterns (e.g., containing a keyword) to be predicted as a target label of the adversary\u2019s choice.", "sentence_starts": [0]}
{"doc_id": "ACL_23_P_725", "wnd_id": "ACL_23_P_725-1", "entity_mentions": [{"id": "ACL_23_P_725-1-E0", "text": "we", "start": 3, "end": 4, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_725-1-E1", "text": "These trigger words are iteratively identified and injected into the target-label instances through natural word-level perturbations", "start": 56, "end": 72, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_725-1-E2", "text": "The poisoned training data instruct the victim model to predict the target label on inputs containing trigger words, forming the backdoor", "start": 72, "end": 93, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_725-1-E3", "text": "We propose BITE, a backdoor attack that poisons the training data to establish strong correlations between the target label and a set of \u201ctrigger words\u201d", "start": 31, "end": 56, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_725-1-E4", "text": "it is possible to design a backdoor attack that is both stealthy (i.e., hard to notice) and effective (i.e., has a high attack success rate)", "start": 6, "end": 31, "entity_type": "UNK", "mention_type": "UNK"}], "relation_mentions": [], "event_mentions": [{"event_type": "Methods/Approach", "id": "ACL_23_P_725-1-EV0", "trigger": {"text": "demonstrate", "start": 4, "end": 5}, "arguments": [{"entity_id": "ACL_23_P_725-1-E0", "text": "we", "role": "Agent"}, {"entity_id": "ACL_23_P_725-1-E1", "text": "These trigger words are iteratively identified and injected into the target-label instances through natural word-level perturbations", "role": "Method"}, {"entity_id": "ACL_23_P_725-1-E2", "text": "The poisoned training data instruct the victim model to predict the target label on inputs containing trigger words, forming the backdoor", "role": "Method"}, {"entity_id": "ACL_23_P_725-1-E3", "text": "We propose BITE, a backdoor attack that poisons the training data to establish strong correlations between the target label and a set of \u201ctrigger words\u201d", "role": "Method"}, {"entity_id": "ACL_23_P_725-1-E4", "text": "it is possible to design a backdoor attack that is both stealthy (i.e., hard to notice) and effective (i.e., has a high attack success rate)", "role": "PrimaryObject"}]}], "entity_coreference": [], "event_coreference": [], "tokens": ["In", "this", "paper,", "we", "demonstrate", "that", "it", "is", "possible", "to", "design", "a", "backdoor", "attack", "that", "is", "both", "stealthy", "(i.e.,", "hard", "to", "notice)", "and", "effective", "(i.e.,", "has", "a", "high", "attack", "success", "rate).", "We", "propose", "BITE,", "a", "backdoor", "attack", "that", "poisons", "the", "training", "data", "to", "establish", "strong", "correlations", "between", "the", "target", "label", "and", "a", "set", "of", "\u201ctrigger", "words\u201d.", "These", "trigger", "words", "are", "iteratively", "identified", "and", "injected", "into", "the", "target-label", "instances", "through", "natural", "word-level", "perturbations.", "The", "poisoned", "training", "data", "instruct", "the", "victim", "model", "to", "predict", "the", "target", "label", "on", "inputs", "containing", "trigger", "words,", "forming", "the", "backdoor."], "pieces": ["In", "this", "paper", ",", "we", "demon", "strate", "that", "it", "is", "p", "ossible", "to", "design", "a", "back", "door", "attack", "that", "is", "both", "ste", "alth", "y", "(", "i", ".", "e", ".,", "hard", "to", "notice", ")", "and", "effective", "(", "i", ".", "e", ".,", "has", "a", "high", "attack", "success", "rate", ").", "We", "pro", "pose", "B", "ITE", ",", "a", "back", "door", "attack", "that", "po", "isons", "the", "training", "data", "to", "establish", "strong", "cor", "relations", "between", "the", "target", "label", "and", "a", "set", "of", "\u00e2\u0122", "\u013e", "trigger", "words", "\u00e2\u0122", "\u013f", ".", "These", "trigger", "words", "are", "iter", "atively", "identified", "and", "in", "jected", "into", "the", "target", "-", "label", "inst", "ances", "through", "natural", "word", "-", "level", "pert", "urb", "ations", ".", "The", "po", "ison", "ed", "training", "data", "in", "struct", "the", "vict", "im", "model", "to", "p", "redict", "the", "target", "label", "on", "input", "s", "containing", "trigger", "words", ",", "forming", "the", "back", "door", "."], "token_lens": [1, 1, 2, 1, 2, 1, 1, 1, 2, 1, 1, 1, 2, 1, 1, 1, 1, 3, 5, 1, 1, 2, 1, 1, 5, 1, 1, 1, 1, 1, 2, 1, 2, 3, 1, 2, 1, 1, 2, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 3, 4, 1, 1, 1, 1, 2, 1, 1, 2, 1, 1, 3, 2, 1, 1, 3, 4, 1, 3, 1, 1, 2, 1, 2, 1, 1, 2, 1, 1, 1, 1, 2, 1, 1, 2, 1, 1, 3], "sentence": "In this paper, we demonstrate that it is possible to design a backdoor attack that is both stealthy (i.e., hard to notice) and effective (i.e., has a high attack success rate). We propose BITE, a backdoor attack that poisons the training data to establish strong correlations between the target label and a set of \u201ctrigger words\u201d. These trigger words are iteratively identified and injected into the target-label instances through natural word-level perturbations. The poisoned training data instruct the victim model to predict the target label on inputs containing trigger words, forming the backdoor.", "sentence_starts": [0]}
{"doc_id": "ACL_23_P_725", "wnd_id": "ACL_23_P_725-2", "entity_mentions": [{"id": "ACL_23_P_725-2-E0", "text": "Experiments on four text classification datasets", "start": 0, "end": 6, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_725-2-E1", "text": "raising alarm on the usage of untrusted training data", "start": 22, "end": 31, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_725-2-E2", "text": "our proposed attack is significantly more effective than baseline methods while maintaining decent stealthiness", "start": 8, "end": 22, "entity_type": "UNK", "mention_type": "UNK"}], "relation_mentions": [], "event_mentions": [{"event_type": "Results/Findings", "id": "ACL_23_P_725-2-EV0", "trigger": {"text": "show", "start": 6, "end": 7}, "arguments": [{"entity_id": "ACL_23_P_725-2-E0", "text": "Experiments on four text classification datasets", "role": "Agent"}, {"entity_id": "ACL_23_P_725-2-E1", "text": "raising alarm on the usage of untrusted training data", "role": "Implications"}, {"entity_id": "ACL_23_P_725-2-E2", "text": "our proposed attack is significantly more effective than baseline methods while maintaining decent stealthiness", "role": "PrimaryObject"}]}], "entity_coreference": [], "event_coreference": [], "tokens": ["Experiments", "on", "four", "text", "classification", "datasets", "show", "that", "our", "proposed", "attack", "is", "significantly", "more", "effective", "than", "baseline", "methods", "while", "maintaining", "decent", "stealthiness,", "raising", "alarm", "on", "the", "usage", "of", "untrusted", "training", "data."], "pieces": ["Exper", "iments", "on", "four", "text", "class", "ification", "dat", "as", "ets", "show", "that", "our", "prop", "osed", "attack", "is", "sign", "ificantly", "more", "effective", "than", "bas", "eline", "method", "s", "while", "m", "aint", "aining", "dec", "ent", "ste", "alth", "iness", ",", "raising", "al", "arm", "on", "the", "usage", "of", "un", "tr", "usted", "training", "data", "."], "token_lens": [2, 1, 1, 1, 2, 3, 1, 1, 1, 2, 1, 1, 2, 1, 1, 1, 2, 2, 1, 3, 2, 4, 1, 2, 1, 1, 1, 1, 3, 1, 2], "sentence": "Experiments on four text classification datasets show that our proposed attack is significantly more effective than baseline methods while maintaining decent stealthiness, raising alarm on the usage of untrusted training data.", "sentence_starts": [0]}
{"doc_id": "ACL_23_P_725", "wnd_id": "ACL_23_P_725-3", "entity_mentions": [{"id": "ACL_23_P_725-3-E0", "text": "We", "start": 0, "end": 1, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_725-3-E1", "text": "outperforms existing methods in defending against BITE", "start": 15, "end": 22, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_725-3-E2", "text": "generalizes well to handling other backdoor attacks", "start": 23, "end": 30, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_725-3-E3", "text": "a defense method", "start": 3, "end": 6, "entity_type": "UNK", "mention_type": "UNK"}], "relation_mentions": [], "event_mentions": [{"event_type": "Conclusions/Implications", "id": "ACL_23_P_725-3-EV0", "trigger": {"text": "propose", "start": 2, "end": 3}, "arguments": [{"entity_id": "ACL_23_P_725-3-E0", "text": "We", "role": "Agent"}, {"entity_id": "ACL_23_P_725-3-E1", "text": "outperforms existing methods in defending against BITE", "role": "Results"}, {"entity_id": "ACL_23_P_725-3-E2", "text": "generalizes well to handling other backdoor attacks", "role": "Results"}, {"entity_id": "ACL_23_P_725-3-E3", "text": "a defense method", "role": "PrimaryObject"}]}], "entity_coreference": [], "event_coreference": [], "tokens": ["We", "further", "propose", "a", "defense", "method", "named", "DeBITE", "based", "on", "potential", "trigger", "word", "removal,", "which", "outperforms", "existing", "methods", "in", "defending", "against", "BITE", "and", "generalizes", "well", "to", "handling", "other", "backdoor", "attacks."], "pieces": ["We", "f", "urther", "pro", "pose", "a", "defense", "method", "named", "De", "B", "ITE", "based", "on", "pot", "ential", "trigger", "word", "rem", "oval", ",", "which", "out", "per", "forms", "existing", "method", "s", "in", "def", "ending", "against", "B", "ITE", "and", "general", "izes", "well", "to", "hand", "ling", "other", "back", "door", "attacks", "."], "token_lens": [1, 2, 2, 1, 1, 1, 1, 3, 1, 1, 2, 1, 1, 3, 1, 3, 1, 2, 1, 2, 1, 2, 1, 2, 1, 1, 2, 1, 2, 2], "sentence": "We further propose a defense method named DeBITE based on potential trigger word removal, which outperforms existing methods in defending against BITE and generalizes well to handling other backdoor attacks.", "sentence_starts": [0]}
{"doc_id": "ACL_23_P_702", "wnd_id": "ACL_23_P_702-0", "entity_mentions": [{"id": "ACL_23_P_702-0-E0", "text": "Similes", "start": 0, "end": 1, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_702-0-E1", "text": "Proper evaluation metrics are like a beacon guiding the research of simile generation (SG)", "start": 14, "end": 28, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_702-0-E2", "text": "it remains under-explored as to what criteria should be considered, how to quantify each criterion into metrics, and whether the metrics are effective for comprehensive, efficient, and reliable SG evaluation", "start": 29, "end": 59, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_702-0-E3", "text": "an imperative role in creative writing", "start": 2, "end": 8, "entity_type": "UNK", "mention_type": "UNK"}], "relation_mentions": [], "event_mentions": [{"event_type": "Background/Introduction", "id": "ACL_23_P_702-0-EV0", "trigger": {"text": "play", "start": 1, "end": 2}, "arguments": [{"entity_id": "ACL_23_P_702-0-E0", "text": "Similes", "role": "Agent"}, {"entity_id": "ACL_23_P_702-0-E1", "text": "Proper evaluation metrics are like a beacon guiding the research of simile generation (SG)", "role": "Context"}, {"entity_id": "ACL_23_P_702-0-E2", "text": "it remains under-explored as to what criteria should be considered, how to quantify each criterion into metrics, and whether the metrics are effective for comprehensive, efficient, and reliable SG evaluation", "role": "Challenge"}, {"entity_id": "ACL_23_P_702-0-E3", "text": "an imperative role in creative writing", "role": "PrimaryObject"}]}], "entity_coreference": [], "event_coreference": [], "tokens": ["Similes", "play", "an", "imperative", "role", "in", "creative", "writing", "such", "as", "story", "and", "dialogue", "generation.", "Proper", "evaluation", "metrics", "are", "like", "a", "beacon", "guiding", "the", "research", "of", "simile", "generation", "(SG).", "However,", "it", "remains", "under-explored", "as", "to", "what", "criteria", "should", "be", "considered,", "how", "to", "quantify", "each", "criterion", "into", "metrics,", "and", "whether", "the", "metrics", "are", "effective", "for", "comprehensive,", "efficient,", "and", "reliable", "SG", "evaluation."], "pieces": ["Sim", "iles", "play", "an", "im", "per", "ative", "role", "in", "creat", "ive", "writing", "such", "as", "story", "and", "dial", "ogue", "generation", ".", "Pro", "per", "eval", "uation", "met", "rics", "are", "like", "a", "be", "acon", "gu", "iding", "the", "research", "of", "sim", "ile", "generation", "(", "SG", ").", "However", ",", "it", "rem", "ains", "under", "-", "expl", "ored", "as", "to", "what", "crit", "eria", "should", "be", "cons", "idered", ",", "how", "to", "quant", "ify", "each", "crit", "erion", "into", "met", "rics", ",", "and", "whether", "the", "met", "rics", "are", "effective", "for", "com", "pre", "hens", "ive", ",", "efficient", ",", "and", "rel", "iable", "SG", "eval", "uation", "."], "token_lens": [2, 1, 1, 3, 1, 1, 2, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 1, 1, 1, 2, 2, 1, 1, 1, 2, 1, 3, 2, 1, 2, 4, 1, 1, 1, 2, 1, 1, 3, 1, 1, 2, 1, 2, 1, 3, 1, 1, 1, 2, 1, 1, 1, 5, 2, 1, 2, 1, 3], "sentence": "Similes play an imperative role in creative writing such as story and dialogue generation. Proper evaluation metrics are like a beacon guiding the research of simile generation (SG). However, it remains under-explored as to what criteria should be considered, how to quantify each criterion into metrics, and whether the metrics are effective for comprehensive, efficient, and reliable SG evaluation.", "sentence_starts": [0]}
{"doc_id": "ACL_23_P_702", "wnd_id": "ACL_23_P_702-1", "entity_mentions": [{"id": "ACL_23_P_702-1-E0", "text": "we", "start": 4, "end": 5, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_702-1-E1", "text": "consists of five criteria from three perspectives and automatic metrics for each criterion", "start": 18, "end": 31, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_702-1-E2", "text": "HAUSER", "start": 6, "end": 7, "entity_type": "UNK", "mention_type": "UNK"}], "relation_mentions": [], "event_mentions": [{"event_type": "Methods/Approach", "id": "ACL_23_P_702-1-EV0", "trigger": {"text": "establish", "start": 5, "end": 6}, "arguments": [{"entity_id": "ACL_23_P_702-1-E0", "text": "we", "role": "Agent"}, {"entity_id": "ACL_23_P_702-1-E1", "text": "consists of five criteria from three perspectives and automatic metrics for each criterion", "role": "Method"}, {"entity_id": "ACL_23_P_702-1-E2", "text": "HAUSER", "role": "PrimaryObject"}]}], "entity_coreference": [], "event_coreference": [], "tokens": ["To", "address", "the", "issues,", "we", "establish", "HAUSER,", "a", "holistic", "and", "automatic", "evaluation", "system", "for", "the", "SG", "task,", "which", "consists", "of", "five", "criteria", "from", "three", "perspectives", "and", "automatic", "metrics", "for", "each", "criterion."], "pieces": ["To", "address", "the", "issues", ",", "we", "establish", "HA", "USER", ",", "a", "hol", "istic", "and", "automatic", "eval", "uation", "system", "for", "the", "SG", "task", ",", "which", "cons", "ists", "of", "five", "crit", "eria", "from", "three", "pers", "pect", "ives", "and", "automatic", "met", "rics", "for", "each", "crit", "erion", "."], "token_lens": [1, 1, 1, 2, 1, 1, 3, 1, 2, 1, 1, 2, 1, 1, 1, 1, 2, 1, 2, 1, 1, 2, 1, 1, 3, 1, 1, 2, 1, 1, 3], "sentence": "To address the issues, we establish HAUSER, a holistic and automatic evaluation system for the SG task, which consists of five criteria from three perspectives and automatic metrics for each criterion.", "sentence_starts": [0]}
{"doc_id": "ACL_23_P_702", "wnd_id": "ACL_23_P_702-2", "entity_mentions": [{"id": "ACL_23_P_702-2-E0", "text": "we", "start": 3, "end": 4, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_702-2-E1", "text": "our metrics are significantly more correlated with human ratings from each perspective compared with prior automatic metrics", "start": 6, "end": 23, "entity_type": "UNK", "mention_type": "UNK"}], "relation_mentions": [], "event_mentions": [{"event_type": "Results/Findings", "id": "ACL_23_P_702-2-EV0", "trigger": {"text": "verify", "start": 4, "end": 5}, "arguments": [{"entity_id": "ACL_23_P_702-2-E0", "text": "we", "role": "Agent"}, {"entity_id": "ACL_23_P_702-2-E1", "text": "our metrics are significantly more correlated with human ratings from each perspective compared with prior automatic metrics", "role": "PrimaryObject"}]}], "entity_coreference": [], "event_coreference": [], "tokens": ["Through", "extensive", "experiments,", "we", "verify", "that", "our", "metrics", "are", "significantly", "more", "correlated", "with", "human", "ratings", "from", "each", "perspective", "compared", "with", "prior", "automatic", "metrics."], "pieces": ["Through", "ext", "ensive", "exper", "iments", ",", "we", "ver", "ify", "that", "our", "met", "rics", "are", "sign", "ificantly", "more", "cor", "related", "with", "human", "rat", "ings", "from", "each", "pers", "pect", "ive", "comp", "ared", "with", "pri", "or", "automatic", "met", "rics", "."], "token_lens": [1, 2, 3, 1, 2, 1, 1, 2, 1, 2, 1, 2, 1, 1, 2, 1, 1, 3, 2, 1, 2, 1, 3], "sentence": "Through extensive experiments, we verify that our metrics are significantly more correlated with human ratings from each perspective compared with prior automatic metrics.", "sentence_starts": [0]}
{"doc_id": "ACL_23_P_03", "wnd_id": "ACL_23_P_03-0", "entity_mentions": [{"id": "ACL_23_P_03-0-E0", "text": "the problem of hallucinations in neural machine translation", "start": 1, "end": 9, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_03-0-E1", "text": "Indeed, recently it turned out that without artificially encouraging models to hallucinate, previously existing methods fall short and even the standard sequence log-probability is more informative", "start": 23, "end": 49, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_03-0-E2", "text": "It means that internal characteristics of the model can give much more information than we expect, and before using external models and measures, we first need to ask: how far can we go if we use nothing but the translation model itself", "start": 49, "end": 91, "entity_type": "UNK", "mention_type": "UNK"}], "relation_mentions": [], "event_mentions": [{"event_type": "Background/Introduction", "id": "ACL_23_P_03-0-EV0", "trigger": {"text": "has long been recognized", "start": 9, "end": 13}, "arguments": [{"entity_id": "ACL_23_P_03-0-E0", "text": "the problem of hallucinations in neural machine translation", "role": "Agent"}, {"entity_id": "ACL_23_P_03-0-E1", "text": "Indeed, recently it turned out that without artificially encouraging models to hallucinate, previously existing methods fall short and even the standard sequence log-probability is more informative", "role": "Context"}, {"entity_id": "ACL_23_P_03-0-E2", "text": "It means that internal characteristics of the model can give much more information than we expect, and before using external models and measures, we first need to ask: how far can we go if we use nothing but the translation model itself", "role": "Analysis"}]}], "entity_coreference": [], "event_coreference": [], "tokens": ["While", "the", "problem", "of", "hallucinations", "in", "neural", "machine", "translation", "has", "long", "been", "recognized,", "so", "far", "the", "progress", "on", "its", "alleviation", "is", "very", "little.", "Indeed,", "recently", "it", "turned", "out", "that", "without", "artificially", "encouraging", "models", "to", "hallucinate,", "previously", "existing", "methods", "fall", "short", "and", "even", "the", "standard", "sequence", "log-probability", "is", "more", "informative.", "It", "means", "that", "internal", "characteristics", "of", "the", "model", "can", "give", "much", "more", "information", "than", "we", "expect,", "and", "before", "using", "external", "models", "and", "measures,", "we", "first", "need", "to", "ask:", "how", "far", "can", "we", "go", "if", "we", "use", "nothing", "but", "the", "translation", "model", "itself?"], "pieces": ["While", "the", "problem", "of", "hall", "uc", "inations", "in", "ne", "ural", "machine", "translation", "has", "long", "been", "recogn", "ized", ",", "so", "far", "the", "progress", "on", "its", "al", "lev", "iation", "is", "very", "little", ".", "Indeed", ",", "recent", "ly", "it", "turned", "out", "that", "without", "art", "ific", "ially", "enc", "our", "aging", "models", "to", "hall", "uc", "inate", ",", "pre", "viously", "existing", "method", "s", "fall", "short", "and", "even", "the", "standard", "sequence", "log", "-", "pro", "b", "ability", "is", "more", "in", "form", "ative", ".", "It", "me", "ans", "that", "internal", "character", "istics", "of", "the", "model", "can", "give", "much", "more", "information", "than", "we", "ex", "pect", ",", "and", "before", "using", "external", "models", "and", "measures", ",", "we", "first", "need", "to", "ask", ":", "how", "far", "can", "we", "go", "if", "we", "use", "nothing", "but", "the", "translation", "model", "it", "self", "?"], "token_lens": [1, 1, 1, 1, 3, 1, 2, 1, 1, 1, 1, 1, 3, 1, 1, 1, 1, 1, 1, 3, 1, 1, 2, 2, 2, 1, 1, 1, 1, 1, 3, 3, 1, 1, 4, 2, 1, 2, 1, 1, 1, 1, 1, 1, 1, 5, 1, 1, 4, 1, 2, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 3, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 3], "sentence": "While the problem of hallucinations in neural machine translation has long been recognized, so far the progress on its alleviation is very little. Indeed, recently it turned out that without artificially encouraging models to hallucinate, previously existing methods fall short and even the standard sequence log-probability is more informative. It means that internal characteristics of the model can give much more information than we expect, and before using external models and measures, we first need to ask: how far can we go if we use nothing but the translation model itself?", "sentence_starts": [0]}
{"doc_id": "ACL_23_P_03", "wnd_id": "ACL_23_P_03-1", "entity_mentions": [{"id": "ACL_23_P_03-1-E0", "text": "We", "start": 0, "end": 1, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_03-1-E1", "text": "Intuitively, hallucinations are translations \u201cdetached\u201d from the source, hence they can be identified by low source contribution.", "start": 18, "end": 35, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_03-1-E2", "text": "a method", "start": 4, "end": 6, "entity_type": "UNK", "mention_type": "UNK"}], "relation_mentions": [], "event_mentions": [{"event_type": "Methods/Approach", "id": "ACL_23_P_03-1-EV0", "trigger": {"text": "propose to use", "start": 1, "end": 4}, "arguments": [{"entity_id": "ACL_23_P_03-1-E0", "text": "We", "role": "Agent"}, {"entity_id": "ACL_23_P_03-1-E1", "text": "Intuitively, hallucinations are translations \u201cdetached\u201d from the source, hence they can be identified by low source contribution.", "role": "Analysis"}, {"entity_id": "ACL_23_P_03-1-E2", "text": "a method", "role": "PrimaryObject"}]}], "entity_coreference": [], "event_coreference": [], "tokens": ["We", "propose", "to", "use", "a", "method", "that", "evaluates", "the", "percentage", "of", "the", "source", "contribution", "to", "a", "generated", "translation.", "Intuitively,", "hallucinations", "are", "translations", "\u201cdetached\u201d", "from", "the", "source,", "hence", "they", "can", "be", "identified", "by", "low", "source", "contribution."], "pieces": ["We", "pro", "pose", "to", "use", "a", "method", "that", "eval", "uates", "the", "percent", "age", "of", "the", "source", "cont", "ribution", "to", "a", "generated", "translation", ".", "Int", "uitive", "ly", ",", "hall", "uc", "inations", "are", "trans", "lations", "\u00e2\u0122", "\u013e", "det", "ached", "\u00e2\u0122", "\u013f", "from", "the", "source", ",", "hen", "ce", "they", "can", "be", "identified", "by", "low", "source", "cont", "ribution", "."], "token_lens": [1, 2, 1, 1, 1, 1, 1, 2, 1, 2, 1, 1, 1, 2, 1, 1, 1, 2, 4, 3, 1, 2, 6, 1, 1, 2, 2, 1, 1, 1, 1, 1, 1, 1, 3], "sentence": "We propose to use a method that evaluates the percentage of the source contribution to a generated translation. Intuitively, hallucinations are translations \u201cdetached\u201d from the source, hence they can be identified by low source contribution.", "sentence_starts": [0]}
{"doc_id": "ACL_23_P_03", "wnd_id": "ACL_23_P_03-2", "entity_mentions": [{"id": "ACL_23_P_03-2-E0", "text": "This method", "start": 0, "end": 2, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_03-2-E1", "text": "alleviate hallucinations at test time on par with the previous best approach that relies on external models", "start": 19, "end": 36, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_03-2-E2", "text": "if we move away from internal model characteristics and allow external tools, we show that using sentence similarity from cross-lingual embeddings further improves these results", "start": 37, "end": 62, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_03-2-E3", "text": "detection accuracy", "start": 3, "end": 5, "entity_type": "UNK", "mention_type": "UNK"}], "relation_mentions": [], "event_mentions": [{"event_type": "Results/Findings", "id": "ACL_23_P_03-2-EV0", "trigger": {"text": "improves", "start": 2, "end": 3}, "arguments": [{"entity_id": "ACL_23_P_03-2-E0", "text": "This method", "role": "Agent"}, {"entity_id": "ACL_23_P_03-2-E1", "text": "alleviate hallucinations at test time on par with the previous best approach that relies on external models", "role": "Results"}, {"entity_id": "ACL_23_P_03-2-E2", "text": "if we move away from internal model characteristics and allow external tools, we show that using sentence similarity from cross-lingual embeddings further improves these results", "role": "Results"}, {"entity_id": "ACL_23_P_03-2-E3", "text": "detection accuracy", "role": "PrimaryObject"}]}], "entity_coreference": [], "event_coreference": [], "tokens": ["This", "method", "improves", "detection", "accuracy", "for", "the", "most", "severe", "hallucinations", "by", "a", "factor", "of", "2", "and", "is", "able", "to", "alleviate", "hallucinations", "at", "test", "time", "on", "par", "with", "the", "previous", "best", "approach", "that", "relies", "on", "external", "models.", "Next,", "if", "we", "move", "away", "from", "internal", "model", "characteristics", "and", "allow", "external", "tools,", "we", "show", "that", "using", "sentence", "similarity", "from", "cross-lingual", "embeddings", "further", "improves", "these", "results."], "pieces": ["This", "method", "impro", "ves", "det", "ection", "acc", "uracy", "for", "the", "most", "severe", "hall", "uc", "inations", "by", "a", "factor", "of", "2", "and", "is", "able", "to", "al", "lev", "iate", "hall", "uc", "inations", "at", "test", "time", "on", "par", "with", "the", "pre", "vious", "best", "appro", "ach", "that", "rel", "ies", "on", "external", "models", ".", "Next", ",", "if", "we", "move", "away", "from", "internal", "model", "character", "istics", "and", "allow", "external", "tools", ",", "we", "show", "that", "using", "sent", "ence", "similar", "ity", "from", "cross", "-", "ling", "ual", "embed", "d", "ings", "f", "urther", "impro", "ves", "these", "results", "."], "token_lens": [1, 1, 2, 2, 2, 1, 1, 1, 1, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 3, 3, 1, 1, 1, 1, 1, 1, 1, 2, 1, 2, 1, 2, 1, 1, 2, 2, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 2, 1, 1, 1, 1, 2, 2, 1, 4, 3, 2, 2, 1, 2], "sentence": "This method improves detection accuracy for the most severe hallucinations by a factor of 2 and is able to alleviate hallucinations at test time on par with the previous best approach that relies on external models. Next, if we move away from internal model characteristics and allow external tools, we show that using sentence similarity from cross-lingual embeddings further improves these results.", "sentence_starts": [0]}
{"doc_id": "ACL_23_P_809", "wnd_id": "ACL_23_P_809-0", "entity_mentions": [{"id": "ACL_23_P_809-0-E0", "text": "The wide accessibility of social media", "start": 0, "end": 6, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_809-0-E1", "text": "speakers of a language in a bilingual community rely on another script or orthography to write their native language", "start": 34, "end": 53, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_809-0-E2", "text": "linguistically under-represented communities", "start": 8, "end": 11, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_809-0-E3", "text": "with an extraordinary opportunity", "start": 11, "end": 15, "entity_type": "UNK", "mention_type": "UNK"}], "relation_mentions": [], "event_mentions": [{"event_type": "Background/Introduction", "id": "ACL_23_P_809-0-EV0", "trigger": {"text": "has provided", "start": 6, "end": 8}, "arguments": [{"entity_id": "ACL_23_P_809-0-E0", "text": "The wide accessibility of social media", "role": "Agent"}, {"entity_id": "ACL_23_P_809-0-E1", "text": "speakers of a language in a bilingual community rely on another script or orthography to write their native language", "role": "Challenge"}, {"entity_id": "ACL_23_P_809-0-E2", "text": "linguistically under-represented communities", "role": "PrimaryObject"}, {"entity_id": "ACL_23_P_809-0-E3", "text": "with an extraordinary opportunity", "role": "SecondaryObject"}]}], "entity_coreference": [], "event_coreference": [], "tokens": ["The", "wide", "accessibility", "of", "social", "media", "has", "provided", "linguistically", "under-represented", "communities", "with", "an", "extraordinary", "opportunity", "to", "create", "content", "in", "their", "native", "languages.", "This,", "however,", "comes", "with", "certain", "challenges", "in", "script", "normalization,", "particularly", "where", "the", "speakers", "of", "a", "language", "in", "a", "bilingual", "community", "rely", "on", "another", "script", "or", "orthography", "to", "write", "their", "native", "language."], "pieces": ["The", "wide", "access", "ibility", "of", "social", "media", "has", "provided", "ling", "u", "istically", "under", "-", "represented", "commun", "ities", "with", "an", "extra", "ordinary", "opp", "ortun", "ity", "to", "create", "content", "in", "their", "native", "l", "anguages", ".", "This", ",", "how", "ever", ",", "comes", "with", "certain", "chall", "enges", "in", "script", "normal", "ization", ",", "particularly", "where", "the", "spe", "akers", "of", "a", "language", "in", "a", "b", "ilingual", "community", "rely", "on", "another", "script", "or", "orth", "ography", "to", "write", "their", "native", "language", "."], "token_lens": [1, 1, 2, 1, 1, 1, 1, 1, 3, 3, 2, 1, 1, 2, 3, 1, 1, 1, 1, 1, 1, 3, 2, 3, 1, 1, 1, 2, 1, 1, 3, 1, 1, 1, 2, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 2], "sentence": "The wide accessibility of social media has provided linguistically under-represented communities with an extraordinary opportunity to create content in their native languages. This, however, comes with certain challenges in script normalization, particularly where the speakers of a language in a bilingual community rely on another script or orthography to write their native language.", "sentence_starts": [0]}
{"doc_id": "ACL_23_P_809", "wnd_id": "ACL_23_P_809-1", "entity_mentions": [{"id": "ACL_23_P_809-1-E0", "text": "This paper", "start": 0, "end": 2, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_809-1-E1", "text": "Using synthetic data with various levels of noise and a transformer-based model", "start": 20, "end": 32, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_809-1-E2", "text": "We conduct a small-scale evaluation of real data as well", "start": 41, "end": 51, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_809-1-E3", "text": "we demonstrate that the problem can be effectively remediated", "start": 32, "end": 41, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_809-1-E4", "text": "the problem of script normalization", "start": 3, "end": 8, "entity_type": "UNK", "mention_type": "UNK"}], "relation_mentions": [], "event_mentions": [{"event_type": "Methods/Approach", "id": "ACL_23_P_809-1-EV0", "trigger": {"text": "addresses", "start": 2, "end": 3}, "arguments": [{"entity_id": "ACL_23_P_809-1-E0", "text": "This paper", "role": "Agent"}, {"entity_id": "ACL_23_P_809-1-E1", "text": "Using synthetic data with various levels of noise and a transformer-based model", "role": "Method"}, {"entity_id": "ACL_23_P_809-1-E2", "text": "We conduct a small-scale evaluation of real data as well", "role": "Method"}, {"entity_id": "ACL_23_P_809-1-E3", "text": "we demonstrate that the problem can be effectively remediated", "role": "Results"}, {"entity_id": "ACL_23_P_809-1-E4", "text": "the problem of script normalization", "role": "PrimaryObject"}]}], "entity_coreference": [], "event_coreference": [], "tokens": ["This", "paper", "addresses", "the", "problem", "of", "script", "normalization", "for", "several", "such", "languages", "that", "are", "mainly", "written", "in", "a", "Perso-Arabic", "script.", "Using", "synthetic", "data", "with", "various", "levels", "of", "noise", "and", "a", "transformer-based", "model,", "we", "demonstrate", "that", "the", "problem", "can", "be", "effectively", "remediated.", "We", "conduct", "a", "small-scale", "evaluation", "of", "real", "data", "as", "well."], "pieces": ["This", "paper", "add", "resses", "the", "problem", "of", "script", "normal", "ization", "for", "sever", "al", "such", "l", "anguages", "that", "are", "main", "ly", "written", "in", "a", "Pers", "o", "-", "Arab", "ic", "script", ".", "Using", "sy", "nt", "hetic", "data", "with", "var", "ious", "levels", "of", "no", "ise", "and", "a", "trans", "former", "-", "based", "model", ",", "we", "demon", "strate", "that", "the", "problem", "can", "be", "effect", "ively", "re", "mediated", ".", "We", "conduct", "a", "small", "-", "scale", "eval", "uation", "of", "real", "data", "as", "well", "."], "token_lens": [1, 1, 2, 1, 1, 1, 1, 2, 1, 2, 1, 2, 1, 1, 2, 1, 1, 1, 5, 2, 1, 3, 1, 1, 2, 1, 1, 2, 1, 1, 4, 2, 1, 2, 1, 1, 1, 1, 1, 2, 3, 1, 1, 1, 3, 2, 1, 1, 1, 1, 2], "sentence": "This paper addresses the problem of script normalization for several such languages that are mainly written in a Perso-Arabic script. Using synthetic data with various levels of noise and a transformer-based model, we demonstrate that the problem can be effectively remediated. We conduct a small-scale evaluation of real data as well.", "sentence_starts": [0]}
{"doc_id": "ACL_23_P_809", "wnd_id": "ACL_23_P_809-2", "entity_mentions": [{"id": "ACL_23_P_809-2-E0", "text": "Our experiments", "start": 0, "end": 2, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_809-2-E1", "text": "script normalization is also beneficial", "start": 4, "end": 9, "entity_type": "UNK", "mention_type": "UNK"}], "relation_mentions": [], "event_mentions": [{"event_type": "Results/Findings", "id": "ACL_23_P_809-2-EV0", "trigger": {"text": "indicate", "start": 2, "end": 3}, "arguments": [{"entity_id": "ACL_23_P_809-2-E0", "text": "Our experiments", "role": "Agent"}, {"entity_id": "ACL_23_P_809-2-E1", "text": "script normalization is also beneficial", "role": "PrimaryObject"}]}], "entity_coreference": [], "event_coreference": [], "tokens": ["Our", "experiments", "indicate", "that", "script", "normalization", "is", "also", "beneficial", "to", "improve", "the", "performance", "of", "downstream", "tasks", "such", "as", "machine", "translation", "and", "language", "identification."], "pieces": ["Our", "exper", "iments", "ind", "icate", "that", "script", "normal", "ization", "is", "also", "benef", "icial", "to", "improve", "the", "performance", "of", "down", "stream", "t", "asks", "such", "as", "machine", "translation", "and", "language", "ident", "ification", "."], "token_lens": [1, 2, 2, 1, 1, 2, 1, 1, 2, 1, 1, 1, 1, 1, 2, 2, 1, 1, 1, 1, 1, 1, 3], "sentence": "Our experiments indicate that script normalization is also beneficial to improve the performance of downstream tasks such as machine translation and language identification.", "sentence_starts": [0]}
{"doc_id": "ACL_23_P_528", "wnd_id": "ACL_23_P_528-0", "entity_mentions": [{"id": "ACL_23_P_528-0-E0", "text": "Text generation", "start": 0, "end": 2, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_528-0-E1", "text": "most approaches for conditional text generation have primarily focused on lexical constraints", "start": 20, "end": 32, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_528-0-E2", "text": "they often struggle to effectively incorporate syntactic constraints, which provide a richer language for approximating semantic constraints", "start": 32, "end": 49, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_528-0-E3", "text": "producing coherent and grammatically correct texts", "start": 4, "end": 10, "entity_type": "UNK", "mention_type": "UNK"}], "relation_mentions": [], "event_mentions": [{"event_type": "Background/Introduction", "id": "ACL_23_P_528-0-EV0", "trigger": {"text": "involves", "start": 3, "end": 4}, "arguments": [{"entity_id": "ACL_23_P_528-0-E0", "text": "Text generation", "role": "Agent"}, {"entity_id": "ACL_23_P_528-0-E1", "text": "most approaches for conditional text generation have primarily focused on lexical constraints", "role": "Context"}, {"entity_id": "ACL_23_P_528-0-E2", "text": "they often struggle to effectively incorporate syntactic constraints, which provide a richer language for approximating semantic constraints", "role": "Challenge"}, {"entity_id": "ACL_23_P_528-0-E3", "text": "producing coherent and grammatically correct texts", "role": "PrimaryObject"}]}], "entity_coreference": [], "event_coreference": [], "tokens": ["Text", "generation", "often", "involves", "producing", "coherent", "and", "grammatically", "correct", "texts", "that", "also", "satisfy", "a", "given", "set", "of", "semantic", "constraints.", "While", "most", "approaches", "for", "conditional", "text", "generation", "have", "primarily", "focused", "on", "lexical", "constraints,", "they", "often", "struggle", "to", "effectively", "incorporate", "syntactic", "constraints,", "which", "provide", "a", "richer", "language", "for", "approximating", "semantic", "constraints."], "pieces": ["Text", "generation", "often", "inv", "olves", "producing", "co", "herent", "and", "gram", "matically", "correct", "text", "s", "that", "also", "s", "atisf", "y", "a", "given", "set", "of", "sem", "antic", "con", "str", "aints", ".", "While", "most", "appro", "aches", "for", "cond", "itional", "text", "generation", "have", "prim", "arily", "focused", "on", "lex", "ical", "con", "str", "aints", ",", "they", "often", "stru", "ggle", "to", "effect", "ively", "inc", "orpor", "ate", "sy", "nt", "actic", "con", "str", "aints", ",", "which", "prov", "ide", "a", "ric", "her", "language", "for", "app", "rox", "imating", "sem", "antic", "con", "str", "aints", "."], "token_lens": [1, 1, 1, 2, 1, 2, 1, 2, 1, 2, 1, 1, 3, 1, 1, 1, 1, 2, 4, 1, 1, 2, 1, 2, 1, 1, 1, 2, 1, 1, 2, 4, 1, 1, 2, 1, 2, 3, 3, 4, 1, 2, 1, 2, 1, 1, 3, 2, 4], "sentence": "Text generation often involves producing coherent and grammatically correct texts that also satisfy a given set of semantic constraints. While most approaches for conditional text generation have primarily focused on lexical constraints, they often struggle to effectively incorporate syntactic constraints, which provide a richer language for approximating semantic constraints.", "sentence_starts": [0]}
{"doc_id": "ACL_23_P_528", "wnd_id": "ACL_23_P_528-1", "entity_mentions": [{"id": "ACL_23_P_528-1-E0", "text": "We", "start": 0, "end": 1, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_528-1-E1", "text": "We build NeuroStructural Decoding on the NeuroLogic Decoding (Lu et al. 2021) algorithm, which enables language generation models to produce fluent text while satisfying complex lexical constraints", "start": 25, "end": 52, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_528-1-E2", "text": "It tracks lexico-syntactic constraints (e.g., we need to observe dog as subject and ball as object) during decoding by parsing the partial generations at each step", "start": 58, "end": 84, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_528-1-E3", "text": "we adapt a dependency parser to generate parses for incomplete sentences", "start": 87, "end": 98, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_528-1-E4", "text": "Our algorithm is powerful and scalable", "start": 52, "end": 58, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_528-1-E5", "text": "this gap", "start": 2, "end": 4, "entity_type": "UNK", "mention_type": "UNK"}], "relation_mentions": [], "event_mentions": [{"event_type": "Methods/Approach", "id": "ACL_23_P_528-1-EV0", "trigger": {"text": "address", "start": 1, "end": 2}, "arguments": [{"entity_id": "ACL_23_P_528-1-E0", "text": "We", "role": "Agent"}, {"entity_id": "ACL_23_P_528-1-E1", "text": "We build NeuroStructural Decoding on the NeuroLogic Decoding (Lu et al. 2021) algorithm, which enables language generation models to produce fluent text while satisfying complex lexical constraints", "role": "Method"}, {"entity_id": "ACL_23_P_528-1-E2", "text": "It tracks lexico-syntactic constraints (e.g., we need to observe dog as subject and ball as object) during decoding by parsing the partial generations at each step", "role": "Method"}, {"entity_id": "ACL_23_P_528-1-E3", "text": "we adapt a dependency parser to generate parses for incomplete sentences", "role": "Method"}, {"entity_id": "ACL_23_P_528-1-E4", "text": "Our algorithm is powerful and scalable", "role": "Results"}, {"entity_id": "ACL_23_P_528-1-E5", "text": "this gap", "role": "PrimaryObject"}]}], "entity_coreference": [], "event_coreference": [], "tokens": ["We", "address", "this", "gap", "by", "introducing", "NeuroStructural", "Decoding,", "a", "new", "decoding", "algorithm", "that", "incorporates", "syntactic", "constraints", "to", "further", "improve", "the", "quality", "of", "the", "generated", "text.", "We", "build", "NeuroStructural", "Decoding", "on", "the", "NeuroLogic", "Decoding", "(Lu", "et", "al.", "2021)", "algorithm,", "which", "enables", "language", "generation", "models", "to", "produce", "fluent", "text", "while", "satisfying", "complex", "lexical", "constraints.", "Our", "algorithm", "is", "powerful", "and", "scalable.", "It", "tracks", "lexico-syntactic", "constraints", "(e.g.,", "we", "need", "to", "observe", "dog", "as", "subject", "and", "ball", "as", "object)", "during", "decoding", "by", "parsing", "the", "partial", "generations", "at", "each", "step.", "To", "this", "end,", "we", "adapt", "a", "dependency", "parser", "to", "generate", "parses", "for", "incomplete", "sentences."], "pieces": ["We", "address", "this", "gap", "by", "introdu", "cing", "Ne", "uro", "Struct", "ural", "Dec", "oding", ",", "a", "new", "dec", "oding", "al", "gorithm", "that", "inc", "orpor", "ates", "sy", "nt", "actic", "con", "str", "aints", "to", "f", "urther", "improve", "the", "quality", "of", "the", "generated", "text", ".", "We", "build", "Ne", "uro", "Struct", "ural", "Dec", "oding", "on", "the", "Ne", "uro", "Log", "ic", "Dec", "oding", "(", "Lu", "et", "al", ".", "20", "21", ")", "al", "gorithm", ",", "which", "en", "ables", "language", "generation", "models", "to", "produ", "ce", "f", "luent", "text", "while", "s", "atisf", "ying", "complex", "lex", "ical", "con", "str", "aints", ".", "Our", "al", "gorithm", "is", "powerful", "and", "sc", "al", "able", ".", "It", "tracks", "lex", "ico", "-", "sy", "nt", "actic", "con", "str", "aints", "(", "e", ".", "g", ".,", "we", "need", "to", "ob", "ser", "ve", "dog", "as", "subject", "and", "ball", "as", "object", ")", "during", "dec", "oding", "by", "p", "ars", "ing", "the", "partial", "gener", "ations", "at", "each", "step", ".", "To", "this", "end", ",", "we", "adapt", "a", "depend", "ency", "parser", "to", "gener", "ate", "p", "ars", "es", "for", "in", "complete", "sent", "ences", "."], "token_lens": [1, 1, 1, 1, 1, 2, 4, 3, 1, 1, 2, 2, 1, 3, 3, 3, 1, 2, 1, 1, 1, 1, 1, 1, 2, 1, 1, 4, 2, 1, 1, 4, 2, 2, 1, 2, 3, 3, 1, 2, 1, 1, 1, 1, 2, 2, 1, 1, 3, 1, 2, 4, 1, 2, 1, 1, 1, 4, 1, 1, 6, 3, 5, 1, 1, 1, 3, 1, 1, 1, 1, 1, 1, 2, 1, 2, 1, 3, 1, 1, 2, 1, 1, 2, 1, 1, 2, 1, 1, 1, 2, 1, 1, 2, 3, 1, 2, 3], "sentence": "We address this gap by introducing NeuroStructural Decoding, a new decoding algorithm that incorporates syntactic constraints to further improve the quality of the generated text. We build NeuroStructural Decoding on the NeuroLogic Decoding (Lu et al. 2021) algorithm, which enables language generation models to produce fluent text while satisfying complex lexical constraints. Our algorithm is powerful and scalable. It tracks lexico-syntactic constraints (e.g., we need to observe dog as subject and ball as object) during decoding by parsing the partial generations at each step. To this end, we adapt a dependency parser to generate parses for incomplete sentences.", "sentence_starts": [0]}
{"doc_id": "ACL_23_P_528", "wnd_id": "ACL_23_P_528-2", "entity_mentions": [{"id": "ACL_23_P_528-2-E0", "text": "Our approach", "start": 0, "end": 2, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_528-2-E1", "text": "improved performance in both lexical and syntactic metrics compared to previous methods", "start": 14, "end": 26, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_528-2-E2", "text": "this is a promising solution for integrating fine-grained controllable generation into the conventional beam search decoding", "start": 29, "end": 45, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_528-2-E3", "text": "three different language generation tasks", "start": 5, "end": 10, "entity_type": "UNK", "mention_type": "UNK"}], "relation_mentions": [], "event_mentions": [{"event_type": "Results/Findings", "id": "ACL_23_P_528-2-EV0", "trigger": {"text": "is evaluated on", "start": 2, "end": 5}, "arguments": [{"entity_id": "ACL_23_P_528-2-E0", "text": "Our approach", "role": "Agent"}, {"entity_id": "ACL_23_P_528-2-E1", "text": "improved performance in both lexical and syntactic metrics compared to previous methods", "role": "Results"}, {"entity_id": "ACL_23_P_528-2-E2", "text": "this is a promising solution for integrating fine-grained controllable generation into the conventional beam search decoding", "role": "Results"}, {"entity_id": "ACL_23_P_528-2-E3", "text": "three different language generation tasks", "role": "PrimaryObject"}]}], "entity_coreference": [], "event_coreference": [], "tokens": ["Our", "approach", "is", "evaluated", "on", "three", "different", "language", "generation", "tasks,", "and", "the", "results", "show", "improved", "performance", "in", "both", "lexical", "and", "syntactic", "metrics", "compared", "to", "previous", "methods.", "The", "results", "suggest", "this", "is", "a", "promising", "solution", "for", "integrating", "fine-grained", "controllable", "generation", "into", "the", "conventional", "beam", "search", "decoding."], "pieces": ["Our", "appro", "ach", "is", "eval", "uated", "on", "three", "different", "language", "generation", "t", "asks", ",", "and", "the", "results", "show", "impro", "ved", "performance", "in", "both", "lex", "ical", "and", "sy", "nt", "actic", "met", "rics", "comp", "ared", "to", "pre", "vious", "method", "s", ".", "The", "results", "suggest", "this", "is", "a", "prom", "ising", "s", "olution", "for", "integ", "rating", "fine", "-", "gr", "ained", "cont", "roll", "able", "generation", "into", "the", "con", "ventional", "beam", "search", "dec", "oding", "."], "token_lens": [1, 2, 1, 2, 1, 1, 1, 1, 1, 3, 1, 1, 1, 1, 2, 1, 1, 1, 2, 1, 3, 2, 2, 1, 2, 3, 1, 1, 1, 1, 1, 1, 2, 2, 1, 2, 4, 3, 1, 1, 1, 2, 1, 1, 3], "sentence": "Our approach is evaluated on three different language generation tasks, and the results show improved performance in both lexical and syntactic metrics compared to previous methods. The results suggest this is a promising solution for integrating fine-grained controllable generation into the conventional beam search decoding.", "sentence_starts": [0]}
{"doc_id": "ACL_23_P_872", "wnd_id": "ACL_23_P_872-0", "entity_mentions": [{"id": "ACL_23_P_872-0-E0", "text": "Direct speech-to-speech translation (S2ST)", "start": 0, "end": 4, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_872-0-E1", "text": "advantageous over cascaded approaches", "start": 13, "end": 17, "entity_type": "UNK", "mention_type": "UNK"}], "relation_mentions": [], "event_mentions": [{"event_type": "Background/Introduction", "id": "ACL_23_P_872-0-EV0", "trigger": {"text": "is", "start": 12, "end": 13}, "arguments": [{"entity_id": "ACL_23_P_872-0-E0", "text": "Direct speech-to-speech translation (S2ST)", "role": "Agent"}, {"entity_id": "ACL_23_P_872-0-E1", "text": "advantageous over cascaded approaches", "role": "PrimaryObject"}]}], "entity_coreference": [], "event_coreference": [], "tokens": ["Direct", "speech-to-speech", "translation", "(S2ST),", "in", "which", "all", "components", "can", "be", "optimized", "jointly,", "is", "advantageous", "over", "cascaded", "approaches", "to", "achieve", "fast", "inference", "with", "a", "simplified", "pipeline."], "pieces": ["Direct", "speech", "-", "to", "-", "speech", "translation", "(", "S", "2", "ST", "),", "in", "which", "all", "comp", "onents", "can", "be", "optim", "ized", "j", "oint", "ly", ",", "is", "advant", "age", "ous", "over", "c", "asc", "aded", "appro", "aches", "to", "ach", "ieve", "fast", "in", "ference", "with", "a", "sim", "pl", "ified", "p", "ip", "eline", "."], "token_lens": [1, 5, 1, 5, 1, 1, 1, 2, 1, 1, 2, 4, 1, 3, 1, 3, 2, 1, 2, 1, 2, 1, 1, 3, 4], "sentence": "Direct speech-to-speech translation (S2ST), in which all components can be optimized jointly, is advantageous over cascaded approaches to achieve fast inference with a simplified pipeline.", "sentence_starts": [0]}
{"doc_id": "ACL_23_P_872", "wnd_id": "ACL_23_P_872-1", "entity_mentions": [{"id": "ACL_23_P_872-1-E0", "text": "We", "start": 0, "end": 1, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_872-1-E1", "text": "We enhance the model performance by subword prediction in the first-pass decoder, advanced two-pass decoder architecture design and search strategy, and better training regularization", "start": 20, "end": 44, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_872-1-E2", "text": "we pre-train the first-pass text decoder based on the self-supervised denoising auto-encoding task", "start": 52, "end": 65, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_872-1-E3", "text": "a novel two-pass direct S2ST architecture, UnitY", "start": 2, "end": 9, "entity_type": "UNK", "mention_type": "UNK"}], "relation_mentions": [], "event_mentions": [{"event_type": "Methods/Approach", "id": "ACL_23_P_872-1-EV0", "trigger": {"text": "present", "start": 1, "end": 2}, "arguments": [{"entity_id": "ACL_23_P_872-1-E0", "text": "We", "role": "Agent"}, {"entity_id": "ACL_23_P_872-1-E1", "text": "We enhance the model performance by subword prediction in the first-pass decoder, advanced two-pass decoder architecture design and search strategy, and better training regularization", "role": "Method"}, {"entity_id": "ACL_23_P_872-1-E2", "text": "we pre-train the first-pass text decoder based on the self-supervised denoising auto-encoding task", "role": "Method"}, {"entity_id": "ACL_23_P_872-1-E3", "text": "a novel two-pass direct S2ST architecture, UnitY", "role": "PrimaryObject"}]}], "entity_coreference": [], "event_coreference": [], "tokens": ["We", "present", "a", "novel", "two-pass", "direct", "S2ST", "architecture,", "UnitY,", "which", "first", "generates", "textual", "representations", "and", "predicts", "discrete", "acoustic", "units", "subsequently.", "We", "enhance", "the", "model", "performance", "by", "subword", "prediction", "in", "the", "first-pass", "decoder,", "advanced", "two-pass", "decoder", "architecture", "design", "and", "search", "strategy,", "and", "better", "training", "regularization.", "To", "leverage", "large", "amounts", "of", "unlabeled", "text", "data,", "we", "pre-train", "the", "first-pass", "text", "decoder", "based", "on", "the", "self-supervised", "denoising", "auto-encoding", "task."], "pieces": ["We", "present", "a", "no", "vel", "two", "-", "pass", "direct", "S", "2", "ST", "arch", "itect", "ure", ",", "Unit", "Y", ",", "which", "first", "gener", "ates", "text", "ual", "represent", "ations", "and", "pred", "icts", "disc", "rete", "ac", "oustic", "units", "sub", "sequently", ".", "We", "enh", "ance", "the", "model", "performance", "by", "sub", "word", "pred", "iction", "in", "the", "first", "-", "pass", "dec", "oder", ",", "adv", "anced", "two", "-", "pass", "dec", "oder", "arch", "itect", "ure", "design", "and", "search", "str", "ategy", ",", "and", "better", "training", "regular", "ization", ".", "To", "le", "verage", "large", "amount", "s", "of", "un", "label", "ed", "text", "data", ",", "we", "pre", "-", "train", "the", "first", "-", "pass", "text", "dec", "oder", "based", "on", "the", "self", "-", "super", "vised", "den", "o", "ising", "auto", "-", "enc", "oding", "task", "."], "token_lens": [1, 1, 1, 2, 3, 1, 3, 4, 3, 1, 1, 2, 2, 2, 1, 2, 2, 2, 1, 3, 1, 2, 1, 1, 1, 1, 2, 2, 1, 1, 3, 3, 2, 3, 2, 3, 1, 1, 1, 3, 1, 1, 1, 3, 1, 2, 1, 2, 1, 3, 1, 2, 1, 3, 1, 3, 1, 2, 1, 1, 1, 4, 3, 4, 2], "sentence": "We present a novel two-pass direct S2ST architecture, UnitY, which first generates textual representations and predicts discrete acoustic units subsequently. We enhance the model performance by subword prediction in the first-pass decoder, advanced two-pass decoder architecture design and search strategy, and better training regularization. To leverage large amounts of unlabeled text data, we pre-train the first-pass text decoder based on the self-supervised denoising auto-encoding task.", "sentence_starts": [0]}
{"doc_id": "ACL_23_P_872", "wnd_id": "ACL_23_P_872-2", "entity_mentions": [{"id": "ACL_23_P_872-2-E0", "text": "We", "start": 25, "end": 26, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_872-2-E1", "text": "the proposed methods boost the performance even when predicting spectrogram in the second pass.", "start": 28, "end": 42, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_872-2-E2", "text": "predicting discrete units achieves 2.51x decoding speed-up compared to that case.", "start": 43, "end": 54, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_872-2-E3", "text": "UnitY outperforms a single-pass speech-to-unit translation model by 2.5-4.2 ASR-BLEU with 2.83x decoding speed-up", "start": 11, "end": 25, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_872-2-E4", "text": "the proposed methods boost the performance even when predicting spectrogram in the second pass", "start": 28, "end": 42, "entity_type": "UNK", "mention_type": "UNK"}], "relation_mentions": [], "event_mentions": [{"event_type": "Results/Findings", "id": "ACL_23_P_872-2-EV0", "trigger": {"text": "show", "start": 26, "end": 27}, "arguments": [{"entity_id": "ACL_23_P_872-2-E0", "text": "We", "role": "Agent"}, {"entity_id": "ACL_23_P_872-2-E1", "text": "the proposed methods boost the performance even when predicting spectrogram in the second pass.", "role": "Results"}, {"entity_id": "ACL_23_P_872-2-E2", "text": "predicting discrete units achieves 2.51x decoding speed-up compared to that case.", "role": "Results"}, {"entity_id": "ACL_23_P_872-2-E3", "text": "UnitY outperforms a single-pass speech-to-unit translation model by 2.5-4.2 ASR-BLEU with 2.83x decoding speed-up", "role": "Results"}, {"entity_id": "ACL_23_P_872-2-E4", "text": "the proposed methods boost the performance even when predicting spectrogram in the second pass", "role": "PrimaryObject"}]}], "entity_coreference": [], "event_coreference": [], "tokens": ["Experimental", "evaluations", "on", "benchmark", "datasets", "at", "various", "data", "scales", "demonstrate", "that", "UnitY", "outperforms", "a", "single-pass", "speech-to-unit", "translation", "model", "by", "2.5-4.2", "ASR-BLEU", "with", "2.83x", "decoding", "speed-up.", "We", "show", "that", "the", "proposed", "methods", "boost", "the", "performance", "even", "when", "predicting", "spectrogram", "in", "the", "second", "pass.", "However,", "predicting", "discrete", "units", "achieves", "2.51x", "decoding", "speed-up", "compared", "to", "that", "case."], "pieces": ["Exper", "imental", "eval", "uations", "on", "bench", "mark", "dat", "as", "ets", "at", "var", "ious", "data", "sc", "ales", "demon", "strate", "that", "Unit", "Y", "out", "per", "forms", "a", "single", "-", "pass", "speech", "-", "to", "-", "unit", "translation", "model", "by", "2", ".", "5", "-", "4", ".", "2", "AS", "R", "-", "BLE", "U", "with", "2", ".", "83", "x", "dec", "oding", "speed", "-", "up", ".", "We", "show", "that", "the", "prop", "osed", "method", "s", "boost", "the", "performance", "even", "when", "p", "redict", "ing", "spect", "rogram", "in", "the", "second", "pass", ".", "However", ",", "p", "redict", "ing", "disc", "rete", "units", "ach", "ieves", "2", ".", "51", "x", "dec", "oding", "speed", "-", "up", "comp", "ared", "to", "that", "case", "."], "token_lens": [2, 2, 1, 2, 3, 1, 2, 1, 2, 2, 1, 2, 3, 1, 3, 5, 1, 1, 1, 7, 5, 1, 4, 2, 4, 1, 1, 1, 1, 2, 2, 1, 1, 1, 1, 1, 3, 2, 1, 1, 1, 2, 2, 3, 2, 1, 2, 4, 2, 3, 2, 1, 1, 2], "sentence": "Experimental evaluations on benchmark datasets at various data scales demonstrate that UnitY outperforms a single-pass speech-to-unit translation model by 2.5-4.2 ASR-BLEU with 2.83x decoding speed-up. We show that the proposed methods boost the performance even when predicting spectrogram in the second pass. However, predicting discrete units achieves 2.51x decoding speed-up compared to that case.", "sentence_starts": [0]}
{"doc_id": "ACL_23_P_378", "wnd_id": "ACL_23_P_378-0", "entity_mentions": [{"id": "ACL_23_P_378-0-E0", "text": "we", "start": 28, "end": 29, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_378-0-E1", "text": "A robust summarization system should be able to capture the gist of the document, regardless of the specific word choices or noise in the input", "start": 0, "end": 25, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_378-0-E2", "text": "the summarization models\u2019 robustness", "start": 31, "end": 35, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_378-0-E3", "text": "against perturbations including word-level synonym substitution and noise", "start": 35, "end": 43, "entity_type": "UNK", "mention_type": "UNK"}], "relation_mentions": [], "event_mentions": [{"event_type": "Background/Introduction", "id": "ACL_23_P_378-0-EV0", "trigger": {"text": "explore", "start": 30, "end": 31}, "arguments": [{"entity_id": "ACL_23_P_378-0-E0", "text": "we", "role": "Agent"}, {"entity_id": "ACL_23_P_378-0-E1", "text": "A robust summarization system should be able to capture the gist of the document, regardless of the specific word choices or noise in the input", "role": "Context"}, {"entity_id": "ACL_23_P_378-0-E2", "text": "the summarization models\u2019 robustness", "role": "PrimaryObject"}, {"entity_id": "ACL_23_P_378-0-E3", "text": "against perturbations including word-level synonym substitution and noise", "role": "SecondaryObject"}]}], "entity_coreference": [], "event_coreference": [], "tokens": ["A", "robust", "summarization", "system", "should", "be", "able", "to", "capture", "the", "gist", "of", "the", "document,", "regardless", "of", "the", "specific", "word", "choices", "or", "noise", "in", "the", "input.", "In", "this", "work,", "we", "first", "explore", "the", "summarization", "models\u2019", "robustness", "against", "perturbations", "including", "word-level", "synonym", "substitution", "and", "noise."], "pieces": ["A", "rob", "ust", "sum", "mar", "ization", "system", "should", "be", "able", "to", "capt", "ure", "the", "g", "ist", "of", "the", "document", ",", "reg", "ardless", "of", "the", "specific", "word", "cho", "ices", "or", "no", "ise", "in", "the", "input", ".", "In", "this", "work", ",", "we", "first", "expl", "ore", "the", "sum", "mar", "ization", "models", "\u00e2\u0122", "\u013b", "rob", "ust", "ness", "against", "pert", "urb", "ations", "including", "word", "-", "level", "syn", "onym", "sub", "st", "itution", "and", "no", "ise", "."], "token_lens": [1, 2, 3, 1, 1, 1, 1, 1, 2, 1, 2, 1, 1, 2, 2, 1, 1, 1, 1, 2, 1, 2, 1, 1, 2, 1, 1, 2, 1, 1, 2, 1, 3, 3, 3, 1, 3, 1, 3, 2, 3, 1, 3], "sentence": "A robust summarization system should be able to capture the gist of the document, regardless of the specific word choices or noise in the input. In this work, we first explore the summarization models\u2019 robustness against perturbations including word-level synonym substitution and noise.", "sentence_starts": [0]}
{"doc_id": "ACL_23_P_378", "wnd_id": "ACL_23_P_378-1", "entity_mentions": [{"id": "ACL_23_P_378-1-E0", "text": "we", "start": 4, "end": 5, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_378-1-E1", "text": "Experimental results show that state-of-the-art summarization models have a significant decrease in performance on adversarial and noisy test sets", "start": 21, "end": 40, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_378-1-E2", "text": "To create semantic-consistent substitutes", "start": 0, "end": 4, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_378-1-E3", "text": "we analyze the vulnerability of the summarization systems and explore improving the robustness by data augmentation", "start": 41, "end": 57, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_378-1-E4", "text": "we expose the encoder to more diverse cases created by SummAttacker in the input space", "start": 73, "end": 88, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_378-1-E5", "text": "we propose an augmentation in the latent space of the decoder to improve its robustness", "start": 98, "end": 113, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_378-1-E6", "text": "we create virtual cases by manifold softmixing two decoder hidden states of similar semantic meanings", "start": 114, "end": 129, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_378-1-E7", "text": "the first vulnerability factor we found is the low diversity of the training inputs", "start": 58, "end": 72, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_378-1-E8", "text": "The second factor is the vulnerability of the decoder", "start": 88, "end": 97, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_378-1-E9", "text": "SummAttacker", "start": 6, "end": 7, "entity_type": "UNK", "mention_type": "UNK"}], "relation_mentions": [], "event_mentions": [{"event_type": "Methods/Approach", "id": "ACL_23_P_378-1-EV0", "trigger": {"text": "propose", "start": 5, "end": 6}, "arguments": [{"entity_id": "ACL_23_P_378-1-E0", "text": "we", "role": "Agent"}, {"entity_id": "ACL_23_P_378-1-E1", "text": "Experimental results show that state-of-the-art summarization models have a significant decrease in performance on adversarial and noisy test sets", "role": "Context"}, {"entity_id": "ACL_23_P_378-1-E2", "text": "To create semantic-consistent substitutes", "role": "Purpose"}, {"entity_id": "ACL_23_P_378-1-E3", "text": "we analyze the vulnerability of the summarization systems and explore improving the robustness by data augmentation", "role": "Method"}, {"entity_id": "ACL_23_P_378-1-E4", "text": "we expose the encoder to more diverse cases created by SummAttacker in the input space", "role": "Method"}, {"entity_id": "ACL_23_P_378-1-E5", "text": "we propose an augmentation in the latent space of the decoder to improve its robustness", "role": "Method"}, {"entity_id": "ACL_23_P_378-1-E6", "text": "we create virtual cases by manifold softmixing two decoder hidden states of similar semantic meanings", "role": "Method"}, {"entity_id": "ACL_23_P_378-1-E7", "text": "the first vulnerability factor we found is the low diversity of the training inputs", "role": "Results"}, {"entity_id": "ACL_23_P_378-1-E8", "text": "The second factor is the vulnerability of the decoder", "role": "Results"}, {"entity_id": "ACL_23_P_378-1-E9", "text": "SummAttacker", "role": "PrimaryObject"}]}], "entity_coreference": [], "event_coreference": [], "tokens": ["To", "create", "semantic-consistent", "substitutes,", "we", "propose", "SummAttacker,", "which", "is", "an", "efficient", "approach", "to", "generating", "adversarial", "samples", "based", "on", "pre-trained", "language", "models.", "Experimental", "results", "show", "that", "state-of-the-art", "summarization", "models", "have", "a", "significant", "decrease", "in", "performance", "on", "adversarial", "and", "noisy", "test", "sets.", "Next,", "we", "analyze", "the", "vulnerability", "of", "the", "summarization", "systems", "and", "explore", "improving", "the", "robustness", "by", "data", "augmentation.", "Specifically,", "the", "first", "vulnerability", "factor", "we", "found", "is", "the", "low", "diversity", "of", "the", "training", "inputs.", "Correspondingly,", "we", "expose", "the", "encoder", "to", "more", "diverse", "cases", "created", "by", "SummAttacker", "in", "the", "input", "space.", "The", "second", "factor", "is", "the", "vulnerability", "of", "the", "decoder,", "and", "we", "propose", "an", "augmentation", "in", "the", "latent", "space", "of", "the", "decoder", "to", "improve", "its", "robustness.", "Concretely,", "we", "create", "virtual", "cases", "by", "manifold", "softmixing", "two", "decoder", "hidden", "states", "of", "similar", "semantic", "meanings."], "pieces": ["To", "create", "sem", "antic", "-", "cons", "istent", "sub", "st", "itutes", ",", "we", "pro", "pose", "Sum", "m", "Att", "acker", ",", "which", "is", "an", "efficient", "appro", "ach", "to", "gener", "ating", "ad", "vers", "arial", "s", "amples", "based", "on", "pre", "-", "trained", "language", "models", ".", "Exper", "imental", "results", "show", "that", "state", "-", "of", "-", "the", "-", "art", "sum", "mar", "ization", "models", "have", "a", "significant", "dec", "re", "ase", "in", "performance", "on", "ad", "vers", "arial", "and", "no", "isy", "test", "sets", ".", "Next", ",", "we", "analy", "ze", "the", "v", "ulnerability", "of", "the", "sum", "mar", "ization", "system", "s", "and", "expl", "ore", "impro", "ving", "the", "rob", "ust", "ness", "by", "data", "au", "gment", "ation", ".", "Specifically", ",", "the", "first", "v", "ulnerability", "factor", "we", "found", "is", "the", "low", "d", "iversity", "of", "the", "training", "input", "s", ".", "Cor", "respond", "ingly", ",", "we", "ex", "pose", "the", "enc", "oder", "to", "more", "d", "iverse", "cases", "created", "by", "Sum", "m", "Att", "acker", "in", "the", "input", "space", ".", "The", "second", "factor", "is", "the", "v", "ulnerability", "of", "the", "dec", "oder", ",", "and", "we", "pro", "pose", "an", "au", "gment", "ation", "in", "the", "lat", "ent", "space", "of", "the", "dec", "oder", "to", "improve", "its", "rob", "ust", "ness", ".", "Con", "crete", "ly", ",", "we", "create", "virtual", "cases", "by", "man", "if", "old", "soft", "mix", "ing", "two", "dec", "oder", "hidden", "states", "of", "similar", "sem", "antic", "mean", "ings", "."], "token_lens": [1, 1, 5, 4, 1, 2, 5, 1, 1, 1, 1, 2, 1, 2, 3, 2, 1, 1, 3, 1, 2, 2, 1, 1, 1, 7, 3, 1, 1, 1, 1, 3, 1, 1, 1, 3, 1, 2, 1, 2, 2, 1, 2, 1, 2, 1, 1, 3, 2, 1, 2, 2, 1, 3, 1, 1, 4, 2, 1, 1, 2, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 3, 4, 1, 2, 1, 2, 1, 1, 2, 1, 1, 1, 4, 1, 1, 1, 2, 1, 1, 1, 1, 1, 2, 1, 1, 3, 1, 1, 2, 1, 3, 1, 1, 2, 1, 1, 1, 2, 1, 1, 1, 4, 4, 1, 1, 1, 1, 1, 3, 3, 1, 2, 1, 1, 1, 1, 2, 3], "sentence": "To create semantic-consistent substitutes, we propose SummAttacker, which is an efficient approach to generating adversarial samples based on pre-trained language models. Experimental results show that state-of-the-art summarization models have a significant decrease in performance on adversarial and noisy test sets. Next, we analyze the vulnerability of the summarization systems and explore improving the robustness by data augmentation. Specifically, the first vulnerability factor we found is the low diversity of the training inputs. Correspondingly, we expose the encoder to more diverse cases created by SummAttacker in the input space. The second factor is the vulnerability of the decoder, and we propose an augmentation in the latent space of the decoder to improve its robustness. Concretely, we create virtual cases by manifold softmixing two decoder hidden states of similar semantic meanings.", "sentence_starts": [0]}
{"doc_id": "ACL_23_P_378", "wnd_id": "ACL_23_P_378-2", "entity_mentions": [{"id": "ACL_23_P_378-2-E0", "text": "Experimental results on Gigaword and CNN/DM datasets", "start": 0, "end": 7, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_378-2-E1", "text": "on Gigaword and CNN/DM datasets", "start": 2, "end": 7, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_378-2-E2", "text": "our approach achieves significant improvements over strong baselines", "start": 9, "end": 17, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_378-2-E3", "text": "exhibits higher robustness on noisy, attacked, and clean datasets", "start": 18, "end": 27, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_378-2-E4", "text": "our approach achieves significant improvements over strong baselines", "start": 9, "end": 17, "entity_type": "UNK", "mention_type": "UNK"}], "relation_mentions": [], "event_mentions": [{"event_type": "Results/Findings", "id": "ACL_23_P_378-2-EV0", "trigger": {"text": "demonstrate", "start": 7, "end": 8}, "arguments": [{"entity_id": "ACL_23_P_378-2-E0", "text": "Experimental results on Gigaword and CNN/DM datasets", "role": "Agent"}, {"entity_id": "ACL_23_P_378-2-E1", "text": "on Gigaword and CNN/DM datasets", "role": "Context"}, {"entity_id": "ACL_23_P_378-2-E2", "text": "our approach achieves significant improvements over strong baselines", "role": "Results"}, {"entity_id": "ACL_23_P_378-2-E3", "text": "exhibits higher robustness on noisy, attacked, and clean datasets", "role": "Results"}, {"entity_id": "ACL_23_P_378-2-E4", "text": "our approach achieves significant improvements over strong baselines", "role": "PrimaryObject"}]}], "entity_coreference": [], "event_coreference": [], "tokens": ["Experimental", "results", "on", "Gigaword", "and", "CNN/DM", "datasets", "demonstrate", "that", "our", "approach", "achieves", "significant", "improvements", "over", "strong", "baselines", "and", "exhibits", "higher", "robustness", "on", "noisy,", "attacked,", "and", "clean", "datasets."], "pieces": ["Exper", "imental", "results", "on", "G", "ig", "aw", "ord", "and", "CNN", "/", "DM", "dat", "as", "ets", "demon", "strate", "that", "our", "appro", "ach", "ach", "ieves", "significant", "improve", "ments", "over", "strong", "bas", "elines", "and", "ex", "hib", "its", "higher", "rob", "ust", "ness", "on", "no", "isy", ",", "att", "acked", ",", "and", "clean", "dat", "as", "ets", "."], "token_lens": [2, 1, 1, 4, 1, 3, 3, 2, 1, 1, 2, 2, 1, 2, 1, 1, 2, 1, 3, 1, 3, 1, 3, 3, 1, 1, 4], "sentence": "Experimental results on Gigaword and CNN/DM datasets demonstrate that our approach achieves significant improvements over strong baselines and exhibits higher robustness on noisy, attacked, and clean datasets.", "sentence_starts": [0]}
{"doc_id": "ACL_23_P_113", "wnd_id": "ACL_23_P_113-0", "entity_mentions": [{"id": "ACL_23_P_113-0-E0", "text": "We", "start": 0, "end": 1, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_113-0-E1", "text": "we define a free-form question answering task on our dataset and conduct evaluations on multiple LLMs (Large Language Models) to analyze their capacity to generate metalinguistic answers", "start": 99, "end": 126, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_113-0-E2", "text": "Collected from two online forums, the >70k questions (from English learners and others) cover wide-ranging topics including grammar, meaning, fluency, and etymology", "start": 15, "end": 37, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_113-0-E3", "text": "The answers include descriptions of general properties of English vocabulary and grammar as well as explanations about specific (correct and incorrect) usage examples", "start": 37, "end": 60, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_113-0-E4", "text": "Unlike most NLP datasets, this corpus is metalinguistic\u2014it consists of language about language", "start": 60, "end": 73, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_113-0-E5", "text": "As such, it can facilitate investigations of the metalinguistic capabilities of NLU models, as well as educational applications in the language learning domain", "start": 73, "end": 96, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_113-0-E6", "text": "ELQA,", "start": 2, "end": 3, "entity_type": "UNK", "mention_type": "UNK"}], "relation_mentions": [], "event_mentions": [{"event_type": "Methods/Approach", "id": "ACL_23_P_113-0-EV0", "trigger": {"text": "present", "start": 1, "end": 2}, "arguments": [{"entity_id": "ACL_23_P_113-0-E0", "text": "We", "role": "Agent"}, {"entity_id": "ACL_23_P_113-0-E1", "text": "we define a free-form question answering task on our dataset and conduct evaluations on multiple LLMs (Large Language Models) to analyze their capacity to generate metalinguistic answers", "role": "Method"}, {"entity_id": "ACL_23_P_113-0-E2", "text": "Collected from two online forums, the >70k questions (from English learners and others) cover wide-ranging topics including grammar, meaning, fluency, and etymology", "role": "Method"}, {"entity_id": "ACL_23_P_113-0-E3", "text": "The answers include descriptions of general properties of English vocabulary and grammar as well as explanations about specific (correct and incorrect) usage examples", "role": "Method"}, {"entity_id": "ACL_23_P_113-0-E4", "text": "Unlike most NLP datasets, this corpus is metalinguistic\u2014it consists of language about language", "role": "Results"}, {"entity_id": "ACL_23_P_113-0-E5", "text": "As such, it can facilitate investigations of the metalinguistic capabilities of NLU models, as well as educational applications in the language learning domain", "role": "Implications"}, {"entity_id": "ACL_23_P_113-0-E6", "text": "ELQA,", "role": "PrimaryObject"}]}], "entity_coreference": [], "event_coreference": [], "tokens": ["We", "present", "ELQA,", "a", "corpus", "of", "questions", "and", "answers", "in", "and", "about", "the", "English", "language.", "Collected", "from", "two", "online", "forums,", "the", ">70k", "questions", "(from", "English", "learners", "and", "others)", "cover", "wide-ranging", "topics", "including", "grammar,", "meaning,", "fluency,", "and", "etymology.", "The", "answers", "include", "descriptions", "of", "general", "properties", "of", "English", "vocabulary", "and", "grammar", "as", "well", "as", "explanations", "about", "specific", "(correct", "and", "incorrect)", "usage", "examples.", "Unlike", "most", "NLP", "datasets,", "this", "corpus", "is", "metalinguistic\u2014it", "consists", "of", "language", "about", "language.", "As", "such,", "it", "can", "facilitate", "investigations", "of", "the", "metalinguistic", "capabilities", "of", "NLU", "models,", "as", "well", "as", "educational", "applications", "in", "the", "language", "learning", "domain.", "To", "study", "this,", "we", "define", "a", "free-form", "question", "answering", "task", "on", "our", "dataset", "and", "conduct", "evaluations", "on", "multiple", "LLMs", "(Large", "Language", "Models)", "to", "analyze", "their", "capacity", "to", "generate", "metalinguistic", "answers."], "pieces": ["We", "present", "EL", "Q", "A", ",", "a", "cor", "p", "us", "of", "quest", "ions", "and", "ans", "w", "ers", "in", "and", "about", "the", "English", "language", ".", "Col", "lected", "from", "two", "online", "forums", ",", "the", ">", "70", "k", "quest", "ions", "(", "from", "English", "learn", "ers", "and", "other", "s", ")", "cover", "wide", "-", "ranging", "top", "ics", "including", "gram", "mar", ",", "meaning", ",", "flu", "ency", ",", "and", "ety", "mology", ".", "The", "ans", "w", "ers", "include", "desc", "ript", "ions", "of", "general", "properties", "of", "English", "voc", "abulary", "and", "gram", "mar", "as", "well", "as", "ex", "plan", "ations", "about", "specific", "(", "correct", "and", "inc", "orrect", ")", "usage", "ex", "amples", ".", "Unlike", "most", "N", "LP", "dat", "as", "ets", ",", "this", "cor", "p", "us", "is", "met", "aling", "u", "istic", "\u00e2\u0122\u0136", "it", "cons", "ists", "of", "language", "about", "language", ".", "As", "such", ",", "it", "can", "fac", "ilit", "ate", "invest", "ig", "ations", "of", "the", "met", "aling", "u", "istic", "cap", "abilities", "of", "NL", "U", "models", ",", "as", "well", "as", "educ", "ational", "app", "lic", "ations", "in", "the", "language", "learning", "domain", ".", "To", "study", "this", ",", "we", "define", "a", "free", "-", "form", "question", "ans", "w", "ering", "task", "on", "our", "dat", "as", "et", "and", "conduct", "eval", "uations", "on", "multiple", "LL", "Ms", "(", "Large", "Language", "Mod", "els", ")", "to", "analy", "ze", "their", "capacity", "to", "gener", "ate", "met", "aling", "u", "istic", "ans", "w", "ers", "."], "token_lens": [1, 1, 4, 1, 3, 1, 2, 1, 3, 1, 1, 1, 1, 1, 2, 2, 1, 1, 1, 2, 1, 3, 2, 2, 1, 2, 1, 3, 1, 3, 2, 1, 3, 2, 3, 1, 3, 1, 3, 1, 3, 1, 1, 1, 1, 1, 2, 1, 2, 1, 1, 1, 3, 1, 1, 2, 1, 3, 1, 3, 1, 1, 2, 4, 1, 3, 1, 6, 2, 1, 1, 1, 2, 1, 2, 1, 1, 3, 3, 1, 1, 4, 2, 1, 2, 2, 1, 1, 1, 2, 3, 1, 1, 1, 1, 2, 1, 1, 2, 1, 1, 1, 3, 1, 3, 1, 1, 1, 3, 1, 1, 2, 1, 1, 2, 2, 1, 3, 1, 2, 1, 1, 1, 2, 4, 4], "sentence": "We present ELQA, a corpus of questions and answers in and about the English language. Collected from two online forums, the >70k questions (from English learners and others) cover wide-ranging topics including grammar, meaning, fluency, and etymology. The answers include descriptions of general properties of English vocabulary and grammar as well as explanations about specific (correct and incorrect) usage examples. Unlike most NLP datasets, this corpus is metalinguistic\u2014it consists of language about language. As such, it can facilitate investigations of the metalinguistic capabilities of NLU models, as well as educational applications in the language learning domain. To study this, we define a free-form question answering task on our dataset and conduct evaluations on multiple LLMs (Large Language Models) to analyze their capacity to generate metalinguistic answers.", "sentence_starts": [0]}
{"doc_id": "ACL_23_P_312", "wnd_id": "ACL_23_P_312-0", "entity_mentions": [{"id": "ACL_23_P_312-0-E0", "text": "Recent methods for event schema induction", "start": 14, "end": 20, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_312-0-E1", "text": "Event schemas are a form of world knowledge about the typical progression of events", "start": 0, "end": 14, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_312-0-E2", "text": "information extraction systems", "start": 21, "end": 24, "entity_type": "UNK", "mention_type": "UNK"}], "relation_mentions": [], "event_mentions": [{"event_type": "Background/Introduction", "id": "ACL_23_P_312-0-EV0", "trigger": {"text": "use", "start": 20, "end": 21}, "arguments": [{"entity_id": "ACL_23_P_312-0-E0", "text": "Recent methods for event schema induction", "role": "Agent"}, {"entity_id": "ACL_23_P_312-0-E1", "text": "Event schemas are a form of world knowledge about the typical progression of events", "role": "Context"}, {"entity_id": "ACL_23_P_312-0-E2", "text": "information extraction systems", "role": "PrimaryObject"}]}], "entity_coreference": [], "event_coreference": [], "tokens": ["Event", "schemas", "are", "a", "form", "of", "world", "knowledge", "about", "the", "typical", "progression", "of", "events.", "Recent", "methods", "for", "event", "schema", "induction", "use", "information", "extraction", "systems", "to", "construct", "a", "large", "number", "of", "event", "graph", "instances", "from", "documents,", "and", "then", "learn", "to", "generalize", "the", "schema", "from", "such", "instances."], "pieces": ["Event", "sc", "hem", "as", "are", "a", "form", "of", "world", "knowledge", "about", "the", "typ", "ical", "pro", "gression", "of", "events", ".", "Recent", "method", "s", "for", "event", "sche", "ma", "ind", "uction", "use", "information", "ext", "raction", "system", "s", "to", "construct", "a", "large", "number", "of", "event", "graph", "inst", "ances", "from", "doc", "uments", ",", "and", "then", "learn", "to", "general", "ize", "the", "sche", "ma", "from", "such", "inst", "ances", "."], "token_lens": [1, 3, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 1, 2, 1, 2, 1, 1, 2, 2, 1, 1, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 3, 1, 1, 1, 1, 2, 1, 2, 1, 1, 3], "sentence": "Event schemas are a form of world knowledge about the typical progression of events. Recent methods for event schema induction use information extraction systems to construct a large number of event graph instances from documents, and then learn to generalize the schema from such instances.", "sentence_starts": [0]}
{"doc_id": "ACL_23_P_312", "wnd_id": "ACL_23_P_312-1", "entity_mentions": [{"id": "ACL_23_P_312-1-E0", "text": "we", "start": 2, "end": 3, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_312-1-E1", "text": "event schemas have complex graph structures", "start": 50, "end": 56, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_312-1-E2", "text": "we design an incremental prompting and verification method IncPrompt to break down the construction of a complex event graph into three stages: event skeleton construction, event expansion, and event-event relation verification", "start": 56, "end": 87, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_312-1-E3", "text": "new paradigm greatly simplifies the schema induction process and allows us to handle both hierarchical relations and temporal relations between events in a straightforward way", "start": 24, "end": 49, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_312-1-E4", "text": "event schemas", "start": 6, "end": 8, "entity_type": "UNK", "mention_type": "UNK"}], "relation_mentions": [], "event_mentions": [{"event_type": "Methods/Approach", "id": "ACL_23_P_312-1-EV0", "trigger": {"text": "propose to treat", "start": 3, "end": 6}, "arguments": [{"entity_id": "ACL_23_P_312-1-E0", "text": "we", "role": "Agent"}, {"entity_id": "ACL_23_P_312-1-E1", "text": "event schemas have complex graph structures", "role": "Context"}, {"entity_id": "ACL_23_P_312-1-E2", "text": "we design an incremental prompting and verification method IncPrompt to break down the construction of a complex event graph into three stages: event skeleton construction, event expansion, and event-event relation verification", "role": "Method"}, {"entity_id": "ACL_23_P_312-1-E3", "text": "new paradigm greatly simplifies the schema induction process and allows us to handle both hierarchical relations and temporal relations between events in a straightforward way", "role": "Results"}, {"entity_id": "ACL_23_P_312-1-E4", "text": "event schemas", "role": "PrimaryObject"}]}], "entity_coreference": [], "event_coreference": [], "tokens": ["In", "contrast,", "we", "propose", "to", "treat", "event", "schemas", "as", "a", "form", "of", "commonsense", "knowledge", "that", "can", "be", "derived", "from", "large", "language", "models", "(LLMs).", "This", "new", "paradigm", "greatly", "simplifies", "the", "schema", "induction", "process", "and", "allows", "us", "to", "handle", "both", "hierarchical", "relations", "and", "temporal", "relations", "between", "events", "in", "a", "straightforward", "way.", "Since", "event", "schemas", "have", "complex", "graph", "structures,", "we", "design", "an", "incremental", "prompting", "and", "verification", "method", "IncPrompt", "to", "break", "down", "the", "construction", "of", "a", "complex", "event", "graph", "into", "three", "stages:", "event", "skeleton", "construction,", "event", "expansion,", "and", "event-event", "relation", "verification"], "pieces": ["In", "cont", "rast", ",", "we", "pro", "pose", "to", "t", "reat", "event", "sc", "hem", "as", "as", "a", "form", "of", "comm", "onsense", "knowledge", "that", "can", "be", "derived", "from", "large", "language", "models", "(", "LL", "Ms", ").", "This", "new", "par", "ad", "igm", "great", "ly", "sim", "pl", "ifies", "the", "sche", "ma", "ind", "uction", "process", "and", "allows", "us", "to", "handle", "both", "h", "ier", "arch", "ical", "relations", "and", "tem", "poral", "relations", "between", "events", "in", "a", "straight", "forward", "way", ".", "Since", "event", "sc", "hem", "as", "have", "complex", "graph", "struct", "ures", ",", "we", "design", "an", "incre", "mental", "prom", "pt", "ing", "and", "ver", "ification", "method", "Inc", "Prom", "pt", "to", "break", "down", "the", "const", "ruction", "of", "a", "complex", "event", "graph", "into", "three", "st", "ages", ":", "event", "s", "keleton", "const", "ruction", ",", "event", "exp", "ansion", ",", "and", "event", "-", "event", "relation", "ver", "ification"], "token_lens": [1, 3, 1, 2, 1, 2, 1, 3, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 4, 1, 1, 3, 2, 3, 1, 2, 2, 1, 1, 1, 1, 1, 1, 1, 4, 1, 1, 2, 1, 1, 1, 1, 1, 2, 2, 1, 1, 3, 1, 1, 1, 3, 1, 1, 1, 2, 3, 1, 2, 1, 3, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 3, 1, 2, 3, 1, 3, 1, 3, 1, 2], "sentence": "In contrast, we propose to treat event schemas as a form of commonsense knowledge that can be derived from large language models (LLMs). This new paradigm greatly simplifies the schema induction process and allows us to handle both hierarchical relations and temporal relations between events in a straightforward way. Since event schemas have complex graph structures, we design an incremental prompting and verification method IncPrompt to break down the construction of a complex event graph into three stages: event skeleton construction, event expansion, and event-event relation verification", "sentence_starts": [0]}
{"doc_id": "ACL_23_P_312", "wnd_id": "ACL_23_P_312-2", "entity_mentions": [{"id": "ACL_23_P_312-2-E0", "text": "IncSchema", "start": 10, "end": 11, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_312-2-E1", "text": "compared to the previous state-of-the-art closed-domain schema induction model, human assessors were able to cover ~10% more events when translating the schemas into coherent stories and rated our schemas 1.3 points higher (on a 5-point scale) in terms of readability", "start": 33, "end": 73, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_312-2-E2", "text": "large and complex schemas", "start": 13, "end": 17, "entity_type": "UNK", "mention_type": "UNK"}], "relation_mentions": [], "event_mentions": [{"event_type": "Results/Findings", "id": "ACL_23_P_312-2-EV0", "trigger": {"text": "generate", "start": 6, "end": 7}, "arguments": [{"entity_id": "ACL_23_P_312-2-E0", "text": "IncSchema", "role": "Agent"}, {"entity_id": "ACL_23_P_312-2-E1", "text": "compared to the previous state-of-the-art closed-domain schema induction model, human assessors were able to cover ~10% more events when translating the schemas into coherent stories and rated our schemas 1.3 points higher (on a 5-point scale) in terms of readability", "role": "Results"}, {"entity_id": "ACL_23_P_312-2-E2", "text": "large and complex schemas", "role": "PrimaryObject"}]}], "entity_coreference": [], "event_coreference": [], "tokens": ["Compared", "to", "directly", "using", "LLMs", "to", "generate", "a", "linearized", "graph,", "IncSchema", "can", "generate", "large", "and", "complex", "schemas", "with", "7.2%", "F1", "improvement", "in", "temporal", "relations", "and", "31.0%", "F1", "improvement", "in", "hierarchical", "relations.", "In", "addition,", "compared", "to", "the", "previous", "state-of-the-art", "closed-domain", "schema", "induction", "model,", "human", "assessors", "were", "able", "to", "cover", "~10%", "more", "events", "when", "translating", "the", "schemas", "into", "coherent", "stories", "and", "rated", "our", "schemas", "1.3", "points", "higher", "(on", "a", "5-point", "scale)", "in", "terms", "of", "readability."], "pieces": ["Compared", "to", "direct", "ly", "using", "LL", "Ms", "to", "gener", "ate", "a", "linear", "ized", "graph", ",", "Inc", "Sche", "ma", "can", "gener", "ate", "large", "and", "complex", "sc", "hem", "as", "with", "7", ".", "2", "%", "F", "1", "improve", "ment", "in", "tem", "poral", "relations", "and", "31", ".", "0", "%", "F", "1", "improve", "ment", "in", "h", "ier", "arch", "ical", "relations", ".", "In", "add", "ition", ",", "comp", "ared", "to", "the", "pre", "vious", "state", "-", "of", "-", "the", "-", "art", "closed", "-", "domain", "sche", "ma", "ind", "uction", "model", ",", "human", "ass", "essors", "were", "able", "to", "cover", "~", "10", "%", "more", "events", "when", "trans", "l", "ating", "the", "sc", "hem", "as", "into", "co", "herent", "stories", "and", "rated", "our", "sc", "hem", "as", "1", ".", "3", "points", "higher", "(", "on", "a", "5", "-", "point", "scale", ")", "in", "terms", "of", "read", "ability", "."], "token_lens": [1, 1, 2, 1, 2, 1, 2, 1, 2, 2, 3, 1, 2, 1, 1, 1, 3, 1, 4, 2, 2, 1, 2, 1, 1, 4, 2, 2, 1, 4, 2, 1, 3, 2, 1, 1, 2, 7, 3, 2, 2, 2, 1, 2, 1, 1, 1, 1, 3, 1, 1, 1, 3, 1, 3, 1, 2, 1, 1, 1, 1, 3, 3, 1, 1, 2, 1, 3, 2, 1, 1, 1, 3], "sentence": "Compared to directly using LLMs to generate a linearized graph, IncSchema can generate large and complex schemas with 7.2% F1 improvement in temporal relations and 31.0% F1 improvement in hierarchical relations. In addition, compared to the previous state-of-the-art closed-domain schema induction model, human assessors were able to cover ~10% more events when translating the schemas into coherent stories and rated our schemas 1.3 points higher (on a 5-point scale) in terms of readability.", "sentence_starts": [0]}
{"doc_id": "ACL_23_P_550", "wnd_id": "ACL_23_P_550-0", "entity_mentions": [{"id": "ACL_23_P_550-0-E0", "text": "Large language models (LLMs)", "start": 0, "end": 4, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_550-0-E1", "text": "This work examines the ability of LLMs on negative commonsense knowledge", "start": 47, "end": 58, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_550-0-E2", "text": "However, negative knowledge, such as \u201clions don\u2019t live in the ocean\u201d, is also ubiquitous in the world but rarely mentioned explicitly in text", "start": 17, "end": 40, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_550-0-E3", "text": "What do LLMs know about negative knowledge", "start": 40, "end": 47, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_550-0-E4", "text": "their ability to store and utilize positive knowledge", "start": 9, "end": 17, "entity_type": "UNK", "mention_type": "UNK"}], "relation_mentions": [], "event_mentions": [{"event_type": "Background/Introduction", "id": "ACL_23_P_550-0-EV0", "trigger": {"text": "have been widely studied for", "start": 4, "end": 9}, "arguments": [{"entity_id": "ACL_23_P_550-0-E0", "text": "Large language models (LLMs)", "role": "Agent"}, {"entity_id": "ACL_23_P_550-0-E1", "text": "This work examines the ability of LLMs on negative commonsense knowledge", "role": "Context"}, {"entity_id": "ACL_23_P_550-0-E2", "text": "However, negative knowledge, such as \u201clions don\u2019t live in the ocean\u201d, is also ubiquitous in the world but rarely mentioned explicitly in text", "role": "Challenge"}, {"entity_id": "ACL_23_P_550-0-E3", "text": "What do LLMs know about negative knowledge", "role": "Challenge"}, {"entity_id": "ACL_23_P_550-0-E4", "text": "their ability to store and utilize positive knowledge", "role": "PrimaryObject"}]}], "entity_coreference": [], "event_coreference": [], "tokens": ["Large", "language", "models", "(LLMs)", "have", "been", "widely", "studied", "for", "their", "ability", "to", "store", "and", "utilize", "positive", "knowledge.", "However,", "negative", "knowledge,", "such", "as", "\u201clions", "don\u2019t", "live", "in", "the", "ocean\u201d,", "is", "also", "ubiquitous", "in", "the", "world", "but", "rarely", "mentioned", "explicitly", "in", "text.", "What", "do", "LLMs", "know", "about", "negative", "knowledge?", "This", "work", "examines", "the", "ability", "of", "LLMs", "on", "negative", "commonsense", "knowledge."], "pieces": ["Large", "language", "models", "(", "LL", "Ms", ")", "have", "been", "wide", "ly", "stud", "ied", "for", "their", "ability", "to", "store", "and", "util", "ize", "positive", "knowledge", ".", "However", ",", "negative", "knowledge", ",", "such", "as", "\u00e2\u0122", "\u013e", "l", "ions", "don", "\u00e2\u0122", "\u013b", "t", "live", "in", "the", "o", "cean", "\u00e2\u0122", "\u013f", ",", "is", "also", "ub", "iqu", "itous", "in", "the", "world", "but", "ra", "rely", "mentioned", "expl", "icit", "ly", "in", "text", ".", "What", "do", "LL", "Ms", "know", "about", "negative", "knowledge", "?", "This", "work", "ex", "amines", "the", "ability", "of", "LL", "Ms", "on", "negative", "comm", "onsense", "knowledge", "."], "token_lens": [1, 1, 1, 4, 1, 1, 2, 2, 1, 1, 1, 1, 1, 1, 2, 1, 2, 2, 1, 2, 1, 1, 4, 4, 1, 1, 1, 5, 1, 1, 3, 1, 1, 1, 1, 2, 1, 3, 1, 2, 1, 1, 2, 1, 1, 1, 2, 1, 1, 2, 1, 1, 1, 2, 1, 1, 2, 2], "sentence": "Large language models (LLMs) have been widely studied for their ability to store and utilize positive knowledge. However, negative knowledge, such as \u201clions don\u2019t live in the ocean\u201d, is also ubiquitous in the world but rarely mentioned explicitly in text. What do LLMs know about negative knowledge? This work examines the ability of LLMs on negative commonsense knowledge.", "sentence_starts": [0]}
{"doc_id": "ACL_23_P_550", "wnd_id": "ACL_23_P_550-1", "entity_mentions": [{"id": "ACL_23_P_550-1-E0", "text": "We", "start": 0, "end": 1, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_550-1-E1", "text": "to probe LLMs", "start": 15, "end": 18, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_550-1-E2", "text": "a constrained keywords-to-sentence generation task (CG)", "start": 2, "end": 8, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_550-1-E3", "text": "a Boolean question answering task (QA)", "start": 9, "end": 15, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_550-1-E4", "text": "a constrained keywords-to-sentence generation task (CG)", "start": 2, "end": 8, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_550-1-E5", "text": "a Boolean question answering task (QA)", "start": 9, "end": 15, "entity_type": "UNK", "mention_type": "UNK"}], "relation_mentions": [], "event_mentions": [{"event_type": "Methods/Approach", "id": "ACL_23_P_550-1-EV0", "trigger": {"text": "design", "start": 1, "end": 2}, "arguments": [{"entity_id": "ACL_23_P_550-1-E0", "text": "We", "role": "Agent"}, {"entity_id": "ACL_23_P_550-1-E1", "text": "to probe LLMs", "role": "Purpose"}, {"entity_id": "ACL_23_P_550-1-E2", "text": "a constrained keywords-to-sentence generation task (CG)", "role": "Method"}, {"entity_id": "ACL_23_P_550-1-E3", "text": "a Boolean question answering task (QA)", "role": "Method"}, {"entity_id": "ACL_23_P_550-1-E4", "text": "a constrained keywords-to-sentence generation task (CG)", "role": "PrimaryObject"}, {"entity_id": "ACL_23_P_550-1-E5", "text": "a Boolean question answering task (QA)", "role": "SecondaryObject"}]}], "entity_coreference": [], "event_coreference": [], "tokens": ["We", "design", "a", "constrained", "keywords-to-sentence", "generation", "task", "(CG)", "and", "a", "Boolean", "question", "answering", "task", "(QA)", "to", "probe", "LLMs."], "pieces": ["We", "design", "a", "con", "str", "ained", "key", "words", "-", "to", "-", "sent", "ence", "generation", "task", "(", "CG", ")", "and", "a", "Boo", "lean", "question", "ans", "w", "ering", "task", "(", "Q", "A", ")", "to", "pro", "be", "LL", "Ms", "."], "token_lens": [1, 1, 1, 3, 7, 1, 1, 3, 1, 1, 2, 1, 3, 1, 4, 1, 2, 3], "sentence": "We design a constrained keywords-to-sentence generation task (CG) and a Boolean question answering task (QA) to probe LLMs.", "sentence_starts": [0]}
{"doc_id": "ACL_23_P_550", "wnd_id": "ACL_23_P_550-2", "entity_mentions": [{"id": "ACL_23_P_550-2-E0", "text": "Our experiments", "start": 0, "end": 2, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_550-2-E1", "text": "We term this phenomenon the belief conflict of LLMs", "start": 24, "end": 33, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_550-2-E2", "text": "they can correctly answer polar yes-or-no questions", "start": 17, "end": 24, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_550-2-E3", "text": "Our further analysis shows that statistical shortcuts and negation reporting bias from language modeling pre-training cause this conflict", "start": 33, "end": 51, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_550-2-E4", "text": "LLMs frequently fail to generate valid sentences grounded in negative commonsense knowledge", "start": 4, "end": 16, "entity_type": "UNK", "mention_type": "UNK"}], "relation_mentions": [], "event_mentions": [{"event_type": "Results/Findings", "id": "ACL_23_P_550-2-EV0", "trigger": {"text": "reveal", "start": 2, "end": 3}, "arguments": [{"entity_id": "ACL_23_P_550-2-E0", "text": "Our experiments", "role": "Agent"}, {"entity_id": "ACL_23_P_550-2-E1", "text": "We term this phenomenon the belief conflict of LLMs", "role": "Method"}, {"entity_id": "ACL_23_P_550-2-E2", "text": "they can correctly answer polar yes-or-no questions", "role": "Results"}, {"entity_id": "ACL_23_P_550-2-E3", "text": "Our further analysis shows that statistical shortcuts and negation reporting bias from language modeling pre-training cause this conflict", "role": "Results"}, {"entity_id": "ACL_23_P_550-2-E4", "text": "LLMs frequently fail to generate valid sentences grounded in negative commonsense knowledge", "role": "PrimaryObject"}]}], "entity_coreference": [], "event_coreference": [], "tokens": ["Our", "experiments", "reveal", "that", "LLMs", "frequently", "fail", "to", "generate", "valid", "sentences", "grounded", "in", "negative", "commonsense", "knowledge,", "yet", "they", "can", "correctly", "answer", "polar", "yes-or-no", "questions.", "We", "term", "this", "phenomenon", "the", "belief", "conflict", "of", "LLMs.", "Our", "further", "analysis", "shows", "that", "statistical", "shortcuts", "and", "negation", "reporting", "bias", "from", "language", "modeling", "pre-training", "cause", "this", "conflict."], "pieces": ["Our", "exper", "iments", "reve", "al", "that", "LL", "Ms", "f", "requently", "fail", "to", "gener", "ate", "valid", "sent", "ences", "ground", "ed", "in", "negative", "comm", "onsense", "knowledge", ",", "yet", "they", "can", "correct", "ly", "answer", "p", "olar", "yes", "-", "or", "-", "no", "quest", "ions", ".", "We", "term", "this", "phen", "omen", "on", "the", "bel", "ief", "conf", "lict", "of", "LL", "Ms", ".", "Our", "f", "urther", "analysis", "shows", "that", "stat", "istical", "short", "cuts", "and", "neg", "ation", "reporting", "b", "ias", "from", "language", "mod", "eling", "pre", "-", "training", "cause", "this", "conf", "lict", "."], "token_lens": [1, 2, 2, 1, 2, 2, 1, 1, 2, 1, 2, 2, 1, 1, 2, 2, 1, 1, 1, 2, 1, 2, 5, 3, 1, 1, 1, 3, 1, 2, 2, 1, 3, 1, 2, 1, 1, 1, 2, 2, 1, 2, 1, 2, 1, 1, 2, 3, 1, 1, 3], "sentence": "Our experiments reveal that LLMs frequently fail to generate valid sentences grounded in negative commonsense knowledge, yet they can correctly answer polar yes-or-no questions. We term this phenomenon the belief conflict of LLMs. Our further analysis shows that statistical shortcuts and negation reporting bias from language modeling pre-training cause this conflict.", "sentence_starts": [0]}
{"doc_id": "ACL_23_P_496", "wnd_id": "ACL_23_P_496-0", "entity_mentions": [{"id": "ACL_23_P_496-0-E0", "text": "Spoken language understanding (SLU) tasks", "start": 0, "end": 5, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_496-0-E1", "text": "have not received as much attention as lower-level tasks like speech and speaker recognition", "start": 17, "end": 31, "entity_type": "UNK", "mention_type": "UNK"}], "relation_mentions": [], "event_mentions": [{"event_type": "Background/Introduction", "id": "ACL_23_P_496-0-EV0", "trigger": {"text": "have been studied", "start": 5, "end": 8}, "arguments": [{"entity_id": "ACL_23_P_496-0-E0", "text": "Spoken language understanding (SLU) tasks", "role": "Agent"}, {"entity_id": "ACL_23_P_496-0-E1", "text": "have not received as much attention as lower-level tasks like speech and speaker recognition", "role": "Challenge"}]}], "entity_coreference": [], "event_coreference": [], "tokens": ["Spoken", "language", "understanding", "(SLU)", "tasks", "have", "been", "studied", "for", "many", "decades", "in", "the", "speech", "research", "community,", "but", "have", "not", "received", "as", "much", "attention", "as", "lower-level", "tasks", "like", "speech", "and", "speaker", "recognition."], "pieces": ["Sp", "oken", "language", "under", "standing", "(", "SL", "U", ")", "t", "asks", "have", "been", "stud", "ied", "for", "many", "dec", "ades", "in", "the", "speech", "research", "community", ",", "but", "have", "not", "received", "as", "much", "att", "ention", "as", "lower", "-", "level", "t", "asks", "like", "speech", "and", "spe", "aker", "recogn", "ition", "."], "token_lens": [2, 1, 2, 4, 2, 1, 1, 2, 1, 1, 2, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 2, 1, 3, 2, 1, 1, 1, 2, 3], "sentence": "Spoken language understanding (SLU) tasks have been studied for many decades in the speech research community, but have not received as much attention as lower-level tasks like speech and speaker recognition.", "sentence_starts": [0]}
{"doc_id": "ACL_23_P_496", "wnd_id": "ACL_23_P_496-1", "entity_mentions": [{"id": "ACL_23_P_496-1-E0", "text": "we", "start": 3, "end": 4, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_496-1-E1", "text": "In order to facilitate the development of SLU models that leverage the success of pre-trained speech representations", "start": 69, "end": 86, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_496-1-E2", "text": "question answering and summarization involve inference over longer speech sequences", "start": 33, "end": 43, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_496-1-E3", "text": "named entity localization addresses the speech-specific task of locating the targeted content in the signal", "start": 43, "end": 58, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_496-1-E4", "text": "dialog act classification identifies the function of a given speech utterance", "start": 58, "end": 69, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_496-1-E5", "text": "curated annotations for a relatively small fine-tuning set", "start": 98, "end": 106, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_496-1-E6", "text": "reproducible pipeline (speech recognizer + text model) and end-to-end baseline models and evaluation metrics", "start": 107, "end": 121, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_496-1-E7", "text": "baseline model performance in various types of systems for easy comparisons", "start": 122, "end": 133, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_496-1-E8", "text": "several new annotated SLU benchmark tasks based on freely available speech data", "start": 5, "end": 17, "entity_type": "UNK", "mention_type": "UNK"}], "relation_mentions": [], "event_mentions": [{"event_type": "Methods/Approach", "id": "ACL_23_P_496-1-EV0", "trigger": {"text": "introduce", "start": 4, "end": 5}, "arguments": [{"entity_id": "ACL_23_P_496-1-E0", "text": "we", "role": "Agent"}, {"entity_id": "ACL_23_P_496-1-E1", "text": "In order to facilitate the development of SLU models that leverage the success of pre-trained speech representations", "role": "Purpose"}, {"entity_id": "ACL_23_P_496-1-E2", "text": "question answering and summarization involve inference over longer speech sequences", "role": "Method"}, {"entity_id": "ACL_23_P_496-1-E3", "text": "named entity localization addresses the speech-specific task of locating the targeted content in the signal", "role": "Method"}, {"entity_id": "ACL_23_P_496-1-E4", "text": "dialog act classification identifies the function of a given speech utterance", "role": "Method"}, {"entity_id": "ACL_23_P_496-1-E5", "text": "curated annotations for a relatively small fine-tuning set", "role": "Method"}, {"entity_id": "ACL_23_P_496-1-E6", "text": "reproducible pipeline (speech recognizer + text model) and end-to-end baseline models and evaluation metrics", "role": "Method"}, {"entity_id": "ACL_23_P_496-1-E7", "text": "baseline model performance in various types of systems for easy comparisons", "role": "Method"}, {"entity_id": "ACL_23_P_496-1-E8", "text": "several new annotated SLU benchmark tasks based on freely available speech data", "role": "PrimaryObject"}]}], "entity_coreference": [], "event_coreference": [], "tokens": ["In", "this", "work,", "we", "introduce", "several", "new", "annotated", "SLU", "benchmark", "tasks", "based", "on", "freely", "available", "speech", "data,", "which", "complement", "existing", "benchmarks", "and", "address", "gaps", "in", "the", "SLU", "evaluation", "landscape.", "We", "contribute", "four", "tasks:", "question", "answering", "and", "summarization", "involve", "inference", "over", "longer", "speech", "sequences;", "named", "entity", "localization", "addresses", "the", "speech-specific", "task", "of", "locating", "the", "targeted", "content", "in", "the", "signal;", "dialog", "act", "classification", "identifies", "the", "function", "of", "a", "given", "speech", "utterance.", "In", "order", "to", "facilitate", "the", "development", "of", "SLU", "models", "that", "leverage", "the", "success", "of", "pre-trained", "speech", "representations,", "we", "will", "release", "a", "new", "benchmark", "suite,", "including", "for", "each", "task", "(i)", "curated", "annotations", "for", "a", "relatively", "small", "fine-tuning", "set,", "(ii)", "reproducible", "pipeline", "(speech", "recognizer", "+", "text", "model)", "and", "end-to-end", "baseline", "models", "and", "evaluation", "metrics,", "(iii)", "baseline", "model", "performance", "in", "various", "types", "of", "systems", "for", "easy", "comparisons."], "pieces": ["In", "this", "work", ",", "we", "introdu", "ce", "sever", "al", "new", "annot", "ated", "SL", "U", "bench", "mark", "t", "asks", "based", "on", "free", "ly", "available", "speech", "data", ",", "which", "com", "plement", "existing", "bench", "marks", "and", "address", "g", "aps", "in", "the", "SL", "U", "eval", "uation", "land", "scape", ".", "We", "cont", "ribute", "four", "t", "asks", ":", "question", "ans", "w", "ering", "and", "sum", "mar", "ization", "inv", "olve", "in", "ference", "over", "long", "er", "speech", "sequ", "ences", ";", "named", "entity", "local", "ization", "add", "resses", "the", "speech", "-", "specific", "task", "of", "loc", "ating", "the", "target", "ed", "content", "in", "the", "sign", "al", ";", "dial", "og", "act", "class", "ification", "ident", "ifies", "the", "function", "of", "a", "given", "speech", "utter", "ance", ".", "In", "order", "to", "fac", "ilit", "ate", "the", "development", "of", "SL", "U", "models", "that", "le", "verage", "the", "success", "of", "pre", "-", "trained", "speech", "represent", "ations", ",", "we", "will", "release", "a", "new", "bench", "mark", "su", "ite", ",", "including", "for", "each", "task", "(", "i", ")", "cur", "ated", "annot", "ations", "for", "a", "rel", "atively", "small", "fine", "-", "tun", "ing", "set", ",", "(", "ii", ")", "re", "pro", "duc", "ible", "p", "ip", "eline", "(", "speech", "recogn", "izer", "+", "text", "model", ")", "and", "end", "-", "to", "-", "end", "bas", "eline", "models", "and", "eval", "uation", "met", "rics", ",", "(", "iii", ")", "bas", "eline", "model", "performance", "in", "var", "ious", "types", "of", "system", "s", "for", "easy", "com", "par", "isons", "."], "token_lens": [1, 1, 2, 1, 2, 2, 1, 2, 2, 2, 2, 1, 1, 2, 1, 1, 2, 1, 2, 1, 2, 1, 1, 2, 1, 1, 2, 2, 3, 1, 2, 1, 3, 1, 3, 1, 3, 2, 2, 1, 2, 1, 3, 1, 1, 2, 2, 1, 3, 1, 1, 2, 1, 2, 1, 1, 1, 3, 2, 1, 2, 2, 1, 1, 1, 1, 1, 1, 3, 1, 1, 1, 3, 1, 1, 1, 2, 1, 1, 2, 1, 1, 1, 3, 1, 3, 1, 1, 1, 1, 1, 2, 3, 1, 1, 1, 1, 3, 2, 2, 1, 1, 2, 1, 4, 2, 3, 4, 3, 2, 2, 1, 1, 2, 1, 5, 2, 1, 1, 2, 3, 3, 2, 1, 1, 1, 2, 1, 1, 2, 1, 1, 4], "sentence": "In this work, we introduce several new annotated SLU benchmark tasks based on freely available speech data, which complement existing benchmarks and address gaps in the SLU evaluation landscape. We contribute four tasks: question answering and summarization involve inference over longer speech sequences; named entity localization addresses the speech-specific task of locating the targeted content in the signal; dialog act classification identifies the function of a given speech utterance. In order to facilitate the development of SLU models that leverage the success of pre-trained speech representations, we will release a new benchmark suite, including for each task (i) curated annotations for a relatively small fine-tuning set, (ii) reproducible pipeline (speech recognizer + text model) and end-to-end baseline models and evaluation metrics, (iii) baseline model performance in various types of systems for easy comparisons.", "sentence_starts": [0]}
{"doc_id": "ACL_23_P_496", "wnd_id": "ACL_23_P_496-2", "entity_mentions": [{"id": "ACL_23_P_496-2-E0", "text": "We", "start": 0, "end": 1, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_496-2-E1", "text": "We also analyze the sensitivity of pipeline models\u2019 performance to the speech recognition accuracy, using more than 20 publicly available speech recognition models", "start": 16, "end": 39, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_496-2-E2", "text": "the details of data collection and annotation and the performance of the baseline models", "start": 2, "end": 16, "entity_type": "UNK", "mention_type": "UNK"}], "relation_mentions": [], "event_mentions": [{"event_type": "Results/Findings", "id": "ACL_23_P_496-2-EV0", "trigger": {"text": "present", "start": 1, "end": 2}, "arguments": [{"entity_id": "ACL_23_P_496-2-E0", "text": "We", "role": "Agent"}, {"entity_id": "ACL_23_P_496-2-E1", "text": "We also analyze the sensitivity of pipeline models\u2019 performance to the speech recognition accuracy, using more than 20 publicly available speech recognition models", "role": "Method"}, {"entity_id": "ACL_23_P_496-2-E2", "text": "the details of data collection and annotation and the performance of the baseline models", "role": "PrimaryObject"}]}], "entity_coreference": [], "event_coreference": [], "tokens": ["We", "present", "the", "details", "of", "data", "collection", "and", "annotation", "and", "the", "performance", "of", "the", "baseline", "models.", "We", "also", "analyze", "the", "sensitivity", "of", "pipeline", "models\u2019", "performance", "to", "the", "speech", "recognition", "accuracy,", "using", "more", "than", "20", "publicly", "available", "speech", "recognition", "models."], "pieces": ["We", "present", "the", "details", "of", "data", "collection", "and", "ann", "otation", "and", "the", "performance", "of", "the", "bas", "eline", "models", ".", "We", "also", "analy", "ze", "the", "s", "ensitivity", "of", "p", "ip", "eline", "models", "\u00e2\u0122", "\u013b", "performance", "to", "the", "speech", "recogn", "ition", "acc", "uracy", ",", "using", "more", "than", "20", "public", "ly", "available", "speech", "recogn", "ition", "models", "."], "token_lens": [1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 2, 2, 1, 1, 2, 1, 2, 1, 3, 3, 1, 1, 1, 1, 2, 3, 1, 1, 1, 1, 2, 1, 1, 2, 2], "sentence": "We present the details of data collection and annotation and the performance of the baseline models. We also analyze the sensitivity of pipeline models\u2019 performance to the speech recognition accuracy, using more than 20 publicly available speech recognition models.", "sentence_starts": [0]}
{"doc_id": "ACL_23_P_828", "wnd_id": "ACL_23_P_828-0", "entity_mentions": [{"id": "ACL_23_P_828-0-E0", "text": "Reasoning about time", "start": 0, "end": 3, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_828-0-E1", "text": "Many facts are time-dependent", "start": 7, "end": 11, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_828-0-E2", "text": "For example, athletes change teams from time to time, and different government officials are elected periodically", "start": 11, "end": 27, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_828-0-E3", "text": "Previous time-dependent question answering (QA) datasets tend to be biased in either their coverage of time spans or question types", "start": 27, "end": 47, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_828-0-E4", "text": "of fundamental importance", "start": 4, "end": 7, "entity_type": "UNK", "mention_type": "UNK"}], "relation_mentions": [], "event_mentions": [{"event_type": "Background/Introduction", "id": "ACL_23_P_828-0-EV0", "trigger": {"text": "is", "start": 3, "end": 4}, "arguments": [{"entity_id": "ACL_23_P_828-0-E0", "text": "Reasoning about time", "role": "Agent"}, {"entity_id": "ACL_23_P_828-0-E1", "text": "Many facts are time-dependent", "role": "Context"}, {"entity_id": "ACL_23_P_828-0-E2", "text": "For example, athletes change teams from time to time, and different government officials are elected periodically", "role": "Analysis"}, {"entity_id": "ACL_23_P_828-0-E3", "text": "Previous time-dependent question answering (QA) datasets tend to be biased in either their coverage of time spans or question types", "role": "Challenge"}, {"entity_id": "ACL_23_P_828-0-E4", "text": "of fundamental importance", "role": "PrimaryObject"}]}], "entity_coreference": [], "event_coreference": [], "tokens": ["Reasoning", "about", "time", "is", "of", "fundamental", "importance.", "Many", "facts", "are", "time-dependent.", "For", "example,", "athletes", "change", "teams", "from", "time", "to", "time,", "and", "different", "government", "officials", "are", "elected", "periodically.", "Previous", "time-dependent", "question", "answering", "(QA)", "datasets", "tend", "to", "be", "biased", "in", "either", "their", "coverage", "of", "time", "spans", "or", "question", "types."], "pieces": ["Reason", "ing", "about", "time", "is", "of", "fund", "amental", "import", "ance", ".", "Many", "facts", "are", "time", "-", "dependent", ".", "For", "example", ",", "ath", "letes", "change", "te", "ams", "from", "time", "to", "time", ",", "and", "different", "government", "offic", "ials", "are", "elected", "period", "ically", ".", "Previous", "time", "-", "dependent", "question", "ans", "w", "ering", "(", "Q", "A", ")", "dat", "as", "ets", "t", "end", "to", "be", "biased", "in", "either", "their", "co", "verage", "of", "time", "sp", "ans", "or", "question", "types", "."], "token_lens": [2, 1, 1, 1, 1, 2, 3, 1, 1, 1, 4, 1, 2, 2, 1, 2, 1, 1, 1, 2, 1, 1, 1, 2, 1, 1, 3, 1, 3, 1, 3, 4, 3, 2, 1, 1, 1, 1, 1, 1, 2, 1, 1, 2, 1, 1, 2], "sentence": "Reasoning about time is of fundamental importance. Many facts are time-dependent. For example, athletes change teams from time to time, and different government officials are elected periodically. Previous time-dependent question answering (QA) datasets tend to be biased in either their coverage of time spans or question types.", "sentence_starts": [0]}
{"doc_id": "ACL_23_P_828", "wnd_id": "ACL_23_P_828-1", "entity_mentions": [{"id": "ACL_23_P_828-1-E0", "text": "we", "start": 3, "end": 4, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_828-1-E1", "text": "to evaluate the temporal reasoning capability of large language models", "start": 10, "end": 20, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_828-1-E2", "text": "Our dataset includes questions of three temporal reasoning levels", "start": 20, "end": 29, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_828-1-E3", "text": "we also propose a novel learning framework to improve the temporal reasoning capability of large language models, based on temporal span extraction and time-sensitive reinforcement learning", "start": 31, "end": 57, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_828-1-E4", "text": "a comprehensive probing dataset TempReason", "start": 5, "end": 10, "entity_type": "UNK", "mention_type": "UNK"}], "relation_mentions": [], "event_mentions": [{"event_type": "Methods/Approach", "id": "ACL_23_P_828-1-EV0", "trigger": {"text": "introduce", "start": 4, "end": 5}, "arguments": [{"entity_id": "ACL_23_P_828-1-E0", "text": "we", "role": "Agent"}, {"entity_id": "ACL_23_P_828-1-E1", "text": "to evaluate the temporal reasoning capability of large language models", "role": "Purpose"}, {"entity_id": "ACL_23_P_828-1-E2", "text": "Our dataset includes questions of three temporal reasoning levels", "role": "Method"}, {"entity_id": "ACL_23_P_828-1-E3", "text": "we also propose a novel learning framework to improve the temporal reasoning capability of large language models, based on temporal span extraction and time-sensitive reinforcement learning", "role": "Method"}, {"entity_id": "ACL_23_P_828-1-E4", "text": "a comprehensive probing dataset TempReason", "role": "PrimaryObject"}]}], "entity_coreference": [], "event_coreference": [], "tokens": ["In", "this", "paper,", "we", "introduce", "a", "comprehensive", "probing", "dataset", "TempReason", "to", "evaluate", "the", "temporal", "reasoning", "capability", "of", "large", "language", "models.", "Our", "dataset", "includes", "questions", "of", "three", "temporal", "reasoning", "levels.", "In", "addition,", "we", "also", "propose", "a", "novel", "learning", "framework", "to", "improve", "the", "temporal", "reasoning", "capability", "of", "large", "language", "models,", "based", "on", "temporal", "span", "extraction", "and", "time-sensitive", "reinforcement", "learning."], "pieces": ["In", "this", "paper", ",", "we", "introdu", "ce", "a", "com", "pre", "hens", "ive", "pro", "bing", "dat", "as", "et", "Temp", "Reason", "to", "evaluate", "the", "tem", "poral", "reason", "ing", "cap", "ability", "of", "large", "language", "models", ".", "Our", "dat", "as", "et", "includes", "quest", "ions", "of", "three", "tem", "poral", "reason", "ing", "levels", ".", "In", "add", "ition", ",", "we", "also", "pro", "pose", "a", "no", "vel", "learning", "framework", "to", "improve", "the", "tem", "poral", "reason", "ing", "cap", "ability", "of", "large", "language", "models", ",", "based", "on", "tem", "poral", "span", "ext", "raction", "and", "time", "-", "sensitive", "re", "in", "forcement", "learning", "."], "token_lens": [1, 1, 2, 1, 2, 1, 4, 2, 3, 2, 1, 1, 1, 2, 2, 2, 1, 1, 1, 2, 1, 3, 1, 2, 1, 1, 2, 2, 2, 1, 3, 1, 1, 2, 1, 2, 1, 1, 1, 1, 1, 2, 2, 2, 1, 1, 1, 2, 1, 1, 2, 1, 2, 1, 3, 3, 2], "sentence": "In this paper, we introduce a comprehensive probing dataset TempReason to evaluate the temporal reasoning capability of large language models. Our dataset includes questions of three temporal reasoning levels. In addition, we also propose a novel learning framework to improve the temporal reasoning capability of large language models, based on temporal span extraction and time-sensitive reinforcement learning.", "sentence_starts": [0]}
{"doc_id": "ACL_23_P_828", "wnd_id": "ACL_23_P_828-2", "entity_mentions": [{"id": "ACL_23_P_828-2-E0", "text": "We", "start": 0, "end": 1, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_828-2-E1", "text": "demonstrated the effectiveness of our approach", "start": 15, "end": 21, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_828-2-E2", "text": "experiments in closed book QA, open book QA, and reasoning QA settings", "start": 2, "end": 14, "entity_type": "UNK", "mention_type": "UNK"}], "relation_mentions": [], "event_mentions": [{"event_type": "Results/Findings", "id": "ACL_23_P_828-2-EV0", "trigger": {"text": "conducted", "start": 1, "end": 2}, "arguments": [{"entity_id": "ACL_23_P_828-2-E0", "text": "We", "role": "Agent"}, {"entity_id": "ACL_23_P_828-2-E1", "text": "demonstrated the effectiveness of our approach", "role": "Results"}, {"entity_id": "ACL_23_P_828-2-E2", "text": "experiments in closed book QA, open book QA, and reasoning QA settings", "role": "PrimaryObject"}]}], "entity_coreference": [], "event_coreference": [], "tokens": ["We", "conducted", "experiments", "in", "closed", "book", "QA,", "open", "book", "QA,", "and", "reasoning", "QA", "settings", "and", "demonstrated", "the", "effectiveness", "of", "our", "approach."], "pieces": ["We", "conduct", "ed", "exper", "iments", "in", "closed", "book", "Q", "A", ",", "open", "book", "Q", "A", ",", "and", "reason", "ing", "Q", "A", "settings", "and", "demon", "str", "ated", "the", "effect", "iveness", "of", "our", "appro", "ach", "."], "token_lens": [1, 2, 2, 1, 1, 1, 3, 1, 1, 3, 1, 2, 2, 1, 1, 3, 1, 2, 1, 1, 3], "sentence": "We conducted experiments in closed book QA, open book QA, and reasoning QA settings and demonstrated the effectiveness of our approach.", "sentence_starts": [0]}
{"doc_id": "ACL_23_P_844", "wnd_id": "ACL_23_P_844-0", "entity_mentions": [{"id": "ACL_23_P_844-0-E0", "text": "we", "start": 19, "end": 20, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_844-0-E1", "text": "Despite the recent progress in language generation models, their outputs may not always meet user expectations", "start": 0, "end": 16, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_844-0-E2", "text": "we consider factual consistency in summarization, the quality that the summary should only contain information supported by the input documents, as the user-expected preference", "start": 41, "end": 65, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_844-0-E3", "text": "whether informational feedback in natural language can be leveraged to improve generation quality and user preference alignment", "start": 21, "end": 38, "entity_type": "UNK", "mention_type": "UNK"}], "relation_mentions": [], "event_mentions": [{"event_type": "Background/Introduction", "id": "ACL_23_P_844-0-EV0", "trigger": {"text": "study", "start": 20, "end": 21}, "arguments": [{"entity_id": "ACL_23_P_844-0-E0", "text": "we", "role": "Agent"}, {"entity_id": "ACL_23_P_844-0-E1", "text": "Despite the recent progress in language generation models, their outputs may not always meet user expectations", "role": "Context"}, {"entity_id": "ACL_23_P_844-0-E2", "text": "we consider factual consistency in summarization, the quality that the summary should only contain information supported by the input documents, as the user-expected preference", "role": "Method"}, {"entity_id": "ACL_23_P_844-0-E3", "text": "whether informational feedback in natural language can be leveraged to improve generation quality and user preference alignment", "role": "PrimaryObject"}]}], "entity_coreference": [], "event_coreference": [], "tokens": ["Despite", "the", "recent", "progress", "in", "language", "generation", "models,", "their", "outputs", "may", "not", "always", "meet", "user", "expectations.", "In", "this", "work,", "we", "study", "whether", "informational", "feedback", "in", "natural", "language", "can", "be", "leveraged", "to", "improve", "generation", "quality", "and", "user", "preference", "alignment.", "To", "this", "end,", "we", "consider", "factual", "consistency", "in", "summarization,", "the", "quality", "that", "the", "summary", "should", "only", "contain", "information", "supported", "by", "the", "input", "documents,", "as", "the", "user-expected", "preference."], "pieces": ["Despite", "the", "recent", "progress", "in", "language", "generation", "models", ",", "their", "output", "s", "may", "not", "always", "meet", "user", "ex", "pect", "ations", ".", "In", "this", "work", ",", "we", "study", "whether", "in", "form", "ational", "feed", "back", "in", "natural", "language", "can", "be", "le", "ver", "aged", "to", "improve", "generation", "quality", "and", "user", "pre", "ference", "al", "ignment", ".", "To", "this", "end", ",", "we", "consider", "fact", "ual", "cons", "ist", "ency", "in", "sum", "mar", "ization", ",", "the", "quality", "that", "the", "summary", "should", "only", "cont", "ain", "information", "supported", "by", "the", "input", "doc", "uments", ",", "as", "the", "user", "-", "expected", "pre", "ference", "."], "token_lens": [1, 1, 1, 1, 1, 1, 1, 2, 1, 2, 1, 1, 1, 1, 1, 4, 1, 1, 2, 1, 1, 1, 3, 2, 1, 1, 1, 1, 1, 3, 1, 1, 1, 1, 1, 1, 2, 3, 1, 1, 2, 1, 1, 2, 3, 1, 4, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 3, 1, 1, 3, 3], "sentence": "Despite the recent progress in language generation models, their outputs may not always meet user expectations. In this work, we study whether informational feedback in natural language can be leveraged to improve generation quality and user preference alignment. To this end, we consider factual consistency in summarization, the quality that the summary should only contain information supported by the input documents, as the user-expected preference.", "sentence_starts": [0]}
{"doc_id": "ACL_23_P_844", "wnd_id": "ACL_23_P_844-1", "entity_mentions": [{"id": "ACL_23_P_844-1-E0", "text": "We", "start": 0, "end": 1, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_844-1-E1", "text": "editing a summary by following the human feedback", "start": 42, "end": 50, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_844-1-E2", "text": "generating human feedback for editing the original summary", "start": 51, "end": 59, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_844-1-E3", "text": "revising the initial summary to correct factual errors by generating both the human feedback and edited summary", "start": 61, "end": 78, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_844-1-E4", "text": "a high-quality dataset, DeFacto", "start": 2, "end": 6, "entity_type": "UNK", "mention_type": "UNK"}], "relation_mentions": [], "event_mentions": [{"event_type": "Methods/Approach", "id": "ACL_23_P_844-1-EV0", "trigger": {"text": "collect", "start": 1, "end": 2}, "arguments": [{"entity_id": "ACL_23_P_844-1-E0", "text": "We", "role": "Agent"}, {"entity_id": "ACL_23_P_844-1-E1", "text": "editing a summary by following the human feedback", "role": "Method"}, {"entity_id": "ACL_23_P_844-1-E2", "text": "generating human feedback for editing the original summary", "role": "Method"}, {"entity_id": "ACL_23_P_844-1-E3", "text": "revising the initial summary to correct factual errors by generating both the human feedback and edited summary", "role": "Method"}, {"entity_id": "ACL_23_P_844-1-E4", "text": "a high-quality dataset, DeFacto", "role": "PrimaryObject"}]}], "entity_coreference": [], "event_coreference": [], "tokens": ["We", "collect", "a", "high-quality", "dataset,", "DeFacto,", "containing", "human", "demonstrations", "and", "informational", "natural", "language", "feedback", "consisting", "of", "corrective", "instructions,", "edited", "summaries,", "and", "explanations", "with", "respect", "to", "the", "factual", "consistency", "of", "the", "summary.", "Using", "our", "dataset,", "we", "study", "three", "natural", "language", "generation", "tasks:", "(1)", "editing", "a", "summary", "by", "following", "the", "human", "feedback,", "(2)", "generating", "human", "feedback", "for", "editing", "the", "original", "summary,", "and", "(3)", "revising", "the", "initial", "summary", "to", "correct", "factual", "errors", "by", "generating", "both", "the", "human", "feedback", "and", "edited", "summary."], "pieces": ["We", "collect", "a", "high", "-", "quality", "dat", "as", "et", ",", "De", "Fact", "o", ",", "containing", "human", "demon", "str", "ations", "and", "in", "form", "ational", "natural", "language", "feed", "back", "cons", "isting", "of", "correct", "ive", "in", "struct", "ions", ",", "edited", "s", "umm", "aries", ",", "and", "ex", "plan", "ations", "with", "respect", "to", "the", "fact", "ual", "cons", "ist", "ency", "of", "the", "summary", ".", "Using", "our", "dat", "as", "et", ",", "we", "study", "three", "natural", "language", "generation", "t", "asks", ":", "(", "1", ")", "ed", "iting", "a", "summary", "by", "follow", "ing", "the", "human", "feed", "back", ",", "(", "2", ")", "gener", "ating", "human", "feed", "back", "for", "ed", "iting", "the", "original", "summary", ",", "and", "(", "3", ")", "rev", "ising", "the", "initial", "summary", "to", "correct", "fact", "ual", "errors", "by", "gener", "ating", "both", "the", "human", "feed", "back", "and", "edited", "summary", "."], "token_lens": [1, 1, 1, 3, 4, 4, 1, 1, 3, 1, 3, 1, 1, 2, 2, 1, 2, 4, 1, 4, 1, 3, 1, 1, 1, 1, 2, 3, 1, 1, 2, 1, 1, 4, 1, 1, 1, 1, 1, 1, 3, 3, 2, 1, 1, 1, 2, 1, 1, 3, 3, 2, 1, 2, 1, 2, 1, 1, 2, 1, 3, 2, 1, 1, 1, 1, 1, 2, 1, 1, 2, 1, 1, 1, 2, 1, 1, 2], "sentence": "We collect a high-quality dataset, DeFacto, containing human demonstrations and informational natural language feedback consisting of corrective instructions, edited summaries, and explanations with respect to the factual consistency of the summary. Using our dataset, we study three natural language generation tasks: (1) editing a summary by following the human feedback, (2) generating human feedback for editing the original summary, and (3) revising the initial summary to correct factual errors by generating both the human feedback and edited summary.", "sentence_starts": [0]}
{"doc_id": "ACL_23_P_844", "wnd_id": "ACL_23_P_844-2", "entity_mentions": [{"id": "ACL_23_P_844-2-E0", "text": "We", "start": 0, "end": 1, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_844-2-E1", "text": "We further demonstrate that fine-tuned language models can leverage our dataset to improve the summary factual consistency", "start": 24, "end": 41, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_844-2-E2", "text": "large language models lack the zero-shot learning ability in our proposed tasks that require controllable text generation", "start": 42, "end": 59, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_844-2-E3", "text": "DeFacto can provide factually consistent human-edited summaries and further insights into summarization factual consistency thanks to its informational natural language feedback", "start": 3, "end": 24, "entity_type": "UNK", "mention_type": "UNK"}], "relation_mentions": [], "event_mentions": [{"event_type": "Results/Findings", "id": "ACL_23_P_844-2-EV0", "trigger": {"text": "show", "start": 1, "end": 2}, "arguments": [{"entity_id": "ACL_23_P_844-2-E0", "text": "We", "role": "Agent"}, {"entity_id": "ACL_23_P_844-2-E1", "text": "We further demonstrate that fine-tuned language models can leverage our dataset to improve the summary factual consistency", "role": "Results"}, {"entity_id": "ACL_23_P_844-2-E2", "text": "large language models lack the zero-shot learning ability in our proposed tasks that require controllable text generation", "role": "Results"}, {"entity_id": "ACL_23_P_844-2-E3", "text": "DeFacto can provide factually consistent human-edited summaries and further insights into summarization factual consistency thanks to its informational natural language feedback", "role": "PrimaryObject"}]}], "entity_coreference": [], "event_coreference": [], "tokens": ["We", "show", "that", "DeFacto", "can", "provide", "factually", "consistent", "human-edited", "summaries", "and", "further", "insights", "into", "summarization", "factual", "consistency", "thanks", "to", "its", "informational", "natural", "language", "feedback.", "We", "further", "demonstrate", "that", "fine-tuned", "language", "models", "can", "leverage", "our", "dataset", "to", "improve", "the", "summary", "factual", "consistency,", "while", "large", "language", "models", "lack", "the", "zero-shot", "learning", "ability", "in", "our", "proposed", "tasks", "that", "require", "controllable", "text", "generation."], "pieces": ["We", "show", "that", "De", "Fact", "o", "can", "prov", "ide", "fact", "ually", "cons", "istent", "human", "-", "edited", "s", "umm", "aries", "and", "f", "urther", "ins", "ights", "into", "sum", "mar", "ization", "fact", "ual", "cons", "ist", "ency", "thanks", "to", "its", "in", "form", "ational", "natural", "language", "feed", "back", ".", "We", "f", "urther", "demon", "strate", "that", "fine", "-", "tun", "ed", "language", "models", "can", "le", "verage", "our", "dat", "as", "et", "to", "improve", "the", "summary", "fact", "ual", "cons", "ist", "ency", ",", "while", "large", "language", "models", "l", "ack", "the", "zero", "-", "shot", "learning", "ability", "in", "our", "prop", "osed", "t", "asks", "that", "require", "cont", "roll", "able", "text", "generation", "."], "token_lens": [1, 1, 1, 3, 1, 2, 2, 2, 3, 3, 1, 2, 2, 1, 3, 2, 3, 1, 1, 1, 3, 1, 1, 3, 1, 2, 2, 1, 4, 1, 1, 1, 2, 1, 3, 1, 1, 1, 1, 2, 4, 1, 1, 1, 1, 2, 1, 3, 1, 1, 1, 1, 2, 2, 1, 1, 3, 1, 2], "sentence": "We show that DeFacto can provide factually consistent human-edited summaries and further insights into summarization factual consistency thanks to its informational natural language feedback. We further demonstrate that fine-tuned language models can leverage our dataset to improve the summary factual consistency, while large language models lack the zero-shot learning ability in our proposed tasks that require controllable text generation.", "sentence_starts": [0]}
{"doc_id": "ACL_23_P_700", "wnd_id": "ACL_23_P_700-0", "entity_mentions": [{"id": "ACL_23_P_700-0-E0", "text": "State-of-the-art techniques common to low-resource Machine Translation (MT)", "start": 0, "end": 8, "entity_type": "UNK", "mention_type": "UNK"}], "relation_mentions": [], "event_mentions": [{"event_type": "Background/Introduction", "id": "ACL_23_P_700-0-EV0", "trigger": {"text": "are applied", "start": 8, "end": 10}, "arguments": [{"entity_id": "ACL_23_P_700-0-E0", "text": "State-of-the-art techniques common to low-resource Machine Translation (MT)", "role": "Agent"}]}], "entity_coreference": [], "event_coreference": [], "tokens": ["State-of-the-art", "techniques", "common", "to", "low-resource", "Machine", "Translation", "(MT)", "are", "applied", "to", "improve", "MT", "of", "spoken", "language", "text", "to", "Sign", "Language", "(SL)", "glosses."], "pieces": ["State", "-", "of", "-", "the", "-", "art", "techn", "iques", "common", "to", "low", "-", "resource", "Machine", "Translation", "(", "MT", ")", "are", "app", "lied", "to", "improve", "MT", "of", "spoken", "language", "text", "to", "Sign", "Language", "(", "SL", ")", "gl", "oss", "es", "."], "token_lens": [7, 2, 1, 1, 3, 1, 1, 3, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 3, 4], "sentence": "State-of-the-art techniques common to low-resource Machine Translation (MT) are applied to improve MT of spoken language text to Sign Language (SL) glosses.", "sentence_starts": [0]}
{"doc_id": "ACL_23_P_700", "wnd_id": "ACL_23_P_700-1", "entity_mentions": [{"id": "ACL_23_P_700-1-E0", "text": "we", "start": 3, "end": 4, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_700-1-E1", "text": "The proposed methods are implemented progressively on two German SL corpora containing gloss annotations", "start": 28, "end": 42, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_700-1-E2", "text": "the performance of the transformer-based models", "start": 5, "end": 11, "entity_type": "UNK", "mention_type": "UNK"}], "relation_mentions": [], "event_mentions": [{"event_type": "Methods/Approach", "id": "ACL_23_P_700-1-EV0", "trigger": {"text": "improve", "start": 4, "end": 5}, "arguments": [{"entity_id": "ACL_23_P_700-1-E0", "text": "we", "role": "Agent"}, {"entity_id": "ACL_23_P_700-1-E1", "text": "The proposed methods are implemented progressively on two German SL corpora containing gloss annotations", "role": "Method"}, {"entity_id": "ACL_23_P_700-1-E2", "text": "the performance of the transformer-based models", "role": "PrimaryObject"}]}], "entity_coreference": [], "event_coreference": [], "tokens": ["In", "our", "experiments,", "we", "improve", "the", "performance", "of", "the", "transformer-based", "models", "via", "(1)", "data", "augmentation,", "(2)", "semi-supervised", "Neural", "Machine", "Translation", "(NMT),", "(3)", "transfer", "learning", "and", "(4)", "multilingual", "NMT.", "The", "proposed", "methods", "are", "implemented", "progressively", "on", "two", "German", "SL", "corpora", "containing", "gloss", "annotations."], "pieces": ["In", "our", "exper", "iments", ",", "we", "improve", "the", "performance", "of", "the", "trans", "former", "-", "based", "models", "via", "(", "1", ")", "data", "au", "gment", "ation", ",", "(", "2", ")", "se", "mi", "-", "super", "vised", "Ne", "ural", "Machine", "Translation", "(", "N", "MT", "),", "(", "3", ")", "transfer", "learning", "and", "(", "4", ")", "mult", "ilingual", "N", "MT", ".", "The", "prop", "osed", "method", "s", "are", "im", "ple", "mented", "progress", "ively", "on", "two", "German", "SL", "cor", "pora", "containing", "gl", "oss", "annot", "ations", "."], "token_lens": [1, 1, 3, 1, 1, 1, 1, 1, 1, 4, 1, 1, 3, 1, 4, 3, 5, 2, 1, 1, 4, 3, 1, 1, 1, 3, 2, 3, 1, 2, 2, 1, 3, 2, 1, 1, 1, 1, 2, 1, 2, 3], "sentence": "In our experiments, we improve the performance of the transformer-based models via (1) data augmentation, (2) semi-supervised Neural Machine Translation (NMT), (3) transfer learning and (4) multilingual NMT. The proposed methods are implemented progressively on two German SL corpora containing gloss annotations.", "sentence_starts": [0]}
{"doc_id": "ACL_23_P_700", "wnd_id": "ACL_23_P_700-2", "entity_mentions": [{"id": "ACL_23_P_700-2-E0", "text": "Multilingual NMT combined with data augmentation", "start": 0, "end": 6, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_700-2-E1", "text": "Our best setting outperforms all previous work that report on the same test-set and is also confirmed on a corpus of the American Sign Language (ASL)", "start": 34, "end": 60, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_700-2-E2", "text": "the most successful setting", "start": 9, "end": 13, "entity_type": "UNK", "mention_type": "UNK"}], "relation_mentions": [], "event_mentions": [{"event_type": "Results/Findings", "id": "ACL_23_P_700-2-EV0", "trigger": {"text": "appear to be", "start": 6, "end": 9}, "arguments": [{"entity_id": "ACL_23_P_700-2-E0", "text": "Multilingual NMT combined with data augmentation", "role": "Agent"}, {"entity_id": "ACL_23_P_700-2-E1", "text": "Our best setting outperforms all previous work that report on the same test-set and is also confirmed on a corpus of the American Sign Language (ASL)", "role": "Results"}, {"entity_id": "ACL_23_P_700-2-E2", "text": "the most successful setting", "role": "PrimaryObject"}]}], "entity_coreference": [], "event_coreference": [], "tokens": ["Multilingual", "NMT", "combined", "with", "data", "augmentation", "appear", "to", "be", "the", "most", "successful", "setting,", "yielding", "statistically", "significant", "improvements", "as", "measured", "by", "three", "automatic", "metrics", "(up", "to", "over", "6", "points", "BLEU),", "and", "confirmed", "via", "human", "evaluation.", "Our", "best", "setting", "outperforms", "all", "previous", "work", "that", "report", "on", "the", "same", "test-set", "and", "is", "also", "confirmed", "on", "a", "corpus", "of", "the", "American", "Sign", "Language", "(ASL)."], "pieces": ["Mult", "ilingual", "N", "MT", "comb", "ined", "with", "data", "au", "gment", "ation", "app", "ear", "to", "be", "the", "most", "successful", "setting", ",", "y", "ielding", "stat", "istically", "significant", "improve", "ments", "as", "me", "asured", "by", "three", "automatic", "met", "rics", "(", "up", "to", "over", "6", "points", "BLE", "U", "),", "and", "confirmed", "via", "human", "eval", "uation", ".", "Our", "best", "setting", "out", "per", "forms", "all", "pre", "vious", "work", "that", "report", "on", "the", "same", "test", "-", "set", "and", "is", "also", "confirmed", "on", "a", "cor", "p", "us", "of", "the", "American", "Sign", "Language", "(", "AS", "L", ")."], "token_lens": [2, 2, 2, 1, 1, 3, 2, 1, 1, 1, 1, 1, 2, 2, 2, 1, 2, 1, 2, 1, 1, 1, 2, 2, 1, 1, 1, 1, 3, 1, 1, 1, 1, 3, 1, 1, 1, 3, 1, 2, 1, 1, 1, 1, 1, 1, 3, 1, 1, 1, 1, 1, 1, 3, 1, 1, 1, 1, 1, 4], "sentence": "Multilingual NMT combined with data augmentation appear to be the most successful setting, yielding statistically significant improvements as measured by three automatic metrics (up to over 6 points BLEU), and confirmed via human evaluation. Our best setting outperforms all previous work that report on the same test-set and is also confirmed on a corpus of the American Sign Language (ASL).", "sentence_starts": [0]}
{"doc_id": "ACL_23_P_22", "wnd_id": "ACL_23_P_22-0", "entity_mentions": [{"id": "ACL_23_P_22-0-E0", "text": "Classic approaches to content moderation typically", "start": 0, "end": 6, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_22-0-E1", "text": "While rules are easily customizable and intuitive for humans to interpret", "start": 14, "end": 25, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_22-0-E2", "text": "Recent advances in deep learning have demonstrated the promise of using highly effective deep neural models to overcome these challenges.", "start": 47, "end": 67, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_22-0-E3", "text": "they are inherently fragile and lack the flexibility or robustness needed to moderate the vast amount of undesirable content found online today", "start": 25, "end": 47, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_22-0-E4", "text": "despite the improved performance, these data-driven models lack transparency and explainability, often leading to mistrust from everyday users and a lack of adoption by many platforms", "start": 68, "end": 94, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_22-0-E5", "text": "a rule-based heuristic approach", "start": 7, "end": 11, "entity_type": "UNK", "mention_type": "UNK"}], "relation_mentions": [], "event_mentions": [{"event_type": "Background/Introduction", "id": "ACL_23_P_22-0-EV0", "trigger": {"text": "apply", "start": 6, "end": 7}, "arguments": [{"entity_id": "ACL_23_P_22-0-E0", "text": "Classic approaches to content moderation typically", "role": "Agent"}, {"entity_id": "ACL_23_P_22-0-E1", "text": "While rules are easily customizable and intuitive for humans to interpret", "role": "Context"}, {"entity_id": "ACL_23_P_22-0-E2", "text": "Recent advances in deep learning have demonstrated the promise of using highly effective deep neural models to overcome these challenges.", "role": "Context"}, {"entity_id": "ACL_23_P_22-0-E3", "text": "they are inherently fragile and lack the flexibility or robustness needed to moderate the vast amount of undesirable content found online today", "role": "Challenge"}, {"entity_id": "ACL_23_P_22-0-E4", "text": "despite the improved performance, these data-driven models lack transparency and explainability, often leading to mistrust from everyday users and a lack of adoption by many platforms", "role": "Challenge"}, {"entity_id": "ACL_23_P_22-0-E5", "text": "a rule-based heuristic approach", "role": "PrimaryObject"}]}], "entity_coreference": [], "event_coreference": [], "tokens": ["Classic", "approaches", "to", "content", "moderation", "typically", "apply", "a", "rule-based", "heuristic", "approach", "to", "flag", "content.", "While", "rules", "are", "easily", "customizable", "and", "intuitive", "for", "humans", "to", "interpret,", "they", "are", "inherently", "fragile", "and", "lack", "the", "flexibility", "or", "robustness", "needed", "to", "moderate", "the", "vast", "amount", "of", "undesirable", "content", "found", "online", "today.", "Recent", "advances", "in", "deep", "learning", "have", "demonstrated", "the", "promise", "of", "using", "highly", "effective", "deep", "neural", "models", "to", "overcome", "these", "challenges.", "However,", "despite", "the", "improved", "performance,", "these", "data-driven", "models", "lack", "transparency", "and", "explainability,", "often", "leading", "to", "mistrust", "from", "everyday", "users", "and", "a", "lack", "of", "adoption", "by", "many", "platforms."], "pieces": ["Classic", "appro", "aches", "to", "content", "mod", "er", "ation", "typically", "apply", "a", "rule", "-", "based", "he", "uristic", "appro", "ach", "to", "flag", "content", ".", "While", "rules", "are", "eas", "ily", "custom", "izable", "and", "intuitive", "for", "humans", "to", "interpret", ",", "they", "are", "in", "herent", "ly", "fr", "ag", "ile", "and", "l", "ack", "the", "flex", "ibility", "or", "rob", "ust", "ness", "needed", "to", "moderate", "the", "v", "ast", "amount", "of", "und", "es", "irable", "content", "found", "online", "today", ".", "Recent", "adv", "ances", "in", "deep", "learning", "have", "demon", "str", "ated", "the", "prom", "ise", "of", "using", "highly", "effective", "deep", "ne", "ural", "models", "to", "over", "come", "these", "chall", "enges", ".", "However", ",", "despite", "the", "impro", "ved", "performance", ",", "these", "data", "-", "driven", "models", "l", "ack", "trans", "parency", "and", "expl", "ain", "ability", ",", "often", "leading", "to", "mist", "rust", "from", "every", "day", "users", "and", "a", "l", "ack", "of", "ad", "option", "by", "many", "platform", "s", "."], "token_lens": [1, 2, 1, 1, 3, 1, 1, 1, 3, 2, 2, 1, 1, 2, 1, 1, 1, 2, 2, 1, 1, 1, 1, 1, 2, 1, 1, 3, 3, 1, 2, 1, 2, 1, 3, 1, 1, 1, 1, 2, 1, 1, 3, 1, 1, 1, 2, 1, 2, 1, 1, 1, 1, 3, 1, 2, 1, 1, 1, 1, 1, 2, 1, 1, 2, 1, 3, 2, 1, 1, 2, 2, 1, 3, 1, 2, 2, 1, 4, 1, 1, 1, 2, 1, 2, 1, 1, 1, 2, 1, 2, 1, 1, 3], "sentence": "Classic approaches to content moderation typically apply a rule-based heuristic approach to flag content. While rules are easily customizable and intuitive for humans to interpret, they are inherently fragile and lack the flexibility or robustness needed to moderate the vast amount of undesirable content found online today. Recent advances in deep learning have demonstrated the promise of using highly effective deep neural models to overcome these challenges. However, despite the improved performance, these data-driven models lack transparency and explainability, often leading to mistrust from everyday users and a lack of adoption by many platforms.", "sentence_starts": [0]}
{"doc_id": "ACL_23_P_22", "wnd_id": "ACL_23_P_22-1", "entity_mentions": [{"id": "ACL_23_P_22-1-E0", "text": "we", "start": 3, "end": 4, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_22-1-E1", "text": "RBE is capable of providing rule-grounded predictions, allowing for more explainable and customizable predictions compared to typical deep learning-based approaches", "start": 27, "end": 47, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_22-1-E2", "text": "Rule By Example (RBE)", "start": 5, "end": 9, "entity_type": "UNK", "mention_type": "UNK"}], "relation_mentions": [], "event_mentions": [{"event_type": "Methods/Approach", "id": "ACL_23_P_22-1-EV0", "trigger": {"text": "present", "start": 4, "end": 5}, "arguments": [{"entity_id": "ACL_23_P_22-1-E0", "text": "we", "role": "Agent"}, {"entity_id": "ACL_23_P_22-1-E1", "text": "RBE is capable of providing rule-grounded predictions, allowing for more explainable and customizable predictions compared to typical deep learning-based approaches", "role": "Results"}, {"entity_id": "ACL_23_P_22-1-E2", "text": "Rule By Example (RBE)", "role": "PrimaryObject"}]}], "entity_coreference": [], "event_coreference": [], "tokens": ["In", "this", "paper,", "we", "present", "Rule", "By", "Example", "(RBE):", "a", "novel", "exemplar-based", "contrastive", "learning", "approach", "for", "learning", "from", "logical", "rules", "for", "the", "task", "of", "textual", "content", "moderation.", "RBE", "is", "capable", "of", "providing", "rule-grounded", "predictions,", "allowing", "for", "more", "explainable", "and", "customizable", "predictions", "compared", "to", "typical", "deep", "learning-based", "approaches."], "pieces": ["In", "this", "paper", ",", "we", "present", "Rule", "By", "Example", "(", "R", "BE", "):", "a", "no", "vel", "ex", "empl", "ar", "-", "based", "cont", "rast", "ive", "learning", "appro", "ach", "for", "learning", "from", "log", "ical", "rules", "for", "the", "task", "of", "text", "ual", "content", "mod", "er", "ation", ".", "R", "BE", "is", "cap", "able", "of", "prov", "iding", "rule", "-", "ground", "ed", "pred", "ictions", ",", "all", "owing", "for", "more", "expl", "ain", "able", "and", "custom", "izable", "pred", "ictions", "comp", "ared", "to", "typ", "ical", "deep", "learning", "-", "based", "appro", "aches", "."], "token_lens": [1, 1, 2, 1, 1, 1, 1, 1, 4, 1, 2, 5, 3, 1, 2, 1, 1, 1, 2, 1, 1, 1, 1, 1, 2, 1, 4, 2, 1, 2, 1, 2, 4, 3, 2, 1, 1, 3, 1, 2, 2, 2, 1, 2, 1, 3, 3], "sentence": "In this paper, we present Rule By Example (RBE): a novel exemplar-based contrastive learning approach for learning from logical rules for the task of textual content moderation. RBE is capable of providing rule-grounded predictions, allowing for more explainable and customizable predictions compared to typical deep learning-based approaches.", "sentence_starts": [0]}
{"doc_id": "ACL_23_P_22", "wnd_id": "ACL_23_P_22-2", "entity_mentions": [{"id": "ACL_23_P_22-2-E0", "text": "We", "start": 0, "end": 1, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_22-2-E1", "text": "Experimental results on 3 popular hate speech classification datasets show that RBE is able to outperform state-of-the-art deep learning classifiers as well as the use of rules in both supervised and unsupervised settings while providing explainable model predictions via rule-grounding", "start": 19, "end": 59, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_22-2-E2", "text": "our approach is capable of learning rich rule embedding representations", "start": 3, "end": 13, "entity_type": "UNK", "mention_type": "UNK"}], "relation_mentions": [], "event_mentions": [{"event_type": "Results/Findings", "id": "ACL_23_P_22-2-EV0", "trigger": {"text": "demonstrate", "start": 1, "end": 2}, "arguments": [{"entity_id": "ACL_23_P_22-2-E0", "text": "We", "role": "Agent"}, {"entity_id": "ACL_23_P_22-2-E1", "text": "Experimental results on 3 popular hate speech classification datasets show that RBE is able to outperform state-of-the-art deep learning classifiers as well as the use of rules in both supervised and unsupervised settings while providing explainable model predictions via rule-grounding", "role": "Results"}, {"entity_id": "ACL_23_P_22-2-E2", "text": "our approach is capable of learning rich rule embedding representations", "role": "PrimaryObject"}]}], "entity_coreference": [], "event_coreference": [], "tokens": ["We", "demonstrate", "that", "our", "approach", "is", "capable", "of", "learning", "rich", "rule", "embedding", "representations", "using", "only", "a", "few", "data", "examples.", "Experimental", "results", "on", "3", "popular", "hate", "speech", "classification", "datasets", "show", "that", "RBE", "is", "able", "to", "outperform", "state-of-the-art", "deep", "learning", "classifiers", "as", "well", "as", "the", "use", "of", "rules", "in", "both", "supervised", "and", "unsupervised", "settings", "while", "providing", "explainable", "model", "predictions", "via", "rule-grounding."], "pieces": ["We", "demon", "strate", "that", "our", "appro", "ach", "is", "cap", "able", "of", "learning", "rich", "rule", "embed", "ding", "represent", "ations", "using", "only", "a", "few", "data", "ex", "amples", ".", "Exper", "imental", "results", "on", "3", "popular", "hate", "speech", "class", "ification", "dat", "as", "ets", "show", "that", "R", "BE", "is", "able", "to", "out", "per", "form", "state", "-", "of", "-", "the", "-", "art", "deep", "learning", "class", "ifiers", "as", "well", "as", "the", "use", "of", "rules", "in", "both", "super", "vised", "and", "un", "super", "vised", "settings", "while", "prov", "iding", "expl", "ain", "able", "model", "pred", "ictions", "via", "rule", "-", "ground", "ing", "."], "token_lens": [1, 2, 1, 1, 2, 1, 2, 1, 1, 1, 1, 2, 2, 1, 1, 1, 1, 1, 3, 2, 1, 1, 1, 1, 1, 1, 2, 3, 1, 1, 2, 1, 1, 1, 3, 7, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 3, 1, 1, 2, 3, 1, 2, 1, 5], "sentence": "We demonstrate that our approach is capable of learning rich rule embedding representations using only a few data examples. Experimental results on 3 popular hate speech classification datasets show that RBE is able to outperform state-of-the-art deep learning classifiers as well as the use of rules in both supervised and unsupervised settings while providing explainable model predictions via rule-grounding.", "sentence_starts": [0]}
{"doc_id": "ACL_23_P_219", "wnd_id": "ACL_23_P_219-0", "entity_mentions": [{"id": "ACL_23_P_219-0-E0", "text": "Monolingual word alignment", "start": 0, "end": 3, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_219-0-E1", "text": "In particular, null alignment, a phenomenon in which words have no corresponding counterparts, is pervasive and critical in handling semantically divergent sentences", "start": 11, "end": 33, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_219-0-E2", "text": "Identification of null alignment is useful on its own to reason about the semantic similarity of sentences by indicating there exists information inequality.", "start": 33, "end": 56, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_219-0-E3", "text": "crucial", "start": 4, "end": 5, "entity_type": "UNK", "mention_type": "UNK"}], "relation_mentions": [], "event_mentions": [{"event_type": "Background/Introduction", "id": "ACL_23_P_219-0-EV0", "trigger": {"text": "is", "start": 3, "end": 4}, "arguments": [{"entity_id": "ACL_23_P_219-0-E0", "text": "Monolingual word alignment", "role": "Agent"}, {"entity_id": "ACL_23_P_219-0-E1", "text": "In particular, null alignment, a phenomenon in which words have no corresponding counterparts, is pervasive and critical in handling semantically divergent sentences", "role": "Context"}, {"entity_id": "ACL_23_P_219-0-E2", "text": "Identification of null alignment is useful on its own to reason about the semantic similarity of sentences by indicating there exists information inequality.", "role": "Context"}, {"entity_id": "ACL_23_P_219-0-E3", "text": "crucial", "role": "PrimaryObject"}]}], "entity_coreference": [], "event_coreference": [], "tokens": ["Monolingual", "word", "alignment", "is", "crucial", "to", "model", "semantic", "interactions", "between", "sentences.", "In", "particular,", "null", "alignment,", "a", "phenomenon", "in", "which", "words", "have", "no", "corresponding", "counterparts,", "is", "pervasive", "and", "critical", "in", "handling", "semantically", "divergent", "sentences.", "Identification", "of", "null", "alignment", "is", "useful", "on", "its", "own", "to", "reason", "about", "the", "semantic", "similarity", "of", "sentences", "by", "indicating", "there", "exists", "information", "inequality."], "pieces": ["Mon", "oling", "ual", "word", "al", "ignment", "is", "cru", "cial", "to", "model", "sem", "antic", "inter", "actions", "between", "sent", "ences", ".", "In", "part", "icular", ",", "null", "al", "ignment", ",", "a", "phen", "omen", "on", "in", "which", "words", "have", "no", "cor", "respond", "ing", "counter", "parts", ",", "is", "per", "vasive", "and", "critical", "in", "hand", "ling", "sem", "antically", "d", "iver", "gent", "sent", "ences", ".", "Ident", "ification", "of", "null", "al", "ignment", "is", "use", "ful", "on", "its", "own", "to", "reason", "about", "the", "sem", "antic", "similar", "ity", "of", "sent", "ences", "by", "ind", "icating", "there", "ex", "ists", "information", "ine", "quality", "."], "token_lens": [3, 1, 2, 1, 2, 1, 1, 2, 2, 1, 3, 1, 3, 1, 3, 1, 3, 1, 1, 1, 1, 1, 3, 3, 1, 2, 1, 1, 1, 2, 2, 3, 3, 2, 1, 1, 2, 1, 2, 1, 1, 1, 1, 1, 1, 1, 2, 2, 1, 2, 1, 2, 1, 2, 1, 3], "sentence": "Monolingual word alignment is crucial to model semantic interactions between sentences. In particular, null alignment, a phenomenon in which words have no corresponding counterparts, is pervasive and critical in handling semantically divergent sentences. Identification of null alignment is useful on its own to reason about the semantic similarity of sentences by indicating there exists information inequality.", "sentence_starts": [0]}
{"doc_id": "ACL_23_P_219", "wnd_id": "ACL_23_P_219-1", "entity_mentions": [{"id": "ACL_23_P_219-1-E0", "text": "this study", "start": 12, "end": 14, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_219-1-E1", "text": "To achieve unbalanced word alignment that values both alignment and null alignment", "start": 0, "end": 12, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_219-1-E2", "text": "that the family of optimal transport (OT), i.e., balanced, partial, and unbalanced OT, are natural and powerful approaches", "start": 15, "end": 33, "entity_type": "UNK", "mention_type": "UNK"}], "relation_mentions": [], "event_mentions": [{"event_type": "Methods/Approach", "id": "ACL_23_P_219-1-EV0", "trigger": {"text": "shows", "start": 14, "end": 15}, "arguments": [{"entity_id": "ACL_23_P_219-1-E0", "text": "this study", "role": "Agent"}, {"entity_id": "ACL_23_P_219-1-E1", "text": "To achieve unbalanced word alignment that values both alignment and null alignment", "role": "Purpose"}, {"entity_id": "ACL_23_P_219-1-E2", "text": "that the family of optimal transport (OT), i.e., balanced, partial, and unbalanced OT, are natural and powerful approaches", "role": "PrimaryObject"}]}], "entity_coreference": [], "event_coreference": [], "tokens": ["To", "achieve", "unbalanced", "word", "alignment", "that", "values", "both", "alignment", "and", "null", "alignment,", "this", "study", "shows", "that", "the", "family", "of", "optimal", "transport", "(OT),", "i.e.,", "balanced,", "partial,", "and", "unbalanced", "OT,", "are", "natural", "and", "powerful", "approaches", "even", "without", "tailor-made", "techniques."], "pieces": ["To", "ach", "ieve", "un", "balanced", "word", "al", "ignment", "that", "values", "both", "al", "ignment", "and", "null", "al", "ignment", ",", "this", "study", "shows", "that", "the", "family", "of", "opt", "imal", "trans", "port", "(", "OT", "),", "i", ".", "e", ".,", "balanced", ",", "partial", ",", "and", "un", "balanced", "OT", ",", "are", "natural", "and", "powerful", "appro", "aches", "even", "without", "tail", "or", "-", "made", "techn", "iques", "."], "token_lens": [1, 2, 2, 1, 2, 1, 1, 1, 2, 1, 1, 3, 1, 1, 1, 1, 1, 1, 1, 2, 2, 3, 4, 2, 2, 1, 2, 2, 1, 1, 1, 1, 2, 1, 1, 4, 3], "sentence": "To achieve unbalanced word alignment that values both alignment and null alignment, this study shows that the family of optimal transport (OT), i.e., balanced, partial, and unbalanced OT, are natural and powerful approaches even without tailor-made techniques.", "sentence_starts": [0]}
{"doc_id": "ACL_23_P_219", "wnd_id": "ACL_23_P_219-2", "entity_mentions": [{"id": "ACL_23_P_219-2-E0", "text": "Our extensive experiments", "start": 0, "end": 3, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_219-2-E1", "text": "remarkably on challenging datasets with high null alignment frequencies", "start": 25, "end": 34, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_219-2-E2", "text": "our generic OT-based alignment methods", "start": 10, "end": 15, "entity_type": "UNK", "mention_type": "UNK"}], "relation_mentions": [], "event_mentions": [{"event_type": "Results/Findings", "id": "ACL_23_P_219-2-EV0", "trigger": {"text": "indicate", "start": 8, "end": 9}, "arguments": [{"entity_id": "ACL_23_P_219-2-E0", "text": "Our extensive experiments", "role": "Agent"}, {"entity_id": "ACL_23_P_219-2-E1", "text": "remarkably on challenging datasets with high null alignment frequencies", "role": "Context"}, {"entity_id": "ACL_23_P_219-2-E2", "text": "our generic OT-based alignment methods", "role": "PrimaryObject"}]}], "entity_coreference": [], "event_coreference": [], "tokens": ["Our", "extensive", "experiments", "covering", "unsupervised", "and", "supervised", "settings", "indicate", "that", "our", "generic", "OT-based", "alignment", "methods", "are", "competitive", "against", "the", "state-of-the-arts", "specially", "designed", "for", "word", "alignment,", "remarkably", "on", "challenging", "datasets", "with", "high", "null", "alignment", "frequencies."], "pieces": ["Our", "ext", "ensive", "exper", "iments", "cover", "ing", "un", "super", "vised", "and", "super", "vised", "settings", "ind", "icate", "that", "our", "generic", "OT", "-", "based", "al", "ignment", "method", "s", "are", "competitive", "against", "the", "state", "-", "of", "-", "the", "-", "arts", "s", "pecially", "designed", "for", "word", "al", "ignment", ",", "rem", "ark", "ably", "on", "chall", "eng", "ing", "dat", "as", "ets", "with", "high", "null", "al", "ignment", "f", "requ", "encies", "."], "token_lens": [1, 2, 2, 2, 3, 1, 2, 1, 2, 1, 1, 1, 3, 2, 2, 1, 1, 1, 1, 7, 2, 1, 1, 1, 3, 3, 1, 3, 3, 1, 1, 1, 2, 4], "sentence": "Our extensive experiments covering unsupervised and supervised settings indicate that our generic OT-based alignment methods are competitive against the state-of-the-arts specially designed for word alignment, remarkably on challenging datasets with high null alignment frequencies.", "sentence_starts": [0]}
{"doc_id": "ACL_23_P_02", "wnd_id": "ACL_23_P_02-0", "entity_mentions": [{"id": "ACL_23_P_02-0-E0", "text": "One of the main challenges", "start": 0, "end": 5, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_02-0-E1", "text": "However, existing dialogue datasets do not provide enough annotation to explain and correct such unsafe behavior", "start": 25, "end": 41, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_02-0-E2", "text": "the prevalence of unsafe behavior", "start": 13, "end": 18, "entity_type": "UNK", "mention_type": "UNK"}], "relation_mentions": [], "event_mentions": [{"event_type": "Background/Introduction", "id": "ACL_23_P_02-0-EV0", "trigger": {"text": "is", "start": 12, "end": 13}, "arguments": [{"entity_id": "ACL_23_P_02-0-E0", "text": "One of the main challenges", "role": "Agent"}, {"entity_id": "ACL_23_P_02-0-E1", "text": "However, existing dialogue datasets do not provide enough annotation to explain and correct such unsafe behavior", "role": "Challenge"}, {"entity_id": "ACL_23_P_02-0-E2", "text": "the prevalence of unsafe behavior", "role": "PrimaryObject"}]}], "entity_coreference": [], "event_coreference": [], "tokens": ["One", "of", "the", "main", "challenges", "open-domain", "end-to-end", "dialogue", "systems,", "or", "chatbots,", "face", "is", "the", "prevalence", "of", "unsafe", "behavior,", "such", "as", "toxic", "languages", "and", "harmful", "suggestions.", "However,", "existing", "dialogue", "datasets", "do", "not", "provide", "enough", "annotation", "to", "explain", "and", "correct", "such", "unsafe", "behavior."], "pieces": ["One", "of", "the", "main", "chall", "enges", "open", "-", "domain", "end", "-", "to", "-", "end", "dial", "ogue", "system", "s", ",", "or", "chat", "bots", ",", "face", "is", "the", "pre", "val", "ence", "of", "uns", "afe", "behavior", ",", "such", "as", "t", "oxic", "l", "anguages", "and", "harm", "ful", "suggest", "ions", ".", "However", ",", "existing", "dial", "ogue", "dat", "as", "ets", "do", "not", "prov", "ide", "enough", "ann", "otation", "to", "expl", "ain", "and", "correct", "such", "uns", "afe", "behavior", "."], "token_lens": [1, 1, 1, 1, 2, 3, 5, 2, 3, 1, 3, 1, 1, 1, 3, 1, 2, 2, 1, 1, 2, 2, 1, 2, 3, 2, 1, 2, 3, 1, 1, 2, 1, 2, 1, 2, 1, 1, 1, 2, 2], "sentence": "One of the main challenges open-domain end-to-end dialogue systems, or chatbots, face is the prevalence of unsafe behavior, such as toxic languages and harmful suggestions. However, existing dialogue datasets do not provide enough annotation to explain and correct such unsafe behavior.", "sentence_starts": [0]}
{"doc_id": "ACL_23_P_02", "wnd_id": "ACL_23_P_02-1", "entity_mentions": [{"id": "ACL_23_P_02-1-E0", "text": "we", "start": 3, "end": 4, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_02-1-E1", "text": "By virtue of the comprehensive annotation of SafeConv, we benchmark three powerful models for the mitigation of conversational unsafe behavior, including a checker to detect unsafe utterances, a tagger to extract unsafe spans, and a rewriter to convert an unsafe response to a safe version", "start": 63, "end": 108, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_02-1-E2", "text": "Moreover, we explore the huge benefits brought by combining the models for explaining the emergence of unsafe behavior and detoxifying chatbots.", "start": 108, "end": 129, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_02-1-E3", "text": "Besides the utterance-level safety labels, SafeConv also provides unsafe spans in an utterance, information able to indicate which words contribute to the detected unsafe behavior", "start": 17, "end": 42, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_02-1-E4", "text": "SafeConv provides safe alternative responses to continue the conversation when unsafe behavior detected, guiding the conversation to a gentle trajectory", "start": 43, "end": 63, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_02-1-E5", "text": "a new dataset", "start": 5, "end": 8, "entity_type": "UNK", "mention_type": "UNK"}], "relation_mentions": [], "event_mentions": [{"event_type": "Methods/Approach", "id": "ACL_23_P_02-1-EV0", "trigger": {"text": "construct", "start": 4, "end": 5}, "arguments": [{"entity_id": "ACL_23_P_02-1-E0", "text": "we", "role": "Agent"}, {"entity_id": "ACL_23_P_02-1-E1", "text": "By virtue of the comprehensive annotation of SafeConv, we benchmark three powerful models for the mitigation of conversational unsafe behavior, including a checker to detect unsafe utterances, a tagger to extract unsafe spans, and a rewriter to convert an unsafe response to a safe version", "role": "Method"}, {"entity_id": "ACL_23_P_02-1-E2", "text": "Moreover, we explore the huge benefits brought by combining the models for explaining the emergence of unsafe behavior and detoxifying chatbots.", "role": "Method"}, {"entity_id": "ACL_23_P_02-1-E3", "text": "Besides the utterance-level safety labels, SafeConv also provides unsafe spans in an utterance, information able to indicate which words contribute to the detected unsafe behavior", "role": "Results"}, {"entity_id": "ACL_23_P_02-1-E4", "text": "SafeConv provides safe alternative responses to continue the conversation when unsafe behavior detected, guiding the conversation to a gentle trajectory", "role": "Results"}, {"entity_id": "ACL_23_P_02-1-E5", "text": "a new dataset", "role": "PrimaryObject"}]}], "entity_coreference": [], "event_coreference": [], "tokens": ["In", "this", "work,", "we", "construct", "a", "new", "dataset", "called", "SafeConv", "for", "the", "research", "of", "conversational", "safety:", "(1)", "Besides", "the", "utterance-level", "safety", "labels,", "SafeConv", "also", "provides", "unsafe", "spans", "in", "an", "utterance,", "information", "able", "to", "indicate", "which", "words", "contribute", "to", "the", "detected", "unsafe", "behavior;", "(2)", "SafeConv", "provides", "safe", "alternative", "responses", "to", "continue", "the", "conversation", "when", "unsafe", "behavior", "detected,", "guiding", "the", "conversation", "to", "a", "gentle", "trajectory.", "By", "virtue", "of", "the", "comprehensive", "annotation", "of", "SafeConv,", "we", "benchmark", "three", "powerful", "models", "for", "the", "mitigation", "of", "conversational", "unsafe", "behavior,", "including", "a", "checker", "to", "detect", "unsafe", "utterances,", "a", "tagger", "to", "extract", "unsafe", "spans,", "and", "a", "rewriter", "to", "convert", "an", "unsafe", "response", "to", "a", "safe", "version.", "Moreover,", "we", "explore", "the", "huge", "benefits", "brought", "by", "combining", "the", "models", "for", "explaining", "the", "emergence", "of", "unsafe", "behavior", "and", "detoxifying", "chatbots."], "pieces": ["In", "this", "work", ",", "we", "construct", "a", "new", "dat", "as", "et", "called", "Safe", "Con", "v", "for", "the", "research", "of", "con", "vers", "ational", "safety", ":", "(", "1", ")", "Besides", "the", "utter", "ance", "-", "level", "safety", "lab", "els", ",", "Safe", "Con", "v", "also", "prov", "ides", "uns", "afe", "sp", "ans", "in", "an", "utter", "ance", ",", "information", "able", "to", "ind", "icate", "which", "words", "cont", "ribute", "to", "the", "det", "ected", "uns", "afe", "behavior", ";", "(", "2", ")", "Safe", "Con", "v", "prov", "ides", "safe", "altern", "ative", "respons", "es", "to", "continue", "the", "con", "vers", "ation", "when", "uns", "afe", "behavior", "det", "ected", ",", "gu", "iding", "the", "con", "vers", "ation", "to", "a", "gent", "le", "tra", "ject", "ory", ".", "By", "virt", "ue", "of", "the", "com", "pre", "hens", "ive", "ann", "otation", "of", "Safe", "Con", "v", ",", "we", "bench", "mark", "three", "powerful", "models", "for", "the", "mit", "igation", "of", "con", "vers", "ational", "uns", "afe", "behavior", ",", "including", "a", "check", "er", "to", "det", "ect", "uns", "afe", "utter", "ances", ",", "a", "t", "agger", "to", "ext", "ract", "uns", "afe", "sp", "ans", ",", "and", "a", "rew", "riter", "to", "con", "vert", "an", "uns", "afe", "response", "to", "a", "safe", "version", ".", "Moreover", ",", "we", "expl", "ore", "the", "huge", "benef", "its", "b", "rought", "by", "comb", "ining", "the", "models", "for", "expl", "aining", "the", "em", "erg", "ence", "of", "uns", "afe", "behavior", "and", "det", "ox", "ifying", "chat", "bots", "."], "token_lens": [1, 1, 2, 1, 1, 1, 1, 3, 1, 3, 1, 1, 1, 1, 3, 2, 3, 1, 1, 4, 1, 3, 3, 1, 2, 2, 2, 1, 1, 3, 1, 1, 1, 2, 1, 1, 2, 1, 1, 2, 2, 2, 3, 3, 2, 1, 2, 2, 1, 1, 1, 3, 1, 2, 1, 3, 2, 1, 3, 1, 1, 2, 4, 1, 2, 1, 1, 4, 2, 1, 4, 1, 2, 1, 1, 1, 1, 1, 2, 1, 3, 2, 2, 1, 1, 2, 1, 2, 2, 3, 1, 2, 1, 2, 2, 3, 1, 1, 2, 1, 2, 1, 2, 1, 1, 1, 1, 2, 2, 1, 2, 1, 1, 2, 2, 1, 2, 1, 1, 1, 2, 1, 3, 1, 2, 1, 1, 3, 3], "sentence": "In this work, we construct a new dataset called SafeConv for the research of conversational safety: (1) Besides the utterance-level safety labels, SafeConv also provides unsafe spans in an utterance, information able to indicate which words contribute to the detected unsafe behavior; (2) SafeConv provides safe alternative responses to continue the conversation when unsafe behavior detected, guiding the conversation to a gentle trajectory. By virtue of the comprehensive annotation of SafeConv, we benchmark three powerful models for the mitigation of conversational unsafe behavior, including a checker to detect unsafe utterances, a tagger to extract unsafe spans, and a rewriter to convert an unsafe response to a safe version. Moreover, we explore the huge benefits brought by combining the models for explaining the emergence of unsafe behavior and detoxifying chatbots.", "sentence_starts": [0]}
{"doc_id": "ACL_23_P_02", "wnd_id": "ACL_23_P_02-2", "entity_mentions": [{"id": "ACL_23_P_02-2-E0", "text": "Experiments", "start": 0, "end": 1, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_02-2-E1", "text": "popular chatbots could be detoxified by a huge extent", "start": 15, "end": 24, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_02-2-E2", "text": "the detected unsafe behavior could be well explained with unsafe spans", "start": 3, "end": 14, "entity_type": "UNK", "mention_type": "UNK"}], "relation_mentions": [], "event_mentions": [{"event_type": "Results/Findings", "id": "ACL_23_P_02-2-EV0", "trigger": {"text": "show", "start": 1, "end": 2}, "arguments": [{"entity_id": "ACL_23_P_02-2-E0", "text": "Experiments", "role": "Agent"}, {"entity_id": "ACL_23_P_02-2-E1", "text": "popular chatbots could be detoxified by a huge extent", "role": "Results"}, {"entity_id": "ACL_23_P_02-2-E2", "text": "the detected unsafe behavior could be well explained with unsafe spans", "role": "PrimaryObject"}]}], "entity_coreference": [], "event_coreference": [], "tokens": ["Experiments", "show", "that", "the", "detected", "unsafe", "behavior", "could", "be", "well", "explained", "with", "unsafe", "spans", "and", "popular", "chatbots", "could", "be", "detoxified", "by", "a", "huge", "extent."], "pieces": ["Exper", "iments", "show", "that", "the", "det", "ected", "uns", "afe", "behavior", "could", "be", "well", "expl", "ained", "with", "uns", "afe", "sp", "ans", "and", "popular", "chat", "bots", "could", "be", "det", "ox", "ified", "by", "a", "huge", "ext", "ent", "."], "token_lens": [2, 1, 1, 1, 2, 2, 1, 1, 1, 1, 2, 1, 2, 2, 1, 1, 2, 1, 1, 3, 1, 1, 1, 3], "sentence": "Experiments show that the detected unsafe behavior could be well explained with unsafe spans and popular chatbots could be detoxified by a huge extent.", "sentence_starts": [0]}
{"doc_id": "ACL_23_P_85", "wnd_id": "ACL_23_P_85-0", "entity_mentions": [{"id": "ACL_23_P_85-0-E0", "text": "Out-of-distribution (OOD) detection, a fundamental task vexing real-world applications", "start": 0, "end": 9, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_85-0-E1", "text": "Recently fine-tuning based methods have made promising progress", "start": 17, "end": 25, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_85-0-E2", "text": "However, it could be costly to store fine-tuned models for each scenario", "start": 25, "end": 37, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_85-0-E3", "text": "growing attention", "start": 11, "end": 13, "entity_type": "UNK", "mention_type": "UNK"}], "relation_mentions": [], "event_mentions": [{"event_type": "Background/Introduction", "id": "ACL_23_P_85-0-EV0", "trigger": {"text": "attracted", "start": 10, "end": 11}, "arguments": [{"entity_id": "ACL_23_P_85-0-E0", "text": "Out-of-distribution (OOD) detection, a fundamental task vexing real-world applications", "role": "Agent"}, {"entity_id": "ACL_23_P_85-0-E1", "text": "Recently fine-tuning based methods have made promising progress", "role": "Context"}, {"entity_id": "ACL_23_P_85-0-E2", "text": "However, it could be costly to store fine-tuned models for each scenario", "role": "Challenge"}, {"entity_id": "ACL_23_P_85-0-E3", "text": "growing attention", "role": "PrimaryObject"}]}], "entity_coreference": [], "event_coreference": [], "tokens": ["Out-of-distribution", "(OOD)", "detection,", "a", "fundamental", "task", "vexing", "real-world", "applications,", "has", "attracted", "growing", "attention", "in", "the", "NLP", "community.", "Recently", "fine-tuning", "based", "methods", "have", "made", "promising", "progress.", "However,", "it", "could", "be", "costly", "to", "store", "fine-tuned", "models", "for", "each", "scenario."], "pieces": ["Out", "-", "of", "-", "dist", "ribution", "(", "OOD", ")", "det", "ection", ",", "a", "fund", "amental", "task", "ve", "x", "ing", "real", "-", "world", "app", "lic", "ations", ",", "has", "att", "racted", "growing", "att", "ention", "in", "the", "N", "LP", "community", ".", "Recently", "fine", "-", "tun", "ing", "based", "method", "s", "have", "made", "prom", "ising", "progress", ".", "However", ",", "it", "could", "be", "cost", "ly", "to", "store", "fine", "-", "tun", "ed", "models", "for", "each", "sc", "enario", "."], "token_lens": [6, 3, 3, 1, 2, 1, 3, 3, 4, 1, 2, 1, 2, 1, 1, 2, 2, 1, 4, 1, 2, 1, 1, 2, 2, 2, 1, 1, 1, 2, 1, 1, 4, 1, 1, 1, 3], "sentence": "Out-of-distribution (OOD) detection, a fundamental task vexing real-world applications, has attracted growing attention in the NLP community. Recently fine-tuning based methods have made promising progress. However, it could be costly to store fine-tuned models for each scenario.", "sentence_starts": [0]}
{"doc_id": "ACL_23_P_85", "wnd_id": "ACL_23_P_85-1", "entity_mentions": [{"id": "ACL_23_P_85-1-E0", "text": "we", "start": 3, "end": 4, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_85-1-E1", "text": "to take advantage of optional training data labels and targeted OOD data", "start": 28, "end": 40, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_85-1-E2", "text": "propose an unsupervised prefix-tuning based OOD detection framework termed PTO", "start": 17, "end": 27, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_85-1-E3", "text": "two practical extensions of PTO are further proposed", "start": 40, "end": 48, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_85-1-E4", "text": "PTO and its extensions offer several key advantages of being lightweight, easy-to-reproduce, and theoretically justified", "start": 49, "end": 64, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_85-1-E5", "text": "the classic fine-tuning based OOD detection", "start": 6, "end": 12, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_85-1-E6", "text": "toward a parameter-efficient alternative", "start": 12, "end": 16, "entity_type": "UNK", "mention_type": "UNK"}], "relation_mentions": [], "event_mentions": [{"event_type": "Methods/Approach", "id": "ACL_23_P_85-1-EV0", "trigger": {"text": "depart from", "start": 4, "end": 6}, "arguments": [{"entity_id": "ACL_23_P_85-1-E0", "text": "we", "role": "Agent"}, {"entity_id": "ACL_23_P_85-1-E1", "text": "to take advantage of optional training data labels and targeted OOD data", "role": "Purpose"}, {"entity_id": "ACL_23_P_85-1-E2", "text": "propose an unsupervised prefix-tuning based OOD detection framework termed PTO", "role": "Method"}, {"entity_id": "ACL_23_P_85-1-E3", "text": "two practical extensions of PTO are further proposed", "role": "Method"}, {"entity_id": "ACL_23_P_85-1-E4", "text": "PTO and its extensions offer several key advantages of being lightweight, easy-to-reproduce, and theoretically justified", "role": "Results"}, {"entity_id": "ACL_23_P_85-1-E5", "text": "the classic fine-tuning based OOD detection", "role": "PrimaryObject"}, {"entity_id": "ACL_23_P_85-1-E6", "text": "toward a parameter-efficient alternative", "role": "SecondaryObject"}]}], "entity_coreference": [], "event_coreference": [], "tokens": ["In", "this", "paper,", "we", "depart", "from", "the", "classic", "fine-tuning", "based", "OOD", "detection", "toward", "a", "parameter-efficient", "alternative,", "and", "propose", "an", "unsupervised", "prefix-tuning", "based", "OOD", "detection", "framework", "termed", "PTO.", "Additionally,", "to", "take", "advantage", "of", "optional", "training", "data", "labels", "and", "targeted", "OOD", "data,", "two", "practical", "extensions", "of", "PTO", "are", "further", "proposed.", "Overall,", "PTO", "and", "its", "extensions", "offer", "several", "key", "advantages", "of", "being", "lightweight,", "easy-to-reproduce,", "and", "theoretically", "justified."], "pieces": ["In", "this", "paper", ",", "we", "dep", "art", "from", "the", "classic", "fine", "-", "tun", "ing", "based", "OOD", "det", "ection", "t", "oward", "a", "param", "eter", "-", "efficient", "altern", "ative", ",", "and", "pro", "pose", "an", "un", "super", "vised", "prefix", "-", "tun", "ing", "based", "OOD", "det", "ection", "framework", "ter", "med", "P", "TO", ".", "Additionally", ",", "to", "take", "advant", "age", "of", "optional", "training", "data", "lab", "els", "and", "target", "ed", "OOD", "data", ",", "two", "pract", "ical", "ext", "ensions", "of", "P", "TO", "are", "f", "urther", "prop", "osed", ".", "Overall", ",", "P", "TO", "and", "its", "ext", "ensions", "offer", "sever", "al", "key", "advant", "ages", "of", "being", "light", "weight", ",", "easy", "-", "to", "-", "re", "produ", "ce", ",", "and", "the", "oret", "ically", "just", "ified", "."], "token_lens": [1, 1, 2, 1, 2, 1, 1, 1, 4, 1, 1, 2, 2, 1, 4, 3, 1, 2, 1, 3, 4, 1, 1, 2, 1, 2, 3, 2, 1, 1, 2, 1, 1, 1, 1, 2, 1, 2, 1, 2, 1, 2, 2, 1, 2, 1, 2, 3, 2, 2, 1, 1, 2, 1, 2, 1, 2, 1, 1, 3, 8, 1, 3, 3], "sentence": "In this paper, we depart from the classic fine-tuning based OOD detection toward a parameter-efficient alternative, and propose an unsupervised prefix-tuning based OOD detection framework termed PTO. Additionally, to take advantage of optional training data labels and targeted OOD data, two practical extensions of PTO are further proposed. Overall, PTO and its extensions offer several key advantages of being lightweight, easy-to-reproduce, and theoretically justified.", "sentence_starts": [0]}
{"doc_id": "ACL_23_P_85", "wnd_id": "ACL_23_P_85-2", "entity_mentions": [{"id": "ACL_23_P_85-2-E0", "text": "Experimental results", "start": 0, "end": 2, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_85-2-E1", "text": "under a wide range of metrics, detection settings, and OOD types", "start": 18, "end": 29, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_85-2-E2", "text": "our methods perform comparably to, even better than, existing fine-tuning based OOD detection approaches", "start": 4, "end": 18, "entity_type": "UNK", "mention_type": "UNK"}], "relation_mentions": [], "event_mentions": [{"event_type": "Results/Findings", "id": "ACL_23_P_85-2-EV0", "trigger": {"text": "show", "start": 2, "end": 3}, "arguments": [{"entity_id": "ACL_23_P_85-2-E0", "text": "Experimental results", "role": "Agent"}, {"entity_id": "ACL_23_P_85-2-E1", "text": "under a wide range of metrics, detection settings, and OOD types", "role": "Context"}, {"entity_id": "ACL_23_P_85-2-E2", "text": "our methods perform comparably to, even better than, existing fine-tuning based OOD detection approaches", "role": "PrimaryObject"}]}], "entity_coreference": [], "event_coreference": [], "tokens": ["Experimental", "results", "show", "that", "our", "methods", "perform", "comparably", "to,", "even", "better", "than,", "existing", "fine-tuning", "based", "OOD", "detection", "approaches", "under", "a", "wide", "range", "of", "metrics,", "detection", "settings,", "and", "OOD", "types."], "pieces": ["Exper", "imental", "results", "show", "that", "our", "method", "s", "per", "form", "com", "par", "ably", "to", ",", "even", "better", "than", ",", "existing", "fine", "-", "tun", "ing", "based", "OOD", "det", "ection", "appro", "aches", "under", "a", "wide", "range", "of", "met", "rics", ",", "det", "ection", "settings", ",", "and", "OOD", "types", "."], "token_lens": [2, 1, 1, 1, 1, 2, 2, 3, 2, 1, 1, 2, 1, 4, 1, 1, 2, 2, 1, 1, 1, 1, 1, 3, 2, 2, 1, 1, 2], "sentence": "Experimental results show that our methods perform comparably to, even better than, existing fine-tuning based OOD detection approaches under a wide range of metrics, detection settings, and OOD types.", "sentence_starts": [0]}
{"doc_id": "ACL_23_P_780", "wnd_id": "ACL_23_P_780-0", "entity_mentions": [{"id": "ACL_23_P_780-0-E0", "text": "Theory of Mind (ToM)", "start": 0, "end": 4, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_780-0-E1", "text": "simply scaling up models will not imbue them with theory of mind due to the inherently symbolic and implicit nature of the phenomenon", "start": 47, "end": 70, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_780-0-E2", "text": "investigate an alternative: can we design a decoding-time algorithm that enhances theory of mind of off-the-shelf neural language models without explicit supervision?", "start": 72, "end": 94, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_780-0-E3", "text": "despite their ever more impressive performance, large-scale neural language models still lack basic theory of mind capabilities out-of-the-box.", "start": 26, "end": 44, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_780-0-E4", "text": "a key element of our social intelligence.", "start": 18, "end": 25, "entity_type": "UNK", "mention_type": "UNK"}], "relation_mentions": [], "event_mentions": [{"event_type": "Background/Introduction", "id": "ACL_23_P_780-0-EV0", "trigger": {"text": "is", "start": 17, "end": 18}, "arguments": [{"entity_id": "ACL_23_P_780-0-E0", "text": "Theory of Mind (ToM)", "role": "Agent"}, {"entity_id": "ACL_23_P_780-0-E1", "text": "simply scaling up models will not imbue them with theory of mind due to the inherently symbolic and implicit nature of the phenomenon", "role": "Context"}, {"entity_id": "ACL_23_P_780-0-E2", "text": "investigate an alternative: can we design a decoding-time algorithm that enhances theory of mind of off-the-shelf neural language models without explicit supervision?", "role": "Purpose"}, {"entity_id": "ACL_23_P_780-0-E3", "text": "despite their ever more impressive performance, large-scale neural language models still lack basic theory of mind capabilities out-of-the-box.", "role": "Challenge"}, {"entity_id": "ACL_23_P_780-0-E4", "text": "a key element of our social intelligence.", "role": "PrimaryObject"}]}], "entity_coreference": [], "event_coreference": [], "tokens": ["Theory", "of", "Mind", "(ToM)", "\u2014", "the", "ability", "to", "reason", "about", "the", "mental", "states", "of", "other", "people", "\u2014", "is", "a", "key", "element", "of", "our", "social", "intelligence.", "Yet,", "despite", "their", "ever", "more", "impressive", "performance,", "large-scale", "neural", "language", "models", "still", "lack", "basic", "theory", "of", "mind", "capabilities", "out-of-the-box.", "We", "posit", "that", "simply", "scaling", "up", "models", "will", "not", "imbue", "them", "with", "theory", "of", "mind", "due", "to", "the", "inherently", "symbolic", "and", "implicit", "nature", "of", "the", "phenomenon,", "and", "instead", "investigate", "an", "alternative:", "can", "we", "design", "a", "decoding-time", "algorithm", "that", "enhances", "theory", "of", "mind", "of", "off-the-shelf", "neural", "language", "models", "without", "explicit", "supervision?"], "pieces": ["The", "ory", "of", "Mind", "(", "To", "M", ")", "\u00e2\u0122\u0136", "the", "ability", "to", "reason", "about", "the", "mental", "states", "of", "other", "people", "\u00e2\u0122\u0136", "is", "a", "key", "element", "of", "our", "social", "intelligence", ".", "Yet", ",", "despite", "their", "ever", "more", "imp", "ressive", "performance", ",", "large", "-", "scale", "ne", "ural", "language", "models", "still", "l", "ack", "basic", "the", "ory", "of", "mind", "cap", "abilities", "out", "-", "of", "-", "the", "-", "box", ".", "We", "pos", "it", "that", "sim", "ply", "sc", "aling", "up", "models", "will", "not", "imb", "ue", "them", "with", "the", "ory", "of", "mind", "due", "to", "the", "in", "herent", "ly", "sy", "mb", "olic", "and", "impl", "icit", "nature", "of", "the", "phen", "omen", "on", ",", "and", "instead", "invest", "igate", "an", "altern", "ative", ":", "can", "we", "design", "a", "dec", "oding", "-", "time", "al", "gorithm", "that", "enh", "ances", "the", "ory", "of", "mind", "of", "off", "-", "the", "-", "she", "lf", "ne", "ural", "language", "models", "without", "expl", "icit", "super", "vision", "?"], "token_lens": [2, 1, 1, 4, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 1, 1, 1, 1, 2, 2, 3, 2, 1, 1, 1, 2, 1, 2, 1, 1, 2, 8, 1, 2, 1, 2, 2, 1, 1, 1, 1, 2, 1, 1, 2, 1, 1, 1, 1, 1, 3, 3, 1, 2, 1, 1, 1, 4, 1, 1, 2, 1, 3, 1, 1, 1, 1, 4, 2, 1, 2, 2, 1, 1, 1, 6, 2, 1, 1, 1, 2, 3], "sentence": "Theory of Mind (ToM) \u2014 the ability to reason about the mental states of other people \u2014 is a key element of our social intelligence. Yet, despite their ever more impressive performance, large-scale neural language models still lack basic theory of mind capabilities out-of-the-box. We posit that simply scaling up models will not imbue them with theory of mind due to the inherently symbolic and implicit nature of the phenomenon, and instead investigate an alternative: can we design a decoding-time algorithm that enhances theory of mind of off-the-shelf neural language models without explicit supervision?", "sentence_starts": [0]}
{"doc_id": "ACL_23_P_780", "wnd_id": "ACL_23_P_780-1", "entity_mentions": [{"id": "ACL_23_P_780-1-E0", "text": "We", "start": 0, "end": 1, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_780-1-E1", "text": "our approach tracks each entity\u2019s beliefs, their estimation of other entities\u2019 beliefs, and higher-order levels of reasoning, all through graphical representations", "start": 25, "end": 46, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_780-1-E2", "text": "allowing for more precise and interpretable reasoning than previous approaches", "start": 46, "end": 56, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_780-1-E3", "text": "SymbolicToM", "start": 2, "end": 3, "entity_type": "UNK", "mention_type": "UNK"}], "relation_mentions": [], "event_mentions": [{"event_type": "Methods/Approach", "id": "ACL_23_P_780-1-EV0", "trigger": {"text": "present", "start": 1, "end": 2}, "arguments": [{"entity_id": "ACL_23_P_780-1-E0", "text": "We", "role": "Agent"}, {"entity_id": "ACL_23_P_780-1-E1", "text": "our approach tracks each entity\u2019s beliefs, their estimation of other entities\u2019 beliefs, and higher-order levels of reasoning, all through graphical representations", "role": "Method"}, {"entity_id": "ACL_23_P_780-1-E2", "text": "allowing for more precise and interpretable reasoning than previous approaches", "role": "Results"}, {"entity_id": "ACL_23_P_780-1-E3", "text": "SymbolicToM", "role": "PrimaryObject"}]}], "entity_coreference": [], "event_coreference": [], "tokens": ["We", "present", "SymbolicToM,", "a", "plug-and-play", "approach", "to", "reason", "about", "the", "belief", "states", "of", "multiple", "characters", "in", "reading", "comprehension", "tasks", "via", "explicit", "symbolic", "representation.", "More", "concretely,", "our", "approach", "tracks", "each", "entity\u2019s", "beliefs,", "their", "estimation", "of", "other", "entities\u2019", "beliefs,", "and", "higher-order", "levels", "of", "reasoning,", "all", "through", "graphical", "representations,", "allowing", "for", "more", "precise", "and", "interpretable", "reasoning", "than", "previous", "approaches."], "pieces": ["We", "present", "Sy", "mb", "olic", "To", "M", ",", "a", "plug", "-", "and", "-", "play", "appro", "ach", "to", "reason", "about", "the", "bel", "ief", "states", "of", "multiple", "char", "acters", "in", "reading", "com", "pre", "hens", "ion", "t", "asks", "via", "expl", "icit", "sy", "mb", "olic", "represent", "ation", ".", "More", "con", "crete", "ly", ",", "our", "appro", "ach", "tracks", "each", "entity", "\u00e2\u0122", "\u013b", "s", "bel", "ief", "s", ",", "their", "est", "imation", "of", "other", "ent", "ities", "\u00e2\u0122", "\u013b", "bel", "ief", "s", ",", "and", "higher", "-", "order", "levels", "of", "reason", "ing", ",", "all", "through", "graph", "ical", "represent", "ations", ",", "all", "owing", "for", "more", "pre", "cise", "and", "interpret", "able", "reason", "ing", "than", "pre", "vious", "appro", "aches", "."], "token_lens": [1, 1, 6, 1, 5, 2, 1, 1, 1, 1, 2, 1, 1, 1, 2, 1, 1, 4, 2, 1, 2, 3, 3, 1, 4, 1, 2, 1, 1, 4, 4, 1, 2, 1, 1, 4, 4, 1, 3, 1, 1, 3, 1, 1, 2, 3, 2, 1, 1, 2, 1, 2, 2, 1, 2, 3], "sentence": "We present SymbolicToM, a plug-and-play approach to reason about the belief states of multiple characters in reading comprehension tasks via explicit symbolic representation. More concretely, our approach tracks each entity\u2019s beliefs, their estimation of other entities\u2019 beliefs, and higher-order levels of reasoning, all through graphical representations, allowing for more precise and interpretable reasoning than previous approaches.", "sentence_starts": [0]}
{"doc_id": "ACL_23_P_780", "wnd_id": "ACL_23_P_780-2", "entity_mentions": [{"id": "ACL_23_P_780-2-E0", "text": "Empirical results on the well-known ToMi benchmark (Le et al., 2019)", "start": 0, "end": 11, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_780-2-E1", "text": "SymbolicToM dramatically enhances off-the-shelf neural networks\u2019 theory of mind in a zero-shot setting", "start": 13, "end": 26, "entity_type": "UNK", "mention_type": "UNK"}], "relation_mentions": [], "event_mentions": [{"event_type": "Results/Findings", "id": "ACL_23_P_780-2-EV0", "trigger": {"text": "demonstrate", "start": 11, "end": 12}, "arguments": [{"entity_id": "ACL_23_P_780-2-E0", "text": "Empirical results on the well-known ToMi benchmark (Le et al., 2019)", "role": "Agent"}, {"entity_id": "ACL_23_P_780-2-E1", "text": "SymbolicToM dramatically enhances off-the-shelf neural networks\u2019 theory of mind in a zero-shot setting", "role": "PrimaryObject"}]}], "entity_coreference": [], "event_coreference": [], "tokens": ["Empirical", "results", "on", "the", "well-known", "ToMi", "benchmark", "(Le", "et", "al.,", "2019)", "demonstrate", "that", "SymbolicToM", "dramatically", "enhances", "off-the-shelf", "neural", "networks\u2019", "theory", "of", "mind", "in", "a", "zero-shot", "setting", "while", "showing", "robust", "out-of-distribution", "performance", "compared", "to", "supervised", "baselines."], "pieces": ["E", "mp", "ir", "ical", "results", "on", "the", "well", "-", "known", "To", "Mi", "bench", "mark", "(", "Le", "et", "al", ".,", "2019", ")", "demon", "strate", "that", "Sy", "mb", "olic", "To", "M", "d", "ram", "atically", "enh", "ances", "off", "-", "the", "-", "she", "lf", "ne", "ural", "net", "works", "\u00e2\u0122", "\u013b", "the", "ory", "of", "mind", "in", "a", "zero", "-", "shot", "setting", "while", "sh", "owing", "rob", "ust", "out", "-", "of", "-", "dist", "ribution", "performance", "comp", "ared", "to", "super", "vised", "bas", "elines", "."], "token_lens": [4, 1, 1, 1, 3, 2, 2, 2, 1, 2, 2, 2, 1, 5, 3, 2, 6, 2, 4, 2, 1, 1, 1, 1, 3, 1, 1, 2, 2, 6, 1, 2, 1, 2, 3], "sentence": "Empirical results on the well-known ToMi benchmark (Le et al., 2019) demonstrate that SymbolicToM dramatically enhances off-the-shelf neural networks\u2019 theory of mind in a zero-shot setting while showing robust out-of-distribution performance compared to supervised baselines.", "sentence_starts": [0]}
{"doc_id": "ACL_23_P_780", "wnd_id": "ACL_23_P_780-3", "entity_mentions": [{"id": "ACL_23_P_780-3-E0", "text": "Our work", "start": 0, "end": 2, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_780-3-E1", "text": "emphasizing the importance of out-of-distribution evaluation and methods that do not overfit a particular dataset", "start": 12, "end": 27, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_780-3-E2", "text": "spurious patterns in existing theory of mind benchmarks", "start": 4, "end": 12, "entity_type": "UNK", "mention_type": "UNK"}], "relation_mentions": [], "event_mentions": [{"event_type": "Conclusions/Implications", "id": "ACL_23_P_780-3-EV0", "trigger": {"text": "reveals", "start": 3, "end": 4}, "arguments": [{"entity_id": "ACL_23_P_780-3-E0", "text": "Our work", "role": "Agent"}, {"entity_id": "ACL_23_P_780-3-E1", "text": "emphasizing the importance of out-of-distribution evaluation and methods that do not overfit a particular dataset", "role": "Implications"}, {"entity_id": "ACL_23_P_780-3-E2", "text": "spurious patterns in existing theory of mind benchmarks", "role": "PrimaryObject"}]}], "entity_coreference": [], "event_coreference": [], "tokens": ["Our", "work", "also", "reveals", "spurious", "patterns", "in", "existing", "theory", "of", "mind", "benchmarks,", "emphasizing", "the", "importance", "of", "out-of-distribution", "evaluation", "and", "methods", "that", "do", "not", "overfit", "a", "particular", "dataset"], "pieces": ["Our", "work", "also", "reve", "als", "sp", "urious", "pattern", "s", "in", "existing", "the", "ory", "of", "mind", "bench", "marks", ",", "em", "phas", "izing", "the", "import", "ance", "of", "out", "-", "of", "-", "dist", "ribution", "eval", "uation", "and", "method", "s", "that", "do", "not", "over", "fit", "a", "part", "icular", "dat", "as", "et"], "token_lens": [1, 1, 1, 2, 2, 2, 1, 1, 2, 1, 1, 3, 3, 1, 2, 1, 6, 2, 1, 2, 1, 1, 1, 2, 1, 2, 3], "sentence": "Our work also reveals spurious patterns in existing theory of mind benchmarks, emphasizing the importance of out-of-distribution evaluation and methods that do not overfit a particular dataset", "sentence_starts": [0]}
{"doc_id": "ACL_23_P_88", "wnd_id": "ACL_23_P_88-0", "entity_mentions": [{"id": "ACL_23_P_88-0-E0", "text": "Visual Word Sense Disambiguation (VWSD)", "start": 0, "end": 5, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_88-0-E1", "text": "image-text matching models often suffered from recognizing polysemous words.", "start": 28, "end": 37, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_88-0-E2", "text": "a task", "start": 6, "end": 8, "entity_type": "UNK", "mention_type": "UNK"}], "relation_mentions": [], "event_mentions": [{"event_type": "Background/Introduction", "id": "ACL_23_P_88-0-EV0", "trigger": {"text": "is", "start": 5, "end": 6}, "arguments": [{"entity_id": "ACL_23_P_88-0-E0", "text": "Visual Word Sense Disambiguation (VWSD)", "role": "Agent"}, {"entity_id": "ACL_23_P_88-0-E1", "text": "image-text matching models often suffered from recognizing polysemous words.", "role": "Challenge"}, {"entity_id": "ACL_23_P_88-0-E2", "text": "a task", "role": "PrimaryObject"}]}], "entity_coreference": [], "event_coreference": [], "tokens": ["Visual", "Word", "Sense", "Disambiguation", "(VWSD)", "is", "a", "task", "to", "find", "the", "image", "that", "most", "accurately", "depicts", "the", "correct", "sense", "of", "the", "target", "word", "for", "the", "given", "context.", "Previously,", "image-text", "matching", "models", "often", "suffered", "from", "recognizing", "polysemous", "words."], "pieces": ["Visual", "Word", "Sense", "Dis", "amb", "ig", "uation", "(", "VW", "SD", ")", "is", "a", "task", "to", "find", "the", "image", "that", "most", "acc", "ur", "ately", "dep", "icts", "the", "correct", "sense", "of", "the", "target", "word", "for", "the", "given", "context", ".", "Previously", ",", "image", "-", "text", "match", "ing", "models", "often", "suff", "ered", "from", "recogn", "izing", "poly", "sem", "ous", "words", "."], "token_lens": [1, 1, 1, 4, 4, 1, 1, 1, 1, 1, 1, 1, 1, 1, 3, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 3, 2, 1, 1, 2, 1, 2, 3, 2], "sentence": "Visual Word Sense Disambiguation (VWSD) is a task to find the image that most accurately depicts the correct sense of the target word for the given context. Previously, image-text matching models often suffered from recognizing polysemous words.", "sentence_starts": [0]}
{"doc_id": "ACL_23_P_88", "wnd_id": "ACL_23_P_88-1", "entity_mentions": [{"id": "ACL_23_P_88-1-E0", "text": "This paper", "start": 0, "end": 2, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_88-1-E1", "text": "we suggest employing Bayesian inference to incorporate the sense definitions when sense information of the answer is not provided", "start": 21, "end": 40, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_88-1-E2", "text": "to ameliorate the out-of-dictionary (OOD) issue, we propose a context-aware definition generation with GPT-3", "start": 42, "end": 56, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_88-1-E3", "text": "an unsupervised VWSD approach", "start": 3, "end": 7, "entity_type": "UNK", "mention_type": "UNK"}], "relation_mentions": [], "event_mentions": [{"event_type": "Methods/Approach", "id": "ACL_23_P_88-1-EV0", "trigger": {"text": "introduces", "start": 2, "end": 3}, "arguments": [{"entity_id": "ACL_23_P_88-1-E0", "text": "This paper", "role": "Agent"}, {"entity_id": "ACL_23_P_88-1-E1", "text": "we suggest employing Bayesian inference to incorporate the sense definitions when sense information of the answer is not provided", "role": "Method"}, {"entity_id": "ACL_23_P_88-1-E2", "text": "to ameliorate the out-of-dictionary (OOD) issue, we propose a context-aware definition generation with GPT-3", "role": "Method"}, {"entity_id": "ACL_23_P_88-1-E3", "text": "an unsupervised VWSD approach", "role": "PrimaryObject"}]}], "entity_coreference": [], "event_coreference": [], "tokens": ["This", "paper", "introduces", "an", "unsupervised", "VWSD", "approach", "that", "uses", "gloss", "information", "of", "an", "external", "lexical", "knowledge-base,", "especially", "the", "sense", "definitions.", "Specifically,", "we", "suggest", "employing", "Bayesian", "inference", "to", "incorporate", "the", "sense", "definitions", "when", "sense", "information", "of", "the", "answer", "is", "not", "provided.", "In", "addition,", "to", "ameliorate", "the", "out-of-dictionary", "(OOD)", "issue,", "we", "propose", "a", "context-aware", "definition", "generation", "with", "GPT-3."], "pieces": ["This", "paper", "introdu", "ces", "an", "un", "super", "vised", "VW", "SD", "appro", "ach", "that", "uses", "gl", "oss", "information", "of", "an", "external", "lex", "ical", "knowledge", "-", "base", ",", "especially", "the", "sense", "def", "initions", ".", "Specifically", ",", "we", "suggest", "employ", "ing", "Bay", "esian", "in", "ference", "to", "inc", "orpor", "ate", "the", "sense", "def", "initions", "when", "sense", "information", "of", "the", "answer", "is", "not", "provided", ".", "In", "add", "ition", ",", "to", "amel", "ior", "ate", "the", "out", "-", "of", "-", "d", "ictionary", "(", "OOD", ")", "issue", ",", "we", "pro", "pose", "a", "context", "-", "aware", "definition", "generation", "with", "G", "PT", "-", "3", "."], "token_lens": [1, 1, 2, 1, 3, 2, 2, 1, 1, 2, 1, 1, 1, 1, 2, 4, 1, 1, 1, 3, 2, 1, 1, 2, 2, 2, 1, 3, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 3, 1, 3, 1, 6, 3, 2, 1, 2, 1, 3, 1, 1, 1, 5], "sentence": "This paper introduces an unsupervised VWSD approach that uses gloss information of an external lexical knowledge-base, especially the sense definitions. Specifically, we suggest employing Bayesian inference to incorporate the sense definitions when sense information of the answer is not provided. In addition, to ameliorate the out-of-dictionary (OOD) issue, we propose a context-aware definition generation with GPT-3.", "sentence_starts": [0]}
{"doc_id": "ACL_23_P_88", "wnd_id": "ACL_23_P_88-2", "entity_mentions": [{"id": "ACL_23_P_88-2-E0", "text": "Experimental results", "start": 0, "end": 2, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_88-2-E1", "text": "with our Bayesian inference-based approach", "start": 9, "end": 14, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_88-2-E2", "text": "our context-aware definition generation achieved prominent performance improvement in OOD examples, exhibiting better performance than the existing definition generation method", "start": 16, "end": 36, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_88-2-E3", "text": "the VWSD performance significantly increased with our Bayesian inference-based approach", "start": 4, "end": 14, "entity_type": "UNK", "mention_type": "UNK"}], "relation_mentions": [], "event_mentions": [{"event_type": "Results/Findings", "id": "ACL_23_P_88-2-EV0", "trigger": {"text": "show", "start": 2, "end": 3}, "arguments": [{"entity_id": "ACL_23_P_88-2-E0", "text": "Experimental results", "role": "Agent"}, {"entity_id": "ACL_23_P_88-2-E1", "text": "with our Bayesian inference-based approach", "role": "Method"}, {"entity_id": "ACL_23_P_88-2-E2", "text": "our context-aware definition generation achieved prominent performance improvement in OOD examples, exhibiting better performance than the existing definition generation method", "role": "Results"}, {"entity_id": "ACL_23_P_88-2-E3", "text": "the VWSD performance significantly increased with our Bayesian inference-based approach", "role": "PrimaryObject"}]}], "entity_coreference": [], "event_coreference": [], "tokens": ["Experimental", "results", "show", "that", "the", "VWSD", "performance", "significantly", "increased", "with", "our", "Bayesian", "inference-based", "approach.", "In", "addition,", "our", "context-aware", "definition", "generation", "achieved", "prominent", "performance", "improvement", "in", "OOD", "examples,", "exhibiting", "better", "performance", "than", "the", "existing", "definition", "generation", "method."], "pieces": ["Exper", "imental", "results", "show", "that", "the", "VW", "SD", "performance", "sign", "ificantly", "incre", "ased", "with", "our", "Bay", "esian", "in", "ference", "-", "based", "appro", "ach", ".", "In", "add", "ition", ",", "our", "context", "-", "aware", "definition", "generation", "ach", "ieved", "prom", "inent", "performance", "improve", "ment", "in", "OOD", "ex", "amples", ",", "ex", "hib", "iting", "better", "performance", "than", "the", "existing", "definition", "generation", "method", "."], "token_lens": [2, 1, 1, 1, 1, 2, 1, 2, 2, 1, 1, 2, 4, 3, 1, 3, 1, 3, 1, 1, 2, 2, 1, 2, 1, 1, 3, 3, 1, 1, 1, 1, 1, 1, 1, 2], "sentence": "Experimental results show that the VWSD performance significantly increased with our Bayesian inference-based approach. In addition, our context-aware definition generation achieved prominent performance improvement in OOD examples, exhibiting better performance than the existing definition generation method.", "sentence_starts": [0]}
{"doc_id": "ACL_23_P_893", "wnd_id": "ACL_23_P_893-0", "entity_mentions": [{"id": "ACL_23_P_893-0-E0", "text": "most interpretability methods", "start": 21, "end": 24, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_893-0-E1", "text": "Understanding Transformer-based models has attracted significant attention, as they lie at the heart of recent technological advances across machine learning", "start": 0, "end": 20, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_893-0-E2", "text": "recent work has shown that a zero-pass approach, where parameters are interpreted directly without a forward/backward pass is feasible for some Transformer parameters, and for two-layer attention networks", "start": 30, "end": 58, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_893-0-E3", "text": "running models over inputs", "start": 26, "end": 30, "entity_type": "UNK", "mention_type": "UNK"}], "relation_mentions": [], "event_mentions": [{"event_type": "Background/Introduction", "id": "ACL_23_P_893-0-EV0", "trigger": {"text": "rely on", "start": 24, "end": 26}, "arguments": [{"entity_id": "ACL_23_P_893-0-E0", "text": "most interpretability methods", "role": "Agent"}, {"entity_id": "ACL_23_P_893-0-E1", "text": "Understanding Transformer-based models has attracted significant attention, as they lie at the heart of recent technological advances across machine learning", "role": "Context"}, {"entity_id": "ACL_23_P_893-0-E2", "text": "recent work has shown that a zero-pass approach, where parameters are interpreted directly without a forward/backward pass is feasible for some Transformer parameters, and for two-layer attention networks", "role": "Context"}, {"entity_id": "ACL_23_P_893-0-E3", "text": "running models over inputs", "role": "PrimaryObject"}]}], "entity_coreference": [], "event_coreference": [], "tokens": ["Understanding", "Transformer-based", "models", "has", "attracted", "significant", "attention,", "as", "they", "lie", "at", "the", "heart", "of", "recent", "technological", "advances", "across", "machine", "learning.", "While", "most", "interpretability", "methods", "rely", "on", "running", "models", "over", "inputs,", "recent", "work", "has", "shown", "that", "a", "zero-pass", "approach,", "where", "parameters", "are", "interpreted", "directly", "without", "a", "forward/backward", "pass", "is", "feasible", "for", "some", "Transformer", "parameters,", "and", "for", "two-layer", "attention", "networks."], "pieces": ["Understanding", "Trans", "former", "-", "based", "models", "has", "att", "racted", "significant", "att", "ention", ",", "as", "they", "lie", "at", "the", "heart", "of", "recent", "techn", "ological", "adv", "ances", "ac", "ross", "machine", "learning", ".", "While", "most", "interpret", "ability", "method", "s", "rely", "on", "running", "models", "over", "input", "s", ",", "recent", "work", "has", "shown", "that", "a", "zero", "-", "pass", "appro", "ach", ",", "where", "param", "eters", "are", "interpret", "ed", "direct", "ly", "without", "a", "forward", "/", "back", "ward", "pass", "is", "fe", "as", "ible", "for", "some", "Trans", "former", "param", "eters", ",", "and", "for", "two", "-", "layer", "att", "ention", "net", "works", "."], "token_lens": [1, 4, 1, 1, 2, 1, 3, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 1, 2, 1, 1, 2, 2, 1, 1, 1, 1, 1, 3, 1, 1, 1, 1, 1, 1, 3, 3, 1, 2, 1, 2, 2, 1, 1, 4, 1, 1, 3, 1, 1, 2, 3, 1, 1, 3, 2, 3], "sentence": "Understanding Transformer-based models has attracted significant attention, as they lie at the heart of recent technological advances across machine learning. While most interpretability methods rely on running models over inputs, recent work has shown that a zero-pass approach, where parameters are interpreted directly without a forward/backward pass is feasible for some Transformer parameters, and for two-layer attention networks.", "sentence_starts": [0]}
{"doc_id": "ACL_23_P_893", "wnd_id": "ACL_23_P_893-1", "entity_mentions": [{"id": "ACL_23_P_893-1-E0", "text": "we", "start": 3, "end": 4, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_893-1-E1", "text": "We derive a simple theoretical framework to support our arguments and provide ample evidence for its validity", "start": 34, "end": 51, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_893-1-E2", "text": "a theoretical analysis", "start": 5, "end": 8, "entity_type": "UNK", "mention_type": "UNK"}], "relation_mentions": [], "event_mentions": [{"event_type": "Methods/Approach", "id": "ACL_23_P_893-1-EV0", "trigger": {"text": "present", "start": 4, "end": 5}, "arguments": [{"entity_id": "ACL_23_P_893-1-E0", "text": "we", "role": "Agent"}, {"entity_id": "ACL_23_P_893-1-E1", "text": "We derive a simple theoretical framework to support our arguments and provide ample evidence for its validity", "role": "Method"}, {"entity_id": "ACL_23_P_893-1-E2", "text": "a theoretical analysis", "role": "PrimaryObject"}]}], "entity_coreference": [], "event_coreference": [], "tokens": ["In", "this", "work,", "we", "present", "a", "theoretical", "analysis", "where", "all", "parameters", "of", "a", "trained", "Transformer", "are", "interpreted", "by", "projecting", "them", "into", "the", "embedding", "space,", "that", "is,", "the", "space", "of", "vocabulary", "items", "they", "operate", "on.", "We", "derive", "a", "simple", "theoretical", "framework", "to", "support", "our", "arguments", "and", "provide", "ample", "evidence", "for", "its", "validity."], "pieces": ["In", "this", "work", ",", "we", "present", "a", "the", "oret", "ical", "analysis", "where", "all", "param", "eters", "of", "a", "trained", "Trans", "former", "are", "interpret", "ed", "by", "project", "ing", "them", "into", "the", "embed", "ding", "space", ",", "that", "is", ",", "the", "space", "of", "voc", "abulary", "items", "they", "oper", "ate", "on", ".", "We", "der", "ive", "a", "simple", "the", "oret", "ical", "framework", "to", "support", "our", "arg", "uments", "and", "prov", "ide", "ample", "evidence", "for", "its", "valid", "ity", "."], "token_lens": [1, 1, 2, 1, 1, 1, 3, 1, 1, 1, 2, 1, 1, 1, 2, 1, 2, 1, 2, 1, 1, 1, 2, 2, 1, 2, 1, 1, 1, 2, 1, 1, 2, 2, 1, 2, 1, 1, 3, 1, 1, 1, 1, 2, 1, 2, 1, 1, 1, 1, 3], "sentence": "In this work, we present a theoretical analysis where all parameters of a trained Transformer are interpreted by projecting them into the embedding space, that is, the space of vocabulary items they operate on. We derive a simple theoretical framework to support our arguments and provide ample evidence for its validity.", "sentence_starts": [0]}
{"doc_id": "ACL_23_P_893", "wnd_id": "ACL_23_P_893-2", "entity_mentions": [{"id": "ACL_23_P_893-2-E0", "text": "an empirical analysis", "start": 1, "end": 4, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_893-2-E1", "text": "constructing a classifier without training by \u201ctranslating\u201d the parameters of a fine-tuned classifier to parameters of a different model that was only pretrained", "start": 40, "end": 63, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_893-2-E2", "text": "aligning the parameters of different models that share a vocabulary", "start": 28, "end": 38, "entity_type": "UNK", "mention_type": "UNK"}], "relation_mentions": [], "event_mentions": [{"event_type": "Results/Findings", "id": "ACL_23_P_893-2-EV0", "trigger": {"text": "can be interpreted", "start": 13, "end": 16}, "arguments": [{"entity_id": "ACL_23_P_893-2-E0", "text": "an empirical analysis", "role": "Agent"}, {"entity_id": "ACL_23_P_893-2-E1", "text": "constructing a classifier without training by \u201ctranslating\u201d the parameters of a fine-tuned classifier to parameters of a different model that was only pretrained", "role": "Results"}, {"entity_id": "ACL_23_P_893-2-E2", "text": "aligning the parameters of different models that share a vocabulary", "role": "Results"}]}], "entity_coreference": [], "event_coreference": [], "tokens": ["First,", "an", "empirical", "analysis", "showing", "that", "parameters", "of", "both", "pretrained", "and", "fine-tuned", "models", "can", "be", "interpreted", "in", "embedding", "space.", "Second,", "we", "present", "two", "applications", "of", "our", "framework:", "(a)", "aligning", "the", "parameters", "of", "different", "models", "that", "share", "a", "vocabulary,", "and", "(b)", "constructing", "a", "classifier", "without", "training", "by", "\u201ctranslating\u201d", "the", "parameters", "of", "a", "fine-tuned", "classifier", "to", "parameters", "of", "a", "different", "model", "that", "was", "only", "pretrained."], "pieces": ["First", ",", "an", "em", "pir", "ical", "analysis", "sh", "owing", "that", "param", "eters", "of", "both", "pret", "rained", "and", "fine", "-", "tun", "ed", "models", "can", "be", "interpret", "ed", "in", "embed", "ding", "space", ".", "Second", ",", "we", "present", "two", "app", "lic", "ations", "of", "our", "framework", ":", "(", "a", ")", "align", "ing", "the", "param", "eters", "of", "different", "models", "that", "share", "a", "voc", "abulary", ",", "and", "(", "b", ")", "construct", "ing", "a", "class", "ifier", "without", "training", "by", "\u00e2\u0122", "\u013e", "trans", "l", "ating", "\u00e2\u0122", "\u013f", "the", "param", "eters", "of", "a", "fine", "-", "tun", "ed", "class", "ifier", "to", "param", "eters", "of", "a", "different", "model", "that", "was", "only", "pret", "rained", "."], "token_lens": [2, 1, 3, 1, 2, 1, 2, 1, 1, 2, 1, 4, 1, 1, 1, 2, 1, 2, 2, 2, 1, 1, 1, 3, 1, 1, 2, 3, 2, 1, 2, 1, 1, 1, 1, 1, 1, 3, 1, 3, 2, 1, 2, 1, 1, 1, 7, 1, 2, 1, 1, 4, 2, 1, 2, 1, 1, 1, 1, 1, 1, 1, 3], "sentence": "First, an empirical analysis showing that parameters of both pretrained and fine-tuned models can be interpreted in embedding space. Second, we present two applications of our framework: (a) aligning the parameters of different models that share a vocabulary, and (b) constructing a classifier without training by \u201ctranslating\u201d the parameters of a fine-tuned classifier to parameters of a different model that was only pretrained.", "sentence_starts": [0]}
{"doc_id": "ACL_23_P_893", "wnd_id": "ACL_23_P_893-3", "entity_mentions": [{"id": "ACL_23_P_893-3-E0", "text": "our findings", "start": 1, "end": 3, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_893-3-E1", "text": "interpretation methods", "start": 7, "end": 9, "entity_type": "UNK", "mention_type": "UNK"}], "relation_mentions": [], "event_mentions": [{"event_type": "Conclusions/Implications", "id": "ACL_23_P_893-3-EV0", "trigger": {"text": "open the door to", "start": 3, "end": 7}, "arguments": [{"entity_id": "ACL_23_P_893-3-E0", "text": "our findings", "role": "Agent"}, {"entity_id": "ACL_23_P_893-3-E1", "text": "interpretation methods", "role": "PrimaryObject"}]}], "entity_coreference": [], "event_coreference": [], "tokens": ["Overall,", "our", "findings", "open", "the", "door", "to", "interpretation", "methods", "that,", "at", "least", "in", "part,", "abstract", "away", "from", "model", "specifics", "and", "operate", "in", "the", "embedding", "space", "only."], "pieces": ["Overall", ",", "our", "find", "ings", "open", "the", "door", "to", "interpret", "ation", "method", "s", "that", ",", "at", "le", "ast", "in", "part", ",", "ab", "stract", "away", "from", "model", "specific", "s", "and", "oper", "ate", "in", "the", "embed", "ding", "space", "only", "."], "token_lens": [2, 1, 2, 1, 1, 1, 1, 2, 2, 2, 1, 2, 1, 2, 2, 1, 1, 1, 2, 1, 2, 1, 1, 2, 1, 2], "sentence": "Overall, our findings open the door to interpretation methods that, at least in part, abstract away from model specifics and operate in the embedding space only.", "sentence_starts": [0]}
{"doc_id": "ACL_23_P_431", "wnd_id": "ACL_23_P_431-0", "entity_mentions": [{"id": "ACL_23_P_431-0-E0", "text": "existing methods", "start": 18, "end": 20, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_431-0-E1", "text": "Coherence is an important aspect of text quality, and various approaches have been applied to coherence modeling", "start": 0, "end": 17, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_431-0-E2", "text": "a single document\u2019s coherence patterns", "start": 23, "end": 28, "entity_type": "UNK", "mention_type": "UNK"}], "relation_mentions": [], "event_mentions": [{"event_type": "Background/Introduction", "id": "ACL_23_P_431-0-EV0", "trigger": {"text": "focus on", "start": 21, "end": 23}, "arguments": [{"entity_id": "ACL_23_P_431-0-E0", "text": "existing methods", "role": "Agent"}, {"entity_id": "ACL_23_P_431-0-E1", "text": "Coherence is an important aspect of text quality, and various approaches have been applied to coherence modeling", "role": "Context"}, {"entity_id": "ACL_23_P_431-0-E2", "text": "a single document\u2019s coherence patterns", "role": "PrimaryObject"}]}], "entity_coreference": [], "event_coreference": [], "tokens": ["Coherence", "is", "an", "important", "aspect", "of", "text", "quality,", "and", "various", "approaches", "have", "been", "applied", "to", "coherence", "modeling.", "However,", "existing", "methods", "solely", "focus", "on", "a", "single", "document\u2019s", "coherence", "patterns,", "ignoring", "the", "underlying", "correlation", "between", "documents."], "pieces": ["Co", "herence", "is", "an", "important", "as", "pect", "of", "text", "quality", ",", "and", "var", "ious", "appro", "aches", "have", "been", "app", "lied", "to", "co", "herence", "mod", "eling", ".", "However", ",", "existing", "method", "s", "sole", "ly", "focus", "on", "a", "single", "document", "\u00e2\u0122", "\u013b", "s", "co", "herence", "pattern", "s", ",", "ign", "oring", "the", "under", "lying", "cor", "relation", "between", "doc", "uments", "."], "token_lens": [2, 1, 1, 1, 2, 1, 1, 2, 1, 2, 2, 1, 1, 2, 1, 2, 3, 2, 1, 2, 2, 1, 1, 1, 1, 4, 2, 3, 2, 1, 2, 2, 1, 3], "sentence": "Coherence is an important aspect of text quality, and various approaches have been applied to coherence modeling. However, existing methods solely focus on a single document\u2019s coherence patterns, ignoring the underlying correlation between documents.", "sentence_starts": [0]}
{"doc_id": "ACL_23_P_431", "wnd_id": "ACL_23_P_431-1", "entity_mentions": [{"id": "ACL_23_P_431-1-E0", "text": "Our model first creates a graph structure for each document, from where we mine different subgraph patterns", "start": 15, "end": 32, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_431-1-E1", "text": "We then construct a heterogeneous graph for the training corpus, connecting documents based on their shared subgraphs", "start": 32, "end": 49, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_431-1-E2", "text": "a GCN is applied to the heterogeneous graph to model the connectivity relationships", "start": 50, "end": 63, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_431-1-E3", "text": "a GCN-based coherence model", "start": 2, "end": 6, "entity_type": "UNK", "mention_type": "UNK"}], "relation_mentions": [], "event_mentions": [{"event_type": "Methods/Approach", "id": "ACL_23_P_431-1-EV0", "trigger": {"text": "investigate", "start": 1, "end": 2}, "arguments": [{"entity_id": "ACL_23_P_431-1-E0", "text": "Our model first creates a graph structure for each document, from where we mine different subgraph patterns", "role": "Method"}, {"entity_id": "ACL_23_P_431-1-E1", "text": "We then construct a heterogeneous graph for the training corpus, connecting documents based on their shared subgraphs", "role": "Method"}, {"entity_id": "ACL_23_P_431-1-E2", "text": "a GCN is applied to the heterogeneous graph to model the connectivity relationships", "role": "Method"}, {"entity_id": "ACL_23_P_431-1-E3", "text": "a GCN-based coherence model", "role": "PrimaryObject"}]}], "entity_coreference": [], "event_coreference": [], "tokens": ["We", "investigate", "a", "GCN-based", "coherence", "model", "that", "is", "capable", "of", "capturing", "structural", "similarities", "between", "documents.", "Our", "model", "first", "creates", "a", "graph", "structure", "for", "each", "document,", "from", "where", "we", "mine", "different", "subgraph", "patterns.", "We", "then", "construct", "a", "heterogeneous", "graph", "for", "the", "training", "corpus,", "connecting", "documents", "based", "on", "their", "shared", "subgraphs.", "Finally,", "a", "GCN", "is", "applied", "to", "the", "heterogeneous", "graph", "to", "model", "the", "connectivity", "relationships."], "pieces": ["We", "invest", "igate", "a", "GC", "N", "-", "based", "co", "herence", "model", "that", "is", "cap", "able", "of", "capt", "uring", "struct", "ural", "similar", "ities", "between", "doc", "uments", ".", "Our", "model", "first", "creat", "es", "a", "graph", "st", "ructure", "for", "each", "document", ",", "from", "where", "we", "mine", "different", "sub", "graph", "pattern", "s", ".", "We", "then", "construct", "a", "heter", "ogeneous", "graph", "for", "the", "training", "cor", "p", "us", ",", "connect", "ing", "doc", "uments", "based", "on", "their", "shared", "sub", "graph", "s", ".", "Finally", ",", "a", "GC", "N", "is", "app", "lied", "to", "the", "heter", "ogeneous", "graph", "to", "model", "the", "connect", "ivity", "relations", "hips", "."], "token_lens": [1, 2, 1, 4, 2, 1, 1, 1, 2, 1, 2, 2, 2, 1, 3, 1, 1, 1, 2, 1, 1, 2, 1, 1, 2, 1, 1, 1, 1, 1, 2, 3, 1, 1, 1, 1, 2, 1, 1, 1, 1, 4, 2, 2, 1, 1, 1, 1, 4, 2, 1, 2, 1, 2, 1, 1, 2, 1, 1, 1, 1, 2, 3], "sentence": "We investigate a GCN-based coherence model that is capable of capturing structural similarities between documents. Our model first creates a graph structure for each document, from where we mine different subgraph patterns. We then construct a heterogeneous graph for the training corpus, connecting documents based on their shared subgraphs. Finally, a GCN is applied to the heterogeneous graph to model the connectivity relationships.", "sentence_starts": [0]}
{"doc_id": "ACL_23_P_431", "wnd_id": "ACL_23_P_431-2", "entity_mentions": [{"id": "ACL_23_P_431-2-E0", "text": "We", "start": 0, "end": 1, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_431-2-E1", "text": "Results show that our GCN-based model outperforms all baselines, achieving a new state-of-the-art on both tasks", "start": 14, "end": 30, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_431-2-E2", "text": "our method", "start": 2, "end": 4, "entity_type": "UNK", "mention_type": "UNK"}], "relation_mentions": [], "event_mentions": [{"event_type": "Results/Findings", "id": "ACL_23_P_431-2-EV0", "trigger": {"text": "evaluate", "start": 1, "end": 2}, "arguments": [{"entity_id": "ACL_23_P_431-2-E0", "text": "We", "role": "Agent"}, {"entity_id": "ACL_23_P_431-2-E1", "text": "Results show that our GCN-based model outperforms all baselines, achieving a new state-of-the-art on both tasks", "role": "Results"}, {"entity_id": "ACL_23_P_431-2-E2", "text": "our method", "role": "PrimaryObject"}]}], "entity_coreference": [], "event_coreference": [], "tokens": ["We", "evaluate", "our", "method", "on", "two", "tasks,", "assessing", "discourse", "coherence", "and", "automated", "essay", "scoring.", "Results", "show", "that", "our", "GCN-based", "model", "outperforms", "all", "baselines,", "achieving", "a", "new", "state-of-the-art", "on", "both", "tasks."], "pieces": ["We", "evaluate", "our", "method", "on", "two", "t", "asks", ",", "ass", "essing", "disc", "ourse", "co", "herence", "and", "aut", "om", "ated", "ess", "ay", "scoring", ".", "Results", "show", "that", "our", "GC", "N", "-", "based", "model", "out", "per", "forms", "all", "bas", "elines", ",", "ach", "ieving", "a", "new", "state", "-", "of", "-", "the", "-", "art", "on", "both", "t", "asks", "."], "token_lens": [1, 1, 1, 1, 1, 1, 3, 2, 2, 2, 1, 3, 2, 2, 1, 1, 1, 1, 4, 1, 3, 1, 3, 2, 1, 1, 7, 1, 1, 3], "sentence": "We evaluate our method on two tasks, assessing discourse coherence and automated essay scoring. Results show that our GCN-based model outperforms all baselines, achieving a new state-of-the-art on both tasks.", "sentence_starts": [0]}
{"doc_id": "ACL_23_P_304", "wnd_id": "ACL_23_P_304-0", "entity_mentions": [{"id": "ACL_23_P_304-0-E0", "text": "Large language models (LMs) beyond a certain scale", "start": 0, "end": 8, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_304-0-E1", "text": "While CoT can yield dramatically improved performance, such gains are only observed for sufficiently large LMs", "start": 23, "end": 39, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_304-0-E2", "text": "there is little guarantee that the generated rationales are consistent with LM\u2019s predictions or faithfully justify the decisions", "start": 42, "end": 60, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_304-0-E3", "text": "the emergent capability", "start": 9, "end": 12, "entity_type": "UNK", "mention_type": "UNK"}], "relation_mentions": [], "event_mentions": [{"event_type": "Background/Introduction", "id": "ACL_23_P_304-0-EV0", "trigger": {"text": "demonstrate", "start": 8, "end": 9}, "arguments": [{"entity_id": "ACL_23_P_304-0-E0", "text": "Large language models (LMs) beyond a certain scale", "role": "Agent"}, {"entity_id": "ACL_23_P_304-0-E1", "text": "While CoT can yield dramatically improved performance, such gains are only observed for sufficiently large LMs", "role": "Challenge"}, {"entity_id": "ACL_23_P_304-0-E2", "text": "there is little guarantee that the generated rationales are consistent with LM\u2019s predictions or faithfully justify the decisions", "role": "Challenge"}, {"entity_id": "ACL_23_P_304-0-E3", "text": "the emergent capability", "role": "PrimaryObject"}]}], "entity_coreference": [], "event_coreference": [], "tokens": ["Large", "language", "models", "(LMs)", "beyond", "a", "certain", "scale,", "demonstrate", "the", "emergent", "capability", "of", "generating", "free-text", "rationales", "for", "their", "predictions", "via", "chain-of-thought", "(CoT)", "prompting.", "While", "CoT", "can", "yield", "dramatically", "improved", "performance,", "such", "gains", "are", "only", "observed", "for", "sufficiently", "large", "LMs.", "Even", "more", "concerning,", "there", "is", "little", "guarantee", "that", "the", "generated", "rationales", "are", "consistent", "with", "LM\u2019s", "predictions", "or", "faithfully", "justify", "the", "decisions."], "pieces": ["Large", "language", "models", "(", "L", "Ms", ")", "be", "yond", "a", "certain", "scale", ",", "demon", "strate", "the", "em", "erg", "ent", "cap", "ability", "of", "gener", "ating", "free", "-", "text", "rational", "es", "for", "their", "pred", "ictions", "via", "chain", "-", "of", "-", "thought", "(", "Co", "T", ")", "prom", "pt", "ing", ".", "While", "Co", "T", "can", "y", "ield", "d", "ram", "atically", "impro", "ved", "performance", ",", "such", "g", "ains", "are", "only", "ob", "served", "for", "sufficient", "ly", "large", "L", "Ms", ".", "Even", "more", "con", "cerning", ",", "there", "is", "little", "gu", "arant", "ee", "that", "the", "generated", "rational", "es", "are", "cons", "istent", "with", "LM", "\u00e2\u0122", "\u013b", "s", "pred", "ictions", "or", "faith", "fully", "just", "ify", "the", "dec", "isions", "."], "token_lens": [1, 1, 1, 4, 2, 1, 1, 2, 2, 1, 3, 2, 1, 2, 3, 2, 1, 1, 2, 1, 5, 4, 4, 1, 2, 1, 2, 3, 2, 2, 1, 2, 1, 1, 2, 1, 2, 1, 3, 1, 1, 3, 1, 1, 1, 3, 1, 1, 1, 2, 1, 2, 1, 4, 2, 1, 2, 2, 1, 3], "sentence": "Large language models (LMs) beyond a certain scale, demonstrate the emergent capability of generating free-text rationales for their predictions via chain-of-thought (CoT) prompting. While CoT can yield dramatically improved performance, such gains are only observed for sufficiently large LMs. Even more concerning, there is little guarantee that the generated rationales are consistent with LM\u2019s predictions or faithfully justify the decisions.", "sentence_starts": [0]}
{"doc_id": "ACL_23_P_304", "wnd_id": "ACL_23_P_304-1", "entity_mentions": [{"id": "ACL_23_P_304-1-E0", "text": "we", "start": 3, "end": 4, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_304-1-E1", "text": "we elicit rationales supporting the gold answers from a large LM (teacher) by contrastive decoding", "start": 32, "end": 47, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_304-1-E2", "text": "we use the teacher-generated rationales to learn a student LM with a counterfactual reasoning objective", "start": 68, "end": 83, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_304-1-E3", "text": "which encourages the teacher to generate tokens that become more plausible only when the answer is considered", "start": 47, "end": 64, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_304-1-E4", "text": "which prevents the student from ignoring the rationales to make inconsistent predictions", "start": 83, "end": 95, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_304-1-E5", "text": "SCOTT", "start": 5, "end": 6, "entity_type": "UNK", "mention_type": "UNK"}], "relation_mentions": [], "event_mentions": [{"event_type": "Methods/Approach", "id": "ACL_23_P_304-1-EV0", "trigger": {"text": "propose", "start": 4, "end": 5}, "arguments": [{"entity_id": "ACL_23_P_304-1-E0", "text": "we", "role": "Agent"}, {"entity_id": "ACL_23_P_304-1-E1", "text": "we elicit rationales supporting the gold answers from a large LM (teacher) by contrastive decoding", "role": "Method"}, {"entity_id": "ACL_23_P_304-1-E2", "text": "we use the teacher-generated rationales to learn a student LM with a counterfactual reasoning objective", "role": "Method"}, {"entity_id": "ACL_23_P_304-1-E3", "text": "which encourages the teacher to generate tokens that become more plausible only when the answer is considered", "role": "Analysis"}, {"entity_id": "ACL_23_P_304-1-E4", "text": "which prevents the student from ignoring the rationales to make inconsistent predictions", "role": "Analysis"}, {"entity_id": "ACL_23_P_304-1-E5", "text": "SCOTT", "role": "PrimaryObject"}]}], "entity_coreference": [], "event_coreference": [], "tokens": ["In", "this", "work,", "we", "propose", "SCOTT,", "a", "faithful", "knowledge", "distillation", "method", "to", "learn", "a", "small,", "self-consistent", "CoT", "model", "from", "a", "teacher", "model", "that", "is", "orders", "of", "magnitude", "larger.", "To", "form", "better", "supervision,", "we", "elicit", "rationales", "supporting", "the", "gold", "answers", "from", "a", "large", "LM", "(teacher)", "by", "contrastive", "decoding,", "which", "encourages", "the", "teacher", "to", "generate", "tokens", "that", "become", "more", "plausible", "only", "when", "the", "answer", "is", "considered.", "To", "ensure", "faithful", "distillation,", "we", "use", "the", "teacher-generated", "rationales", "to", "learn", "a", "student", "LM", "with", "a", "counterfactual", "reasoning", "objective,", "which", "prevents", "the", "student", "from", "ignoring", "the", "rationales", "to", "make", "inconsistent", "predictions."], "pieces": ["In", "this", "work", ",", "we", "pro", "pose", "SC", "OTT", ",", "a", "faith", "ful", "knowledge", "dist", "illation", "method", "to", "learn", "a", "small", ",", "self", "-", "cons", "istent", "Co", "T", "model", "from", "a", "te", "acher", "model", "that", "is", "orders", "of", "m", "agn", "itude", "larg", "er", ".", "To", "form", "better", "super", "vision", ",", "we", "el", "icit", "rational", "es", "support", "ing", "the", "gold", "ans", "w", "ers", "from", "a", "large", "LM", "(", "te", "acher", ")", "by", "cont", "rast", "ive", "dec", "oding", ",", "which", "enc", "our", "ages", "the", "te", "acher", "to", "gener", "ate", "t", "ok", "ens", "that", "bec", "ome", "more", "pl", "ausible", "only", "when", "the", "answer", "is", "cons", "idered", ".", "To", "ens", "ure", "faith", "ful", "dist", "illation", ",", "we", "use", "the", "te", "acher", "-", "generated", "rational", "es", "to", "learn", "a", "student", "LM", "with", "a", "counter", "fact", "ual", "reason", "ing", "object", "ive", ",", "which", "prev", "ents", "the", "student", "from", "ign", "oring", "the", "rational", "es", "to", "make", "inc", "ons", "istent", "pred", "ictions", "."], "token_lens": [1, 1, 2, 1, 2, 3, 1, 2, 1, 2, 1, 1, 1, 1, 2, 4, 2, 1, 1, 1, 2, 1, 1, 1, 1, 1, 3, 3, 1, 1, 1, 3, 1, 2, 2, 2, 1, 1, 3, 1, 1, 1, 1, 4, 1, 3, 3, 1, 3, 1, 2, 1, 2, 3, 1, 2, 1, 2, 1, 1, 1, 1, 1, 3, 1, 2, 2, 3, 1, 1, 1, 4, 2, 1, 1, 1, 1, 1, 1, 1, 3, 2, 3, 1, 2, 1, 1, 1, 2, 1, 2, 1, 1, 3, 3], "sentence": "In this work, we propose SCOTT, a faithful knowledge distillation method to learn a small, self-consistent CoT model from a teacher model that is orders of magnitude larger. To form better supervision, we elicit rationales supporting the gold answers from a large LM (teacher) by contrastive decoding, which encourages the teacher to generate tokens that become more plausible only when the answer is considered. To ensure faithful distillation, we use the teacher-generated rationales to learn a student LM with a counterfactual reasoning objective, which prevents the student from ignoring the rationales to make inconsistent predictions.", "sentence_starts": [0]}
{"doc_id": "ACL_23_P_304", "wnd_id": "ACL_23_P_304-2", "entity_mentions": [{"id": "ACL_23_P_304-2-E0", "text": "Experiments", "start": 0, "end": 1, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_304-2-E1", "text": "we can improve its performance more by refining its rationales", "start": 32, "end": 42, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_304-2-E2", "text": "Further analysis shows that such a model respects the rationales more when making decisions", "start": 17, "end": 31, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_304-2-E3", "text": "while yielding comparable performance, our method leads to a more faithful model than baselines", "start": 3, "end": 17, "entity_type": "UNK", "mention_type": "UNK"}], "relation_mentions": [], "event_mentions": [{"event_type": "Results/Findings", "id": "ACL_23_P_304-2-EV0", "trigger": {"text": "show", "start": 1, "end": 2}, "arguments": [{"entity_id": "ACL_23_P_304-2-E0", "text": "Experiments", "role": "Agent"}, {"entity_id": "ACL_23_P_304-2-E1", "text": "we can improve its performance more by refining its rationales", "role": "Method"}, {"entity_id": "ACL_23_P_304-2-E2", "text": "Further analysis shows that such a model respects the rationales more when making decisions", "role": "Results"}, {"entity_id": "ACL_23_P_304-2-E3", "text": "while yielding comparable performance, our method leads to a more faithful model than baselines", "role": "PrimaryObject"}]}], "entity_coreference": [], "event_coreference": [], "tokens": ["Experiments", "show", "that", "while", "yielding", "comparable", "performance,", "our", "method", "leads", "to", "a", "more", "faithful", "model", "than", "baselines.", "Further", "analysis", "shows", "that", "such", "a", "model", "respects", "the", "rationales", "more", "when", "making", "decisions;", "thus,", "we", "can", "improve", "its", "performance", "more", "by", "refining", "its", "rationales."], "pieces": ["Exper", "iments", "show", "that", "while", "y", "ielding", "com", "parable", "performance", ",", "our", "method", "le", "ads", "to", "a", "more", "faith", "ful", "model", "than", "bas", "elines", ".", "Further", "analysis", "shows", "that", "such", "a", "model", "respect", "s", "the", "rational", "es", "more", "when", "making", "dec", "isions", ";", "thus", ",", "we", "can", "improve", "its", "performance", "more", "by", "ref", "ining", "its", "rational", "es", "."], "token_lens": [2, 1, 1, 1, 2, 2, 2, 1, 1, 2, 1, 1, 1, 2, 1, 1, 3, 1, 1, 1, 1, 1, 1, 1, 2, 1, 2, 1, 1, 1, 3, 2, 1, 1, 1, 1, 1, 1, 1, 2, 1, 3], "sentence": "Experiments show that while yielding comparable performance, our method leads to a more faithful model than baselines. Further analysis shows that such a model respects the rationales more when making decisions; thus, we can improve its performance more by refining its rationales.", "sentence_starts": [0]}
{"doc_id": "ACL_23_P_626", "wnd_id": "ACL_23_P_626-0", "entity_mentions": [{"id": "ACL_23_P_626-0-E0", "text": "GPT-3, a large-scale language model developed by OpenAI", "start": 40, "end": 48, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_626-0-E1", "text": "Data annotation is the process of labeling data that could be used to train machine learning models. Having high quality annotation is crucial, as it allows the model to learn the relationship between the input data and the desired output", "start": 0, "end": 40, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_626-0-E2", "text": "It is therefore natural to wonder whether it can be used to effectively annotate data for NLP tasks.", "start": 62, "end": 80, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_626-0-E3", "text": "impressive zero- and few-shot performance", "start": 50, "end": 55, "entity_type": "UNK", "mention_type": "UNK"}], "relation_mentions": [], "event_mentions": [{"event_type": "Background/Introduction", "id": "ACL_23_P_626-0-EV0", "trigger": {"text": "has demonstrated", "start": 48, "end": 50}, "arguments": [{"entity_id": "ACL_23_P_626-0-E0", "text": "GPT-3, a large-scale language model developed by OpenAI", "role": "Agent"}, {"entity_id": "ACL_23_P_626-0-E1", "text": "Data annotation is the process of labeling data that could be used to train machine learning models. Having high quality annotation is crucial, as it allows the model to learn the relationship between the input data and the desired output", "role": "Context"}, {"entity_id": "ACL_23_P_626-0-E2", "text": "It is therefore natural to wonder whether it can be used to effectively annotate data for NLP tasks.", "role": "Implications"}, {"entity_id": "ACL_23_P_626-0-E3", "text": "impressive zero- and few-shot performance", "role": "PrimaryObject"}]}], "entity_coreference": [], "event_coreference": [], "tokens": ["Data", "annotation", "is", "the", "process", "of", "labeling", "data", "that", "could", "be", "used", "to", "train", "machine", "learning", "models.", "Having", "high", "quality", "annotation", "is", "crucial,", "as", "it", "allows", "the", "model", "to", "learn", "the", "relationship", "between", "the", "input", "data", "and", "the", "desired", "output.", "GPT-3,", "a", "large-scale", "language", "model", "developed", "by", "OpenAI,", "has", "demonstrated", "impressive", "zero-", "and", "few-shot", "performance", "on", "a", "wide", "range", "of", "NLP", "tasks.", "It", "is", "therefore", "natural", "to", "wonder", "whether", "it", "can", "be", "used", "to", "effectively", "annotate", "data", "for", "NLP", "tasks."], "pieces": ["Data", "ann", "otation", "is", "the", "process", "of", "label", "ing", "data", "that", "could", "be", "used", "to", "train", "machine", "learning", "models", ".", "Having", "high", "quality", "ann", "otation", "is", "cru", "cial", ",", "as", "it", "allows", "the", "model", "to", "learn", "the", "relations", "hip", "between", "the", "input", "data", "and", "the", "des", "ired", "output", ".", "G", "PT", "-", "3", ",", "a", "large", "-", "scale", "language", "model", "developed", "by", "Open", "AI", ",", "has", "demon", "str", "ated", "imp", "ressive", "zero", "-", "and", "few", "-", "shot", "performance", "on", "a", "wide", "range", "of", "N", "LP", "t", "asks", ".", "It", "is", "there", "fore", "natural", "to", "w", "onder", "whether", "it", "can", "be", "used", "to", "effect", "ively", "annot", "ate", "data", "for", "N", "LP", "t", "asks", "."], "token_lens": [1, 2, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 2, 1, 3, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 2, 2, 5, 1, 3, 1, 1, 1, 1, 3, 1, 3, 2, 2, 1, 3, 1, 1, 1, 1, 1, 1, 2, 3, 1, 1, 2, 1, 1, 2, 1, 1, 1, 1, 1, 1, 2, 2, 1, 1, 2, 3], "sentence": "Data annotation is the process of labeling data that could be used to train machine learning models. Having high quality annotation is crucial, as it allows the model to learn the relationship between the input data and the desired output. GPT-3, a large-scale language model developed by OpenAI, has demonstrated impressive zero- and few-shot performance on a wide range of NLP tasks. It is therefore natural to wonder whether it can be used to effectively annotate data for NLP tasks.", "sentence_starts": [0]}
{"doc_id": "ACL_23_P_626", "wnd_id": "ACL_23_P_626-1", "entity_mentions": [{"id": "ACL_23_P_626-1-E0", "text": "we", "start": 3, "end": 4, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_626-1-E1", "text": "Through this analysis, we aim to provide insight into the potential of GPT-3 as a general-purpose data annotator in NLP", "start": 30, "end": 50, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_626-1-E2", "text": "the performance of GPT-3 as a data annotator", "start": 5, "end": 13, "entity_type": "UNK", "mention_type": "UNK"}], "relation_mentions": [], "event_mentions": [{"event_type": "Methods/Approach", "id": "ACL_23_P_626-1-EV0", "trigger": {"text": "evaluate", "start": 4, "end": 5}, "arguments": [{"entity_id": "ACL_23_P_626-1-E0", "text": "we", "role": "Agent"}, {"entity_id": "ACL_23_P_626-1-E1", "text": "Through this analysis, we aim to provide insight into the potential of GPT-3 as a general-purpose data annotator in NLP", "role": "Purpose"}, {"entity_id": "ACL_23_P_626-1-E2", "text": "the performance of GPT-3 as a data annotator", "role": "PrimaryObject"}]}], "entity_coreference": [], "event_coreference": [], "tokens": ["In", "this", "paper,", "we", "evaluate", "the", "performance", "of", "GPT-3", "as", "a", "data", "annotator", "by", "comparing", "it", "with", "traditional", "data", "annotation", "methods", "and", "analyzing", "its", "output", "on", "a", "range", "of", "tasks.", "Through", "this", "analysis,", "we", "aim", "to", "provide", "insight", "into", "the", "potential", "of", "GPT-3", "as", "a", "general-purpose", "data", "annotator", "in", "NLP."], "pieces": ["In", "this", "paper", ",", "we", "evaluate", "the", "performance", "of", "G", "PT", "-", "3", "as", "a", "data", "annot", "ator", "by", "comp", "aring", "it", "with", "traditional", "data", "ann", "otation", "method", "s", "and", "analy", "zing", "its", "output", "on", "a", "range", "of", "t", "asks", ".", "Through", "this", "analysis", ",", "we", "aim", "to", "prov", "ide", "ins", "ight", "into", "the", "pot", "ential", "of", "G", "PT", "-", "3", "as", "a", "general", "-", "purpose", "data", "annot", "ator", "in", "N", "LP", "."], "token_lens": [1, 1, 2, 1, 1, 1, 1, 1, 4, 1, 1, 1, 2, 1, 2, 1, 1, 1, 1, 2, 2, 1, 2, 1, 1, 1, 1, 1, 1, 3, 1, 1, 2, 1, 1, 1, 2, 2, 1, 1, 2, 1, 4, 1, 1, 3, 1, 2, 1, 3], "sentence": " In this paper, we evaluate the performance of GPT-3 as a data annotator by comparing it with traditional data annotation methods and analyzing its output on a range of tasks. Through this analysis, we aim to provide insight into the potential of GPT-3 as a general-purpose data annotator in NLP.", "sentence_starts": [0]}
{"doc_id": "ACL_23_P_505", "wnd_id": "ACL_23_P_505-0", "entity_mentions": [{"id": "ACL_23_P_505-0-E0", "text": "Design biases in NLP systems", "start": 0, "end": 5, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_505-0-E1", "text": "such as performance differences for different populations", "start": 5, "end": 12, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_505-0-E2", "text": "they are hard to quantify because researcher, system, and dataset positionality is often unobserved.", "start": 36, "end": 50, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_505-0-E3", "text": "their creator\u2019s positionality", "start": 15, "end": 18, "entity_type": "UNK", "mention_type": "UNK"}], "relation_mentions": [], "event_mentions": [{"event_type": "Background/Introduction", "id": "ACL_23_P_505-0-EV0", "trigger": {"text": "stem from", "start": 13, "end": 15}, "arguments": [{"entity_id": "ACL_23_P_505-0-E0", "text": "Design biases in NLP systems", "role": "Agent"}, {"entity_id": "ACL_23_P_505-0-E1", "text": "such as performance differences for different populations", "role": "Context"}, {"entity_id": "ACL_23_P_505-0-E2", "text": "they are hard to quantify because researcher, system, and dataset positionality is often unobserved.", "role": "Challenge"}, {"entity_id": "ACL_23_P_505-0-E3", "text": "their creator\u2019s positionality", "role": "PrimaryObject"}]}], "entity_coreference": [], "event_coreference": [], "tokens": ["Design", "biases", "in", "NLP", "systems,", "such", "as", "performance", "differences", "for", "different", "populations,", "often", "stem", "from", "their", "creator\u2019s", "positionality,", "i.e.,", "views", "and", "lived", "experiences", "shaped", "by", "identity", "and", "background.", "Despite", "the", "prevalence", "and", "risks", "of", "design", "biases,", "they", "are", "hard", "to", "quantify", "because", "researcher,", "system,", "and", "dataset", "positionality", "is", "often", "unobserved."], "pieces": ["Design", "bi", "ases", "in", "N", "LP", "system", "s", ",", "such", "as", "performance", "diff", "erences", "for", "different", "pop", "ulations", ",", "often", "stem", "from", "their", "creator", "\u00e2\u0122", "\u013b", "s", "position", "ality", ",", "i", ".", "e", ".,", "views", "and", "lived", "exper", "iences", "shaped", "by", "ident", "ity", "and", "background", ".", "Despite", "the", "pre", "val", "ence", "and", "ris", "ks", "of", "design", "bi", "ases", ",", "they", "are", "hard", "to", "quant", "ify", "because", "re", "se", "ar", "cher", ",", "system", ",", "and", "dat", "as", "et", "position", "ality", "is", "often", "un", "ob", "served", "."], "token_lens": [1, 2, 1, 2, 3, 1, 1, 1, 2, 1, 1, 3, 1, 1, 1, 1, 4, 3, 4, 1, 1, 1, 2, 1, 1, 2, 1, 2, 1, 1, 3, 1, 2, 1, 1, 3, 1, 1, 1, 1, 2, 1, 5, 2, 1, 3, 2, 1, 1, 4], "sentence": "Design biases in NLP systems, such as performance differences for different populations, often stem from their creator\u2019s positionality, i.e., views and lived experiences shaped by identity and background. Despite the prevalence and risks of design biases, they are hard to quantify because researcher, system, and dataset positionality is often unobserved.", "sentence_starts": [0]}
{"doc_id": "ACL_23_P_505", "wnd_id": "ACL_23_P_505-1", "entity_mentions": [{"id": "ACL_23_P_505-1-E0", "text": "We", "start": 0, "end": 1, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_505-1-E1", "text": "We apply NLPositionality to existing datasets and models for two tasks\u2014social acceptability and hate speech detection.", "start": 42, "end": 58, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_505-1-E2", "text": "Our framework continuously collects annotations from a diverse pool of volunteer participants on LabintheWild, and statistically quantifies alignment with dataset labels and model predictions", "start": 18, "end": 42, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_505-1-E3", "text": "NLPositionality", "start": 2, "end": 3, "entity_type": "UNK", "mention_type": "UNK"}], "relation_mentions": [], "event_mentions": [{"event_type": "Methods/Approach", "id": "ACL_23_P_505-1-EV0", "trigger": {"text": "introduce", "start": 1, "end": 2}, "arguments": [{"entity_id": "ACL_23_P_505-1-E0", "text": "We", "role": "Agent"}, {"entity_id": "ACL_23_P_505-1-E1", "text": "We apply NLPositionality to existing datasets and models for two tasks\u2014social acceptability and hate speech detection.", "role": "Method"}, {"entity_id": "ACL_23_P_505-1-E2", "text": "Our framework continuously collects annotations from a diverse pool of volunteer participants on LabintheWild, and statistically quantifies alignment with dataset labels and model predictions", "role": "Method"}, {"entity_id": "ACL_23_P_505-1-E3", "text": "NLPositionality", "role": "PrimaryObject"}]}], "entity_coreference": [], "event_coreference": [], "tokens": ["We", "introduce", "NLPositionality,", "a", "framework", "for", "characterizing", "design", "biases", "and", "quantifying", "the", "positionality", "of", "NLP", "datasets", "and", "models.", "Our", "framework", "continuously", "collects", "annotations", "from", "a", "diverse", "pool", "of", "volunteer", "participants", "on", "LabintheWild,", "and", "statistically", "quantifies", "alignment", "with", "dataset", "labels", "and", "model", "predictions.", "We", "apply", "NLPositionality", "to", "existing", "datasets", "and", "models", "for", "two", "tasks\u2014social", "acceptability", "and", "hate", "speech", "detection."], "pieces": ["We", "introdu", "ce", "N", "LP", "osition", "ality", ",", "a", "framework", "for", "character", "izing", "design", "bi", "ases", "and", "quant", "ifying", "the", "position", "ality", "of", "N", "LP", "dat", "as", "ets", "and", "models", ".", "Our", "framework", "contin", "uously", "collect", "s", "annot", "ations", "from", "a", "d", "iverse", "pool", "of", "vol", "unte", "er", "particip", "ants", "on", "Lab", "int", "he", "Wild", ",", "and", "stat", "istically", "quant", "ifies", "al", "ignment", "with", "dat", "as", "et", "lab", "els", "and", "model", "pred", "ictions", ".", "We", "apply", "N", "LP", "osition", "ality", "to", "existing", "dat", "as", "ets", "and", "models", "for", "two", "t", "asks", "\u00e2\u0122\u0136", "social", "accept", "ability", "and", "hate", "speech", "det", "ection", "."], "token_lens": [1, 2, 5, 1, 1, 1, 2, 1, 2, 1, 2, 1, 2, 1, 2, 3, 1, 2, 1, 1, 2, 2, 2, 1, 1, 2, 1, 1, 3, 2, 1, 5, 1, 2, 2, 2, 1, 3, 2, 1, 1, 3, 1, 1, 4, 1, 1, 3, 1, 1, 1, 1, 4, 2, 1, 1, 1, 3], "sentence": "We introduce NLPositionality, a framework for characterizing design biases and quantifying the positionality of NLP datasets and models. Our framework continuously collects annotations from a diverse pool of volunteer participants on LabintheWild, and statistically quantifies alignment with dataset labels and model predictions. We apply NLPositionality to existing datasets and models for two tasks\u2014social acceptability and hate speech detection.", "sentence_starts": [0]}
{"doc_id": "ACL_23_P_505", "wnd_id": "ACL_23_P_505-2", "entity_mentions": [{"id": "ACL_23_P_505-2-E0", "text": "We", "start": 2, "end": 3, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_505-2-E1", "text": "we have collected 16,299 annotations in over a year for 600 instances from 1,096 annotators across 87 countries", "start": 2, "end": 20, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_505-2-E2", "text": "certain groups, such as non-binary people and non-native English speakers, are further marginalized by datasets and models as they rank least in alignment across all tasks", "start": 36, "end": 62, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_505-2-E3", "text": "datasets and models align predominantly", "start": 23, "end": 28, "entity_type": "UNK", "mention_type": "UNK"}], "relation_mentions": [], "event_mentions": [{"event_type": "Results/Findings", "id": "ACL_23_P_505-2-EV0", "trigger": {"text": "find", "start": 21, "end": 22}, "arguments": [{"entity_id": "ACL_23_P_505-2-E0", "text": "We", "role": "Agent"}, {"entity_id": "ACL_23_P_505-2-E1", "text": "we have collected 16,299 annotations in over a year for 600 instances from 1,096 annotators across 87 countries", "role": "Context"}, {"entity_id": "ACL_23_P_505-2-E2", "text": "certain groups, such as non-binary people and non-native English speakers, are further marginalized by datasets and models as they rank least in alignment across all tasks", "role": "Results"}, {"entity_id": "ACL_23_P_505-2-E3", "text": "datasets and models align predominantly", "role": "PrimaryObject"}]}], "entity_coreference": [], "event_coreference": [], "tokens": ["To", "date,", "we", "have", "collected", "16,299", "annotations", "in", "over", "a", "year", "for", "600", "instances", "from", "1,096", "annotators", "across", "87", "countries.", "We", "find", "that", "datasets", "and", "models", "align", "predominantly", "with", "Western,", "White,", "college-educated,", "and", "younger", "populations.", "Additionally,", "certain", "groups,", "such", "as", "non-binary", "people", "and", "non-native", "English", "speakers,", "are", "further", "marginalized", "by", "datasets", "and", "models", "as", "they", "rank", "least", "in", "alignment", "across", "all", "tasks."], "pieces": ["To", "date", ",", "we", "have", "col", "lected", "16", ",", "299", "annot", "ations", "in", "over", "a", "year", "for", "600", "inst", "ances", "from", "1", ",", "09", "6", "annot", "ators", "ac", "ross", "87", "count", "ries", ".", "We", "find", "that", "dat", "as", "ets", "and", "models", "align", "pred", "omin", "antly", "with", "Western", ",", "White", ",", "college", "-", "educated", ",", "and", "young", "er", "pop", "ulations", ".", "Additionally", ",", "certain", "groups", ",", "such", "as", "non", "-", "binary", "people", "and", "non", "-", "native", "English", "spe", "akers", ",", "are", "f", "urther", "marg", "inal", "ized", "by", "dat", "as", "ets", "and", "models", "as", "they", "rank", "le", "ast", "in", "al", "ignment", "ac", "ross", "all", "t", "asks", "."], "token_lens": [1, 2, 1, 1, 2, 3, 2, 1, 1, 1, 1, 1, 1, 2, 1, 4, 2, 2, 1, 3, 1, 1, 1, 3, 1, 1, 1, 3, 1, 2, 2, 4, 1, 2, 3, 2, 1, 2, 1, 1, 3, 1, 1, 3, 1, 3, 1, 2, 3, 1, 3, 1, 1, 1, 1, 1, 2, 1, 2, 2, 1, 3], "sentence": "To date, we have collected 16,299 annotations in over a year for 600 instances from 1,096 annotators across 87 countries. We find that datasets and models align predominantly with Western, White, college-educated, and younger populations. Additionally, certain groups, such as non-binary people and non-native English speakers, are further marginalized by datasets and models as they rank least in alignment across all tasks.", "sentence_starts": [0]}
{"doc_id": "ACL_23_P_505", "wnd_id": "ACL_23_P_505-3", "entity_mentions": [{"id": "ACL_23_P_505-3-E0", "text": "we", "start": 1, "end": 2, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_505-3-E1", "text": "to discuss how researchers can examine their own positionality and that of their datasets and models", "start": 6, "end": 22, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_505-3-E2", "text": "opening the door for more inclusive NLP systems.", "start": 22, "end": 30, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_505-3-E3", "text": "prior literature", "start": 4, "end": 6, "entity_type": "UNK", "mention_type": "UNK"}], "relation_mentions": [], "event_mentions": [{"event_type": "Conclusions/Implications", "id": "ACL_23_P_505-3-EV0", "trigger": {"text": "draw from", "start": 2, "end": 4}, "arguments": [{"entity_id": "ACL_23_P_505-3-E0", "text": "we", "role": "Agent"}, {"entity_id": "ACL_23_P_505-3-E1", "text": "to discuss how researchers can examine their own positionality and that of their datasets and models", "role": "Purpose"}, {"entity_id": "ACL_23_P_505-3-E2", "text": "opening the door for more inclusive NLP systems.", "role": "Implications"}, {"entity_id": "ACL_23_P_505-3-E3", "text": "prior literature", "role": "PrimaryObject"}]}], "entity_coreference": [], "event_coreference": [], "tokens": ["Finally,", "we", "draw", "from", "prior", "literature", "to", "discuss", "how", "researchers", "can", "examine", "their", "own", "positionality", "and", "that", "of", "their", "datasets", "and", "models,", "opening", "the", "door", "for", "more", "inclusive", "NLP", "systems."], "pieces": ["Finally", ",", "we", "draw", "from", "pri", "or", "liter", "ature", "to", "disc", "uss", "how", "re", "se", "ar", "chers", "can", "ex", "amine", "their", "own", "position", "ality", "and", "that", "of", "their", "dat", "as", "ets", "and", "models", ",", "opening", "the", "door", "for", "more", "in", "clusive", "N", "LP", "system", "s", "."], "token_lens": [2, 1, 1, 1, 2, 2, 1, 2, 1, 4, 1, 2, 1, 1, 2, 1, 1, 1, 1, 3, 1, 2, 1, 1, 1, 1, 1, 2, 2, 3], "sentence": "Finally, we draw from prior literature to discuss how researchers can examine their own positionality and that of their datasets and models, opening the door for more inclusive NLP systems.", "sentence_starts": [0]}
{"doc_id": "ACL_23_P_215", "wnd_id": "ACL_23_P_215-0", "entity_mentions": [{"id": "ACL_23_P_215-0-E0", "text": "we", "start": 3, "end": 4, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_215-0-E1", "text": "During training, DiffusionNER gradually adds noises to the golden entity boundaries by a fixed forward diffusion process and learns a reverse diffusion process to recover the entity boundaries", "start": 26, "end": 54, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_215-0-E2", "text": "In inference, DiffusionNER first randomly samples some noisy spans from a standard Gaussian distribution and then generates the named entities by denoising them with the learned reverse diffusion process.", "start": 54, "end": 83, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_215-0-E3", "text": "DiffusionNER", "start": 5, "end": 6, "entity_type": "UNK", "mention_type": "UNK"}], "relation_mentions": [], "event_mentions": [{"event_type": "Methods/Approach", "id": "ACL_23_P_215-0-EV0", "trigger": {"text": "propose", "start": 4, "end": 5}, "arguments": [{"entity_id": "ACL_23_P_215-0-E0", "text": "we", "role": "Agent"}, {"entity_id": "ACL_23_P_215-0-E1", "text": "During training, DiffusionNER gradually adds noises to the golden entity boundaries by a fixed forward diffusion process and learns a reverse diffusion process to recover the entity boundaries", "role": "Method"}, {"entity_id": "ACL_23_P_215-0-E2", "text": "In inference, DiffusionNER first randomly samples some noisy spans from a standard Gaussian distribution and then generates the named entities by denoising them with the learned reverse diffusion process.", "role": "Method"}, {"entity_id": "ACL_23_P_215-0-E3", "text": "DiffusionNER", "role": "PrimaryObject"}]}], "entity_coreference": [], "event_coreference": [], "tokens": ["In", "this", "paper,", "we", "propose", "DiffusionNER,", "which", "formulates", "the", "named", "entity", "recognition", "task", "as", "a", "boundary-denoising", "diffusion", "process", "and", "thus", "generates", "named", "entities", "from", "noisy", "spans.", "During", "training,", "DiffusionNER", "gradually", "adds", "noises", "to", "the", "golden", "entity", "boundaries", "by", "a", "fixed", "forward", "diffusion", "process", "and", "learns", "a", "reverse", "diffusion", "process", "to", "recover", "the", "entity", "boundaries.", "In", "inference,", "DiffusionNER", "first", "randomly", "samples", "some", "noisy", "spans", "from", "a", "standard", "Gaussian", "distribution", "and", "then", "generates", "the", "named", "entities", "by", "denoising", "them", "with", "the", "learned", "reverse", "diffusion", "process."], "pieces": ["In", "this", "paper", ",", "we", "pro", "pose", "Diff", "usion", "NER", ",", "which", "form", "ulates", "the", "named", "entity", "recogn", "ition", "task", "as", "a", "bound", "ary", "-", "den", "o", "ising", "diff", "usion", "process", "and", "thus", "gener", "ates", "named", "ent", "ities", "from", "no", "isy", "sp", "ans", ".", "During", "training", ",", "Diff", "usion", "NER", "grad", "ually", "add", "s", "no", "ises", "to", "the", "gold", "en", "entity", "bound", "aries", "by", "a", "fixed", "forward", "diff", "usion", "process", "and", "learn", "s", "a", "reverse", "diff", "usion", "process", "to", "re", "cover", "the", "entity", "bound", "aries", ".", "In", "in", "ference", ",", "Diff", "usion", "NER", "first", "random", "ly", "s", "amples", "some", "no", "isy", "sp", "ans", "from", "a", "standard", "Ga", "ussian", "dist", "ribution", "and", "then", "gener", "ates", "the", "named", "ent", "ities", "by", "den", "o", "ising", "them", "with", "the", "learn", "ed", "reverse", "diff", "usion", "process", "."], "token_lens": [1, 1, 2, 1, 2, 4, 1, 2, 1, 1, 1, 2, 1, 1, 1, 6, 2, 1, 1, 1, 2, 1, 2, 1, 2, 3, 1, 2, 3, 2, 2, 2, 1, 1, 2, 1, 2, 1, 1, 1, 1, 2, 1, 1, 2, 1, 1, 2, 1, 1, 2, 1, 1, 3, 1, 3, 3, 1, 2, 2, 1, 2, 2, 1, 1, 1, 2, 2, 1, 1, 2, 1, 1, 2, 1, 3, 1, 1, 1, 2, 1, 2, 2], "sentence": "In this paper, we propose DiffusionNER, which formulates the named entity recognition task as a boundary-denoising diffusion process and thus generates named entities from noisy spans. During training, DiffusionNER gradually adds noises to the golden entity boundaries by a fixed forward diffusion process and learns a reverse diffusion process to recover the entity boundaries. In inference, DiffusionNER first randomly samples some noisy spans from a standard Gaussian distribution and then generates the named entities by denoising them with the learned reverse diffusion process.", "sentence_starts": [0]}
{"doc_id": "ACL_23_P_215", "wnd_id": "ACL_23_P_215-1", "entity_mentions": [{"id": "ACL_23_P_215-1-E0", "text": "Experiments on multiple flat and nested NER datasets", "start": 22, "end": 30, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_215-1-E1", "text": "The proposed boundary-denoising diffusion process allows progressive refinement and dynamic sampling of entities, empowering DiffusionNER with efficient and flexible entity generation capability", "start": 0, "end": 22, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_215-1-E2", "text": "DiffusionNER achieves comparable or even better performance", "start": 32, "end": 39, "entity_type": "UNK", "mention_type": "UNK"}], "relation_mentions": [], "event_mentions": [{"event_type": "Results/Findings", "id": "ACL_23_P_215-1-EV0", "trigger": {"text": "demonstrate", "start": 30, "end": 31}, "arguments": [{"entity_id": "ACL_23_P_215-1-E0", "text": "Experiments on multiple flat and nested NER datasets", "role": "Agent"}, {"entity_id": "ACL_23_P_215-1-E1", "text": "The proposed boundary-denoising diffusion process allows progressive refinement and dynamic sampling of entities, empowering DiffusionNER with efficient and flexible entity generation capability", "role": "Results"}, {"entity_id": "ACL_23_P_215-1-E2", "text": "DiffusionNER achieves comparable or even better performance", "role": "PrimaryObject"}]}], "entity_coreference": [], "event_coreference": [], "tokens": ["The", "proposed", "boundary-denoising", "diffusion", "process", "allows", "progressive", "refinement", "and", "dynamic", "sampling", "of", "entities,", "empowering", "DiffusionNER", "with", "efficient", "and", "flexible", "entity", "generation", "capability.", "Experiments", "on", "multiple", "flat", "and", "nested", "NER", "datasets", "demonstrate", "that", "DiffusionNER", "achieves", "comparable", "or", "even", "better", "performance", "than", "previous", "state-of-the-art", "models."], "pieces": ["The", "prop", "osed", "bound", "ary", "-", "den", "o", "ising", "diff", "usion", "process", "allows", "pro", "gressive", "ref", "inement", "and", "d", "ynamic", "sam", "pling", "of", "ent", "ities", ",", "em", "power", "ing", "Diff", "usion", "NER", "with", "efficient", "and", "flex", "ible", "entity", "generation", "cap", "ability", ".", "Exper", "iments", "on", "multiple", "flat", "and", "n", "ested", "NER", "dat", "as", "ets", "demon", "strate", "that", "Diff", "usion", "NER", "ach", "ieves", "com", "parable", "or", "even", "better", "performance", "than", "pre", "vious", "state", "-", "of", "-", "the", "-", "art", "models", "."], "token_lens": [1, 2, 6, 2, 1, 1, 2, 2, 1, 2, 2, 1, 3, 3, 3, 1, 1, 1, 2, 1, 1, 3, 2, 1, 1, 1, 1, 2, 1, 3, 2, 1, 3, 2, 2, 1, 1, 1, 1, 1, 2, 7, 2], "sentence": "The proposed boundary-denoising diffusion process allows progressive refinement and dynamic sampling of entities, empowering DiffusionNER with efficient and flexible entity generation capability. Experiments on multiple flat and nested NER datasets demonstrate that DiffusionNER achieves comparable or even better performance than previous state-of-the-art models.", "sentence_starts": [0]}
{"doc_id": "ACL_23_P_571", "wnd_id": "ACL_23_P_571-0", "entity_mentions": [{"id": "ACL_23_P_571-0-E0", "text": "Transformer encoders", "start": 0, "end": 2, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_571-0-E1", "text": "the input text of many NLP tasks can be seen as a sequence of related segments", "start": 28, "end": 44, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_571-0-E2", "text": "While attending across these segments is highly beneficial for many tasks, we hypothesize that this interaction can be delayed until later encoding stages", "start": 59, "end": 82, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_571-0-E3", "text": "token representations", "start": 3, "end": 5, "entity_type": "UNK", "mention_type": "UNK"}], "relation_mentions": [], "event_mentions": [{"event_type": "Background/Introduction", "id": "ACL_23_P_571-0-EV0", "trigger": {"text": "contextualize", "start": 2, "end": 3}, "arguments": [{"entity_id": "ACL_23_P_571-0-E0", "text": "Transformer encoders", "role": "Agent"}, {"entity_id": "ACL_23_P_571-0-E1", "text": "the input text of many NLP tasks can be seen as a sequence of related segments", "role": "Context"}, {"entity_id": "ACL_23_P_571-0-E2", "text": "While attending across these segments is highly beneficial for many tasks, we hypothesize that this interaction can be delayed until later encoding stages", "role": "Purpose"}, {"entity_id": "ACL_23_P_571-0-E3", "text": "token representations", "role": "PrimaryObject"}]}], "entity_coreference": [], "event_coreference": [], "tokens": ["Transformer", "encoders", "contextualize", "token", "representations", "by", "attending", "to", "all", "other", "tokens", "at", "each", "layer,", "leading", "to", "quadratic", "increase", "in", "compute", "effort", "with", "the", "input", "length.", "In", "practice,", "however,", "the", "input", "text", "of", "many", "NLP", "tasks", "can", "be", "seen", "as", "a", "sequence", "of", "related", "segments", "(e.g.,", "the", "sequence", "of", "sentences", "within", "a", "passage,", "or", "the", "hypothesis", "and", "premise", "in", "NLI).", "While", "attending", "across", "these", "segments", "is", "highly", "beneficial", "for", "many", "tasks,", "we", "hypothesize", "that", "this", "interaction", "can", "be", "delayed", "until", "later", "encoding", "stages."], "pieces": ["Trans", "former", "enc", "od", "ers", "context", "ual", "ize", "token", "represent", "ations", "by", "att", "ending", "to", "all", "other", "t", "ok", "ens", "at", "each", "layer", ",", "leading", "to", "qu", "adr", "atic", "incre", "ase", "in", "comp", "ute", "eff", "ort", "with", "the", "input", "length", ".", "In", "practice", ",", "how", "ever", ",", "the", "input", "text", "of", "many", "N", "LP", "t", "asks", "can", "be", "seen", "as", "a", "sequence", "of", "related", "se", "gments", "(", "e", ".", "g", ".,", "the", "sequence", "of", "sent", "ences", "within", "a", "pass", "age", ",", "or", "the", "hyp", "ot", "hesis", "and", "prem", "ise", "in", "N", "LI", ").", "While", "att", "ending", "ac", "ross", "these", "se", "gments", "is", "highly", "benef", "icial", "for", "many", "t", "asks", ",", "we", "hyp", "othes", "ize", "that", "this", "inter", "action", "can", "be", "del", "ayed", "until", "later", "enc", "oding", "st", "ages", "."], "token_lens": [2, 3, 3, 1, 2, 1, 2, 1, 1, 1, 3, 1, 1, 2, 1, 1, 3, 2, 1, 2, 2, 1, 1, 1, 2, 1, 2, 3, 1, 1, 1, 1, 1, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 2, 5, 1, 1, 1, 2, 1, 1, 3, 1, 1, 3, 1, 2, 1, 3, 1, 2, 2, 1, 2, 1, 1, 2, 1, 1, 3, 1, 3, 1, 1, 2, 1, 1, 2, 1, 1, 2, 3], "sentence": "Transformer encoders contextualize token representations by attending to all other tokens at each layer, leading to quadratic increase in compute effort with the input length. In practice, however, the input text of many NLP tasks can be seen as a sequence of related segments (e.g., the sequence of sentences within a passage, or the hypothesis and premise in NLI). While attending across these segments is highly beneficial for many tasks, we hypothesize that this interaction can be delayed until later encoding stages.", "sentence_starts": [0]}
{"doc_id": "ACL_23_P_571", "wnd_id": "ACL_23_P_571-1", "entity_mentions": [{"id": "ACL_23_P_571-1-E0", "text": "we", "start": 3, "end": 4, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_571-1-E1", "text": "segmented inputs are first encoded independently, and then jointly", "start": 12, "end": 21, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_571-1-E2", "text": "This partial two-tower architecture bridges the gap between a Dual Encoder\u2019s ability to pre-compute representations for segments and a fully self-attentive Transformer\u2019s capacity to model cross-segment attention", "start": 21, "end": 48, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_571-1-E3", "text": "The LAIT framework effectively leverages existing pretrained Transformers and converts them into the hybrid of the two aforementioned architectures", "start": 48, "end": 67, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_571-1-E4", "text": "easy and intuitive control over the performance-efficiency tradeoff", "start": 69, "end": 77, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_571-1-E5", "text": "Layer-Adjustable Interactions", "start": 5, "end": 7, "entity_type": "UNK", "mention_type": "UNK"}], "relation_mentions": [], "event_mentions": [{"event_type": "Methods/Approach", "id": "ACL_23_P_571-1-EV0", "trigger": {"text": "introduce", "start": 4, "end": 5}, "arguments": [{"entity_id": "ACL_23_P_571-1-E0", "text": "we", "role": "Agent"}, {"entity_id": "ACL_23_P_571-1-E1", "text": "segmented inputs are first encoded independently, and then jointly", "role": "Method"}, {"entity_id": "ACL_23_P_571-1-E2", "text": "This partial two-tower architecture bridges the gap between a Dual Encoder\u2019s ability to pre-compute representations for segments and a fully self-attentive Transformer\u2019s capacity to model cross-segment attention", "role": "Method"}, {"entity_id": "ACL_23_P_571-1-E3", "text": "The LAIT framework effectively leverages existing pretrained Transformers and converts them into the hybrid of the two aforementioned architectures", "role": "Method"}, {"entity_id": "ACL_23_P_571-1-E4", "text": "easy and intuitive control over the performance-efficiency tradeoff", "role": "Results"}, {"entity_id": "ACL_23_P_571-1-E5", "text": "Layer-Adjustable Interactions", "role": "PrimaryObject"}]}], "entity_coreference": [], "event_coreference": [], "tokens": ["To", "this", "end,", "we", "introduce", "Layer-Adjustable", "Interactions", "in", "Transformers", "(LAIT).", "Within", "LAIT,", "segmented", "inputs", "are", "first", "encoded", "independently,", "and", "then", "jointly.", "This", "partial", "two-tower", "architecture", "bridges", "the", "gap", "between", "a", "Dual", "Encoder\u2019s", "ability", "to", "pre-compute", "representations", "for", "segments", "and", "a", "fully", "self-attentive", "Transformer\u2019s", "capacity", "to", "model", "cross-segment", "attention.", "The", "LAIT", "framework", "effectively", "leverages", "existing", "pretrained", "Transformers", "and", "converts", "them", "into", "the", "hybrid", "of", "the", "two", "aforementioned", "architectures,", "allowing", "for", "easy", "and", "intuitive", "control", "over", "the", "performance-efficiency", "tradeoff."], "pieces": ["To", "this", "end", ",", "we", "introdu", "ce", "Layer", "-", "Adjust", "able", "Inter", "actions", "in", "Transform", "ers", "(", "LA", "IT", ").", "Within", "LA", "IT", ",", "se", "gment", "ed", "input", "s", "are", "first", "enc", "oded", "ind", "epend", "ently", ",", "and", "then", "j", "oint", "ly", ".", "This", "partial", "two", "-", "tower", "arch", "itect", "ure", "brid", "ges", "the", "gap", "between", "a", "Dual", "Enc", "oder", "\u00e2\u0122", "\u013b", "s", "ability", "to", "pre", "-", "comp", "ute", "represent", "ations", "for", "se", "gments", "and", "a", "fully", "self", "-", "att", "ent", "ive", "Trans", "former", "\u00e2\u0122", "\u013b", "s", "capacity", "to", "model", "cross", "-", "se", "gment", "att", "ention", ".", "The", "LA", "IT", "framework", "effect", "ively", "le", "verages", "existing", "pret", "rained", "Transform", "ers", "and", "con", "verts", "them", "into", "the", "hy", "brid", "of", "the", "two", "a", "fore", "mentioned", "arch", "itect", "ures", ",", "all", "owing", "for", "easy", "and", "intuitive", "control", "over", "the", "performance", "-", "efficiency", "trade", "off", "."], "token_lens": [1, 1, 2, 1, 2, 4, 2, 1, 2, 4, 1, 3, 3, 2, 1, 1, 2, 4, 1, 1, 4, 1, 1, 3, 3, 2, 1, 1, 1, 1, 1, 5, 1, 1, 4, 2, 1, 2, 1, 1, 1, 5, 5, 1, 1, 1, 4, 3, 1, 2, 1, 2, 2, 1, 2, 2, 1, 2, 1, 1, 1, 2, 1, 1, 1, 3, 4, 2, 1, 1, 1, 1, 1, 1, 1, 3, 3], "sentence": "To this end, we introduce Layer-Adjustable Interactions in Transformers (LAIT). Within LAIT, segmented inputs are first encoded independently, and then jointly. This partial two-tower architecture bridges the gap between a Dual Encoder\u2019s ability to pre-compute representations for segments and a fully self-attentive Transformer\u2019s capacity to model cross-segment attention. The LAIT framework effectively leverages existing pretrained Transformers and converts them into the hybrid of the two aforementioned architectures, allowing for easy and intuitive control over the performance-efficiency tradeoff.", "sentence_starts": [0]}
{"doc_id": "ACL_23_P_571", "wnd_id": "ACL_23_P_571-2", "entity_mentions": [{"id": "ACL_23_P_571-2-E0", "text": "we", "start": 8, "end": 9, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_571-2-E1", "text": "in some practical settings, LAIT could reduce actual latency by orders of magnitude", "start": 26, "end": 39, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_571-2-E2", "text": "LAIT able to reduce 30-50% of the attention FLOPs on many tasks", "start": 10, "end": 22, "entity_type": "UNK", "mention_type": "UNK"}], "relation_mentions": [], "event_mentions": [{"event_type": "Results/Findings", "id": "ACL_23_P_571-2-EV0", "trigger": {"text": "find", "start": 9, "end": 10}, "arguments": [{"entity_id": "ACL_23_P_571-2-E0", "text": "we", "role": "Agent"}, {"entity_id": "ACL_23_P_571-2-E1", "text": "in some practical settings, LAIT could reduce actual latency by orders of magnitude", "role": "Results"}, {"entity_id": "ACL_23_P_571-2-E2", "text": "LAIT able to reduce 30-50% of the attention FLOPs on many tasks", "role": "PrimaryObject"}]}], "entity_coreference": [], "event_coreference": [], "tokens": ["Experimenting", "on", "a", "wide", "range", "of", "NLP", "tasks,", "we", "find", "LAIT", "able", "to", "reduce", "30-50%", "of", "the", "attention", "FLOPs", "on", "many", "tasks,", "while", "preserving", "high", "accuracy;", "in", "some", "practical", "settings,", "LAIT", "could", "reduce", "actual", "latency", "by", "orders", "of", "magnitude."], "pieces": ["Exper", "iment", "ing", "on", "a", "wide", "range", "of", "N", "LP", "t", "asks", ",", "we", "find", "LA", "IT", "able", "to", "red", "uce", "30", "-", "50", "%", "of", "the", "att", "ention", "FL", "OP", "s", "on", "many", "t", "asks", ",", "while", "pres", "erving", "high", "acc", "uracy", ";", "in", "some", "pract", "ical", "settings", ",", "LA", "IT", "could", "red", "uce", "actual", "lat", "ency", "by", "orders", "of", "m", "agn", "itude", "."], "token_lens": [3, 1, 1, 1, 1, 1, 2, 3, 1, 1, 2, 1, 1, 2, 4, 1, 1, 2, 3, 1, 1, 3, 1, 2, 1, 3, 1, 1, 2, 2, 2, 1, 2, 1, 2, 1, 1, 1, 4], "sentence": "Experimenting on a wide range of NLP tasks, we find LAIT able to reduce 30-50% of the attention FLOPs on many tasks, while preserving high accuracy; in some practical settings, LAIT could reduce actual latency by orders of magnitude.", "sentence_starts": [0]}
{"doc_id": "ACL_23_P_196", "wnd_id": "ACL_23_P_196-0", "entity_mentions": [{"id": "ACL_23_P_196-0-E0", "text": "Entailment Graphs (EGs)", "start": 0, "end": 3, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_196-0-E1", "text": "EGs built by previous methods often suffer from severe sparsity issues, due to limited corpora available and the long-tail phenomenon of predicate distributions", "start": 25, "end": 48, "entity_type": "UNK", "mention_type": "UNK"}], "relation_mentions": [], "event_mentions": [{"event_type": "Background/Introduction", "id": "ACL_23_P_196-0-EV0", "trigger": {"text": "have been constructed", "start": 3, "end": 6}, "arguments": [{"entity_id": "ACL_23_P_196-0-E0", "text": "Entailment Graphs (EGs)", "role": "Agent"}, {"entity_id": "ACL_23_P_196-0-E1", "text": "EGs built by previous methods often suffer from severe sparsity issues, due to limited corpora available and the long-tail phenomenon of predicate distributions", "role": "Challenge"}]}], "entity_coreference": [], "event_coreference": [], "tokens": ["Entailment", "Graphs", "(EGs)", "have", "been", "constructed", "based", "on", "extracted", "corpora", "as", "a", "strong", "and", "explainable", "form", "to", "indicate", "context-independent", "entailment", "relation", "in", "natural", "languages.", "However,", "EGs", "built", "by", "previous", "methods", "often", "suffer", "from", "severe", "sparsity", "issues,", "due", "to", "limited", "corpora", "available", "and", "the", "long-tail", "phenomenon", "of", "predicate", "distributions."], "pieces": ["Ent", "ail", "ment", "Graph", "s", "(", "EG", "s", ")", "have", "been", "con", "structed", "based", "on", "ext", "racted", "cor", "pora", "as", "a", "strong", "and", "expl", "ain", "able", "form", "to", "ind", "icate", "context", "-", "independent", "ent", "ail", "ment", "relation", "in", "natural", "l", "anguages", ".", "However", ",", "EG", "s", "built", "by", "pre", "vious", "method", "s", "often", "s", "uffer", "from", "severe", "sp", "arsity", "issues", ",", "due", "to", "limited", "cor", "pora", "available", "and", "the", "long", "-", "tail", "phen", "omen", "on", "of", "pred", "icate", "dist", "ribut", "ions", "."], "token_lens": [3, 2, 4, 1, 1, 2, 1, 1, 2, 2, 1, 1, 1, 1, 3, 1, 1, 2, 3, 3, 1, 1, 1, 3, 2, 2, 1, 1, 2, 2, 1, 2, 1, 1, 2, 2, 1, 1, 1, 2, 1, 1, 1, 3, 3, 1, 2, 4], "sentence": "Entailment Graphs (EGs) have been constructed based on extracted corpora as a strong and explainable form to indicate context-independent entailment relation in natural languages. However, EGs built by previous methods often suffer from severe sparsity issues, due to limited corpora available and the long-tail phenomenon of predicate distributions.", "sentence_starts": [0]}
{"doc_id": "ACL_23_P_196", "wnd_id": "ACL_23_P_196-1", "entity_mentions": [{"id": "ACL_23_P_196-1-E0", "text": "we", "start": 3, "end": 4, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_196-1-E1", "text": "Given several seed predicates, TP-EGG builds the graphs by generating new predicates and detecting entailment relations among them", "start": 17, "end": 35, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_196-1-E2", "text": "The generative nature of TP-EGG helps us leverage the recent advances from large pretrained language models (PLMs), while avoiding the reliance on carefully prepared corpora", "start": 35, "end": 60, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_196-1-E3", "text": "a multi-stage method", "start": 5, "end": 8, "entity_type": "UNK", "mention_type": "UNK"}], "relation_mentions": [], "event_mentions": [{"event_type": "Methods/Approach", "id": "ACL_23_P_196-1-EV0", "trigger": {"text": "propose", "start": 4, "end": 5}, "arguments": [{"entity_id": "ACL_23_P_196-1-E0", "text": "we", "role": "Agent"}, {"entity_id": "ACL_23_P_196-1-E1", "text": "Given several seed predicates, TP-EGG builds the graphs by generating new predicates and detecting entailment relations among them", "role": "Method"}, {"entity_id": "ACL_23_P_196-1-E2", "text": "The generative nature of TP-EGG helps us leverage the recent advances from large pretrained language models (PLMs), while avoiding the reliance on carefully prepared corpora", "role": "Method"}, {"entity_id": "ACL_23_P_196-1-E3", "text": "a multi-stage method", "role": "PrimaryObject"}]}], "entity_coreference": [], "event_coreference": [], "tokens": ["In", "this", "paper,", "we", "propose", "a", "multi-stage", "method,", "Typed", "Predicate-Entailment", "Graph", "Generator", "(TP-EGG),", "to", "tackle", "this", "problem.", "Given", "several", "seed", "predicates,", "TP-EGG", "builds", "the", "graphs", "by", "generating", "new", "predicates", "and", "detecting", "entailment", "relations", "among", "them.", "The", "generative", "nature", "of", "TP-EGG", "helps", "us", "leverage", "the", "recent", "advances", "from", "large", "pretrained", "language", "models", "(PLMs),", "while", "avoiding", "the", "reliance", "on", "carefully", "prepared", "corpora."], "pieces": ["In", "this", "paper", ",", "we", "pro", "pose", "a", "multi", "-", "stage", "method", ",", "Typ", "ed", "Pred", "icate", "-", "Ent", "ail", "ment", "Graph", "Gener", "ator", "(", "TP", "-", "EG", "G", "),", "to", "tackle", "this", "problem", ".", "Given", "sever", "al", "seed", "pred", "icates", ",", "TP", "-", "EG", "G", "build", "s", "the", "graph", "s", "by", "gener", "ating", "new", "pred", "icates", "and", "det", "ect", "ing", "ent", "ail", "ment", "relations", "among", "them", ".", "The", "gener", "ative", "nature", "of", "TP", "-", "EG", "G", "helps", "us", "le", "verage", "the", "recent", "adv", "ances", "from", "large", "pret", "rained", "language", "models", "(", "PL", "Ms", "),", "while", "avoid", "ing", "the", "rel", "iance", "on", "care", "fully", "pre", "pared", "cor", "pora", "."], "token_lens": [1, 1, 2, 1, 2, 1, 3, 2, 2, 6, 1, 2, 6, 1, 1, 1, 2, 1, 2, 1, 3, 4, 2, 1, 2, 1, 2, 1, 2, 1, 3, 3, 1, 1, 2, 1, 2, 1, 1, 4, 1, 1, 2, 1, 1, 2, 1, 1, 2, 1, 1, 4, 1, 2, 1, 2, 1, 2, 2, 3], "sentence": "In this paper, we propose a multi-stage method, Typed Predicate-Entailment Graph Generator (TP-EGG), to tackle this problem. Given several seed predicates, TP-EGG builds the graphs by generating new predicates and detecting entailment relations among them. The generative nature of TP-EGG helps us leverage the recent advances from large pretrained language models (PLMs), while avoiding the reliance on carefully prepared corpora.", "sentence_starts": [0]}
{"doc_id": "ACL_23_P_196", "wnd_id": "ACL_23_P_196-2", "entity_mentions": [{"id": "ACL_23_P_196-2-E0", "text": "Experiments on benchmark datasets", "start": 0, "end": 4, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_196-2-E1", "text": "TP-EGG can generate high-quality and scale-controllable entailment graphs", "start": 6, "end": 14, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_196-2-E2", "text": "significant in-domain improvement over state-of-the-art EGs and boosting the performance of downstream inference tasks", "start": 15, "end": 29, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_196-2-E3", "text": "TP-EGG can generate high-quality and scale-controllable entailment graphs", "start": 6, "end": 14, "entity_type": "UNK", "mention_type": "UNK"}], "relation_mentions": [], "event_mentions": [{"event_type": "Results/Findings", "id": "ACL_23_P_196-2-EV0", "trigger": {"text": "show", "start": 4, "end": 5}, "arguments": [{"entity_id": "ACL_23_P_196-2-E0", "text": "Experiments on benchmark datasets", "role": "Agent"}, {"entity_id": "ACL_23_P_196-2-E1", "text": "TP-EGG can generate high-quality and scale-controllable entailment graphs", "role": "Results"}, {"entity_id": "ACL_23_P_196-2-E2", "text": "significant in-domain improvement over state-of-the-art EGs and boosting the performance of downstream inference tasks", "role": "Results"}, {"entity_id": "ACL_23_P_196-2-E3", "text": "TP-EGG can generate high-quality and scale-controllable entailment graphs", "role": "PrimaryObject"}]}], "entity_coreference": [], "event_coreference": [], "tokens": ["Experiments", "on", "benchmark", "datasets", "show", "that", "TP-EGG", "can", "generate", "high-quality", "and", "scale-controllable", "entailment", "graphs,", "achieving", "significant", "in-domain", "improvement", "over", "state-of-the-art", "EGs", "and", "boosting", "the", "performance", "of", "downstream", "inference", "tasks."], "pieces": ["Exper", "iments", "on", "bench", "mark", "dat", "as", "ets", "show", "that", "TP", "-", "EG", "G", "can", "gener", "ate", "high", "-", "quality", "and", "scale", "-", "cont", "roll", "able", "ent", "ail", "ment", "graph", "s", ",", "ach", "ieving", "significant", "in", "-", "domain", "improve", "ment", "over", "state", "-", "of", "-", "the", "-", "art", "EG", "s", "and", "boost", "ing", "the", "performance", "of", "down", "stream", "in", "ference", "t", "asks", "."], "token_lens": [2, 1, 2, 3, 1, 1, 4, 1, 2, 3, 1, 5, 3, 3, 2, 1, 3, 2, 1, 7, 2, 1, 2, 1, 1, 1, 2, 2, 3], "sentence": "Experiments on benchmark datasets show that TP-EGG can generate high-quality and scale-controllable entailment graphs, achieving significant in-domain improvement over state-of-the-art EGs and boosting the performance of downstream inference tasks.", "sentence_starts": [0]}
{"doc_id": "ACL_23_P_511", "wnd_id": "ACL_23_P_511-0", "entity_mentions": [{"id": "ACL_23_P_511-0-E0", "text": "Pre-trained large language models (PLMs)", "start": 0, "end": 5, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_511-0-E1", "text": "shifted the field from application-specific model pipelines to a single model that is adapted to a wide range of tasks", "start": 15, "end": 35, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_511-0-E2", "text": "Autoregressive PLMs like GPT-3 or PaLM and associated techniques like few-shot learning, have additionally shifted the output modality to generation instead of classification or regression", "start": 35, "end": 60, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_511-0-E3", "text": "the generation quality of language models is rarely evaluated when these models are introduced", "start": 64, "end": 78, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_511-0-E4", "text": "it is unclear how existing generation tasks \u2013 while they can be used to compare systems at a high level \u2013 relate to the real-world use cases for which people have been adopting them", "start": 79, "end": 113, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_511-0-E5", "text": "most new developments", "start": 6, "end": 9, "entity_type": "UNK", "mention_type": "UNK"}], "relation_mentions": [], "event_mentions": [{"event_type": "Background/Introduction", "id": "ACL_23_P_511-0-EV0", "trigger": {"text": "underly", "start": 5, "end": 6}, "arguments": [{"entity_id": "ACL_23_P_511-0-E0", "text": "Pre-trained large language models (PLMs)", "role": "Agent"}, {"entity_id": "ACL_23_P_511-0-E1", "text": "shifted the field from application-specific model pipelines to a single model that is adapted to a wide range of tasks", "role": "Context"}, {"entity_id": "ACL_23_P_511-0-E2", "text": "Autoregressive PLMs like GPT-3 or PaLM and associated techniques like few-shot learning, have additionally shifted the output modality to generation instead of classification or regression", "role": "Context"}, {"entity_id": "ACL_23_P_511-0-E3", "text": "the generation quality of language models is rarely evaluated when these models are introduced", "role": "Challenge"}, {"entity_id": "ACL_23_P_511-0-E4", "text": "it is unclear how existing generation tasks \u2013 while they can be used to compare systems at a high level \u2013 relate to the real-world use cases for which people have been adopting them", "role": "Challenge"}, {"entity_id": "ACL_23_P_511-0-E5", "text": "most new developments", "role": "PrimaryObject"}]}], "entity_coreference": [], "event_coreference": [], "tokens": ["Pre-trained", "large", "language", "models", "(PLMs)", "underly", "most", "new", "developments", "in", "natural", "language", "processing.", "They", "have", "shifted", "the", "field", "from", "application-specific", "model", "pipelines", "to", "a", "single", "model", "that", "is", "adapted", "to", "a", "wide", "range", "of", "tasks.", "Autoregressive", "PLMs", "like", "GPT-3", "or", "PaLM", "and", "associated", "techniques", "like", "few-shot", "learning,", "have", "additionally", "shifted", "the", "output", "modality", "to", "generation", "instead", "of", "classification", "or", "regression.", "Despite", "their", "ubiquitous", "use,", "the", "generation", "quality", "of", "language", "models", "is", "rarely", "evaluated", "when", "these", "models", "are", "introduced.", "Additionally,", "it", "is", "unclear", "how", "existing", "generation", "tasks", "\u2013", "while", "they", "can", "be", "used", "to", "compare", "systems", "at", "a", "high", "level", "\u2013", "relate", "to", "the", "real-world", "use", "cases", "for", "which", "people", "have", "been", "adopting", "them."], "pieces": ["Pre", "-", "trained", "large", "language", "models", "(", "PL", "Ms", ")", "under", "ly", "most", "new", "develop", "ments", "in", "natural", "language", "processing", ".", "They", "have", "sh", "ifted", "the", "field", "from", "application", "-", "specific", "model", "p", "ip", "elines", "to", "a", "single", "model", "that", "is", "adapt", "ed", "to", "a", "wide", "range", "of", "t", "asks", ".", "Aut", "ore", "gressive", "PL", "Ms", "like", "G", "PT", "-", "3", "or", "Pa", "LM", "and", "associated", "techn", "iques", "like", "few", "-", "shot", "learning", ",", "have", "add", "itionally", "sh", "ifted", "the", "output", "mod", "ality", "to", "generation", "instead", "of", "class", "ification", "or", "reg", "ression", ".", "Despite", "their", "ub", "iqu", "itous", "use", ",", "the", "generation", "quality", "of", "language", "models", "is", "ra", "rely", "eval", "uated", "when", "these", "models", "are", "introdu", "ced", ".", "Additionally", ",", "it", "is", "un", "clear", "how", "existing", "generation", "t", "asks", "\u00e2\u0122\u0135", "while", "they", "can", "be", "used", "to", "comp", "are", "system", "s", "at", "a", "high", "level", "\u00e2\u0122\u0135", "rel", "ate", "to", "the", "real", "-", "world", "use", "cases", "for", "which", "people", "have", "been", "ad", "op", "ting", "them", "."], "token_lens": [3, 1, 1, 1, 4, 2, 1, 1, 2, 1, 1, 1, 2, 1, 1, 2, 1, 1, 1, 3, 1, 3, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 3, 3, 2, 1, 4, 1, 2, 1, 1, 2, 1, 3, 2, 1, 2, 2, 1, 1, 2, 1, 1, 1, 1, 2, 1, 3, 1, 1, 3, 2, 1, 1, 1, 1, 1, 1, 1, 2, 2, 1, 1, 1, 1, 3, 2, 1, 1, 2, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 2, 2, 1, 1, 1, 1, 1, 2, 1, 1, 3, 1, 1, 1, 1, 1, 1, 1, 3, 2], "sentence": "Pre-trained large language models (PLMs) underly most new developments in natural language processing. They have shifted the field from application-specific model pipelines to a single model that is adapted to a wide range of tasks. Autoregressive PLMs like GPT-3 or PaLM and associated techniques like few-shot learning, have additionally shifted the output modality to generation instead of classification or regression. Despite their ubiquitous use, the generation quality of language models is rarely evaluated when these models are introduced. Additionally, it is unclear how existing generation tasks \u2013 while they can be used to compare systems at a high level \u2013 relate to the real-world use cases for which people have been adopting them.", "sentence_starts": [0]}
{"doc_id": "ACL_23_P_511", "wnd_id": "ACL_23_P_511-1", "entity_mentions": [{"id": "ACL_23_P_511-1-E0", "text": "we", "start": 3, "end": 4, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_511-1-E1", "text": "how to adapt existing application-specific generation benchmarks to PLMs", "start": 5, "end": 14, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_511-1-E2", "text": "an in-depth, empirical study of the limitations and capabilities of PLMs in natural language generation tasks along dimensions such as scale, architecture, input and output language", "start": 16, "end": 42, "entity_type": "UNK", "mention_type": "UNK"}], "relation_mentions": [], "event_mentions": [{"event_type": "Methods/Approach", "id": "ACL_23_P_511-1-EV0", "trigger": {"text": "discuss", "start": 4, "end": 5}, "arguments": [{"entity_id": "ACL_23_P_511-1-E0", "text": "we", "role": "Agent"}, {"entity_id": "ACL_23_P_511-1-E1", "text": "how to adapt existing application-specific generation benchmarks to PLMs", "role": "Method"}, {"entity_id": "ACL_23_P_511-1-E2", "text": "an in-depth, empirical study of the limitations and capabilities of PLMs in natural language generation tasks along dimensions such as scale, architecture, input and output language", "role": "Method"}]}], "entity_coreference": [], "event_coreference": [], "tokens": ["In", "this", "work,", "we", "discuss", "how", "to", "adapt", "existing", "application-specific", "generation", "benchmarks", "to", "PLMs", "and", "provide", "an", "in-depth,", "empirical", "study", "of", "the", "limitations", "and", "capabilities", "of", "PLMs", "in", "natural", "language", "generation", "tasks", "along", "dimensions", "such", "as", "scale,", "architecture,", "input", "and", "output", "language."], "pieces": ["In", "this", "work", ",", "we", "disc", "uss", "how", "to", "adapt", "existing", "application", "-", "specific", "generation", "bench", "marks", "to", "PL", "Ms", "and", "prov", "ide", "an", "in", "-", "depth", ",", "em", "pir", "ical", "study", "of", "the", "lim", "itations", "and", "cap", "abilities", "of", "PL", "Ms", "in", "natural", "language", "generation", "t", "asks", "along", "dim", "ensions", "such", "as", "scale", ",", "arch", "itect", "ure", ",", "input", "and", "output", "language", "."], "token_lens": [1, 1, 2, 1, 2, 1, 1, 1, 1, 3, 1, 2, 1, 2, 1, 2, 1, 4, 3, 1, 1, 1, 2, 1, 2, 1, 2, 1, 1, 1, 1, 2, 1, 2, 1, 1, 2, 4, 1, 1, 1, 2], "sentence": "In this work, we discuss how to adapt existing application-specific generation benchmarks to PLMs and provide an in-depth, empirical study of the limitations and capabilities of PLMs in natural language generation tasks along dimensions such as scale, architecture, input and output language.", "sentence_starts": [0]}
{"doc_id": "ACL_23_P_511", "wnd_id": "ACL_23_P_511-2", "entity_mentions": [{"id": "ACL_23_P_511-2-E0", "text": "Our results", "start": 0, "end": 2, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_511-2-E1", "text": "PLMs differ in their applicability to different data regimes and their generalization to multiple languages", "start": 4, "end": 19, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_511-2-E2", "text": "inform practitioners as to which PLMs to use for a given generation task setup", "start": 21, "end": 35, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_511-2-E3", "text": "PLMs differ in their applicability to different data regimes and their generalization to multiple languages", "start": 4, "end": 19, "entity_type": "UNK", "mention_type": "UNK"}], "relation_mentions": [], "event_mentions": [{"event_type": "Results/Findings", "id": "ACL_23_P_511-2-EV0", "trigger": {"text": "show", "start": 2, "end": 3}, "arguments": [{"entity_id": "ACL_23_P_511-2-E0", "text": "Our results", "role": "Agent"}, {"entity_id": "ACL_23_P_511-2-E1", "text": "PLMs differ in their applicability to different data regimes and their generalization to multiple languages", "role": "Results"}, {"entity_id": "ACL_23_P_511-2-E2", "text": "inform practitioners as to which PLMs to use for a given generation task setup", "role": "Results"}, {"entity_id": "ACL_23_P_511-2-E3", "text": "PLMs differ in their applicability to different data regimes and their generalization to multiple languages", "role": "PrimaryObject"}]}], "entity_coreference": [], "event_coreference": [], "tokens": ["Our", "results", "show", "that", "PLMs", "differ", "in", "their", "applicability", "to", "different", "data", "regimes", "and", "their", "generalization", "to", "multiple", "languages.", "They", "further", "inform", "practitioners", "as", "to", "which", "PLMs", "to", "use", "for", "a", "given", "generation", "task", "setup."], "pieces": ["Our", "results", "show", "that", "PL", "Ms", "diff", "er", "in", "their", "app", "lic", "ability", "to", "different", "data", "reg", "imes", "and", "their", "general", "ization", "to", "multiple", "l", "anguages", ".", "They", "f", "urther", "in", "form", "pract", "ition", "ers", "as", "to", "which", "PL", "Ms", "to", "use", "for", "a", "given", "generation", "task", "setup", "."], "token_lens": [1, 1, 1, 1, 2, 2, 1, 1, 3, 1, 1, 1, 2, 1, 1, 2, 1, 1, 3, 1, 2, 2, 3, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 2], "sentence": "Our results show that PLMs differ in their applicability to different data regimes and their generalization to multiple languages. They further inform practitioners as to which PLMs to use for a given generation task setup.", "sentence_starts": [0]}
{"doc_id": "ACL_23_P_511", "wnd_id": "ACL_23_P_511-3", "entity_mentions": [{"id": "ACL_23_P_511-3-E0", "text": "We", "start": 0, "end": 1, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_511-3-E1", "text": "best practices", "start": 2, "end": 4, "entity_type": "UNK", "mention_type": "UNK"}], "relation_mentions": [], "event_mentions": [{"event_type": "Conclusions/Implications", "id": "ACL_23_P_511-3-EV0", "trigger": {"text": "share", "start": 1, "end": 2}, "arguments": [{"entity_id": "ACL_23_P_511-3-E0", "text": "We", "role": "Agent"}, {"entity_id": "ACL_23_P_511-3-E1", "text": "best practices", "role": "PrimaryObject"}]}], "entity_coreference": [], "event_coreference": [], "tokens": ["We", "share", "best", "practices", "to", "be", "taken", "into", "consideration", "when", "benchmarking", "generation", "capabilities", "during", "the", "development", "of", "upcoming", "PLMs."], "pieces": ["We", "share", "best", "pract", "ices", "to", "be", "t", "aken", "into", "consider", "ation", "when", "bench", "mark", "ing", "generation", "cap", "abilities", "during", "the", "development", "of", "up", "coming", "PL", "Ms", "."], "token_lens": [1, 1, 1, 2, 1, 1, 2, 1, 2, 1, 3, 1, 2, 1, 1, 1, 1, 2, 3], "sentence": "We share best practices to be taken into consideration when benchmarking generation capabilities during the development of upcoming PLMs.", "sentence_starts": [0]}
{"doc_id": "ACL_23_P_388", "wnd_id": "ACL_23_P_388-0", "entity_mentions": [{"id": "ACL_23_P_388-0-E0", "text": "Multilingual pre-trained language models", "start": 0, "end": 4, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_388-0-E1", "text": "their performance is hindered when the target language has distant typology from the source language or when pre-training data is limited in size", "start": 12, "end": 35, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_388-0-E2", "text": "impressive (zero-shot) cross-lingual transfer abilities", "start": 6, "end": 11, "entity_type": "UNK", "mention_type": "UNK"}], "relation_mentions": [], "event_mentions": [{"event_type": "Background/Introduction", "id": "ACL_23_P_388-0-EV0", "trigger": {"text": "demonstrated", "start": 5, "end": 6}, "arguments": [{"entity_id": "ACL_23_P_388-0-E0", "text": "Multilingual pre-trained language models", "role": "Agent"}, {"entity_id": "ACL_23_P_388-0-E1", "text": "their performance is hindered when the target language has distant typology from the source language or when pre-training data is limited in size", "role": "Challenge"}, {"entity_id": "ACL_23_P_388-0-E2", "text": "impressive (zero-shot) cross-lingual transfer abilities", "role": "PrimaryObject"}]}], "entity_coreference": [], "event_coreference": [], "tokens": ["Multilingual", "pre-trained", "language", "models", "have", "demonstrated", "impressive", "(zero-shot)", "cross-lingual", "transfer", "abilities,", "however,", "their", "performance", "is", "hindered", "when", "the", "target", "language", "has", "distant", "typology", "from", "the", "source", "language", "or", "when", "pre-training", "data", "is", "limited", "in", "size."], "pieces": ["Mult", "ilingual", "pre", "-", "trained", "language", "models", "have", "demon", "str", "ated", "imp", "ressive", "(", "zero", "-", "shot", ")", "cross", "-", "ling", "ual", "transfer", "abilities", ",", "how", "ever", ",", "their", "performance", "is", "h", "ind", "ered", "when", "the", "target", "language", "has", "d", "istant", "typ", "ology", "from", "the", "source", "language", "or", "when", "pre", "-", "training", "data", "is", "limited", "in", "size", "."], "token_lens": [2, 3, 1, 1, 1, 3, 2, 5, 4, 1, 2, 3, 1, 1, 1, 3, 1, 1, 1, 1, 1, 2, 2, 1, 1, 1, 1, 1, 1, 3, 1, 1, 1, 1, 2], "sentence": "Multilingual pre-trained language models have demonstrated impressive (zero-shot) cross-lingual transfer abilities, however, their performance is hindered when the target language has distant typology from the source language or when pre-training data is limited in size.", "sentence_starts": [0]}
{"doc_id": "ACL_23_P_388", "wnd_id": "ACL_23_P_388-1", "entity_mentions": [{"id": "ACL_23_P_388-1-E0", "text": "we", "start": 3, "end": 4, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_388-1-E1", "text": "contextually retrieves prompts as flexible guidance for encoding instances conditionally", "start": 9, "end": 19, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_388-1-E2", "text": "Our space-efficient and model-agnostic XLM-P approach enables (1) lightweight modeling of language-invariant and language-specific knowledge across languages", "start": 19, "end": 36, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_388-1-E3", "text": "(2) easy integration with other multilingual pre-training methods", "start": 37, "end": 45, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_388-1-E4", "text": "XLM-P", "start": 5, "end": 6, "entity_type": "UNK", "mention_type": "UNK"}], "relation_mentions": [], "event_mentions": [{"event_type": "Methods/Approach", "id": "ACL_23_P_388-1-EV0", "trigger": {"text": "propose", "start": 4, "end": 5}, "arguments": [{"entity_id": "ACL_23_P_388-1-E0", "text": "we", "role": "Agent"}, {"entity_id": "ACL_23_P_388-1-E1", "text": "contextually retrieves prompts as flexible guidance for encoding instances conditionally", "role": "Method"}, {"entity_id": "ACL_23_P_388-1-E2", "text": "Our space-efficient and model-agnostic XLM-P approach enables (1) lightweight modeling of language-invariant and language-specific knowledge across languages", "role": "Results"}, {"entity_id": "ACL_23_P_388-1-E3", "text": "(2) easy integration with other multilingual pre-training methods", "role": "Results"}, {"entity_id": "ACL_23_P_388-1-E4", "text": "XLM-P", "role": "PrimaryObject"}]}], "entity_coreference": [], "event_coreference": [], "tokens": ["In", "this", "paper,", "we", "propose", "XLM-P,", "a", "method", "that", "contextually", "retrieves", "prompts", "as", "flexible", "guidance", "for", "encoding", "instances", "conditionally.", "Our", "space-efficient", "and", "model-agnostic", "XLM-P", "approach", "enables", "(1)", "lightweight", "modeling", "of", "language-invariant", "and", "language-specific", "knowledge", "across", "languages,", "and", "(2)", "easy", "integration", "with", "other", "multilingual", "pre-training", "methods."], "pieces": ["In", "this", "paper", ",", "we", "pro", "pose", "X", "LM", "-", "P", ",", "a", "method", "that", "context", "ually", "ret", "rie", "ves", "prom", "pt", "s", "as", "flex", "ible", "gu", "id", "ance", "for", "enc", "oding", "inst", "ances", "cond", "itionally", ".", "Our", "space", "-", "efficient", "and", "model", "-", "agn", "ostic", "X", "LM", "-", "P", "appro", "ach", "en", "ables", "(", "1", ")", "light", "weight", "mod", "eling", "of", "language", "-", "inv", "ari", "ant", "and", "language", "-", "specific", "knowledge", "ac", "ross", "l", "anguages", ",", "and", "(", "2", ")", "easy", "integ", "ration", "with", "other", "mult", "ilingual", "pre", "-", "training", "method", "s", "."], "token_lens": [1, 1, 2, 1, 2, 5, 1, 1, 1, 2, 3, 3, 1, 2, 3, 1, 2, 2, 3, 1, 3, 1, 4, 4, 2, 2, 3, 2, 2, 1, 5, 1, 3, 1, 2, 3, 1, 3, 1, 2, 1, 1, 2, 3, 3], "sentence": "In this paper, we propose XLM-P, a method that contextually retrieves prompts as flexible guidance for encoding instances conditionally. Our space-efficient and model-agnostic XLM-P approach enables (1) lightweight modeling of language-invariant and language-specific knowledge across languages, and (2) easy integration with other multilingual pre-training methods.", "sentence_starts": [0]}
{"doc_id": "ACL_23_P_388", "wnd_id": "ACL_23_P_388-2", "entity_mentions": [{"id": "ACL_23_P_388-2-E0", "text": "base- and large-size language models", "start": 17, "end": 22, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_388-2-E1", "text": "On the tasks of XTREME, which include text classification, sequence labeling, question answering, and sentence retrieval", "start": 0, "end": 16, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_388-2-E2", "text": "pre-trained with our proposed method", "start": 22, "end": 27, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_388-2-E3", "text": "it provides substantial advantages for low-resource languages in unsupervised sentence retrieval and for target languages that differ greatly from the source language in cross-lingual transfer", "start": 32, "end": 57, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_388-2-E4", "text": "consistent performance improvement", "start": 28, "end": 31, "entity_type": "UNK", "mention_type": "UNK"}], "relation_mentions": [], "event_mentions": [{"event_type": "Results/Findings", "id": "ACL_23_P_388-2-EV0", "trigger": {"text": "exhibit", "start": 27, "end": 28}, "arguments": [{"entity_id": "ACL_23_P_388-2-E0", "text": "base- and large-size language models", "role": "Agent"}, {"entity_id": "ACL_23_P_388-2-E1", "text": "On the tasks of XTREME, which include text classification, sequence labeling, question answering, and sentence retrieval", "role": "Context"}, {"entity_id": "ACL_23_P_388-2-E2", "text": "pre-trained with our proposed method", "role": "Method"}, {"entity_id": "ACL_23_P_388-2-E3", "text": "it provides substantial advantages for low-resource languages in unsupervised sentence retrieval and for target languages that differ greatly from the source language in cross-lingual transfer", "role": "Results"}, {"entity_id": "ACL_23_P_388-2-E4", "text": "consistent performance improvement", "role": "PrimaryObject"}]}], "entity_coreference": [], "event_coreference": [], "tokens": ["On", "the", "tasks", "of", "XTREME,", "which", "include", "text", "classification,", "sequence", "labeling,", "question", "answering,", "and", "sentence", "retrieval,", "both", "base-", "and", "large-size", "language", "models", "pre-trained", "with", "our", "proposed", "method", "exhibit", "consistent", "performance", "improvement.", "Furthermore,", "it", "provides", "substantial", "advantages", "for", "low-resource", "languages", "in", "unsupervised", "sentence", "retrieval", "and", "for", "target", "languages", "that", "differ", "greatly", "from", "the", "source", "language", "in", "cross-lingual", "transfer."], "pieces": ["On", "the", "t", "asks", "of", "XT", "RE", "ME", ",", "which", "include", "text", "class", "ification", ",", "sequence", "label", "ing", ",", "question", "ans", "w", "ering", ",", "and", "sent", "ence", "ret", "ri", "eval", ",", "both", "base", "-", "and", "large", "-", "size", "language", "models", "pre", "-", "trained", "with", "our", "prop", "osed", "method", "ex", "hibit", "cons", "istent", "performance", "improve", "ment", ".", "Furthermore", ",", "it", "prov", "ides", "sub", "stantial", "advant", "ages", "for", "low", "-", "resource", "l", "anguages", "in", "un", "super", "vised", "sent", "ence", "ret", "ri", "eval", "and", "for", "target", "l", "anguages", "that", "diff", "er", "great", "ly", "from", "the", "source", "language", "in", "cross", "-", "ling", "ual", "transfer", "."], "token_lens": [1, 1, 2, 1, 4, 1, 1, 1, 3, 1, 3, 1, 4, 1, 2, 4, 1, 2, 1, 3, 1, 1, 3, 1, 1, 2, 1, 2, 2, 1, 3, 2, 1, 2, 2, 2, 1, 3, 2, 1, 3, 2, 3, 1, 1, 1, 2, 1, 2, 2, 1, 1, 1, 1, 1, 4, 2], "sentence": "On the tasks of XTREME, which include text classification, sequence labeling, question answering, and sentence retrieval, both base- and large-size language models pre-trained with our proposed method exhibit consistent performance improvement. Furthermore, it provides substantial advantages for low-resource languages in unsupervised sentence retrieval and for target languages that differ greatly from the source language in cross-lingual transfer.", "sentence_starts": [0]}
{"doc_id": "ACL_23_P_664", "wnd_id": "ACL_23_P_664-0", "entity_mentions": [{"id": "ACL_23_P_664-0-E0", "text": "Supervised visual captioning models", "start": 0, "end": 4, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_664-0-E1", "text": "collecting and labeling large-scale datasets is time-consuming and expensive for many scenarios and languages", "start": 27, "end": 41, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_664-0-E2", "text": "Therefore, sufficient labeled pairs are usually not available", "start": 41, "end": 49, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_664-0-E3", "text": "a large scale of images or videos", "start": 6, "end": 13, "entity_type": "UNK", "mention_type": "UNK"}], "relation_mentions": [], "event_mentions": [{"event_type": "Background/Introduction", "id": "ACL_23_P_664-0-EV0", "trigger": {"text": "require", "start": 5, "end": 6}, "arguments": [{"entity_id": "ACL_23_P_664-0-E0", "text": "Supervised visual captioning models", "role": "Agent"}, {"entity_id": "ACL_23_P_664-0-E1", "text": "collecting and labeling large-scale datasets is time-consuming and expensive for many scenarios and languages", "role": "Challenge"}, {"entity_id": "ACL_23_P_664-0-E2", "text": "Therefore, sufficient labeled pairs are usually not available", "role": "Challenge"}, {"entity_id": "ACL_23_P_664-0-E3", "text": "a large scale of images or videos", "role": "PrimaryObject"}]}], "entity_coreference": [], "event_coreference": [], "tokens": ["Supervised", "visual", "captioning", "models", "typically", "require", "a", "large", "scale", "of", "images", "or", "videos", "paired", "with", "descriptions", "in", "a", "specific", "language", "(i.e.,", "the", "vision-caption", "pairs)", "for", "training.", "However,", "collecting", "and", "labeling", "large-scale", "datasets", "is", "time-consuming", "and", "expensive", "for", "many", "scenarios", "and", "languages.", "Therefore,", "sufficient", "labeled", "pairs", "are", "usually", "not", "available."], "pieces": ["Super", "vised", "visual", "ca", "ption", "ing", "models", "typically", "require", "a", "large", "scale", "of", "images", "or", "videos", "pa", "ired", "with", "desc", "ript", "ions", "in", "a", "specific", "language", "(", "i", ".", "e", ".,", "the", "vision", "-", "ca", "ption", "p", "airs", ")", "for", "training", ".", "However", ",", "collect", "ing", "and", "label", "ing", "large", "-", "scale", "dat", "as", "ets", "is", "time", "-", "consuming", "and", "expensive", "for", "many", "sc", "en", "arios", "and", "l", "anguages", ".", "Therefore", ",", "sufficient", "label", "ed", "p", "airs", "are", "usually", "not", "available", "."], "token_lens": [2, 1, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 3, 1, 1, 1, 1, 5, 1, 4, 3, 1, 2, 2, 2, 1, 2, 3, 3, 1, 3, 1, 1, 1, 1, 3, 1, 3, 2, 1, 2, 2, 1, 1, 1, 2], "sentence": "Supervised visual captioning models typically require a large scale of images or videos paired with descriptions in a specific language (i.e., the vision-caption pairs) for training. However, collecting and labeling large-scale datasets is time-consuming and expensive for many scenarios and languages. Therefore, sufficient labeled pairs are usually not available.", "sentence_starts": [0]}
{"doc_id": "ACL_23_P_664", "wnd_id": "ACL_23_P_664-1", "entity_mentions": [{"id": "ACL_23_P_664-1-E0", "text": "we", "start": 7, "end": 8, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_664-1-E1", "text": "To deal with the label shortage problem", "start": 0, "end": 7, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_664-1-E2", "text": "generate visual captions for different scenarios and languages without any labeled vision-caption pairs of downstream datasets.", "start": 18, "end": 34, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_664-1-E3", "text": "In the training stage, MultiCapCLIP only requires text data for input", "start": 34, "end": 45, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_664-1-E4", "text": "retrieving concept prompts that preserve the corresponding domain knowledge of new scenarios", "start": 52, "end": 64, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_664-1-E5", "text": "auto-encoding the prompts to learn writing styles to output captions in a desired language", "start": 65, "end": 79, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_664-1-E6", "text": "In the testing stage, MultiCapCLIP instead takes visual data as input directly to retrieve the concept prompts to generate the final visual descriptions", "start": 79, "end": 102, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_664-1-E7", "text": "MultiCapCLIP", "start": 15, "end": 16, "entity_type": "UNK", "mention_type": "UNK"}], "relation_mentions": [], "event_mentions": [{"event_type": "Methods/Approach", "id": "ACL_23_P_664-1-EV0", "trigger": {"text": "present", "start": 8, "end": 9}, "arguments": [{"entity_id": "ACL_23_P_664-1-E0", "text": "we", "role": "Agent"}, {"entity_id": "ACL_23_P_664-1-E1", "text": "To deal with the label shortage problem", "role": "Purpose"}, {"entity_id": "ACL_23_P_664-1-E2", "text": "generate visual captions for different scenarios and languages without any labeled vision-caption pairs of downstream datasets.", "role": "Method"}, {"entity_id": "ACL_23_P_664-1-E3", "text": "In the training stage, MultiCapCLIP only requires text data for input", "role": "Method"}, {"entity_id": "ACL_23_P_664-1-E4", "text": "retrieving concept prompts that preserve the corresponding domain knowledge of new scenarios", "role": "Method"}, {"entity_id": "ACL_23_P_664-1-E5", "text": "auto-encoding the prompts to learn writing styles to output captions in a desired language", "role": "Method"}, {"entity_id": "ACL_23_P_664-1-E6", "text": "In the testing stage, MultiCapCLIP instead takes visual data as input directly to retrieve the concept prompts to generate the final visual descriptions", "role": "Method"}, {"entity_id": "ACL_23_P_664-1-E7", "text": "MultiCapCLIP", "role": "PrimaryObject"}]}], "entity_coreference": [], "event_coreference": [], "tokens": ["To", "deal", "with", "the", "label", "shortage", "problem,", "we", "present", "a", "simple", "yet", "effective", "zero-shot", "approach", "MultiCapCLIP", "that", "can", "generate", "visual", "captions", "for", "different", "scenarios", "and", "languages", "without", "any", "labeled", "vision-caption", "pairs", "of", "downstream", "datasets.", "In", "the", "training", "stage,", "MultiCapCLIP", "only", "requires", "text", "data", "for", "input.", "Then", "it", "conducts", "two", "main", "steps:", "1)", "retrieving", "concept", "prompts", "that", "preserve", "the", "corresponding", "domain", "knowledge", "of", "new", "scenarios;", "2)", "auto-encoding", "the", "prompts", "to", "learn", "writing", "styles", "to", "output", "captions", "in", "a", "desired", "language.", "In", "the", "testing", "stage,", "MultiCapCLIP", "instead", "takes", "visual", "data", "as", "input", "directly", "to", "retrieve", "the", "concept", "prompts", "to", "generate", "the", "final", "visual", "descriptions."], "pieces": ["To", "deal", "with", "the", "label", "short", "age", "problem", ",", "we", "present", "a", "simple", "yet", "effective", "zero", "-", "shot", "appro", "ach", "Multi", "Cap", "CL", "IP", "that", "can", "gener", "ate", "visual", "capt", "ions", "for", "different", "sc", "en", "arios", "and", "l", "anguages", "without", "any", "label", "ed", "vision", "-", "ca", "ption", "p", "airs", "of", "down", "stream", "dat", "as", "ets", ".", "In", "the", "training", "stage", ",", "Multi", "Cap", "CL", "IP", "only", "requires", "text", "data", "for", "input", ".", "Then", "it", "conduct", "s", "two", "main", "steps", ":", "1", ")", "ret", "rieving", "concept", "prom", "pt", "s", "that", "pres", "erve", "the", "cor", "respond", "ing", "domain", "knowledge", "of", "new", "sc", "en", "arios", ";", "2", ")", "auto", "-", "enc", "oding", "the", "prom", "pt", "s", "to", "learn", "writing", "styles", "to", "output", "capt", "ions", "in", "a", "des", "ired", "language", ".", "In", "the", "testing", "stage", ",", "Multi", "Cap", "CL", "IP", "instead", "t", "akes", "visual", "data", "as", "input", "direct", "ly", "to", "ret", "rieve", "the", "concept", "prom", "pt", "s", "to", "gener", "ate", "the", "final", "visual", "desc", "ript", "ions", "."], "token_lens": [1, 1, 1, 1, 1, 2, 2, 1, 1, 1, 1, 1, 1, 3, 2, 4, 1, 1, 2, 1, 2, 1, 1, 3, 1, 2, 1, 1, 2, 4, 2, 1, 2, 4, 1, 1, 1, 2, 4, 1, 1, 1, 1, 1, 2, 1, 1, 2, 1, 1, 2, 2, 2, 1, 3, 1, 2, 1, 3, 1, 1, 1, 1, 4, 2, 4, 1, 3, 1, 1, 1, 1, 1, 1, 2, 1, 1, 2, 2, 1, 1, 1, 2, 4, 1, 2, 1, 1, 1, 1, 2, 1, 2, 1, 1, 3, 1, 2, 1, 1, 1, 4], "sentence": "To deal with the label shortage problem, we present a simple yet effective zero-shot approach MultiCapCLIP that can generate visual captions for different scenarios and languages without any labeled vision-caption pairs of downstream datasets. In the training stage, MultiCapCLIP only requires text data for input. Then it conducts two main steps: 1) retrieving concept prompts that preserve the corresponding domain knowledge of new scenarios; 2) auto-encoding the prompts to learn writing styles to output captions in a desired language. In the testing stage, MultiCapCLIP instead takes visual data as input directly to retrieve the concept prompts to generate the final visual descriptions.", "sentence_starts": [0]}
{"doc_id": "ACL_23_P_664", "wnd_id": "ACL_23_P_664-2", "entity_mentions": [{"id": "ACL_23_P_664-2-E0", "text": "our method", "start": 33, "end": 35, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_664-2-E1", "text": "The extensive experiments on image and video captioning across four benchmarks and four languages (i.e., English, Chinese, German, and French) confirm the effectiveness of our approach", "start": 0, "end": 26, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_664-2-E2", "text": "4.8% and 21.5% absolute improvements", "start": 36, "end": 41, "entity_type": "UNK", "mention_type": "UNK"}], "relation_mentions": [], "event_mentions": [{"event_type": "Results/Findings", "id": "ACL_23_P_664-2-EV0", "trigger": {"text": "achieves", "start": 35, "end": 36}, "arguments": [{"entity_id": "ACL_23_P_664-2-E0", "text": "our method", "role": "Agent"}, {"entity_id": "ACL_23_P_664-2-E1", "text": "The extensive experiments on image and video captioning across four benchmarks and four languages (i.e., English, Chinese, German, and French) confirm the effectiveness of our approach", "role": "Results"}, {"entity_id": "ACL_23_P_664-2-E2", "text": "4.8% and 21.5% absolute improvements", "role": "PrimaryObject"}]}], "entity_coreference": [], "event_coreference": [], "tokens": ["The", "extensive", "experiments", "on", "image", "and", "video", "captioning", "across", "four", "benchmarks", "and", "four", "languages", "(i.e.,", "English,", "Chinese,", "German,", "and", "French)", "confirm", "the", "effectiveness", "of", "our", "approach.", "Compared", "with", "state-of-the-art", "zero-shot", "and", "weakly-supervised", "methods,", "our", "method", "achieves", "4.8%", "and", "21.5%", "absolute", "improvements", "in", "terms", "of", "BLEU@4", "and", "CIDEr", "metrics."], "pieces": ["The", "ext", "ensive", "exper", "iments", "on", "image", "and", "video", "ca", "ption", "ing", "ac", "ross", "four", "bench", "marks", "and", "four", "l", "anguages", "(", "i", ".", "e", ".,", "English", ",", "Chinese", ",", "German", ",", "and", "French", ")", "conf", "irm", "the", "effect", "iveness", "of", "our", "appro", "ach", ".", "Compared", "with", "state", "-", "of", "-", "the", "-", "art", "zero", "-", "shot", "and", "weak", "ly", "-", "super", "vised", "method", "s", ",", "our", "method", "ach", "ieves", "4", ".", "8", "%", "and", "21", ".", "5", "%", "absolute", "improve", "ments", "in", "terms", "of", "BLE", "U", "@", "4", "and", "C", "ID", "Er", "met", "rics", "."], "token_lens": [1, 2, 2, 1, 1, 1, 1, 3, 2, 1, 2, 1, 1, 2, 5, 2, 2, 2, 1, 2, 2, 1, 2, 1, 1, 3, 1, 1, 7, 3, 1, 5, 3, 1, 1, 2, 4, 1, 4, 1, 2, 1, 1, 1, 4, 1, 3, 3], "sentence": "The extensive experiments on image and video captioning across four benchmarks and four languages (i.e., English, Chinese, German, and French) confirm the effectiveness of our approach. Compared with state-of-the-art zero-shot and weakly-supervised methods, our method achieves 4.8% and 21.5% absolute improvements in terms of BLEU@4 and CIDEr metrics.", "sentence_starts": [0]}
{"doc_id": "ACL_23_P_605", "wnd_id": "ACL_23_P_605-0", "entity_mentions": [{"id": "ACL_23_P_605-0-E0", "text": "It", "start": 17, "end": 18, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_605-0-E1", "text": "Knowledge distillation (KD) is the process of transferring knowledge from a large model to a small one", "start": 0, "end": 17, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_605-0-E2", "text": "increasing attention", "start": 20, "end": 22, "entity_type": "UNK", "mention_type": "UNK"}], "relation_mentions": [], "event_mentions": [{"event_type": "Background/Introduction", "id": "ACL_23_P_605-0-EV0", "trigger": {"text": "has gained", "start": 18, "end": 20}, "arguments": [{"entity_id": "ACL_23_P_605-0-E0", "text": "It", "role": "Agent"}, {"entity_id": "ACL_23_P_605-0-E1", "text": "Knowledge distillation (KD) is the process of transferring knowledge from a large model to a small one", "role": "Context"}, {"entity_id": "ACL_23_P_605-0-E2", "text": "increasing attention", "role": "PrimaryObject"}]}], "entity_coreference": [], "event_coreference": [], "tokens": ["Knowledge", "distillation", "(KD)", "is", "the", "process", "of", "transferring", "knowledge", "from", "a", "large", "model", "to", "a", "small", "one.", "It", "has", "gained", "increasing", "attention", "in", "the", "natural", "language", "processing", "community,", "driven", "by", "the", "demands", "of", "compressing", "ever-growing", "language", "models."], "pieces": ["Know", "ledge", "dist", "illation", "(", "K", "D", ")", "is", "the", "process", "of", "transfer", "ring", "knowledge", "from", "a", "large", "model", "to", "a", "small", "one", ".", "It", "has", "g", "ained", "increasing", "att", "ention", "in", "the", "natural", "language", "processing", "community", ",", "driven", "by", "the", "dem", "ands", "of", "comp", "ressing", "ever", "-", "growing", "language", "models", "."], "token_lens": [2, 2, 4, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 2, 1, 2, 1, 1, 1, 1, 1, 2, 1, 1, 1, 2, 1, 2, 3, 1, 2], "sentence": "Knowledge distillation (KD) is the process of transferring knowledge from a large model to a small one. It has gained increasing attention in the natural language processing community, driven by the demands of compressing ever-growing language models.", "sentence_starts": [0]}
{"doc_id": "ACL_23_P_605", "wnd_id": "ACL_23_P_605-1", "entity_mentions": [{"id": "ACL_23_P_605-1-E0", "text": "we", "start": 3, "end": 4, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_605-1-E1", "text": "We propose four distilling variants under our framework and show that existing SeqKD and ENGINE approaches are approximations of our FDISTILL methods", "start": 19, "end": 41, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_605-1-E2", "text": "We further derive step-wise decomposition for our FDISTILL, reducing intractable sequence-level divergence to word-level losses that can be computed in a tractable manner", "start": 41, "end": 64, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_605-1-E3", "text": "an FDISTILL framework", "start": 5, "end": 8, "entity_type": "UNK", "mention_type": "UNK"}], "relation_mentions": [], "event_mentions": [{"event_type": "Methods/Approach", "id": "ACL_23_P_605-1-EV0", "trigger": {"text": "propose", "start": 4, "end": 5}, "arguments": [{"entity_id": "ACL_23_P_605-1-E0", "text": "we", "role": "Agent"}, {"entity_id": "ACL_23_P_605-1-E1", "text": "We propose four distilling variants under our framework and show that existing SeqKD and ENGINE approaches are approximations of our FDISTILL methods", "role": "Method"}, {"entity_id": "ACL_23_P_605-1-E2", "text": "We further derive step-wise decomposition for our FDISTILL, reducing intractable sequence-level divergence to word-level losses that can be computed in a tractable manner", "role": "Method"}, {"entity_id": "ACL_23_P_605-1-E3", "text": "an FDISTILL framework", "role": "PrimaryObject"}]}], "entity_coreference": [], "event_coreference": [], "tokens": ["In", "this", "work,", "we", "propose", "an", "FDISTILL", "framework,", "which", "formulates", "sequence-level", "knowledge", "distillation", "as", "minimizing", "a", "generalized", "f-divergence", "function.", "We", "propose", "four", "distilling", "variants", "under", "our", "framework", "and", "show", "that", "existing", "SeqKD", "and", "ENGINE", "approaches", "are", "approximations", "of", "our", "FDISTILL", "methods.", "We", "further", "derive", "step-wise", "decomposition", "for", "our", "FDISTILL,", "reducing", "intractable", "sequence-level", "divergence", "to", "word-level", "losses", "that", "can", "be", "computed", "in", "a", "tractable", "manner."], "pieces": ["In", "this", "work", ",", "we", "pro", "pose", "an", "FD", "IST", "ILL", "framework", ",", "which", "form", "ulates", "sequence", "-", "level", "knowledge", "dist", "illation", "as", "min", "im", "izing", "a", "general", "ized", "f", "-", "d", "iver", "gence", "function", ".", "We", "pro", "pose", "four", "dist", "illing", "vari", "ants", "under", "our", "framework", "and", "show", "that", "existing", "Se", "q", "K", "D", "and", "ENG", "INE", "appro", "aches", "are", "app", "rox", "im", "ations", "of", "our", "FD", "IST", "ILL", "method", "s", ".", "We", "f", "urther", "der", "ive", "step", "-", "wise", "dec", "om", "position", "for", "our", "FD", "IST", "ILL", ",", "red", "ucing", "int", "ract", "able", "sequence", "-", "level", "d", "iver", "gence", "to", "word", "-", "level", "loss", "es", "that", "can", "be", "com", "puted", "in", "a", "t", "ract", "able", "man", "ner", "."], "token_lens": [1, 1, 2, 1, 2, 1, 3, 2, 1, 2, 3, 1, 2, 1, 3, 1, 2, 5, 2, 1, 2, 1, 2, 2, 1, 1, 1, 1, 1, 1, 1, 4, 1, 2, 2, 1, 4, 1, 1, 3, 3, 1, 2, 2, 3, 3, 1, 1, 4, 2, 3, 3, 3, 1, 3, 2, 1, 1, 1, 2, 1, 1, 3, 3], "sentence": "In this work, we propose an FDISTILL framework, which formulates sequence-level knowledge distillation as minimizing a generalized f-divergence function. We propose four distilling variants under our framework and show that existing SeqKD and ENGINE approaches are approximations of our FDISTILL methods. We further derive step-wise decomposition for our FDISTILL, reducing intractable sequence-level divergence to word-level losses that can be computed in a tractable manner.", "sentence_starts": [0]}
{"doc_id": "ACL_23_P_605", "wnd_id": "ACL_23_P_605-2", "entity_mentions": [{"id": "ACL_23_P_605-2-E0", "text": "Experiments across four datasets", "start": 0, "end": 4, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_605-2-E1", "text": "our symmetric distilling losses can better force the student to learn from the teacher distribution", "start": 14, "end": 29, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_605-2-E2", "text": "our methods outperform existing KD approaches", "start": 6, "end": 12, "entity_type": "UNK", "mention_type": "UNK"}], "relation_mentions": [], "event_mentions": [{"event_type": "Results/Findings", "id": "ACL_23_P_605-2-EV0", "trigger": {"text": "show", "start": 4, "end": 5}, "arguments": [{"entity_id": "ACL_23_P_605-2-E0", "text": "Experiments across four datasets", "role": "Agent"}, {"entity_id": "ACL_23_P_605-2-E1", "text": "our symmetric distilling losses can better force the student to learn from the teacher distribution", "role": "Results"}, {"entity_id": "ACL_23_P_605-2-E2", "text": "our methods outperform existing KD approaches", "role": "PrimaryObject"}]}], "entity_coreference": [], "event_coreference": [], "tokens": ["Experiments", "across", "four", "datasets", "show", "that", "our", "methods", "outperform", "existing", "KD", "approaches,", "and", "that", "our", "symmetric", "distilling", "losses", "can", "better", "force", "the", "student", "to", "learn", "from", "the", "teacher", "distribution."], "pieces": ["Exper", "iments", "ac", "ross", "four", "dat", "as", "ets", "show", "that", "our", "method", "s", "out", "per", "form", "existing", "K", "D", "appro", "aches", ",", "and", "that", "our", "sy", "mm", "etric", "dist", "illing", "loss", "es", "can", "better", "force", "the", "student", "to", "learn", "from", "the", "te", "acher", "dist", "ribution", "."], "token_lens": [2, 2, 1, 3, 1, 1, 1, 2, 3, 1, 2, 3, 1, 1, 1, 3, 2, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 3], "sentence": "Experiments across four datasets show that our methods outperform existing KD approaches, and that our symmetric distilling losses can better force the student to learn from the teacher distribution.", "sentence_starts": [0]}
{"doc_id": "ACL_23_P_37", "wnd_id": "ACL_23_P_37-0", "entity_mentions": [{"id": "ACL_23_P_37-0-E0", "text": "most of today\u2019s fake news", "start": 8, "end": 13, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_37-0-E1", "text": "Most existing multi-modal fake news detection methods neglect the fact that some label-specific features learned from the training set cannot generalize well to the testing set, thus inevitably suffering from the harm caused by the latent data bias", "start": 21, "end": 59, "entity_type": "UNK", "mention_type": "UNK"}], "relation_mentions": [], "event_mentions": [{"event_type": "Background/Introduction", "id": "ACL_23_P_37-0-EV0", "trigger": {"text": "is published and spread", "start": 13, "end": 17}, "arguments": [{"entity_id": "ACL_23_P_37-0-E0", "text": "most of today\u2019s fake news", "role": "Agent"}, {"entity_id": "ACL_23_P_37-0-E1", "text": "Most existing multi-modal fake news detection methods neglect the fact that some label-specific features learned from the training set cannot generalize well to the testing set, thus inevitably suffering from the harm caused by the latent data bias", "role": "Challenge"}]}], "entity_coreference": [], "event_coreference": [], "tokens": ["Due", "to", "the", "rapid", "upgrade", "of", "social", "platforms,", "most", "of", "today\u2019s", "fake", "news", "is", "published", "and", "spread", "in", "a", "multi-modal", "form.", "Most", "existing", "multi-modal", "fake", "news", "detection", "methods", "neglect", "the", "fact", "that", "some", "label-specific", "features", "learned", "from", "the", "training", "set", "cannot", "generalize", "well", "to", "the", "testing", "set,", "thus", "inevitably", "suffering", "from", "the", "harm", "caused", "by", "the", "latent", "data", "bias."], "pieces": ["Due", "to", "the", "rap", "id", "up", "grade", "of", "social", "platform", "s", ",", "most", "of", "today", "\u00e2\u0122", "\u013b", "s", "fake", "news", "is", "published", "and", "spread", "in", "a", "multi", "-", "mod", "al", "form", ".", "Most", "existing", "multi", "-", "mod", "al", "fake", "news", "det", "ection", "method", "s", "neg", "lect", "the", "fact", "that", "some", "label", "-", "specific", "features", "learn", "ed", "from", "the", "training", "set", "c", "annot", "general", "ize", "well", "to", "the", "testing", "set", ",", "thus", "ine", "v", "itably", "suff", "ering", "from", "the", "harm", "ca", "used", "by", "the", "lat", "ent", "data", "b", "ias", "."], "token_lens": [1, 1, 1, 2, 2, 1, 1, 3, 1, 1, 4, 1, 1, 1, 1, 1, 1, 1, 1, 4, 2, 1, 1, 4, 1, 1, 2, 2, 2, 1, 1, 1, 1, 3, 1, 2, 1, 1, 1, 1, 2, 2, 1, 1, 1, 1, 2, 1, 3, 2, 1, 1, 1, 2, 1, 1, 2, 1, 3], "sentence": "Due to the rapid upgrade of social platforms, most of today\u2019s fake news is published and spread in a multi-modal form. Most existing multi-modal fake news detection methods neglect the fact that some label-specific features learned from the training set cannot generalize well to the testing set, thus inevitably suffering from the harm caused by the latent data bias.", "sentence_starts": [0]}
{"doc_id": "ACL_23_P_37", "wnd_id": "ACL_23_P_37-1", "entity_mentions": [{"id": "ACL_23_P_37-1-E0", "text": "we", "start": 3, "end": 4, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_37-1-E1", "text": "We mitigate these biases from a causality perspective and propose a Causal intervention and Counterfactual reasoning based Debiasing framework (CCD) for multi-modal fake news detection", "start": 25, "end": 50, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_37-1-E2", "text": "To achieve our goal, we first utilize causal intervention to remove the psycholinguistic bias which introduces the spurious correlations between text features and news label", "start": 50, "end": 75, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_37-1-E3", "text": "we apply counterfactual reasoning by imagining a counterfactual world where each news has only image features for estimating the direct effect of the image", "start": 77, "end": 101, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_37-1-E4", "text": "Therefore, we can eliminate the image-only bias by deducting the direct effect of the image from the total effect on labels", "start": 101, "end": 122, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_37-1-E5", "text": "the psycholinguistic bias in the text and the bias of inferring news label", "start": 7, "end": 20, "entity_type": "UNK", "mention_type": "UNK"}], "relation_mentions": [], "event_mentions": [{"event_type": "Methods/Approach", "id": "ACL_23_P_37-1-EV0", "trigger": {"text": "analyze and identify", "start": 4, "end": 7}, "arguments": [{"entity_id": "ACL_23_P_37-1-E0", "text": "we", "role": "Agent"}, {"entity_id": "ACL_23_P_37-1-E1", "text": "We mitigate these biases from a causality perspective and propose a Causal intervention and Counterfactual reasoning based Debiasing framework (CCD) for multi-modal fake news detection", "role": "Method"}, {"entity_id": "ACL_23_P_37-1-E2", "text": "To achieve our goal, we first utilize causal intervention to remove the psycholinguistic bias which introduces the spurious correlations between text features and news label", "role": "Method"}, {"entity_id": "ACL_23_P_37-1-E3", "text": "we apply counterfactual reasoning by imagining a counterfactual world where each news has only image features for estimating the direct effect of the image", "role": "Method"}, {"entity_id": "ACL_23_P_37-1-E4", "text": "Therefore, we can eliminate the image-only bias by deducting the direct effect of the image from the total effect on labels", "role": "Results"}, {"entity_id": "ACL_23_P_37-1-E5", "text": "the psycholinguistic bias in the text and the bias of inferring news label", "role": "PrimaryObject"}]}], "entity_coreference": [], "event_coreference": [], "tokens": ["In", "this", "paper,", "we", "analyze", "and", "identify", "the", "psycholinguistic", "bias", "in", "the", "text", "and", "the", "bias", "of", "inferring", "news", "label", "based", "on", "only", "image", "features.", "We", "mitigate", "these", "biases", "from", "a", "causality", "perspective", "and", "propose", "a", "Causal", "intervention", "and", "Counterfactual", "reasoning", "based", "Debiasing", "framework", "(CCD)", "for", "multi-modal", "fake", "news", "detection.", "To", "achieve", "our", "goal,", "we", "first", "utilize", "causal", "intervention", "to", "remove", "the", "psycholinguistic", "bias", "which", "introduces", "the", "spurious", "correlations", "between", "text", "features", "and", "news", "label.", "And", "then,", "we", "apply", "counterfactual", "reasoning", "by", "imagining", "a", "counterfactual", "world", "where", "each", "news", "has", "only", "image", "features", "for", "estimating", "the", "direct", "effect", "of", "the", "image.", "Therefore,", "we", "can", "eliminate", "the", "image-only", "bias", "by", "deducting", "the", "direct", "effect", "of", "the", "image", "from", "the", "total", "effect", "on", "labels."], "pieces": ["In", "this", "paper", ",", "we", "analy", "ze", "and", "ident", "ify", "the", "psych", "ol", "ingu", "istic", "b", "ias", "in", "the", "text", "and", "the", "b", "ias", "of", "in", "fer", "ring", "news", "label", "based", "on", "only", "image", "features", ".", "We", "mit", "igate", "these", "bi", "ases", "from", "a", "ca", "us", "ality", "pers", "pect", "ive", "and", "pro", "pose", "a", "Ca", "usal", "inter", "vention", "and", "Counter", "fact", "ual", "reason", "ing", "based", "Deb", "i", "asing", "framework", "(", "CC", "D", ")", "for", "multi", "-", "mod", "al", "fake", "news", "det", "ection", ".", "To", "ach", "ieve", "our", "goal", ",", "we", "first", "util", "ize", "ca", "usal", "inter", "vention", "to", "remove", "the", "psych", "ol", "ingu", "istic", "b", "ias", "which", "introdu", "ces", "the", "sp", "urious", "cor", "relations", "between", "text", "features", "and", "news", "label", ".", "And", "then", ",", "we", "apply", "counter", "fact", "ual", "reason", "ing", "by", "imag", "ining", "a", "counter", "fact", "ual", "world", "where", "each", "news", "has", "only", "image", "features", "for", "est", "imating", "the", "direct", "effect", "of", "the", "image", ".", "Therefore", ",", "we", "can", "el", "im", "inate", "the", "image", "-", "only", "b", "ias", "by", "ded", "uct", "ing", "the", "direct", "effect", "of", "the", "image", "from", "the", "total", "effect", "on", "lab", "els", "."], "token_lens": [1, 1, 2, 1, 2, 1, 2, 1, 4, 2, 1, 1, 1, 1, 1, 2, 1, 3, 1, 1, 1, 1, 1, 1, 2, 1, 2, 1, 2, 1, 1, 3, 3, 1, 2, 1, 2, 2, 1, 3, 2, 1, 3, 1, 4, 1, 4, 1, 1, 3, 1, 2, 1, 2, 1, 1, 2, 2, 2, 1, 1, 1, 4, 2, 1, 2, 1, 2, 2, 1, 1, 1, 1, 1, 2, 1, 2, 1, 1, 3, 2, 1, 2, 1, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 2, 2, 1, 1, 3, 1, 3, 2, 1, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 3], "sentence": "In this paper, we analyze and identify the psycholinguistic bias in the text and the bias of inferring news label based on only image features. We mitigate these biases from a causality perspective and propose a Causal intervention and Counterfactual reasoning based Debiasing framework (CCD) for multi-modal fake news detection. To achieve our goal, we first utilize causal intervention to remove the psycholinguistic bias which introduces the spurious correlations between text features and news label. And then, we apply counterfactual reasoning by imagining a counterfactual world where each news has only image features for estimating the direct effect of the image. Therefore, we can eliminate the image-only bias by deducting the direct effect of the image from the total effect on labels.", "sentence_starts": [0]}
{"doc_id": "ACL_23_P_37", "wnd_id": "ACL_23_P_37-2", "entity_mentions": [{"id": "ACL_23_P_37-2-E0", "text": "Extensive experiments on two real-world benchmark datasets", "start": 0, "end": 7, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_37-2-E1", "text": "the effectiveness of our framework", "start": 8, "end": 13, "entity_type": "UNK", "mention_type": "UNK"}], "relation_mentions": [], "event_mentions": [{"event_type": "Results/Findings", "id": "ACL_23_P_37-2-EV0", "trigger": {"text": "demonstrate", "start": 7, "end": 8}, "arguments": [{"entity_id": "ACL_23_P_37-2-E0", "text": "Extensive experiments on two real-world benchmark datasets", "role": "Agent"}, {"entity_id": "ACL_23_P_37-2-E1", "text": "the effectiveness of our framework", "role": "PrimaryObject"}]}], "entity_coreference": [], "event_coreference": [], "tokens": ["Extensive", "experiments", "on", "two", "real-world", "benchmark", "datasets", "demonstrate", "the", "effectiveness", "of", "our", "framework", "for", "improving", "multi-modal", "fake", "news", "detection."], "pieces": ["Ext", "ensive", "exper", "iments", "on", "two", "real", "-", "world", "bench", "mark", "dat", "as", "ets", "demon", "strate", "the", "effect", "iveness", "of", "our", "framework", "for", "impro", "ving", "multi", "-", "mod", "al", "fake", "news", "det", "ection", "."], "token_lens": [2, 2, 1, 1, 3, 2, 3, 2, 1, 2, 1, 1, 1, 1, 2, 4, 1, 1, 3], "sentence": "Extensive experiments on two real-world benchmark datasets demonstrate the effectiveness of our framework for improving multi-modal fake news detection.", "sentence_starts": [0]}
{"doc_id": "ACL_23_P_507", "wnd_id": "ACL_23_P_507-0", "entity_mentions": [{"id": "ACL_23_P_507-0-E0", "text": "We", "start": 0, "end": 1, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_507-0-E1", "text": "WinoQueer", "start": 2, "end": 3, "entity_type": "UNK", "mention_type": "UNK"}], "relation_mentions": [], "event_mentions": [{"event_type": "Background/Introduction", "id": "ACL_23_P_507-0-EV0", "trigger": {"text": "present", "start": 1, "end": 2}, "arguments": [{"entity_id": "ACL_23_P_507-0-E0", "text": "We", "role": "Agent"}, {"entity_id": "ACL_23_P_507-0-E1", "text": "WinoQueer", "role": "PrimaryObject"}]}], "entity_coreference": [], "event_coreference": [], "tokens": ["We", "present", "WinoQueer:", "a", "benchmark", "specifically", "designed", "to", "measure", "whether", "large", "language", "models", "(LLMs)", "encode", "biases", "that", "are", "harmful", "to", "the", "LGBTQ+", "community."], "pieces": ["We", "present", "W", "ino", "Que", "er", ":", "a", "bench", "mark", "specific", "ally", "designed", "to", "me", "asure", "whether", "large", "language", "models", "(", "LL", "Ms", ")", "en", "code", "bi", "ases", "that", "are", "harm", "ful", "to", "the", "LGBT", "Q", "+", "community", "."], "token_lens": [1, 1, 5, 1, 2, 2, 1, 1, 2, 1, 1, 1, 1, 4, 2, 2, 1, 1, 2, 1, 1, 3, 2], "sentence": "We present WinoQueer: a benchmark specifically designed to measure whether large language models (LLMs) encode biases that are harmful to the LGBTQ+ community.", "sentence_starts": [0]}
{"doc_id": "ACL_23_P_507", "wnd_id": "ACL_23_P_507-1", "entity_mentions": [{"id": "ACL_23_P_507-1-E0", "text": "We", "start": 19, "end": 20, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_507-1-E1", "text": "The benchmark is community-sourced, via application of a novel method that generates a bias benchmark from a community survey", "start": 0, "end": 19, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_507-1-E2", "text": "find that off-the-shelf models generally do exhibit considerable anti-queer bias", "start": 28, "end": 38, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_507-1-E3", "text": "our benchmark", "start": 21, "end": 23, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_507-1-E4", "text": "to several popular LLMs", "start": 23, "end": 27, "entity_type": "UNK", "mention_type": "UNK"}], "relation_mentions": [], "event_mentions": [{"event_type": "Methods/Approach", "id": "ACL_23_P_507-1-EV0", "trigger": {"text": "apply", "start": 20, "end": 21}, "arguments": [{"entity_id": "ACL_23_P_507-1-E0", "text": "We", "role": "Agent"}, {"entity_id": "ACL_23_P_507-1-E1", "text": "The benchmark is community-sourced, via application of a novel method that generates a bias benchmark from a community survey", "role": "Method"}, {"entity_id": "ACL_23_P_507-1-E2", "text": "find that off-the-shelf models generally do exhibit considerable anti-queer bias", "role": "Results"}, {"entity_id": "ACL_23_P_507-1-E3", "text": "our benchmark", "role": "PrimaryObject"}, {"entity_id": "ACL_23_P_507-1-E4", "text": "to several popular LLMs", "role": "SecondaryObject"}]}], "entity_coreference": [], "event_coreference": [], "tokens": ["The", "benchmark", "is", "community-sourced,", "via", "application", "of", "a", "novel", "method", "that", "generates", "a", "bias", "benchmark", "from", "a", "community", "survey.", "We", "apply", "our", "benchmark", "to", "several", "popular", "LLMs", "and", "find", "that", "off-the-shelf", "models", "generally", "do", "exhibit", "considerable", "anti-queer", "bias."], "pieces": ["The", "bench", "mark", "is", "community", "-", "s", "ourced", ",", "via", "application", "of", "a", "no", "vel", "method", "that", "gener", "ates", "a", "b", "ias", "bench", "mark", "from", "a", "community", "sur", "vey", ".", "We", "apply", "our", "bench", "mark", "to", "sever", "al", "popular", "LL", "Ms", "and", "find", "that", "off", "-", "the", "-", "she", "lf", "models", "gener", "ally", "do", "ex", "hibit", "consider", "able", "anti", "-", "que", "er", "b", "ias", "."], "token_lens": [1, 2, 1, 5, 1, 1, 1, 1, 2, 1, 1, 2, 1, 2, 2, 1, 1, 1, 3, 1, 1, 1, 2, 1, 2, 1, 2, 1, 1, 1, 6, 1, 2, 1, 2, 2, 4, 3], "sentence": "The benchmark is community-sourced, via application of a novel method that generates a bias benchmark from a community survey. We apply our benchmark to several popular LLMs and find that off-the-shelf models generally do exhibit considerable anti-queer bias.", "sentence_starts": [0]}
{"doc_id": "ACL_23_P_507", "wnd_id": "ACL_23_P_507-2", "entity_mentions": [{"id": "ACL_23_P_507-2-E0", "text": "we", "start": 1, "end": 2, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_507-2-E1", "text": "LLM bias against a marginalized community can be somewhat mitigated by finetuning on data written about or by members of that community", "start": 4, "end": 26, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_507-2-E2", "text": "social media text written by community members is more effective than news text written about the community by non-members", "start": 28, "end": 47, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_507-2-E3", "text": "LLM bias against a marginalized community can be somewhat mitigated by finetuning on data written about or by members of that community", "start": 4, "end": 26, "entity_type": "UNK", "mention_type": "UNK"}], "relation_mentions": [], "event_mentions": [{"event_type": "Results/Findings", "id": "ACL_23_P_507-2-EV0", "trigger": {"text": "show", "start": 2, "end": 3}, "arguments": [{"entity_id": "ACL_23_P_507-2-E0", "text": "we", "role": "Agent"}, {"entity_id": "ACL_23_P_507-2-E1", "text": "LLM bias against a marginalized community can be somewhat mitigated by finetuning on data written about or by members of that community", "role": "Results"}, {"entity_id": "ACL_23_P_507-2-E2", "text": "social media text written by community members is more effective than news text written about the community by non-members", "role": "Results"}, {"entity_id": "ACL_23_P_507-2-E3", "text": "LLM bias against a marginalized community can be somewhat mitigated by finetuning on data written about or by members of that community", "role": "PrimaryObject"}]}], "entity_coreference": [], "event_coreference": [], "tokens": ["Finally,", "we", "show", "that", "LLM", "bias", "against", "a", "marginalized", "community", "can", "be", "somewhat", "mitigated", "by", "finetuning", "on", "data", "written", "about", "or", "by", "members", "of", "that", "community,", "and", "that", "social", "media", "text", "written", "by", "community", "members", "is", "more", "effective", "than", "news", "text", "written", "about", "the", "community", "by", "non-members."], "pieces": ["Finally", ",", "we", "show", "that", "LL", "M", "b", "ias", "against", "a", "marg", "inal", "ized", "community", "can", "be", "s", "omew", "hat", "mit", "igated", "by", "fin", "et", "uning", "on", "data", "written", "about", "or", "by", "members", "of", "that", "community", ",", "and", "that", "social", "media", "text", "written", "by", "community", "members", "is", "more", "effective", "than", "news", "text", "written", "about", "the", "community", "by", "non", "-", "members", "."], "token_lens": [2, 1, 1, 1, 2, 2, 1, 1, 3, 1, 1, 1, 3, 2, 1, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 4], "sentence": "Finally, we show that LLM bias against a marginalized community can be somewhat mitigated by finetuning on data written about or by members of that community, and that social media text written by community members is more effective than news text written about the community by non-members.", "sentence_starts": [0]}
{"doc_id": "ACL_23_P_507", "wnd_id": "ACL_23_P_507-3", "entity_mentions": [{"id": "ACL_23_P_507-3-E0", "text": "Our method for community-in-the-loop benchmark development", "start": 0, "end": 6, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_507-3-E1", "text": "to develop community-driven, harms-grounded LLM benchmarks for other marginalized communities", "start": 12, "end": 22, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_507-3-E2", "text": "a blueprint", "start": 7, "end": 9, "entity_type": "UNK", "mention_type": "UNK"}], "relation_mentions": [], "event_mentions": [{"event_type": "Conclusions/Implications", "id": "ACL_23_P_507-3-EV0", "trigger": {"text": "provides", "start": 6, "end": 7}, "arguments": [{"entity_id": "ACL_23_P_507-3-E0", "text": "Our method for community-in-the-loop benchmark development", "role": "Agent"}, {"entity_id": "ACL_23_P_507-3-E1", "text": "to develop community-driven, harms-grounded LLM benchmarks for other marginalized communities", "role": "Purpose"}, {"entity_id": "ACL_23_P_507-3-E2", "text": "a blueprint", "role": "PrimaryObject"}]}], "entity_coreference": [], "event_coreference": [], "tokens": ["Our", "method", "for", "community-in-the-loop", "benchmark", "development", "provides", "a", "blueprint", "for", "future", "researchers", "to", "develop", "community-driven,", "harms-grounded", "LLM", "benchmarks", "for", "other", "marginalized", "communities."], "pieces": ["Our", "method", "for", "community", "-", "in", "-", "the", "-", "loop", "bench", "mark", "development", "prov", "ides", "a", "blue", "print", "for", "future", "re", "se", "ar", "chers", "to", "develop", "community", "-", "driven", ",", "h", "arms", "-", "ground", "ed", "LL", "M", "bench", "marks", "for", "other", "marg", "inal", "ized", "commun", "ities", "."], "token_lens": [1, 1, 1, 7, 2, 1, 2, 1, 2, 1, 1, 4, 1, 1, 4, 5, 2, 2, 1, 1, 3, 3], "sentence": "Our method for community-in-the-loop benchmark development provides a blueprint for future researchers to develop community-driven, harms-grounded LLM benchmarks for other marginalized communities.", "sentence_starts": [0]}
{"doc_id": "ACL_23_P_653", "wnd_id": "ACL_23_P_653-0", "entity_mentions": [{"id": "ACL_23_P_653-0-E0", "text": "The BLOOM model", "start": 0, "end": 3, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_653-0-E1", "text": "To extend the benefits of BLOOM to other languages without incurring prohibitively large costs, it is desirable to adapt BLOOM to new languages not seen during pretraining", "start": 19, "end": 46, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_653-0-E2", "text": "its pretraining was limited to 46 languages", "start": 12, "end": 19, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_653-0-E3", "text": "a large publicly available multilingual language model", "start": 4, "end": 11, "entity_type": "UNK", "mention_type": "UNK"}], "relation_mentions": [], "event_mentions": [{"event_type": "Background/Introduction", "id": "ACL_23_P_653-0-EV0", "trigger": {"text": "is", "start": 3, "end": 4}, "arguments": [{"entity_id": "ACL_23_P_653-0-E0", "text": "The BLOOM model", "role": "Agent"}, {"entity_id": "ACL_23_P_653-0-E1", "text": "To extend the benefits of BLOOM to other languages without incurring prohibitively large costs, it is desirable to adapt BLOOM to new languages not seen during pretraining", "role": "Purpose"}, {"entity_id": "ACL_23_P_653-0-E2", "text": "its pretraining was limited to 46 languages", "role": "Challenge"}, {"entity_id": "ACL_23_P_653-0-E3", "text": "a large publicly available multilingual language model", "role": "PrimaryObject"}]}], "entity_coreference": [], "event_coreference": [], "tokens": ["The", "BLOOM", "model", "is", "a", "large", "publicly", "available", "multilingual", "language", "model,", "but", "its", "pretraining", "was", "limited", "to", "46", "languages.", "To", "extend", "the", "benefits", "of", "BLOOM", "to", "other", "languages", "without", "incurring", "prohibitively", "large", "costs,", "it", "is", "desirable", "to", "adapt", "BLOOM", "to", "new", "languages", "not", "seen", "during", "pretraining."], "pieces": ["The", "BL", "O", "OM", "model", "is", "a", "large", "public", "ly", "available", "mult", "ilingual", "language", "model", ",", "but", "its", "pret", "raining", "was", "limited", "to", "46", "l", "anguages", ".", "To", "ext", "end", "the", "benef", "its", "of", "BL", "O", "OM", "to", "other", "l", "anguages", "without", "inc", "urring", "pro", "hib", "itive", "ly", "large", "cost", "s", ",", "it", "is", "des", "irable", "to", "adapt", "BL", "O", "OM", "to", "new", "l", "anguages", "not", "seen", "during", "pret", "raining", "."], "token_lens": [1, 3, 1, 1, 1, 1, 2, 1, 2, 1, 2, 1, 1, 2, 1, 1, 1, 1, 3, 1, 2, 1, 2, 1, 3, 1, 1, 2, 1, 2, 4, 1, 3, 1, 1, 2, 1, 1, 3, 1, 1, 2, 1, 1, 1, 3], "sentence": "The BLOOM model is a large publicly available multilingual language model, but its pretraining was limited to 46 languages. To extend the benefits of BLOOM to other languages without incurring prohibitively large costs, it is desirable to adapt BLOOM to new languages not seen during pretraining.", "sentence_starts": [0]}
{"doc_id": "ACL_23_P_653", "wnd_id": "ACL_23_P_653-1", "entity_mentions": [{"id": "ACL_23_P_653-1-E0", "text": "we", "start": 3, "end": 4, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_653-1-E1", "text": "We find language adaptation to be effective at improving zero-shot performance in new languages", "start": 25, "end": 39, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_653-1-E2", "text": "adapter-based finetuning is more effective than continued pretraining for large models", "start": 43, "end": 54, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_653-1-E3", "text": "prompting performance is not significantly affected by language specifics, such as the writing system", "start": 59, "end": 73, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_653-1-E4", "text": "It is primarily determined by the size of the language adaptation data", "start": 73, "end": 85, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_653-1-E5", "text": "existing language adaptation strategies", "start": 5, "end": 9, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_653-1-E6", "text": "to BLOOM", "start": 9, "end": 11, "entity_type": "UNK", "mention_type": "UNK"}], "relation_mentions": [], "event_mentions": [{"event_type": "Methods/Approach", "id": "ACL_23_P_653-1-EV0", "trigger": {"text": "apply", "start": 4, "end": 5}, "arguments": [{"entity_id": "ACL_23_P_653-1-E0", "text": "we", "role": "Agent"}, {"entity_id": "ACL_23_P_653-1-E1", "text": "We find language adaptation to be effective at improving zero-shot performance in new languages", "role": "Results"}, {"entity_id": "ACL_23_P_653-1-E2", "text": "adapter-based finetuning is more effective than continued pretraining for large models", "role": "Results"}, {"entity_id": "ACL_23_P_653-1-E3", "text": "prompting performance is not significantly affected by language specifics, such as the writing system", "role": "Results"}, {"entity_id": "ACL_23_P_653-1-E4", "text": "It is primarily determined by the size of the language adaptation data", "role": "Results"}, {"entity_id": "ACL_23_P_653-1-E5", "text": "existing language adaptation strategies", "role": "PrimaryObject"}, {"entity_id": "ACL_23_P_653-1-E6", "text": "to BLOOM", "role": "SecondaryObject"}]}], "entity_coreference": [], "event_coreference": [], "tokens": ["In", "this", "work,", "we", "apply", "existing", "language", "adaptation", "strategies", "to", "BLOOM", "and", "benchmark", "its", "zero-shot", "prompting", "performance", "on", "eight", "new", "languages", "in", "a", "resource-constrained", "setting.", "We", "find", "language", "adaptation", "to", "be", "effective", "at", "improving", "zero-shot", "performance", "in", "new", "languages.", "Surprisingly,", "we", "find", "that", "adapter-based", "finetuning", "is", "more", "effective", "than", "continued", "pretraining", "for", "large", "models.", "In", "addition,", "we", "discover", "that", "prompting", "performance", "is", "not", "significantly", "affected", "by", "language", "specifics,", "such", "as", "the", "writing", "system.", "It", "is", "primarily", "determined", "by", "the", "size", "of", "the", "language", "adaptation", "data."], "pieces": ["In", "this", "work", ",", "we", "apply", "existing", "language", "adapt", "ation", "str", "ateg", "ies", "to", "BL", "O", "OM", "and", "bench", "mark", "its", "zero", "-", "shot", "prom", "pt", "ing", "performance", "on", "eight", "new", "l", "anguages", "in", "a", "resource", "-", "con", "str", "ained", "setting", ".", "We", "find", "language", "adapt", "ation", "to", "be", "effective", "at", "impro", "ving", "zero", "-", "shot", "performance", "in", "new", "l", "anguages", ".", "Sur", "prisingly", ",", "we", "find", "that", "ad", "apter", "-", "based", "fin", "et", "uning", "is", "more", "effective", "than", "contin", "ued", "pret", "raining", "for", "large", "models", ".", "In", "add", "ition", ",", "we", "d", "iscover", "that", "prom", "pt", "ing", "performance", "is", "not", "sign", "ificantly", "affected", "by", "language", "specific", "s", ",", "such", "as", "the", "writing", "system", ".", "It", "is", "prim", "arily", "d", "etermined", "by", "the", "size", "of", "the", "language", "adapt", "ation", "data", "."], "token_lens": [1, 1, 2, 1, 1, 1, 1, 2, 3, 1, 3, 1, 2, 1, 3, 3, 1, 1, 1, 1, 2, 1, 1, 5, 2, 1, 1, 1, 2, 1, 1, 1, 1, 2, 3, 1, 1, 1, 3, 3, 1, 1, 1, 4, 3, 1, 1, 1, 1, 2, 2, 1, 1, 2, 1, 3, 1, 2, 1, 3, 1, 1, 1, 2, 1, 1, 1, 3, 1, 1, 1, 1, 2, 1, 1, 2, 2, 1, 1, 1, 1, 1, 1, 2, 2], "sentence": "In this work, we apply existing language adaptation strategies to BLOOM and benchmark its zero-shot prompting performance on eight new languages in a resource-constrained setting. We find language adaptation to be effective at improving zero-shot performance in new languages. Surprisingly, we find that adapter-based finetuning is more effective than continued pretraining for large models. In addition, we discover that prompting performance is not significantly affected by language specifics, such as the writing system. It is primarily determined by the size of the language adaptation data.", "sentence_starts": [0]}
{"doc_id": "ACL_23_P_653", "wnd_id": "ACL_23_P_653-2", "entity_mentions": [{"id": "ACL_23_P_653-2-E0", "text": "We", "start": 0, "end": 1, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_653-2-E1", "text": "We find including a new language in the multitask fine-tuning mixture to be the most effective method to teach BLOOMZ a new language", "start": 21, "end": 44, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_653-2-E2", "text": "We conclude that with sufficient training data, language adaptation can generalize well to diverse languages", "start": 44, "end": 59, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_653-2-E3", "text": "new languages", "start": 3, "end": 5, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_653-2-E4", "text": "to BLOOMZ", "start": 5, "end": 7, "entity_type": "UNK", "mention_type": "UNK"}], "relation_mentions": [], "event_mentions": [{"event_type": "Results/Findings", "id": "ACL_23_P_653-2-EV0", "trigger": {"text": "add", "start": 2, "end": 3}, "arguments": [{"entity_id": "ACL_23_P_653-2-E0", "text": "We", "role": "Agent"}, {"entity_id": "ACL_23_P_653-2-E1", "text": "We find including a new language in the multitask fine-tuning mixture to be the most effective method to teach BLOOMZ a new language", "role": "Results"}, {"entity_id": "ACL_23_P_653-2-E2", "text": "We conclude that with sufficient training data, language adaptation can generalize well to diverse languages", "role": "Results"}, {"entity_id": "ACL_23_P_653-2-E3", "text": "new languages", "role": "PrimaryObject"}, {"entity_id": "ACL_23_P_653-2-E4", "text": "to BLOOMZ", "role": "SecondaryObject"}]}], "entity_coreference": [], "event_coreference": [], "tokens": ["We", "also", "add", "new", "languages", "to", "BLOOMZ,", "which", "is", "a", "multitask", "finetuned", "version", "of", "BLOOM", "capable", "of", "following", "task", "instructions", "zero-shot.", "We", "find", "including", "a", "new", "language", "in", "the", "multitask", "fine-tuning", "mixture", "to", "be", "the", "most", "effective", "method", "to", "teach", "BLOOMZ", "a", "new", "language.", "We", "conclude", "that", "with", "sufficient", "training", "data,", "language", "adaptation", "can", "generalize", "well", "to", "diverse", "languages."], "pieces": ["We", "also", "add", "new", "l", "anguages", "to", "BL", "O", "OM", "Z", ",", "which", "is", "a", "mult", "it", "ask", "fin", "et", "uned", "version", "of", "BL", "O", "OM", "cap", "able", "of", "follow", "ing", "task", "in", "struct", "ions", "zero", "-", "shot", ".", "We", "find", "including", "a", "new", "language", "in", "the", "mult", "it", "ask", "fine", "-", "tun", "ing", "m", "ixture", "to", "be", "the", "most", "effective", "method", "to", "te", "ach", "BL", "O", "OM", "Z", "a", "new", "language", ".", "We", "con", "clude", "that", "with", "sufficient", "training", "data", ",", "language", "adapt", "ation", "can", "general", "ize", "well", "to", "d", "iverse", "l", "anguages", "."], "token_lens": [1, 1, 1, 1, 2, 1, 5, 1, 1, 1, 3, 3, 1, 1, 3, 2, 1, 2, 1, 3, 4, 1, 1, 1, 1, 1, 1, 1, 1, 3, 4, 2, 1, 1, 1, 1, 1, 1, 1, 2, 4, 1, 1, 2, 1, 2, 1, 1, 1, 1, 2, 1, 2, 1, 2, 1, 1, 2, 3], "sentence": "We also add new languages to BLOOMZ, which is a multitask finetuned version of BLOOM capable of following task instructions zero-shot. We find including a new language in the multitask fine-tuning mixture to be the most effective method to teach BLOOMZ a new language. We conclude that with sufficient training data, language adaptation can generalize well to diverse languages.", "sentence_starts": [0]}
{"doc_id": "ACL_23_P_23", "wnd_id": "ACL_23_P_23-0", "entity_mentions": [{"id": "ACL_23_P_23-0-E0", "text": "we", "start": 11, "end": 12, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_23-0-E1", "text": "Exclusion is particularly harmful in one of the most popular NLP applications, machine translation (MT)", "start": 18, "end": 33, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_23-0-E2", "text": "Wrong pronoun translations can discriminate against marginalized groups, e.g., non-binary individuals (Dev et al., 2021)", "start": 33, "end": 48, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_23-0-E3", "text": "more research", "start": 13, "end": 15, "entity_type": "UNK", "mention_type": "UNK"}], "relation_mentions": [], "event_mentions": [{"event_type": "Background/Introduction", "id": "ACL_23_P_23-0-EV0", "trigger": {"text": "need", "start": 12, "end": 13}, "arguments": [{"entity_id": "ACL_23_P_23-0-E0", "text": "we", "role": "Agent"}, {"entity_id": "ACL_23_P_23-0-E1", "text": "Exclusion is particularly harmful in one of the most popular NLP applications, machine translation (MT)", "role": "Challenge"}, {"entity_id": "ACL_23_P_23-0-E2", "text": "Wrong pronoun translations can discriminate against marginalized groups, e.g., non-binary individuals (Dev et al., 2021)", "role": "Challenge"}, {"entity_id": "ACL_23_P_23-0-E3", "text": "more research", "role": "PrimaryObject"}]}], "entity_coreference": [], "event_coreference": [], "tokens": ["As", "3rd-person", "pronoun", "usage", "shifts", "to", "include", "novel", "forms,", "e.g.,", "neopronouns,", "we", "need", "more", "research", "on", "identity-inclusive", "NLP.", "Exclusion", "is", "particularly", "harmful", "in", "one", "of", "the", "most", "popular", "NLP", "applications,", "machine", "translation", "(MT).", "Wrong", "pronoun", "translations", "can", "discriminate", "against", "marginalized", "groups,", "e.g.,", "non-binary", "individuals", "(Dev", "et", "al.,", "2021)."], "pieces": ["As", "3", "rd", "-", "person", "pron", "oun", "usage", "sh", "ifts", "to", "include", "no", "vel", "forms", ",", "e", ".", "g", ".,", "ne", "op", "ron", "oun", "s", ",", "we", "need", "more", "research", "on", "ident", "ity", "-", "in", "clusive", "N", "LP", ".", "Ex", "clusion", "is", "particularly", "harm", "ful", "in", "one", "of", "the", "most", "popular", "N", "LP", "app", "lic", "ations", ",", "machine", "translation", "(", "MT", ").", "Wr", "ong", "pron", "oun", "trans", "lations", "can", "disc", "rim", "inate", "against", "marg", "inal", "ized", "groups", ",", "e", ".", "g", ".,", "non", "-", "binary", "individual", "s", "(", "Dev", "et", "al", ".,", "20", "21", ")."], "token_lens": [1, 4, 2, 1, 2, 1, 1, 2, 2, 4, 6, 1, 1, 1, 1, 1, 5, 3, 2, 1, 1, 2, 1, 1, 1, 1, 1, 1, 2, 4, 1, 1, 3, 2, 2, 2, 1, 3, 1, 3, 2, 4, 3, 2, 2, 1, 2, 3], "sentence": "As 3rd-person pronoun usage shifts to include novel forms, e.g., neopronouns, we need more research on identity-inclusive NLP. Exclusion is particularly harmful in one of the most popular NLP applications, machine translation (MT). Wrong pronoun translations can discriminate against marginalized groups, e.g., non-binary individuals (Dev et al., 2021).", "sentence_starts": [0]}
{"doc_id": "ACL_23_P_23", "wnd_id": "ACL_23_P_23-1", "entity_mentions": [{"id": "ACL_23_P_23-1-E0", "text": "we", "start": 4, "end": 5, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_23-1-E1", "text": "we compare the translations of gendered vs. gender-neutral pronouns from English to five other languages (Danish, Farsi, French, German, Italian), and vice versa, from Danish to English", "start": 15, "end": 42, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_23-1-E2", "text": "how three commercial MT systems translate 3rd-person pronouns.", "start": 6, "end": 14, "entity_type": "UNK", "mention_type": "UNK"}], "relation_mentions": [], "event_mentions": [{"event_type": "Methods/Approach", "id": "ACL_23_P_23-1-EV0", "trigger": {"text": "study", "start": 5, "end": 6}, "arguments": [{"entity_id": "ACL_23_P_23-1-E0", "text": "we", "role": "Agent"}, {"entity_id": "ACL_23_P_23-1-E1", "text": "we compare the translations of gendered vs. gender-neutral pronouns from English to five other languages (Danish, Farsi, French, German, Italian), and vice versa, from Danish to English", "role": "Method"}, {"entity_id": "ACL_23_P_23-1-E2", "text": "how three commercial MT systems translate 3rd-person pronouns.", "role": "PrimaryObject"}]}], "entity_coreference": [], "event_coreference": [], "tokens": ["In", "this", "\u201creality", "check\u201d,", "we", "study", "how", "three", "commercial", "MT", "systems", "translate", "3rd-person", "pronouns.", "Concretely,", "we", "compare", "the", "translations", "of", "gendered", "vs.", "gender-neutral", "pronouns", "from", "English", "to", "five", "other", "languages", "(Danish,", "Farsi,", "French,", "German,", "Italian),", "and", "vice", "versa,", "from", "Danish", "to", "English."], "pieces": ["In", "this", "\u00e2\u0122", "\u013e", "reality", "check", "\u00e2\u0122", "\u013f", ",", "we", "study", "how", "three", "commercial", "MT", "system", "s", "trans", "late", "3", "rd", "-", "person", "pron", "oun", "s", ".", "Con", "crete", "ly", ",", "we", "comp", "are", "the", "trans", "lations", "of", "g", "endered", "vs", ".", "gender", "-", "neutral", "pron", "oun", "s", "from", "English", "to", "five", "other", "l", "anguages", "(", "D", "anish", ",", "F", "ars", "i", ",", "French", ",", "German", ",", "Italian", "),", "and", "vice", "vers", "a", ",", "from", "D", "anish", "to", "English", "."], "token_lens": [1, 1, 3, 4, 1, 1, 1, 1, 1, 1, 2, 2, 4, 4, 4, 1, 2, 1, 2, 1, 2, 2, 3, 3, 1, 1, 1, 1, 1, 2, 4, 4, 2, 2, 2, 1, 1, 3, 1, 2, 1, 2], "sentence": "In this \u201creality check\u201d, we study how three commercial MT systems translate 3rd-person pronouns. Concretely, we compare the translations of gendered vs. gender-neutral pronouns from English to five other languages (Danish, Farsi, French, German, Italian), and vice versa, from Danish to English.", "sentence_starts": [0]}
{"doc_id": "ACL_23_P_23", "wnd_id": "ACL_23_P_23-2", "entity_mentions": [{"id": "ACL_23_P_23-2-E0", "text": "Our error analysis", "start": 0, "end": 3, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_23-2-E1", "text": "the presence of a gender-neutral pronoun often leads to grammatical and semantic translation errors", "start": 5, "end": 19, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_23-2-E2", "text": "gender neutrality is often not preserved", "start": 20, "end": 26, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_23-2-E3", "text": "the presence of a gender-neutral pronoun often leads to grammatical and semantic translation errors", "start": 5, "end": 19, "entity_type": "UNK", "mention_type": "UNK"}], "relation_mentions": [], "event_mentions": [{"event_type": "Results/Findings", "id": "ACL_23_P_23-2-EV0", "trigger": {"text": "shows", "start": 3, "end": 4}, "arguments": [{"entity_id": "ACL_23_P_23-2-E0", "text": "Our error analysis", "role": "Agent"}, {"entity_id": "ACL_23_P_23-2-E1", "text": "the presence of a gender-neutral pronoun often leads to grammatical and semantic translation errors", "role": "Results"}, {"entity_id": "ACL_23_P_23-2-E2", "text": "gender neutrality is often not preserved", "role": "Results"}, {"entity_id": "ACL_23_P_23-2-E3", "text": "the presence of a gender-neutral pronoun often leads to grammatical and semantic translation errors", "role": "PrimaryObject"}]}], "entity_coreference": [], "event_coreference": [], "tokens": ["Our", "error", "analysis", "shows", "that", "the", "presence", "of", "a", "gender-neutral", "pronoun", "often", "leads", "to", "grammatical", "and", "semantic", "translation", "errors.", "Similarly,", "gender", "neutrality", "is", "often", "not", "preserved."], "pieces": ["Our", "error", "analysis", "shows", "that", "the", "pres", "ence", "of", "a", "gender", "-", "neutral", "pron", "oun", "often", "le", "ads", "to", "gram", "matical", "and", "sem", "antic", "translation", "errors", ".", "Similarly", ",", "gender", "neutral", "ity", "is", "often", "not", "pres", "erved", "."], "token_lens": [1, 1, 1, 1, 1, 1, 2, 1, 1, 3, 2, 1, 2, 1, 2, 1, 2, 1, 2, 2, 1, 2, 1, 1, 1, 3], "sentence": "Our error analysis shows that the presence of a gender-neutral pronoun often leads to grammatical and semantic translation errors. Similarly, gender neutrality is often not preserved.", "sentence_starts": [0]}
{"doc_id": "ACL_23_P_23", "wnd_id": "ACL_23_P_23-3", "entity_mentions": [{"id": "ACL_23_P_23-3-E0", "text": "we", "start": 11, "end": 12, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_23-3-E1", "text": "By surveying the opinions of affected native speakers from diverse languages", "start": 0, "end": 11, "entity_type": "UNK", "mention_type": "UNK"}, {"id": "ACL_23_P_23-3-E2", "text": "recommendations to address the issue in future MT research", "start": 13, "end": 22, "entity_type": "UNK", "mention_type": "UNK"}], "relation_mentions": [], "event_mentions": [{"event_type": "Conclusions/Implications", "id": "ACL_23_P_23-3-EV0", "trigger": {"text": "provide", "start": 12, "end": 13}, "arguments": [{"entity_id": "ACL_23_P_23-3-E0", "text": "we", "role": "Agent"}, {"entity_id": "ACL_23_P_23-3-E1", "text": "By surveying the opinions of affected native speakers from diverse languages", "role": "Method"}, {"entity_id": "ACL_23_P_23-3-E2", "text": "recommendations to address the issue in future MT research", "role": "PrimaryObject"}]}], "entity_coreference": [], "event_coreference": [], "tokens": ["By", "surveying", "the", "opinions", "of", "affected", "native", "speakers", "from", "diverse", "languages,", "we", "provide", "recommendations", "to", "address", "the", "issue", "in", "future", "MT", "research."], "pieces": ["By", "sur", "ve", "ying", "the", "op", "in", "ions", "of", "affected", "native", "spe", "akers", "from", "d", "iverse", "l", "anguages", ",", "we", "prov", "ide", "recomm", "end", "ations", "to", "address", "the", "issue", "in", "future", "MT", "research", "."], "token_lens": [1, 3, 1, 3, 1, 1, 1, 2, 1, 2, 3, 1, 2, 3, 1, 1, 1, 1, 1, 1, 1, 2], "sentence": "By surveying the opinions of affected native speakers from diverse languages, we provide recommendations to address the issue in future MT research.", "sentence_starts": [0]}
