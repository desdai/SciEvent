Paper Code: ACL_23_P_359

[Background]: Because these analyses are often conducted manually and at a small scale, such investigations can benefit from the use of more recent natural language processing (NLP) methods that examine social bias in models and data corpora.

[Method]: Our work joins this interdisciplinary effort and makes a unique contribution by taking into account the event narrative structures when analyzing the social bias of stories. We propose a computational pipeline that automatically extracts a storyâ€™s temporal narrative verb-based event chain for each of its characters as well as character attributes such as gender. We also present a verb-based event annotation scheme that can facilitate bias analysis by including categories such as those that align with traditional stereotypes.

[Results]: Through a case study analyzing gender bias in fairy tales, we demonstrate that our framework can reveal bias in not only the unigram verb-based events in which female and male characters participate but also in the temporal narrative order of such event participation.

[Implications]: We believe that our approach has important implications for understanding how social biases are perpetuated through storytelling and for developing strategies to mitigate them.


Paper Code: ACL_23_P_900

[Background]: Current image generation models struggle to reliably produce well-formed visual text.

[Method]: To quantify this effect, we conduct a series of experiments comparing character-aware vs. character-blind text encoders. In the text-only domain, we find that character-aware models provide large gains on a novel spelling task (WikiSpell).

[Results]: Applying our learnings to the visual domain, we train a suite of image generation models, and show that character-aware variants outperform their character-blind counterparts across a range of novel text rendering tasks (our DrawText benchmark). Our models set a much higher state-of-the-art on visual spelling, with 30+ point accuracy gains over competitors on rare words, despite training on far fewer examples.

[Implications]: Our results demonstrate the importance of incorporating character-level information into text encoding for improved performance in both text-only and visual domains. This has significant implications for various natural language processing and computer vision applications where accurate text recognition is crucial.

