Paper Code: ACL_23_P_783

[Background]: Various design settings for in-context learning (ICL), such as the choice and order of the in-context examples, can bias the model's predictions.

[Method]: In this work, we define a typology for three types of label biases in ICL for text classification: vanilla-label bias, context-label bias, and domain-label bias (which we conceptualize and detect for the first time).

[Results]: Our analysis demonstrates that prior label bias calibration methods fall short of addressing all three types of biases. Specifically, domain-label bias restricts LLMs to random-level performance on many tasks regardless of the choice of in-context examples.

[Implications]: <NONE>


Paper Code: ACL_23_P_139

[Background]: Multimodal sarcasm detection is an important research topic in natural language processing and multimedia computing, and benefits a wide range of applications in multiple domains.

[Method]: Most existing studies regard the incongruity between image and text as the indicative clue in identifying multimodal sarcasm. To capture cross-modal incongruity, previous methods rely on fixed architectures in network design, which restricts the model from dynamically adjusting to diverse image-text pairs. Inspired by routing-based dynamic network, we model the dynamic mechanism in multimodal sarcastic detection and propose the Dynamic Routing Transformer Network (DynRT-Net).

[Results]: Experimental results on a public dataset demonstrate the effectiveness of our method compared to the state-of-the-art methods.

[Implications]: <NONE>

