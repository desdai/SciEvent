Paper Code: ACL_23_P_314

[Background]: <NONE>

[Method]: [NONE]

[Results]: In this work, aiming to improve the robustness of ‘true’ ZS-XLT and FS-XLT, we propose a simple and effective method that averages different checkpoints (i.e., model snapshots) during task fine-tuning. We conduct exhaustive ZS-XLT and FS-XLT experiments across higher-level semantic tasks (NLI, extractive QA) and lower-level token classification tasks (NER, POS). The results indicate that averaging model checkpoints yields systematic and consistent performance gains across diverse target languages in all tasks. Importantly, it simultaneously substantially desensitizes XLT to varying hyperparameter choices in the absence of target language validation. We also show that checkpoint averaging benefits performance when further combined with run averaging (i.e., averaging the parameters of models fine-tuned over independent runs).

[Implications]: <NONE>


Paper Code: ACL_23_P_96

[Background]: Emotional support conversation (ESC) aims to provide emotional support (ES) to improve one’s mental state.

[Method]: <NONE>

[Results]: <NONE>

[Implications]: <NONE>

