Paper Code: cscw_23_P_179

[Background]: Algorithmic risk assessments are being deployed in an increasingly broad spectrum of domains including banking, medicine, and law enforcement. However, there is widespread concern about their fairness and trustworthiness, and people are also known to display algorithm aversion, preferring human assessments even when they are quantitatively worse.

[Method]: [NONE]

[Results]: We find that predictions made by the model are consistently perceived as less fair and less interpretable than those made by the analyst despite being identical. Furthermore, biased predictive errors were more likely to widen this perception gap, with the algorithm being judged even more harshly for making a biased mistake.

[Implications]: <NONE>


Paper Code: cscw_23_P_92

[Background]: Group deliberation enables people to collaborate and solve problems, however, it is understudied due to a lack of resources.

[Method]: To this end, we introduce the first publicly available dataset containing collaborative conversations on solving a well-established cognitive task, consisting of 500 group dialogues and 14k utterances.

[Results]: In 64% of these conversations, the group members are able to find a better solution than they had identified individually, and in 43.8% of the groups who had a correct answer as their final solution, none of the participants had solved the task correctly by themselves.

[Implications]: <NONE>

