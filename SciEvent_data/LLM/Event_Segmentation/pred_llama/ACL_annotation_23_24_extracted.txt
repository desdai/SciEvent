Paper Code: ACL_23_P_378

[Background]: A robust summarization system should be able to capture the gist of the document, regardless of the specific word choices or noise in the input.

[Method]: <NONE>

[Results]: Experimental results show that state-of-the-art summarization models have a significant decrease in performance on adversarial and noisy test sets. Next, we analyze the vulnerability of the summarization systems and explore improving the robustness by data augmentation. Specifically, the first vulnerability factor we found is the low diversity of the training inputs. Correspondingly, we expose the encoder to more diverse cases created by SummAttacker in the input space. The second factor is the vulnerability of the decoder, and we propose an augmentation in the latent space of the decoder to improve its robustness. Concretely, we create virtual cases by manifold softmixing two decoder hidden states of similar semantic meanings. Experimental results on Gigaword and CNN/DM datasets demonstrate that our approach achieves significant improvements over strong baselines and exhibits higher robustness on noisy, attacked, and clean datasets.

[Implications]: <NONE>


Paper Code: ACL_23_P_113

[Background]: We present ELQA, a corpus of questions and answers in and about the English language.

[Method]: Collected from two online forums, the >70k questions (from English learners and others) cover wide-ranging topics including grammar, meaning, fluency, and etymology.

[Results]: Unlike most NLP datasets, this corpus is metalinguisticâ€”it consists of language about language.

[Implications]: <NONE>

