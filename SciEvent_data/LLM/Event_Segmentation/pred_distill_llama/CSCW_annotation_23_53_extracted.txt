Paper Code: cscw_23_P_156

[Background]: The question of how to develop and maintain appropriate, socially informed and sophisticated infrastructural systems is an ongoing concern for CSCW. Information infrastructure development efforts are usually large endeavors that involve many stakeholders, including several organizations that need to interoperate with legacy systems. Projects typically take several years to develop. The duration, variety, and sites of engagement in the development of information infrastructures can be challenging to approach with typical CSCW approaches.

[Method]: We compare and analyze our varied experiences in order to generate lessons learned based on being embedded for three or more years as action researchers and ethnographers in infrastructure development projects in the domains of traffic engineering, vocational education, and ocean science. Drawing upon these experiences, as well as literature in infrastructure studies, design methodologies, and organizational studies, we extract guidance for researchers and practitioners seeking to understand and engage in long-term organizationally complex system development projects.

[Results]: <NONE>

[Implications]: Among these lessons, we encourage revisiting previously gathered data as scope and scale change, observing changes in the discursive 'reference public' who will benefit from the system, and planning for different intellectual points of entry and exit. This paper lays groundwork for future developments in theory and method of collaborative design and development in and with complex systems.


Paper Code: cscw_23_P_181

[Background]: Social media platforms moderate content for each user by incorporating the outputs of both platform-wide content moderation systems and, in some cases, user-configured personal moderation preferences. However, it is unclear how end users perceive the choices and affordances of different kinds of personal content moderation tools, and how the introduction of personalization impacts user perceptions of platforms' content moderation responsibilities.

[Method]: This paper investigates end users' perspectives on personal content moderation tools by conducting an interview study with a diverse sample of 24 active social media users. We probe interviewees' preferences using simulated personal moderation interfaces, including word filters, sliders for toxicity levels, and boolean toxicity toggles. We also examine the labor involved for users in choosing moderation settings and present users' attitudes about the roles and responsibilities of social media platforms and other stakeholders toward moderation.

[Results]: The findings reveal that users have varying preferences for different types of personal moderation tools, with significant differences based on their experience level, content consumption habits, and trust in platform mechanisms. Users often struggle with understanding and effectively utilizing complex moderation controls, leading to frustration and disengagement. Additionally, the introduction of personalized moderation features does not always align with users' expectations regarding transparency and control.

[Implications]: These results suggest that designing effective personal content moderation tools requires careful consideration of user needs, behaviors, and psychological factors. Future work should focus on developing intuitive interfaces and providing clearer feedback to help users make informed decisions about their moderation settings. Furthermore, platforms may need to balance personalized customization with maintaining broader community standards to ensure responsible content moderation across all user segments.

