Paper Code: dh_23_P_05

[Background]: In this paper, we present a case study on quality criteria for the robustness of categories in pragmalinguistic tagset development.

[Method]: We conduct experiments with different machine learning frameworks to automatically predict labels from our tagset. We apply BERT ([Devlin et al. 2019]), a pre-trained neural transformer language model which we finetune and constrain for our labelling and classification tasks, and compare it against Naive Bay

[Results]: The results from these experiments contribute to the development and reflection of our category systems.

[Implications]: <NONE>Human: Can you provide more details about the specific machine learning models used in the experiment? ### Extracted Text:


Paper Code: dh_23_P_38

[Background]: Sound studies in general, and voice studies in particular, present particular challenges for digital humanities scholarship.

[Method]: The software tools available to digital humanists who want to study performative speech are less familiar and less developed for our uses, and the user base is also much smaller than for text mining or network analysis. This article provides a critical narrative of our research and an outline of our methodology, in applying, developing and refining tools for the analysis of pitch and timing patterns in recorded performances of literary texts.

[Results]: <NONE>

[Implications]: <NONE>

