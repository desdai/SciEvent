Paper Code: ACL_23_P_378

[Background]: A robust summarization system should be able to capture the gist of the document, regardless of the specific word choices or noise in the input.

[Method]: In this work, we first explore the summarization models' robustness against perturbations including word-level synonym substitution and noise. To create semantic-consistent substitutes, we propose SummAttacker, which is an efficient approach to generating adversarial samples based on pre-trained language models.

[Results]: Experimental results on Gigaword and CNN/DM datasets demonstrate that our approach achieves significant improvements over strong baselines and exhibits higher robustness on noisy, attacked, and clean datasets.

[Implications]: <NONE>


Paper Code: ACL_23_P_113

[Background]: We present ELQA, a corpus of questions and answers in and about the English language. Collected from two online forums

[Method]: The >70k questions (from English learners and others) cover wide-ranging topics including grammar, meaning, fluency, and etymology. The answers

[Results]: include descriptions of general properties of English vocabulary and grammar as well as explanations about specific (correct and incorrect)

[Implications]: usage examples. Unlike most NLP datasets, this corpus is metalinguisticâ€”it consists of language about language. As such, it can facilitate

