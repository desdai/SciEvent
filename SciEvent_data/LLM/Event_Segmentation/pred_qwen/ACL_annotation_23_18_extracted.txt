Paper Code: ACL_23_P_52

[Background]: Recently proposed Key Point Analysis (KPA) derives fine-grained insights from collections of textual comments by extracting the main points as a list of concise sentences or phrases called Key Points, and quantifying their prevalence. However, understanding such a long, flat list can be difficult due to its lack of structure.

[Method]: The challenge addressed is that while key points offer greater expressiveness compared to traditional techniques like word clouds and key phrases, they do not provide an organized view when expressed as a simple list. A solution introduced involves organizing key points into a hierarchical structure based on their specificity, akin to a new form of Textual Entailment Graph. This organization was achieved through developing ThinkP, a benchmark dataset comprising annotated key point hierarchies derived from business and product reviews. Different approaches were evaluated for determining relationships between pairs of key points and constructing overall hierarchies; notable improvements came from using directional distributional similarity with specialized representations combined with weak supervision.

[Results]: Not specified directly but implied within method description regarding evaluation outcomes leading to enhanced predictive accuracy.

[Implications]: <NONE>


Paper Code: ACL_23_P_364

[Background]: Dialogue models are often enriched with extensive external knowledge to provide informative responses through a retrieval-augmented pipeline. Nevertheless, retrieval-augmented approaches rely on finely annotated retrieval training data and knowledge-grounded response generation data, making it costly to transfer.

[Method]: To tackle this challenge, this paper proposes a retrieval-free approach, KiDG, by automatically turning knowledge documents into simulated multi-turn dialogues through a Multi-Document Traversal algorithm.

[Results]: The simulated knowledge-intensive dialogues constructed by KiDG in one domain can be easily used to train and enhance pre-trained dialogue models' knowledge w.r.t. this domain without costly annotation. We conducted extensive experiments comparing retrieval-augmented models and a variety of retrieval-free models. We found that dialogue models enhanced with data simulated with KiDG largely outperform state-of-the-art retrieval-free methods, and it achieves comparable performance compared to retrieval-augmented methods while being better, and cheaper at domain transfer.

[Implications]: <NONE>

