{
  "papers": [
    {
      "paper_code": "ACL_23_P_22",
      "abstract": "Classic approaches to content moderation typically apply a rule-based heuristic approach to flag content. While rules are easily customizable and intuitive for humans to interpret, they are inherently fragile and lack the flexibility or robustness needed to moderate the vast amount of undesirable content found online today. Recent advances in deep learning have demonstrated the promise of using highly effective deep neural models to overcome these challenges. However, despite the improved performance, these data-driven models lack transparency and explainability, often leading to mistrust from everyday users and a lack of adoption by many platforms. In this paper, we present Rule By Example (RBE): a novel exemplar-based contrastive learning approach for learning from logical rules for the task of textual content moderation. RBE is capable of providing rule-grounded predictions, allowing for more explainable and customizable predictions compared to typical deep learning-based approaches. We demonstrate that our approach is capable of learning rich rule embedding representations using only a few data examples. Experimental results on 3 popular hate speech classification datasets show that RBE is able to outperform state-of-the-art deep learning classifiers as well as the use of rules in both supervised and unsupervised settings while providing explainable model predictions via rule-grounding.",
      "events": [
        {
          "Background/Introduction": "",
          "Text": "Classic approaches to content moderation typically apply a rule-based heuristic approach to flag content. While rules are easily customizable and intuitive for humans to interpret, they are inherently fragile and lack the flexibility or robustness needed to moderate the vast amount of undesirable content found online today. Recent advances in deep learning have demonstrated the promise of using highly effective deep neural models to overcome these challenges. However, despite the improved performance, these data-driven models lack transparency and explainability, often leading to mistrust from everyday users and a lack of adoption by many platforms.",
          "Main Action": "<NONE>",
          "Arguments": {
            "Agent": [
              "classic approaches",
              "recent advances in deep learning"
            ],
            "Object": {
              "Primary Object": [
                "rule-based heuristic approach",
                "data-driven models"
              ],
              "Secondary Object": [
                "undesirable content",
                "mistrust from everyday users and a lack of adoption by many platforms"
              ]
            },
            "Context": [
              "Typically applied to flag content",
              "Despite the improved performance"
            ],
            "Purpose": [
              "To moderate the vast amount of undesirable content found online today",
              "To overcome fragility and lack of flexibility/robustness issues"
            ],
            "Method": [
              "applying a rule-based heuristic approach",
              "using highly effective deep neural models"
            ],
            "Results": [
              "None mentioned"
            ],
            "Analysis": [
              "None mentioned"
            ],
            "Challenge": [
              "fragile and lacking flexibility or robustness",
              "lack of transparency and explainability"
            ],
            "Ethical": [
              "None mentioned"
            ],
            "Implications": [
              "increased mistrust among users",
              "limited platform adoption due to opacity"
            ],
            "Contradictions": [
              "None mentioned"
            ]
          }
        },
        {
          "Methods/Approach": "",
          "Text": "In this paper, we present Rule By Example (RBE): a novel exemplar-based contrastive learning approach for learning from logical rules for the task of textual content moderation. RBE is capable of providing rule-grounded predictions, allowing for more explainable and customizable predictions compared to typical deep learning-based approaches.",
          "Main Action": "<NONE>",
          "Arguments": {
            "Agent": [
              "we"
            ],
            "Object": {
              "Primary Object": [
                "Rule By Example (RBE)",
                "exemplar-based contrastive learning approach"
              ],
              "Secondary Object": [
                "logical rules",
                "task of textual content moderation"
              ]
            },
            "Context": [
              "novel exemplar-based contrastive learning approach"
            ],
            "Purpose": [
              "learning from logical rules for the task of textual content moderation"
            ],
            "Method": [
              "a novel exemplar-based contrastive learning approach"
            ],
            "Results": [
              "more explainable and customizable predictions compared to typical deep learning-based approaches"
            ],
            "Analysis": [
              "<NONE>"
            ],
            "Challenge": [
              "<NONE>"
            ],
            "Ethical": [
              "<NONE>"
            ],
            "Implications": [
              "<NONE>"
            ],
            "Contradictions": [
              "<NONE>"
            ]
          }
        },
        {
          "Results/Findings": "",
          "Text": "We demonstrate that our approach is capable of learning rich rule embedding representations using only a few data examples. Experimental results on 3 popular hate speech classification datasets show that RBE is able to outperform state-of-the-art deep learning classifiers as well as the use of rules in both supervised and unsupervised settings while providing explainable model predictions via rule-grounding.",
          "Main Action": "demonstrate",
          "Arguments": {
            "Agent": [
              "our approach"
            ],
            "Object": {
              "Primary Object": [
                "learning rich rule embedding representations"
              ],
              "Secondary Object": [
                "using only a few data examples"
              ]
            },
            "Context": [
              "on 3 popular hate speech classification datasets"
            ],
            "Purpose": [
              "to outperform state-of-the-art deep learning classifiers as well as the use of rules in both supervised and unsupervised settings while providing explainable model predictions via rule-grounding"
            ],
            "Method": [
              "none mentioned directly but implies usage of machine learning techniques based on dataset performance claims"
            ],
            "Results": [
              "outperforms state-of-the-art deep learning classifiers as well as the use of rules in both supervised and unsupervised settings"
            ],
            "Analysis": [
              "providing explainable model predictions via rule-grounding"
            ],
            "Challenge": [
              "none explicit challenges mentioned"
            ],
            "Ethical": [
              "none explicit ethics mentioned"
            ],
            "Implications": [
              "broader significance or potential for future applications/research implied through superior performance metrics compared to current methods"
            ],
            "Contradictions": [
              "none explicit contradictions mentioned"
            ]
          }
        }
      ]
    },
    {
      "paper_code": "ACL_23_P_219",
      "abstract": "Monolingual word alignment is crucial to model semantic interactions between sentences. In particular, null alignment, a phenomenon in which words have no corresponding counterparts, is pervasive and critical in handling semantically divergent sentences. Identification of null alignment is useful on its own to reason about the semantic similarity of sentences by indicating there exists information inequality. To achieve unbalanced word alignment that values both alignment and null alignment, this study shows that the family of optimal transport (OT), i.e., balanced, partial, and unbalanced OT, are natural and powerful approaches even without tailor-made techniques. Our extensive experiments covering unsupervised and supervised settings indicate that our generic OT-based alignment methods are competitive against the state-of-the-arts specially designed for word alignment, remarkably on challenging datasets with high null alignment frequencies.",
      "events": [
        {
          "Background/Introduction": "",
          "Text": "Monolingual word alignment is crucial to model semantic interactions between sentences. In particular, null alignment, a phenomenon in which words have no corresponding counterparts, is pervasive and critical in handling semantically divergent sentences. Identification of null alignment is useful on its own to reason about the semantic similarity of sentences by indicating there exists information inequality.",
          "Main Action": "<NONE>",
          "Arguments": {
            "Agent": [
              "null alignment identification"
            ],
            "Object": {
              "Primary Object": [
                "words"
              ],
              "Secondary Object": [
                "semantically divergent sentences"
              ]
            },
            "Context": [
              "monolingual word alignment",
              "pervasive and critical"
            ],
            "Purpose": [
              "to reason about the semantic similarity of sentences by indicating there exists information inequality"
            ],
            "Method": [
              "<NONE>"
            ],
            "Results": [
              "useful on its own"
            ],
            "Analysis": [
              "indicating there exists information inequality"
            ],
            "Challenge": [
              "<NONE>"
            ],
            "Ethical": [
              "<NONE>"
            ],
            "Implications": [
              "not applicable here; it's more focused on background"
            ],
            "Contradictions": [
              "<NONE>"
            ]
          }
        },
        {
          "Methods/Approach": "",
          "Text": "To achieve unbalanced word alignment that values both alignment and null alignment, this study shows that the family of optimal transport (OT), i.e., balanced, partial, and unbalanced OT, are natural and powerful approaches even without tailor-made techniques.",
          "Main Action": "show",
          "Arguments": {
            "Agent": [
              "this study"
            ],
            "Object": {
              "Primary Object": [
                "family of optimal transport (OT)",
                "balanced, partial, and unbalanced OT"
              ],
              "Secondary Object": [
                "null alignment"
              ]
            },
            "Context": [
              "unbalanced word alignment that values both alignment and null alignment"
            ],
            "Purpose": [
              "natural and powerful approaches even without tailor-made techniques"
            ],
            "Method": [
              "<NONE>"
            ],
            "Results": [
              "<NONE>"
            ],
            "Analysis": [
              "<NONE>"
            ],
            "Challenge": [
              "<NONE>"
            ],
            "Ethical": [
              "<NONE>"
            ],
            "Implications": [
              "<NONE>"
            ],
            "Contradictions": [
              "<NONE>"
            ]
          }
        },
        {
          "Results/Findings": "",
          "Text": "Our extensive experiments covering unsupervised and supervised settings indicate that our generic OT-based alignment methods are competitive against the state-of-the-arts specially designed for word alignment, remarkably on challenging datasets with high null alignment frequencies.",
          "Main Action": "indicate",
          "Arguments": {
            "Agent": [
              "our generic OT-based alignment methods"
            ],
            "Object": {
              "Primary Object": [
                "competitive against the state-of-the-arts specially designed for word alignment"
              ],
              "Secondary Object": [
                "remarkably on challenging datasets with high null alignment frequencies"
              ]
            },
            "Context": [
              "extensive experiments covering unsupervised and supervised settings"
            ],
            "Purpose": [
              "<NONE>"
            ],
            "Method": [
              "<NONE>"
            ],
            "Results": [
              "indicating that our generic OT-based alignment methods are competitive against the state-of-the-arts specially designed for word alignment, remarkably on challenging datasets with high null alignment frequencies"
            ],
            "Analysis": [
              "<NONE>"
            ],
            "Challenge": [
              "high null alignment frequencies"
            ],
            "Ethical": [
              "<NONE>"
            ],
            "Implications": [
              "<NONE>"
            ],
            "Contradictions": [
              "<NONE>"
            ]
          }
        }
      ]
    }
  ]
}