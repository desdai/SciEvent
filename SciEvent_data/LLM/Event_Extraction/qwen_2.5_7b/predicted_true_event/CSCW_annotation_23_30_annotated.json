{
  "papers": [
    {
      "paper_code": "cscw_23_P_257",
      "abstract": "AI explanations are often mentioned as a way to improve human-AI decision-making, but empirical studies have not found consistent evidence of explanations' effectiveness and, on the contrary, suggest that they can increase overreliance when the AI system is wrong. While many factors may affect reliance on AI support, one important factor is how decision-makers reconcile their own intuition — beliefs or heuristics, based on prior knowledge, experience, or pattern recognition, used to make judgments — with the information provided by the AI system to determine when to override AI predictions. We conduct a think-aloud, mixed-methods study with two explanation types (feature- and example-based) for two prediction tasks to explore how decision-makers' intuition affects their use of AI predictions and explanations, and ultimately their choice of when to rely on AI. Our results identify three types of intuition involved in reasoning about AI predictions and explanations: intuition about the task outcome, features, and AI limitations. Building on these, we summarize three observed pathways for decision-makers to apply their own intuition and override AI predictions. We use these pathways to explain why (1) the feature-based explanations we used did not improve participants' decision outcomes and increased their overreliance on AI, and (2) the example-based explanations we used improved decision-makers' performance over feature-based explanations and helped achieve complementary human-AI performance. Overall, our work identifies directions for further development of AI decision-support systems and explanation methods that help decision-makers effectively apply their intuition to achieve appropriate reliance on AI.",
      "events": [
        {
          "Background/Introduction": "",
          "Text": "AI explanations are often mentioned as a way to improve human-AI decision-making, but empirical studies have not found consistent evidence of explanations' effectiveness and, on the contrary, suggest that they can increase overreliance when the AI system is wrong. While many factors may affect reliance on AI support, one important factor is how decision-makers reconcile their own intuition — beliefs or heuristics, based on prior knowledge, experience, or pattern recognition, used to make judgments — with the information provided by the AI system to determine when to override AI predictions.",
          "Main Action": "<NONE>",
          "Arguments": {
            "Agent": [
              "decision-makers"
            ],
            "Object": {
              "Primary Object": [
                "intuition",
                "heuristics",
                "prior knowledge",
                "experience",
                "pattern recognition"
              ],
              "Secondary Object": [
                "information provided by the AI system"
              ]
            },
            "Context": [
              "AI explanations",
              "human-AI decision-making",
              "many factors affecting reliance on AI support"
            ],
            "Purpose": [
              "determine when to override AI predictions"
            ],
            "Method": [
              "reconcile their own intuition with the information provided by the AI system"
            ],
            "Results": [
              "empirical studies have not found consistent evidence of explanations' effectiveness",
              "suggest that they can increase overreliance when the AI system is wrong"
            ],
            "Analysis": [
              "one important factor is how decision-makers reconcile their own intuition with the information provided by the AI system"
            ],
            "Challenge": [
              "contrary results from previous studies about the effectiveness of AI explanations"
            ],
            "Ethical": [
              "none explicitly stated"
            ],
            "Implications": [
              "broader significance or potential for future applications/research regarding understanding and improving human-AI interaction through better alignment between human intuitions and AI systems"
            ],
            "Contradictions": [
              "existing knowledge suggesting positive effects of AI explanations vs current study's findings"
            ]
          }
        },
        {
          "Methods/Approach": "",
          "Text": "We conduct a think-aloud, mixed-methods study with two explanation types (feature- and example-based) for two prediction tasks to explore how decision-makers' intuition affects their use of AI predictions and explanations, and ultimately their choice of when to rely on AI.",
          "Main Action": "conduct",
          "Arguments": {
            "Agent": [
              "we"
            ],
            "Object": {
              "Primary Object": [
                "a think-aloud, mixed-methods study"
              ],
              "Secondary Object": [
                "two explanation types (feature- and example-based)",
                "for two prediction tasks"
              ]
            },
            "Context": [
              "to explore how decision-makers' intuition affects their use of AI predictions and explanations, and ultimately their choice of when to rely on AI"
            ],
            "Purpose": [
              "to explore how decision-makers' intuition affects their use of AI predictions and explanations, and ultimately their choice of when to rely on AI"
            ],
            "Method": [
              "think-aloud, mixed-methods study"
            ],
            "Results": [
              "<NONE>"
            ],
            "Analysis": [
              "<NONE>"
            ],
            "Challenge": [
              "<NONE>"
            ],
            "Ethical": [
              "<NONE>"
            ],
            "Implications": [
              "<NONE>"
            ],
            "Contradictions": [
              "<NONE>"
            ]
          }
        },
        {
          "Results/Findings": "",
          "Text": "Our results identify three types of intuition involved in reasoning about AI predictions and explanations: intuition about the task outcome, features, and AI limitations. Building on these, we summarize three observed pathways for decision-makers to apply their own intuition and override AI predictions. We use these pathways to explain why (1) the feature-based explanations we used did not improve participants' decision outcomes and increased their overreliance on AI, and (2) the example-based explanations we used improved decision-makers' performance over feature-based explanations and helped achieve complementary human-AI performance.",
          "Main Action": "<NONE>",
          "Arguments": {
            "Agent": [
              "We"
            ],
            "Object": {
              "Primary Object": [
                "three types of intuition",
                "participants"
              ],
              "Secondary Object": [
                "AI predictions and explanations",
                "decision-makers",
                "example-based explanations",
                "feature-based explanations"
              ]
            },
            "Context": [
              "reasoning about AI predictions and explanations"
            ],
            "Purpose": [
              "to explain why certain types of explanations were effective or ineffective"
            ],
            "Method": [
              "using summaries of observed pathways"
            ],
            "Results": [
              "(1) the feature-based explanations did not improve participants' decision outcomes and increased their overreliance on AI",
              "(2) the example-based explanations improved decision-makers' performance over feature-based explanations and helped achieve complementary human-AI performance"
            ],
            "Analysis": [
              "why certain types of explanations worked better than others"
            ],
            "Challenge": [
              "none mentioned"
            ],
            "Ethical": [
              "none mentioned"
            ],
            "Implications": [
              "potential for improving human-AI collaboration through tailored explanations"
            ],
            "Contradictions": [
              "none mentioned"
            ]
          }
        },
        {
          "Conclusions/Implications": "",
          "Text": "Overall, our work identifies directions for further development of AI decision-support systems and explanation methods that help decision-makers effectively apply their intuition to achieve appropriate reliance on AI.",
          "Main Action": "<NONE>",
          "Arguments": {
            "Agent": [
              "our work"
            ],
            "Object": {
              "Primary Object": [
                "directions for further development of AI decision-support systems and explanation methods"
              ],
              "Secondary Object": [
                "decision-makers effectively applying their intuition to achieve appropriate reliance on AI"
              ]
            },
            "Context": [
              "<NONE>"
            ],
            "Purpose": [
              "helping decision-makers effectively apply their intuition to achieve appropriate reliance on AI"
            ],
            "Method": [
              "<NONE>"
            ],
            "Results": [
              "identifies"
            ],
            "Analysis": [
              "<NONE>"
            ],
            "Challenge": [
              "<NONE>"
            ],
            "Ethical": [
              "<NONE>"
            ],
            "Implications": [
              "providing directions for further development of AI decision-support systems and explanation methods"
            ],
            "Contradictions": [
              "<NONE>"
            ]
          }
        }
      ]
    },
    {
      "paper_code": "cscw_23_P_182",
      "abstract": "With the shift to hybrid meetings in work spaces, there is an increasing need to create a more inclusive hybrid meeting experience where people meeting together in a room interact with those joining remotely. This paper describes a design exploration, implementation, and evaluation of Perspectives, a novel hybrid meeting system that aimed to create an inclusive and equitable space for hybrid meetings. Perspectives digitally composites everyone into a virtual room so that each person has a unique but spatially consistent viewpoint into the meeting. The user study compared Perspectives with three commercially available UX designs for hybrid meetings: Gallery, Together Mode, and Front Row. Results from this study revealed key benefits of Perspectives, including supporting natural interactions, creating a strong sense of co-presence, and reducing cognitive load. Results from the study also helped iterate on the design principles of Perspectives, which offer important insights on supporting hybrid meetings.",
      "events": [
        {
          "Background/Introduction": "",
          "Text": "With the shift to hybrid meetings in work spaces, there is an increasing need to create a more inclusive hybrid meeting experience where people meeting together in a room interact with those joining remotely.",
          "Main Action": "<NONE>",
          "Arguments": {
            "Agent": [
              "there is an increasing need"
            ],
            "Object": {
              "Primary Object": [
                "to create a more inclusive hybrid meeting experience"
              ],
              "Secondary Object": [
                "where people meeting together in a room interact with those joining remotely"
              ]
            },
            "Context": [
              "With the shift to hybrid meetings in work spaces"
            ],
            "Purpose": [
              "<NONE>"
            ],
            "Method": [
              "<NONE>"
            ],
            "Results": [
              "<NONE>"
            ],
            "Analysis": [
              "<NONE>"
            ],
            "Challenge": [
              "<NONE>"
            ],
            "Ethical": [
              "<NONE>"
            ],
            "Implications": [
              "<NONE>"
            ],
            "Contradictions": [
              "<NONE>"
            ]
          }
        },
        {
          "Methods/Approach": "",
          "Text": "This paper describes a design exploration, implementation, and evaluation of Perspectives, a novel hybrid meeting system that aimed to create an inclusive and equitable space for hybrid meetings. Perspectives digitally composites everyone into a virtual room so that each person has a unique but spatially consistent viewpoint into the meeting. The user study compared Perspectives with three commercially available UX designs for hybrid meetings: Gallery, Together Mode, and Front Row.",
          "Main Action": "describes",
          "Arguments": {
            "Agent": [
              "This paper"
            ],
            "Object": {
              "Primary Object": [
                "a design exploration, implementation, and evaluation of Perspectives, a novel hybrid meeting system"
              ],
              "Secondary Object": [
                "three commercially available UX designs for hybrid meetings"
              ]
            },
            "Context": [
              "Perspectives digitally composites everyone into a virtual room so that each person has a unique but spatially consistent viewpoint into the meeting."
            ],
            "Purpose": [
              "to create an inclusive and equitable space for hybrid meetings"
            ],
            "Method": [
              "digitally composites everyone into a virtual room"
            ],
            "Results": [
              "The user study compared Perspectives with three commercially available UX designs for hybrid meetings"
            ],
            "Analysis": [
              "<NONE>"
            ],
            "Challenge": [
              "<NONE>"
            ],
            "Ethical": [
              "<NONE>"
            ],
            "Implications": [
              "<NONE>"
            ],
            "Contradictions": [
              "<NONE>"
            ]
          }
        },
        {
          "Results/Findings": "",
          "Text": "Results from this study revealed key benefits of Perspectives, including supporting natural interactions, creating a strong sense of co-presence, and reducing cognitive load. Results from the study also helped iterate on the design principles of Perspectives, which offer important insights on supporting hybrid meetings.",
          "Main Action": "revealed",
          "Arguments": {
            "Agent": [
              "Results from this study"
            ],
            "Object": {
              "Primary Object": [
                "key benefits of Perspectives"
              ],
              "Secondary Object": [
                "supporting natural interactions",
                "creating a strong sense of co-presence",
                "reducing cognitive load"
              ]
            },
            "Context": [
              "from the study"
            ],
            "Purpose": [
              "<NONE>"
            ],
            "Method": [
              "<NONE>"
            ],
            "Results": [
              "key benefits of Perspectives, including supporting natural interactions, creating a strong sense of co-presence, and reducing cognitive load"
            ],
            "Analysis": [
              "helped iterate on the design principles of Perspectives, which offer important insights on supporting hybrid meetings"
            ],
            "Challenge": [
              "<NONE>"
            ],
            "Ethical": [
              "<NONE>"
            ],
            "Implications": [
              "important insights on supporting hybrid meetings"
            ],
            "Contradictions": [
              "<NONE>"
            ]
          }
        }
      ]
    }
  ]
}