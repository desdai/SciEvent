{
  "papers": [
    {
      "paper_code": "cscw_23_P_60",
      "abstract": "One-on-one tutoring is effective for learning computer science since a tutor can work alongside a student and provide tailored feedback on their code. However, translating this type of instruction to a remote setting is challenging. Traditional methods such as screensharing lack key pedagogical functionality and most available tools are designed for collaboration rather than instruction. To identify tools that can support remote tutoring, we conducted an experiment to assess two resources: synchronous editing and awareness tools. In our study, an instructor teaches a learner introductory programming concepts remotely, collaborating through screensharing alone, a shared notebook with real-time collaborative editing, or a shared notebook with additional awareness tools overlaid. To embed the awareness tools, we designed a Chrome extension that enables real-time sharing of gaze and cursor data. Our results show that synchronous editing combined with awareness tools significantly improved learning. The awareness tools also helped tutors better communicate with the student, track their understanding, and establish a sense of presence. As a final contribution, we also assessed the efficacy of gaze-sharing using a webcam eye-tracker. While the accuracy was not as precise as a dedicated sensor, instructors described instances when the gaze was useful for gauging student attention and establishing presence. We discuss implications for remote tutoring in computer science and scaling awareness technology.",
      "events": [
        {
          "Background/Introduction": "",
          "Text": "One-on-one tutoring is effective for learning computer science since a tutor can work alongside a student and provide tailored feedback on their code. However, translating this type of instruction to a remote setting is challenging. Traditional methods such as screensharing lack key pedagogical functionality and most available tools are designed for collaboration rather than instruction.",
          "Main Action": "<NONE>",
          "Arguments": {
            "Agent": [
              "Traditional methods",
              "Most available tools"
            ],
            "Object": {
              "Primary Object": [
                "screensharing"
              ],
              "Secondary Object": [
                "collaboration tools"
              ]
            },
            "Context": [
              "translating this type of instruction to a remote setting",
              "challenging"
            ],
            "Purpose": [
              "providing key pedagogical functionality",
              "designed for collaboration rather than instruction"
            ],
            "Method": [
              "<NONE>"
            ],
            "Results": [
              "<NONE>"
            ],
            "Analysis": [
              "<NONE>"
            ],
            "Challenge": [
              "challenging"
            ],
            "Ethical": [
              "<NONE>"
            ],
            "Implications": [
              "<NONE>"
            ],
            "Contradictions": [
              "<NONE>"
            ]
          }
        },
        {
          "Methods/Approach": "",
          "Text": "To identify tools that can support remote tutoring, we conducted an experiment to assess two resources: synchronous editing and awareness tools. In our study, an instructor teaches a learner introductory programming concepts remotely, collaborating through screensharing alone, a shared notebook with real-time collaborative editing, or a shared notebook with additional awareness tools overlaid. To embed the awareness tools, we designed a Chrome extension that enables real-time sharing of gaze and cursor data.",
          "Main Action": "conducted an experiment",
          "Arguments": {
            "Agent": [
              "we"
            ],
            "Object": {
              "Primary Object": [
                "an experiment"
              ],
              "Secondary Object": [
                "two resources: synchronous editing and awareness tools"
              ]
            },
            "Context": [
              "To identify tools that can support remote tutoring"
            ],
            "Purpose": [
              "to assess"
            ],
            "Method": [
              "designed a Chrome extension that enables real-time sharing of gaze and cursor data"
            ],
            "Results": [
              "<NONE>"
            ],
            "Analysis": [
              "<NONE>"
            ],
            "Challenge": [
              "<NONE>"
            ],
            "Ethical": [
              "<NONE>"
            ],
            "Implications": [
              "<NONE>"
            ],
            "Contradictions": [
              "<NONE>"
            ]
          }
        },
        {
          "Results/Findings": "",
          "Text": "Our results show that synchronous editing combined with awareness tools significantly improved learning. The awareness tools also helped tutors better communicate with the student, track their understanding, and establish a sense of presence. As a final contribution, we also assessed the efficacy of gaze-sharing using a webcam eye-tracker. While the accuracy was not as precise as a dedicated sensor, instructors described instances when the gaze was useful for gauging student attention and establishing presence.",
          "Main Action": "showed",
          "Arguments": {
            "Agent": [
              "our results"
            ],
            "Object": {
              "Primary Object": [
                "that synchronous editing combined with awareness tools significantly improved learning"
              ],
              "Secondary Object": [
                "awareness tools also helped tutors better communicate with the student, track their understanding, and establish a sense of presence"
              ]
            },
            "Context": [
              "synchronous editing combined with awareness tools"
            ],
            "Purpose": [
              "improved learning"
            ],
            "Method": [
              "using awareness tools"
            ],
            "Results": [
              "significantly improved learning",
              "helped tutors better communicate with the student, track their understanding, and establish a sense of presence"
            ],
            "Analysis": [
              "while the accuracy was not as precise as a dedicated sensor, instructors described instances when the gaze was useful for gauging student attention and establishing presence"
            ],
            "Challenge": [
              "accuracy was not as precise as a dedicated sensor"
            ],
            "Ethical": [
              "<NONE>"
            ],
            "Implications": [
              "useful for gauging student attention and establishing presence"
            ],
            "Contradictions": [
              "<NONE>"
            ]
          }
        },
        {
          "Conclusions/Implications": "",
          "Text": "We discuss implications for remote tutoring in computer science and scaling awareness technology.",
          "Main Action": "<NONE>",
          "Arguments": {
            "Agent": [
              "we"
            ],
            "Object": {
              "Primary Object": [
                "implications"
              ],
              "Secondary Object": [
                "remote tutoring in computer science",
                "scaling awareness technology"
              ]
            },
            "Context": [
              "discuss"
            ],
            "Purpose": [
              "<NONE>"
            ],
            "Method": [
              "<NONE>"
            ],
            "Results": [
              "<NONE>"
            ],
            "Analysis": [
              "<NONE>"
            ],
            "Challenge": [
              "<NONE>"
            ],
            "Ethical": [
              "<NONE>"
            ],
            "Implications": [
              "for remote tutoring in computer science and scaling awareness technology"
            ],
            "Contradictions": [
              "<NONE>"
            ]
          }
        }
      ]
    },
    {
      "paper_code": "cscw_23_P_79",
      "abstract": "Getting training data for machine learning (ML) prediction of mental illness on social media data is labor intensive. To work around this, ML teams will extrapolate proxy signals, or alternative signs from data to evaluate illness status and create training datasets. However, these signals' validity has not been determined, whether signals align with important contextual factors, and how proxy quality impacts downstream model integrity. We use ML and qualitative methods to evaluate whether a popular proxy signal, diagnostic self-disclosure, produces a conceptually sound ML model of mental illness. Our findings identify major conceptual errors only seen through a qualitative investigation — training data built from diagnostic disclosures encodes a narrow vision of diagnosis experiences that propagates into paradoxes in the downstream ML model. This gap is obscured by strong performance of the ML classifier (F1 = 0.91). We discuss the implications of conceptual gaps in creating training data for human-centered models, and make suggestions for improving research methods.",
      "events": [
        {
          "Background/Introduction": "",
          "Text": "Getting training data for machine learning (ML) prediction of mental illness on social media data is labor intensive. To work around this, ML teams will extrapolate proxy signals, or alternative signs from data to evaluate illness status and create training datasets. However, these signals' validity has not been determined, whether signals align with important contextual factors, and how proxy quality impacts downstream model integrity.",
          "Main Action": "<NONE>",
          "Arguments": {
            "Agent": [
              "ML teams"
            ],
            "Object": {
              "Primary Object": [
                "training data"
              ],
              "Secondary Object": [
                "proxy signals"
              ]
            },
            "Context": [
              "getting training data for machine learning (ML) prediction of mental illness on social media data",
              "labor intensive"
            ],
            "Purpose": [
              "to work around the issue of getting training data which is labor-intensive"
            ],
            "Method": [
              "extrapolating proxy signals, creating training datasets"
            ],
            "Results": [
              "validity of signals has not been determined yet; alignment between signals and contextual factors unknown; effect of signal quality on model integrity unverified"
            ],
            "Analysis": [
              "none"
            ],
            "Challenge": [
              "determining the validity of proxy signals, ensuring they align with important contextual factors, assessing their impact on model integrity"
            ],
            "Ethical": [
              "none"
            ],
            "Implications": [
              "broader significance lies in understanding the limitations of using proxy signals for predicting mental illnesses via social media data"
            ],
            "Contradictions": [
              "none"
            ]
          }
        },
        {
          "Methods/Approach": "",
          "Text": "We use ML and qualitative methods to evaluate whether a popular proxy signal, diagnostic self-disclosure, produces a conceptually sound ML model of mental illness.",
          "Main Action": "use",
          "Arguments": {
            "Agent": [
              "We"
            ],
            "Object": {
              "Primary Object": [
                "ML and qualitative methods"
              ],
              "Secondary Object": [
                "a popular proxy signal, diagnostic self-disclosure"
              ]
            },
            "Context": [
              "evaluate whether it produces a conceptually sound ML model of mental illness"
            ],
            "Purpose": [
              "<NONE>"
            ],
            "Method": [
              "<NONE>"
            ],
            "Results": [
              "<NONE>"
            ],
            "Analysis": [
              "<NONE>"
            ],
            "Challenge": [
              "<NONE>"
            ],
            "Ethical": [
              "<NONE>"
            ],
            "Implications": [
              "<NONE>"
            ],
            "Contradictions": [
              "<NONE>"
            ]
          }
        },
        {
          "Results/Findings": "",
          "Text": "Our findings identify major conceptual errors only seen through a qualitative investigation — training data built from diagnostic disclosures encodes a narrow vision of diagnosis experiences that propagates into paradoxes in the downstream ML model. This gap is obscured by strong performance of the ML classifier (F1 = 0.91).",
          "Main Action": "<NONE>",
          "Arguments": {
            "Agent": [
              "Our findings"
            ],
            "Object": {
              "Primary Object": [
                "major conceptual errors"
              ],
              "Secondary Object": [
                "training data",
                "ML model"
              ]
            },
            "Context": [
              "qualitative investigation",
              "diagnostic disclosures encode a narrow vision of diagnosis experiences that propagates into paradoxes in the downstream ML model",
              "strong performance of the ML classifier (F1 = 0.91)"
            ],
            "Purpose": [
              "identify major conceptual errors"
            ],
            "Method": [
              "qualitative investigation"
            ],
            "Results": [
              "identifying major conceptual errors only seen through a qualitative investigation",
              "training data built from diagnostic disclosures encodes a narrow vision of diagnosis experiences that propagates into paradoxes in the downstream ML model",
              "gap is obscured by strong performance of the ML classifier (F1 = 0.91)"
            ],
            "Analysis": [
              "This gap is obscured by strong performance of the ML classifier (F1 = 0.91)."
            ],
            "Challenge": [
              "narrow vision of diagnosis experiences that propagates into paradoxes in the downstream ML model"
            ],
            "Ethical": [
              "<NONE>"
            ],
            "Implications": [
              "implications of the gap being obscured by strong performance of the ML classifier"
            ],
            "Contradictions": [
              "contradictions between identified errors and high F1 score"
            ]
          }
        },
        {
          "Conclusions/Implications": "",
          "Text": "We discuss the implications of conceptual gaps in creating training data for human-centered models, and make suggestions for improving research methods.",
          "Main Action": "<NONE>",
          "Arguments": {
            "Agent": [
              "we"
            ],
            "Object": {
              "Primary Object": [
                "conceptual gaps",
                "training data",
                "human-centered models"
              ],
              "Secondary Object": [
                "research methods"
              ]
            },
            "Context": [
              "creating training data for human-centered models"
            ],
            "Purpose": [
              "improving research methods"
            ],
            "Method": [
              "discussing implications",
              "making suggestions"
            ],
            "Results": [
              "<NONE>"
            ],
            "Analysis": [
              "<NONE>"
            ],
            "Challenge": [
              "<NONE>"
            ],
            "Ethical": [
              "<NONE>"
            ],
            "Implications": [
              "importance, impact, applications, or future work"
            ],
            "Contradictions": [
              "<NONE>"
            ]
          }
        }
      ]
    }
  ]
}