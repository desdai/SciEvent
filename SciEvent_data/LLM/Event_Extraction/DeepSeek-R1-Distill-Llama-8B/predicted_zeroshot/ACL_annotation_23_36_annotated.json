{
  "papers": [
    {
      "paper_code": "ACL_23_P_211",
      "abstract": "Multilingual neural machine translation has witnessed remarkable progress in recent years. However, the long-tailed distribution of multilingual corpora poses a challenge of Pareto optimization, i.e., optimizing for some languages may come at the cost of degrading the performance of others. Existing balancing training strategies are equivalent to a series of Pareto optimal solutions, which trade off on a Pareto frontierIn Pareto optimization, Pareto optimal solutions refer to solutions in which none of the objectives can be improved without sacrificing at least one of the other objectives. The set of all Pareto optimal solutions forms a Pareto frontier. In this work, we propose a new training framework, Pareto Mutual Distillation (Pareto-MD), towards pushing the Pareto frontier outwards rather than making trade-offs. Specifically, Pareto-MD collaboratively trains two Pareto optimal solutions that favor different languages and allows them to learn from the strengths of each other via knowledge distillation. Furthermore, we introduce a novel strategy to enable stronger communication between Pareto optimal solutions and broaden the applicability of our approach. Experimental results on the widely-used WMT and TED datasets show that our method significantly pushes the Pareto frontier and outperforms baselines by up to +2.46 BLEU.",
      "events": [
        {
          "Background/Introduction": "ERROR",
          "Text": "Multilingual neural machine translation has witnessed remarkable progress in recent years. However, the long-tailed distribution of multilingual corpora poses a challenge of Pareto optimization, i.e., optimizing for some languages may come at the cost of degrading the performance of others. Existing balancing training strategies are equivalent to a series of Pareto optimal solutions, which trade off on a Pareto frontierIn Pareto optimization, Pareto optimal solutions refer to solutions in which none of the objectives can be improved without sacrificing at least one of the other objectives. The set of all Pareto optimal solutions forms a Pareto frontier.",
          "Main Action": "ERROR",
          "Arguments": {
            "Agent": [
              "ERROR"
            ],
            "Object": {
              "Primary Object": [
                "ERROR"
              ],
              "Secondary Object": [
                "ERROR"
              ]
            },
            "Context": [
              "ERROR"
            ],
            "Purpose": [
              "ERROR"
            ],
            "Method": [
              "ERROR"
            ],
            "Results": [
              "ERROR"
            ],
            "Analysis": [
              "ERROR"
            ],
            "Challenge": [
              "ERROR"
            ],
            "Ethical": [
              "ERROR"
            ],
            "Implications": [
              "ERROR"
            ],
            "Contradictions": [
              "ERROR"
            ]
          },
          "Error_Type": "RECONSTRUCTION_ERROR"
        },
        {
          "Methods/Approach": "",
          "Text": "In this work, we propose a new training framework, Pareto Mutual Distillation (Pareto-MD), towards pushing the Pareto frontier outwards rather than making trade-offs. Specifically, Pareto-MD collaboratively trains two Pareto optimal solutions that favor different languages and allows them to learn from the strengths of each other via knowledge distillation. Furthermore, we introduce a novel strategy to enable stronger communication between Pareto optimal solutions and broaden the applicability of our approach.",
          "Main Action": "<NONE>",
          "Arguments": {
            "Agent": [
              "<NONE>"
            ],
            "Object": {
              "Primary Object": [
                "<NONE>"
              ],
              "Secondary Object": [
                "<NONE>"
              ]
            },
            "Context": [
              "<NONE>"
            ],
            "Purpose": [
              "<NONE>"
            ],
            "Method": [
              "novel strategy"
            ],
            "Results": [
              "broadening the applicability",
              "pushing the Pareto frontier outwards"
            ],
            "Analysis": [
              "<NONE>"
            ],
            "Challenge": [
              "<NONE>"
            ],
            "Ethical": [
              "<NONE>"
            ],
            "Implications": [
              "enabling stronger communication",
              "broader applicability"
            ],
            "Contradictions": [
              "<NONE>"
            ]
          }
        },
        {
          "Results/Findings": "",
          "Text": "Experimental results on the widely-used WMT and TED datasets show that our method significantly pushes the Pareto frontier and outperforms baselines by up to +2.46 BLEU.",
          "Main Action": "Show",
          "Arguments": {
            "Agent": [
              "Our method"
            ],
            "Object": {
              "Primary Object": [
                "WMT and TED datasets"
              ],
              "Secondary Object": [
                "<NONE>"
              ]
            },
            "Context": [
              "widely-used datasets",
              "Pareto frontier"
            ],
            "Purpose": [
              "Outperform baselines"
            ],
            "Method": [
              "<NONE>"
            ],
            "Results": [
              "+2.46 BLEU"
            ],
            "Analysis": [
              "<NONE>"
            ],
            "Challenge": [
              "<NONE>"
            ],
            "Ethical": [
              "<NONE>"
            ],
            "Implications": [
              "Advancements in NLP technologies"
            ],
            "Contradictions": [
              "<NONE>"
            ]
          }
        }
      ]
    },
    {
      "paper_code": "ACL_23_P_367",
      "abstract": "Although pretrained language models (PLMs) can be prompted to perform a wide range of language tasks, it remains an open question how much this ability comes from generalizable linguistic understanding versus surface-level lexical patterns. To test this, we present a structured prompting approach for linguistic structured prediction tasks, allowing us to perform zero- and few-shot sequence tagging with autoregressive PLMs. We evaluate this approach on part-of-speech tagging, named entity recognition, and sentence chunking, demonstrating strong few-shot performance in all cases. We also find that while PLMs contain significant prior knowledge of task labels due to task leakage into the pretraining corpus, structured prompting can also retrieve linguistic structure with arbitrary labels. These findings indicate that the in-context learning ability and linguistic knowledge of PLMs generalizes beyond memorization of their training data.",
      "events": [
        {
          "Background/Introduction": "",
          "Text": "Although pretrained language models (PLMs) can be prompted to perform a wide range of language tasks, it remains an open question how much this ability comes from generalizable linguistic understanding versus surface-level lexical patterns.",
          "Main Action": "Examining the source of PLMs' abilities",
          "Arguments": {
            "Agent": [
              "Researchers"
            ],
            "Object": {
              "Primary Object": [
                "Pretrained language models (PLMs)'s abilities"
              ],
              "Secondary Object": [
                "Generalizable linguistic understanding",
                "Surface-level lexical patterns"
              ]
            },
            "Context": [
              "The widespread usage and success of PLMs prompting systems"
            ],
            "Purpose": [
              "To understand the nature of PLMs' cognitive processes and improve AI design"
            ],
            "Method": [
              "Empirical analysis comparing task performance against linguistic structures and patterns"
            ],
            "Results": [
              "Uncertainty about the origin of PLMs' abilities"
            ],
            "Analysis": [
              "Interpretations of findings relating to human-like intelligence vs. statistical learning"
            ],
            "Challenge": [
              "Complexity in testing hypotheses within computational models"
            ],
            "Ethical": [
              "Questions about AI transparency and accountability"
            ],
            "Implications": [
              "Influence on AI design, education, and哲学讨论关于智能性"
            ],
            "Contradictions": [
              "Conflicting theories between linguistics and AI research"
            ]
          }
        },
        {
          "Methods/Approach": "",
          "Text": "To test this, we present a structured prompting approach for linguistic structured prediction tasks, allowing us to perform zero- and few-shot sequence tagging with autoregressive PLMs. We evaluate this approach on part-of-speech tagging, named entity recognition, and sentence chunking, demonstrating strong few-shot performance in all cases.",
          "Main Action": "<NONE>",
          "Arguments": {
            "Agent": [
              "<NONE>"
            ],
            "Object": {
              "Primary Object": [
                "<NONE>"
              ],
              "Secondary Object": [
                "<NONE>"
              ]
            },
            "Context": [
              "<NONE>"
            ],
            "Purpose": [
              "<NONE>"
            ],
            "Method": [
              "autoregressive PLMs"
            ],
            "Results": [
              "part-of-speech tagging",
              "named entity recognition",
              "sentence chunking"
            ],
            "Analysis": [
              "<NONE>"
            ],
            "Challenge": [
              "<NONE>"
            ],
            "Ethical": [
              "<NONE>"
            ],
            "Implications": [
              "<NONE>"
            ],
            "Contradictions": [
              "<NONE>"
            ]
          }
        },
        {
          "Results/Findings": "",
          "Text": "We also find that while PLMs contain significant prior knowledge of task labels due to task leakage into the pretraining corpus, structured prompting can also retrieve linguistic structure with arbitrary labels. These findings indicate that the in-context learning ability and linguistic knowledge of PLMs generalizes beyond memorization of their training data.",
          "Main Action": "can retrieve",
          "Arguments": {
            "Agent": [
              "PLMs"
            ],
            "Object": {
              "Primary Object": [
                "linguistic structure with arbitrary labels"
              ],
              "Secondary Object": [
                "<NONE>"
              ]
            },
            "Context": [
              "understanding the mechanisms behind language model knowledge acquisition"
            ],
            "Purpose": [
              "to demonstrate the generalized learning capabilities of PLMs beyond memorization"
            ],
            "Method": [
              "structured prompting"
            ],
            "Results": [
              "successful retrieval of linguistic structure with arbitrary labels"
            ],
            "Analysis": [
              "indicating that PLMs’ in-context learning and linguistic knowledge extends beyond memorization"
            ],
            "Challenge": [
              "potential biases in structured prompting and dependency on task leakage"
            ],
            "Ethical": [
              "<NONE>"
            ],
            "Implications": [
              "enhancing the development and application of large language models in natural language processing tasks"
            ],
            "Contradictions": [
              "<NONE>"
            ]
          }
        }
      ]
    }
  ]
}