{
  "papers": [
    {
      "paper_code": "ACL_23_P_725",
      "abstract": "Backdoor attacks have become an emerging threat to NLP systems. By providing poisoned training data, the adversary can embed a “backdoor” into the victim model, which allows input instances satisfying certain textual patterns (e.g., containing a keyword) to be predicted as a target label of the adversary’s choice. In this paper, we demonstrate that it is possible to design a backdoor attack that is both stealthy (i.e., hard to notice) and effective (i.e., has a high attack success rate). We propose BITE, a backdoor attack that poisons the training data to establish strong correlations between the target label and a set of “trigger words”. These trigger words are iteratively identified and injected into the target-label instances through natural word-level perturbations. The poisoned training data instruct the victim model to predict the target label on inputs containing trigger words, forming the backdoor. Experiments on four text classification datasets show that our proposed attack is significantly more effective than baseline methods while maintaining decent stealthiness, raising alarm on the usage of untrusted training data. We further propose a defense method named DeBITE based on potential trigger word removal, which outperforms existing methods in defending against BITE and generalizes well to handling other backdoor attacks.",
      "events": [
        {
          "Background/Introduction": "",
          "Text": "Backdoor attacks have become an emerging threat to NLP systems. By providing poisoned training data, the adversary can embed a “backdoor” into the victim model, which allows input instances satisfying certain textual patterns (e.g., containing a keyword) to be predicted as a target label of the adversary’s choice.",
          "Main Action": "Backdoor attacks have become an emerging threat",
          "Arguments": {
            "Agent": [
              "an adversary"
            ],
            "Object": {
              "Primary Object": [
                "Natural Language Processing (NLP) systems"
              ],
              "Secondary Object": [
                "poisoned training data"
              ]
            },
            "Context": [
              "Within the field of Natural Language Processing (NLP)"
            ],
            "Purpose": [
              "allowing input instances [...] to be predicted as a target label of the adversary’s choice"
            ],
            "Method": [
              "providing poisoned training data"
            ],
            "Results": [
              "models behave adversarially when inputs match certain patterns"
            ],
            "Analysis": [
              "This highlights a critical vulnerability in NLP systems"
            ],
            "Challenge": [
              "None explicitly mentioned"
            ],
            "Ethical": [
              "None explicitly mentioned"
            ],
            "Implications": [
              "None explicitly mentioned"
            ],
            "Contradictions": [
              "None explicitly mentioned"
            ]
          }
        },
        {
          "Methods/Approach": "",
          "Text": "In this paper, we demonstrate that it is possible to design a backdoor attack that is both stealthy (i.e., hard to notice) and effective (i.e., has a high attack success rate). We propose BITE, a backdoor attack that poisons the training data to establish strong correlations between the target label and a set of “trigger words”. These trigger words are iteratively identified and injected into the target-label instances through natural word-level perturbations. The poisoned training data instruct the victim model to predict the target label on inputs containing trigger words, forming the backdoor.",
          "Main Action": "Proposing a backdoor attack",
          "Arguments": {
            "Agent": [
              "We"
            ],
            "Object": {
              "Primary Object": [
                "Training data"
              ],
              "Secondary Object": [
                "Target label"
              ]
            },
            "Context": [
              "This paper"
            ],
            "Purpose": [
              "To create a backdoor attack that is both stealthy and effective"
            ],
            "Method": [
              "Using natural word-level perturbations",
              "Injecting trigger words into target-label instances",
              "Establishing strong correlations"
            ],
            "Results": [
              "Having a high attack success rate"
            ],
            "Analysis": [
              "<NONE>"
            ],
            "Challenge": [
              "<NONE>"
            ],
            "Ethical": [
              "<NONE>"
            ],
            "Implications": [
              "Potential for future applications"
            ],
            "Contradictions": [
              "<NONE>"
            ]
          }
        },
        {
          "Results/Findings": "",
          "Text": "Experiments on four text classification datasets show that our proposed attack is significantly more effective than baseline methods while maintaining decent stealthiness, raising alarm on the usage of untrusted training data.",
          "Main Action": "Experiments on four text classification datasets show that our proposed attack is significantly more effective than baseline methods while maintaining decent stealthiness, raising alarm on the usage of untrusted training data.",
          "Arguments": {
            "Agent": [
              "Our team"
            ],
            "Object": {
              "Primary Object": [
                "Four text classification datasets"
              ],
              "Secondary Object": [
                "Untrusted training data"
              ]
            },
            "Context": [
              "Using untrusted training data raises alarm"
            ],
            "Purpose": [
              "To evaluate the effectiveness and safety of our attack compared to baseline methods"
            ],
            "Method": [
              "Testing against baseline methods, assessing effectiveness and stealthiness"
            ],
            "Results": [
              "Our attack is significantly more effective while maintaining decent stealthiness"
            ],
            "Analysis": [
              "Highlighting vulnerabilities in current systems and risks associated with untrusted data"
            ],
            "Challenge": [
              "Dataset bias and difficulty in ensuring data provenance"
            ],
            "Ethical": [
              "Security and privacy implications of using untrusted data"
            ],
            "Implications": [
              "Warning about reliance on unverified data sources and improving data verification processes"
            ],
            "Contradictions": [
              "Discrepancy between expected and actual results supporting hypotheses"
            ]
          }
        },
        {
          "Conclusions/Implications": "",
          "Text": "We further propose a defense method named DeBITE based on potential trigger word removal, which outperforms existing methods in defending against BITE and generalizes well to handling other backdoor attacks.",
          "Main Action": "proposing",
          "Arguments": {
            "Agent": [
              "researchers"
            ],
            "Object": {
              "Primary Object": [
                "DeBITE defense method"
              ],
              "Secondary Object": [
                "<NONE>"
              ]
            },
            "Context": [
              "<NONE>"
            ],
            "Purpose": [
              "creating a better defense mechanism"
            ],
            "Method": [
              "potential trigger word removal"
            ],
            "Results": [
              "outperforming existing methods",
              "defending against BITE",
              "generalizing well to handle other backdoor attacks"
            ],
            "Analysis": [
              "<NONE>"
            ],
            "Challenge": [
              "<NONE>"
            ],
            "Ethical": [
              "<NONE>"
            ],
            "Implications": [
              "advancements in cybersecurity",
              "significant improvements in protecting systems"
            ],
            "Contradictions": [
              "<NONE>"
            ]
          }
        }
      ]
    },
    {
      "paper_code": "ACL_23_P_702",
      "abstract": "Similes play an imperative role in creative writing such as story and dialogue generation. Proper evaluation metrics are like a beacon guiding the research of simile generation (SG). However, it remains under-explored as to what criteria should be considered, how to quantify each criterion into metrics, and whether the metrics are effective for comprehensive, efficient, and reliable SG evaluation. To address the issues, we establish HAUSER, a holistic and automatic evaluation system for the SG task, which consists of five criteria from three perspectives and automatic metrics for each criterion. Through extensive experiments, we verify that our metrics are significantly more correlated with human ratings from each perspective compared with prior automatic metrics.",
      "events": [
        {
          "Background/Introduction": "",
          "Text": "Similes play an imperative role in creative writing such as story and dialogue generation. Proper evaluation metrics are like a beacon guiding the research of simile generation (SG). However, it remains under-explored as to what criteria should be considered, how to quantify each criterion into metrics, and whether the metrics are effective for comprehensive, efficient, and reliable SG evaluation.",
          "Main Action": "Evaluating",
          "Arguments": {
            "Agent": [
              "Researchers"
            ],
            "Object": {
              "Primary Object": [
                "Simile Generation (SG)"
              ],
              "Secondary Object": [
                "<NONE>"
              ]
            },
            "Context": [
              "Similes play an imperative role in creative writing such as story and dialogue generation"
            ],
            "Purpose": [
              "To develop better metrics for SG evaluation, ensuring comprehensiveness, efficiency, and reliability"
            ],
            "Method": [
              "Identifying criteria, quantifying each criterion into metrics"
            ],
            "Results": [
              "Improvements in accuracy and advancements in SG technology"
            ],
            "Analysis": [
              "Analyzing which metrics perform best and their effectiveness through testing"
            ],
            "Challenge": [
              "Current metrics may lack sufficient coverage or robustness"
            ],
            "Ethical": [
              "<NONE>"
            ],
            "Implications": [
              "Better evaluation metrics could lead to improvements in AI systems generating similes"
            ],
            "Contradictions": [
              "<NONE>"
            ]
          }
        },
        {
          "Methods/Approach": "",
          "Text": "To address the issues, we establish HAUSER, a holistic and automatic evaluation system for the SG task, which consists of five criteria from three perspectives and automatic metrics for each criterion.",
          "Main Action": "Establish",
          "Arguments": {
            "Agent": [
              "We"
            ],
            "Object": {
              "Primary Object": [
                "HAUSER"
              ],
              "Secondary Object": [
                "SG task"
              ]
            },
            "Context": [
              "<NONE>"
            ],
            "Purpose": [
              "To address the issues"
            ],
            "Method": [
              "a holistic and automatic evaluation system",
              "consists of five criteria from three perspectives",
              "automatic metrics for each criterion"
            ],
            "Results": [
              "five criteria from three perspectives",
              "automatic metrics for each criterion"
            ],
            "Analysis": [
              "<NONE>"
            ],
            "Challenge": [
              "<NONE>"
            ],
            "Ethical": [
              "<NONE>"
            ],
            "Implications": [
              "<NONE>"
            ],
            "Contradictions": [
              "<NONE>"
            ]
          }
        },
        {
          "Results/Findings": "",
          "Text": "Through extensive experiments, we verify that our metrics are significantly more correlated with human ratings from each perspective compared with prior automatic metrics.",
          "Main Action": "verify",
          "Arguments": {
            "Agent": [
              "we"
            ],
            "Object": {
              "Primary Object": [
                "our metrics"
              ],
              "Secondary Object": [
                "human ratings"
              ]
            },
            "Context": [
              "comparing with prior automatic metrics"
            ],
            "Purpose": [
              "assessing alignment with human ratings"
            ],
            "Method": [
              "extensive experiments"
            ],
            "Results": [
              "significant correlation improvements"
            ],
            "Analysis": [
              "<NONE>"
            ],
            "Challenge": [
              "<NONE>"
            ],
            "Ethical": [
              "<NONE>"
            ],
            "Implications": [
              "improving metric quality through human-centric evaluation"
            ],
            "Contradictions": [
              "<NONE>"
            ]
          }
        }
      ]
    }
  ]
}