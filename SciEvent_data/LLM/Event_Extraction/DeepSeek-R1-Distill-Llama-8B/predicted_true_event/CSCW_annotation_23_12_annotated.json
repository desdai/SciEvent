{
  "papers": [
    {
      "paper_code": "cscw_23_P_57",
      "abstract": "Sexist content is widespread on social media and can reduce women's psychological well-being and their willingness to participate in online discourse, making it a societal issue. To counter these effects, social media platforms employ moderators. To date, little is known about the effectiveness of different forms of moderation in creating a safe space and their acceptance, in particular from the perspective of women as members of the targeted group and users in general (rather than perpetrators). In this research, we propose that some common forms of moderation can be systematized along two facets of visibility, namely visibility of sexist content and of counterspeech. In an online experiment (N = 839), we manipulated these two facets and tested how they shaped social norms, feelings of safety, and intent to participate, as well as fairness, trustworthiness, and efficacy evaluations. In line with our predictions, deletion of sexist content - i.e., its invisibility - and (public) counterspeech - i.e., its visibility - against visible sexist content contributed to creating a safe space. Looking at the underlying psychological mechanism, we found that these effects were largely driven by changes in what was perceived normative in the presented context. Interestingly, deletion of sexist content was judged as less fair than counterspeech against visible sexist content. Our research contributes to a growing body of literature that highlights the importance of norms in creating safer online environments and provides practical implications for moderators for selecting actions that can be effective and accepted.",
      "events": [
        {
          "Background/Introduction": "",
          "Text": "Sexist content is widespread on social media and can reduce women's psychological well-being and their willingness to participate in online discourse, making it a societal issue. To counter these effects, social media platforms employ moderators. To date, little is known about the effectiveness of different forms of moderation in creating a safe space and their acceptance, in particular from the perspective of women as members of the targeted group and users in general (rather than perpetrators).",
          "Main Action": "Social media platforms employ moderators",
          "Arguments": {
            "Agent": [
              "social media platforms"
            ],
            "Object": {
              "Primary Object": [
                "different forms of moderation"
              ],
              "Secondary Object": [
                "women as members of the targeted group"
              ]
            },
            "Context": [
              "sexist content is widespread on social media",
              "reduces women's psychological well-being",
              "willingness to participate in online discourse"
            ],
            "Purpose": [
              "to counter these effects",
              "create a safe space",
              "acceptance from the perspective of women"
            ],
            "Method": [
              "<NONE>"
            ],
            "Results": [
              "<NONE>"
            ],
            "Analysis": [
              "<NONE>"
            ],
            "Challenge": [
              "little is known about the effectiveness of different forms of moderation"
            ],
            "Ethical": [
              "<NONE>"
            ],
            "Implications": [
              "future work",
              "tailored to protecting vulnerable groups"
            ],
            "Contradictions": [
              "<NONE>"
            ]
          }
        },
        {
          "Methods/Approach": "",
          "Text": "In this research, we propose that some common forms of moderation can be systematized along two facets of visibility, namely visibility of sexist content and of counterspeech. In an online experiment (N = 839), we manipulated these two facets and tested how they shaped social norms, feelings of safety, and intent to participate, as well as fairness, trustworthiness, and efficacy evaluations.",
          "Main Action": "We propose that some common forms of moderation can be systematized along two facets of visibility",
          "Arguments": {
            "Agent": [
              "we"
            ],
            "Object": {
              "Primary Object": [
                "two facets of visibility"
              ],
              "Secondary Object": [
                "social norms, feelings of safety, and intent to participate, as well as fairness, trustworthiness, and efficacy evaluations"
              ]
            },
            "Context": [
              "<NONE>"
            ],
            "Purpose": [
              "<NONE>"
            ],
            "Method": [
              "<NONE>"
            ],
            "Results": [
              "<NONE>"
            ],
            "Analysis": [
              "<NONE>"
            ],
            "Challenge": [
              "<NONE>"
            ],
            "Ethical": [
              "<NONE>"
            ],
            "Implications": [
              "<NONE>"
            ],
            "Contradictions": [
              "<NONE>"
            ]
          }
        },
        {
          "Results/Findings": "",
          "Text": "In line with our predictions, deletion of sexist content - i.e., its invisibility - and (public) counterspeech - i.e., its visibility - against visible sexist content contributed to creating a safe space. Looking at the underlying psychological mechanism, we found that these effects were largely driven by changes in what was perceived normative in the presented context. Interestingly, deletion of sexist content was judged as less fair than counterspeech against visible sexist content.",
          "Main Action": "Studying the effects",
          "Arguments": {
            "Agent": [
              "Our predictions"
            ],
            "Object": {
              "Primary Object": [
                "Creating a safe space"
              ],
              "Secondary Object": [
                "Underlying psychological mechanism"
              ]
            },
            "Context": [
              "Discursive context where sexist content exists and counterspeech is possible"
            ],
            "Purpose": [
              "Assessing the effectiveness of these measures"
            ],
            "Method": [
              "Analyzing the effects of deletion and counterspeech"
            ],
            "Results": [
              "These actions led to a safer environment and influenced perceptions of fairness"
            ],
            "Analysis": [
              "Deletion was judged as less fair than counterspeech"
            ],
            "Challenge": [
              "Limitations in scope or generalizability"
            ],
            "Ethical": [
              "None explicitly mentioned"
            ],
            "Implications": [
              "Broader impacts on discourse regulation and understanding of fairness in online spaces"
            ],
            "Contradictions": [
              "None explicitly stated"
            ]
          }
        },
        {
          "Conclusions/Implications": "",
          "Text": "Our research contributes to a growing body of literature that highlights the importance of norms in creating safer online environments and provides practical implications for moderators for selecting actions that can be effective and accepted.",
          "Main Action": "contributes",
          "Arguments": {
            "Agent": [
              "our research"
            ],
            "Object": {
              "Primary Object": [
                "a growing body of literature that highlights the importance of norms in creating safer online environments"
              ],
              "Secondary Object": [
                "<NONE>"
              ]
            },
            "Context": [
              "<NONE>"
            ],
            "Purpose": [
              "provides practical implications for moderators for selecting actions that can be effective and accepted"
            ],
            "Method": [
              "<NONE>"
            ],
            "Results": [
              "<NONE>"
            ],
            "Analysis": [
              "<NONE>"
            ],
            "Challenge": [
              "<NONE>"
            ],
            "Ethical": [
              "<NONE>"
            ],
            "Implications": [
              "<NONE>"
            ],
            "Contradictions": [
              "<NONE>"
            ]
          }
        }
      ]
    },
    {
      "paper_code": "cscw_23_P_249",
      "abstract": "News sharing has become prevalent on many social media platforms. Users are not only exposed to news shared by others, but also actively share information with a diverse set of motivations. In this work, we propose five news sharing motivations based on the intrinsic and extrinsic factors found in prior literature. Through an online experiment, we further examine how a host of factors, including motivations, influence participants' decision to share news online. We then prompt participants to switch their original decision for extra compensation, observing how different news types, motivational and demographic factors may affect the switch. Our analysis suggests that sharing decisions can be reversed when a strong external stimulus (higher bonus) is presented. Further, there are motivational factors that independently influence participants' reversal decisions. Finally, using our work as an empirical basis, we propose designs for future new sharing systems.",
      "events": [
        {
          "Background/Introduction": "",
          "Text": "News sharing has become prevalent on many social media platforms. Users are not only exposed to news shared by others, but also actively share information with a diverse set of motivations.",
          "Main Action": "actively share",
          "Arguments": {
            "Agent": [
              "users"
            ],
            "Object": {
              "Primary Object": [
                "information"
              ],
              "Secondary Object": [
                "<NONE>"
              ]
            },
            "Context": [
              "many social media platforms"
            ],
            "Purpose": [
              "a diverse set of motivations"
            ],
            "Method": [
              "<NONE>"
            ],
            "Results": [
              "<NONE>"
            ],
            "Analysis": [
              "<NONE>"
            ],
            "Challenge": [
              "<NONE>"
            ],
            "Ethical": [
              "<NONE>"
            ],
            "Implications": [
              "understanding user behavior better"
            ],
            "Contradictions": [
              "<NONE>"
            ]
          }
        },
        {
          "Methods/Approach": "ERROR",
          "Text": "In this work, we propose five news sharing motivations based on the intrinsic and extrinsic factors found in prior literature. Through an online experiment, we further examine how a host of factors, including motivations, influence participants' decision to share news online. We then prompt participants to switch their original decision for extra compensation, observing how different news types, motivational and demographic factors may affect the switch.",
          "Main Action": "ERROR",
          "Arguments": {
            "Agent": [
              "ERROR"
            ],
            "Object": {
              "Primary Object": [
                "ERROR"
              ],
              "Secondary Object": [
                "ERROR"
              ]
            },
            "Context": [
              "ERROR"
            ],
            "Purpose": [
              "ERROR"
            ],
            "Method": [
              "ERROR"
            ],
            "Results": [
              "ERROR"
            ],
            "Analysis": [
              "ERROR"
            ],
            "Challenge": [
              "ERROR"
            ],
            "Ethical": [
              "ERROR"
            ],
            "Implications": [
              "ERROR"
            ],
            "Contradictions": [
              "ERROR"
            ]
          },
          "Error_Type": "NO_JSON_FOUND"
        },
        {
          "Results/Findings": "",
          "Text": "Our analysis suggests that sharing decisions can be reversed when a strong external stimulus (higher bonus) is presented. Further, there are motivational factors that independently influence participants' reversal decisions.",
          "Main Action": "Our analysis suggests that sharing decisions can be reversed",
          "Arguments": {
            "Agent": [
              "<NONE>"
            ],
            "Object": {
              "Primary Object": [
                "participants' reversal decisions"
              ],
              "Secondary Object": [
                "strong external stimulus (higher bonus)"
              ]
            },
            "Context": [
              "when a strong external stimulus (higher bonus) is presented"
            ],
            "Purpose": [
              "<NONE>"
            ],
            "Method": [
              "<NONE>"
            ],
            "Results": [
              "sharing decisions can be reversed"
            ],
            "Analysis": [
              "Further, there are motivational factors that independently influence participants' reversal decisions"
            ],
            "Challenge": [
              "<NONE>"
            ],
            "Ethical": [
              "<NONE>"
            ],
            "Implications": [
              "<NONE>"
            ],
            "Contradictions": [
              "<NONE>"
            ]
          }
        },
        {
          "Conclusions/Implications": "",
          "Text": "Finally, using our work as an empirical basis, we propose designs for future new sharing systems.",
          "Main Action": "propose",
          "Arguments": {
            "Agent": [
              "we"
            ],
            "Object": {
              "Primary Object": [
                "designs for future new sharing systems"
              ],
              "Secondary Object": [
                "<NONE>"
              ]
            },
            "Context": [
              "<NONE>"
            ],
            "Purpose": [
              "advancing future sharing systems"
            ],
            "Method": [
              "<NONE>"
            ],
            "Results": [
              "<NONE>"
            ],
            "Analysis": [
              "<NONE>"
            ],
            "Challenge": [
              "<NONE>"
            ],
            "Ethical": [
              "<NONE>"
            ],
            "Implications": [
              "proposing designs for future new sharing systems"
            ],
            "Contradictions": [
              "<NONE>"
            ]
          }
        }
      ]
    }
  ]
}