{
  "papers": [
    {
      "paper_code": "cscw_23_P_143",
      "abstract": "A conversational agent (CA) effectively facilitates online group discussions at scale. However, users may have expectations about how well the CA would perform that do not match with the actual performance, compromising technology acceptance. We built a facilitator CA that detects a member who has low contribution during a synchronous group chat discussion and asks the person to participate more. We designed three techniques to set end-user expectations about how accurately the CA identifies an under-contributing member: 1) information: explicitly communicating the accuracy of the detection algorithm, 2) explanation: providing an overview of the algorithm and the data used for the detection, and 3) adjustment: enabling users to gain a feeling of control over the algorithm. We conducted an online experiment with 163 crowdworkers in which each group completed a collaborative decision-making task and experienced one of the techniques. Through surveys and interviews, we found that the explanation technique was the most effective strategy overall as it reduced user embarrassment, increased the perceived intelligence of the CA, and helped users better understand the detection algorithm. In contrast, the information technique reduced members' contributions, and the adjustment technique led to a more negative perceived discussion experience. We also discovered that the interactions with other team members diluted the effects of the techniques on users' performance expectations and acceptance of the CA. We discuss implications for better designing expectation-setting techniques for AI-team collaboration such as ways to improve collaborative decision outcomes and quality of contributions.",
      "events": [
        {
          "Background/Introduction": "",
          "Text": "A conversational agent (CA) effectively facilitates online group discussions at scale. However, users may have expectations about how well the CA would perform that do not match with the actual performance, compromising technology acceptance.",
          "Main Action": "<NONE>",
          "Arguments": {
            "Agent": [
              "users"
            ],
            "Object": {
              "Primary Object": [
                "expectations",
                "performance"
              ],
              "Primary Modifier": [
                "<NONE>"
              ],
              "Secondary Object": [
                "technology acceptance"
              ],
              "Secondary Modifier": [
                "<NONE>"
              ]
            },
            "Context": [
              "conversational agent (CA)",
              "facilitates online group discussions at scale"
            ],
            "Purpose": [
              "<NONE>"
            ],
            "Method": [
              "<NONE>"
            ],
            "Results": [
              "user's expectations may not match actual performance"
            ],
            "Analysis": [
              "compromising technology acceptance"
            ],
            "Challenge": [
              "<NONE>"
            ],
            "Ethical": [
              "<NONE>"
            ],
            "Implications": [
              "<NONE>"
            ],
            "Contradictions": [
              "<NONE>"
            ]
          }
        },
        {
          "Methods/Approach": "",
          "Text": "We built a facilitator CA that detects a member who has low contribution during a synchronous group chat discussion and asks the person to participate more. We designed three techniques to set end-user expectations about how accurately the CA identifies an under-contributing member: 1) information: explicitly communicating the accuracy of the detection algorithm, 2) explanation: providing an overview of the algorithm and the data used for the detection, and 3) adjustment: enabling users to gain a feeling of control over the algorithm. We conducted an online experiment with 163 crowdworkers in which each group completed a collaborative decision-making task and experienced one of the techniques.",
          "Main Action": "built",
          "Arguments": {
            "Agent": [
              "we"
            ],
            "Object": {
              "Primary Object": [
                "a facilitator CA"
              ],
              "Primary Modifier": [
                "<NONE>"
              ],
              "Secondary Object": [
                "<NONE>"
              ],
              "Secondary Modifier": [
                "<NONE>"
              ]
            },
            "Context": [
              "detects a member who has low contribution during a synchronous group chat discussion"
            ],
            "Purpose": [
              "asks the person to participate more"
            ],
            "Method": [
              "designed three techniques to set end-user expectations about how accurately the CA identifies an under-contributing member:"
            ],
            "Results": [
              "<NONE>"
            ],
            "Analysis": [
              "<NONE>"
            ],
            "Challenge": [
              "<NONE>"
            ],
            "Ethical": [
              "<NONE>"
            ],
            "Implications": [
              "<NONE>"
            ],
            "Contradictions": [
              "<NONE>"
            ]
          }
        },
        {
          "Results/Findings": "",
          "Text": "Through surveys and interviews, we found that the explanation technique was the most effective strategy overall as it reduced user embarrassment, increased the perceived intelligence of the CA, and helped users better understand the detection algorithm. In contrast, the information technique reduced members' contributions, and the adjustment technique led to a more negative perceived discussion experience. We also discovered that the interactions with other team members diluted the effects of the techniques on users' performance expectations and acceptance of the CA.",
          "Main Action": "<NONE>",
          "Arguments": {
            "Agent": [
              "we"
            ],
            "Object": {
              "Primary Object": [
                "explanation technique",
                "information technique",
                "adjustment technique"
              ],
              "Primary Modifier": [
                "<NONE>"
              ],
              "Secondary Object": [
                "user embarrassment",
                "perceived intelligence of the CA",
                "users understanding of the detection algorithm",
                "members' contributions",
                "discussion experience"
              ],
              "Secondary Modifier": [
                "<NONE>"
              ]
            },
            "Context": [
              "through surveys and interviews"
            ],
            "Purpose": [
              "to find out which technique was most effective"
            ],
            "Method": [
              "surveys and interviews"
            ],
            "Results": [
              "reduced user embarrassment, increased the perceived intelligence of the CA, and helped users better understand the detection algorithm",
              "reduced members' contributions",
              "led to a more negative perceived discussion experience"
            ],
            "Analysis": [
              "interactions with other team members diluted the effects of the techniques on users' performance expectations and acceptance of the CA"
            ],
            "Challenge": [
              "<NONE>"
            ],
            "Ethical": [
              "<NONE>"
            ],
            "Implications": [
              "<NONE>"
            ],
            "Contradictions": [
              "<NONE>"
            ]
          }
        },
        {
          "Conclusions/Implications": "",
          "Text": "We discuss implications for better designing expectation-setting techniques for AI-team collaboration such as ways to improve collaborative decision outcomes and quality of contributions.",
          "Main Action": "<discuss>",
          "Arguments": {
            "Agent": [
              "<NONE>"
            ],
            "Object": {
              "Primary Object": [
                "implications"
              ],
              "Primary Modifier": [
                "<NONE>"
              ],
              "Secondary Object": [
                "better designing expectation-setting techniques for AI-team collaboration such as ways to improve collaborative decision outcomes and quality of contributions"
              ],
              "Secondary Modifier": [
                "<NONE>"
              ]
            },
            "Context": [
              "for better designing expectation-setting techniques for AI-team collaboration"
            ],
            "Purpose": [
              "<NONE>"
            ],
            "Method": [
              "<NONE>"
            ],
            "Results": [
              "<NONE>"
            ],
            "Analysis": [
              "<NONE>"
            ],
            "Challenge": [
              "<NONE>"
            ],
            "Ethical": [
              "<NONE>"
            ],
            "Implications": [
              "broad significance or potential for future applications/research"
            ],
            "Contradictions": [
              "<NONE>"
            ]
          }
        }
      ]
    },
    {
      "paper_code": "cscw_23_P_211",
      "abstract": "The COVID-19 pandemic transformed many aspects of health and daily life. A subset of people who were infected with the virus have ongoing chronic health issues that range in type of symptom and severity. In this study, we conducted a qualitative assessment of self-reported post-COVID symptoms from patients' electronic health records (EHR, n=564) and a randomized collection of Reddit and Twitter posts (n=500 for each). We show the inconsistencies in what types of symptoms are shared between platforms in addition to assessing the severity of the symptoms and how social media characterizations of post-COVID do not tell a complete story of this phenomenon. This research contributes to CSCW health literature by connecting digital traces of post-COVID with EHR data, critiquing the use of social media as a health proxy and points to its potential to add context to the analysis of traditional health data extracted from the EHR.",
      "events": [
        {
          "Background/Introduction": "",
          "Text": "The COVID-19 pandemic transformed many aspects of health and daily life. A subset of people who were infected with the virus have ongoing chronic health issues that range in type of symptom and severity.",
          "Main Action": "<NONE>",
          "Arguments": {
            "Agent": [
              "A subset of people who were infected with the virus"
            ],
            "Object": {
              "Primary Object": [
                "ongoing chronic health issues"
              ],
              "Primary Modifier": [
                "<NONE>"
              ],
              "Secondary Object": [
                "that range in type of symptom and severity"
              ],
              "Secondary Modifier": [
                "<NONE>"
              ]
            },
            "Context": [
              "The COVID-19 pandemic transformed many aspects of health and daily life"
            ],
            "Purpose": [
              "<NONE>"
            ],
            "Method": [
              "<NONE>"
            ],
            "Results": [
              "<NONE>"
            ],
            "Analysis": [
              "<NONE>"
            ],
            "Challenge": [
              "<NONE>"
            ],
            "Ethical": [
              "<NONE>"
            ],
            "Implications": [
              "<NONE>"
            ],
            "Contradictions": [
              "<NONE>"
            ]
          }
        },
        {
          "Methods/Approach": "",
          "Text": "In this study, we conducted a qualitative assessment of self-reported post-COVID symptoms from patients' electronic health records (EHR, n=564) and a randomized collection of Reddit and Twitter posts (n=500 for each).",
          "Main Action": "conducted",
          "Arguments": {
            "Agent": [
              "we"
            ],
            "Object": {
              "Primary Object": [
                "a qualitative assessment"
              ],
              "Primary Modifier": [
                "<NONE>"
              ],
              "Secondary Object": [
                  "self-reported post-COVID symptoms",
                  "patients' electronic health records (EHR, n=564)",
                  "Reddit and Twitter posts"
              ],
              "Secondary Modifier": [
                "<NONE>"
              ]
            },
            "Context": [
              "from patients' electronic health records (EHR, n=564) and a randomized collection of Reddit and Twitter posts (n=500 for each)"
            ],
            "Purpose": [
              "<NONE>"
            ],
            "Method": [
              "qualitative assessment"
            ],
            "Results": [
              "<NONE>"
            ],
            "Analysis": [
              "<NONE>"
            ],
            "Challenge": [
              "<NONE>"
            ],
            "Ethical": [
              "<NONE>"
            ],
            "Implications": [
              "<NONE>"
            ],
            "Contradictions": [
              "<NONE>"
            ]
          }
        },
        {
          "Results/Findings": "",
          "Text": "We show the inconsistencies in what types of symptoms are shared between platforms in addition to assessing the severity of the symptoms and how social media characterizations of post-COVID do not tell a complete story of this phenomenon.",
          "Main Action": "show",
          "Arguments": {
            "Agent": [
              "we"
            ],
            "Object": {
              "Primary Object": [
                "inconsistencies",
                "symptoms",
                "platforms",
                "severity",
                "symptoms",
                "social media characterizations",
                "post-COVID"
              ],
              "Primary Modifier": [
                "<NONE>"
              ],
              "Secondary Object": [
                "complete story"
              ],
              "Secondary Modifier": [
                "<NONE>"
              ]
            },
            "Context": [
              "types of symptoms are shared between platforms",
              "assessing the severity of the symptoms"
            ],
            "Purpose": [
              "to assess the consistency and completeness of symptom reporting on various platforms regarding post-COVID conditions via social media"
            ],
            "Method": [
              "<NONE>"
            ],
            "Results": [
              "inconsistencies in what types of symptoms are shared between platforms",
              "assessment of the severity of the symptoms"
            ],
            "Analysis": [
              "how social media characterizations of post-COVID do not tell a complete story of this phenomenon"
            ],
            "Challenge": [
              "<NONE>"
            ],
            "Ethical": [
              "<NONE>"
            ],
            "Implications": [
              "<NONE>"
            ],
            "Contradictions": [
              "<NONE>"
            ]
          }
        },
        {
          "Conclusions/Implications": "",
          "Text": "This research contributes to CSCW health literature by connecting digital traces of post-COVID with EHR data, critiquing the use of social media as a health proxy and points to its potential to add context to the analysis of traditional health data extracted from the EHR.",
          "Main Action": "contributes",
          "Arguments": {
            "Agent": [
              "This research"
            ],
            "Object": {
              "Primary Object": [
                "CSCW health literature"
              ],
              "Primary Modifier": [
                "<NONE>"
              ],
              "Secondary Object": [
                "digital traces of post-COVID",
                "EHR data"
              ],
              "Secondary Modifier": [
                "<NONE>"
              ]
            },
            "Context": [
              "connecting...health proxy and points to its potential to add context to the analysis of traditional health data extracted from the EHR."
            ],
            "Purpose": [
              "critiquing the use of social media as a health proxy"
            ],
            "Method": [
              "<NONE>"
            ],
            "Results": [
              "points to its potential to add context to the analysis of traditional health data extracted from the EHR"
            ],
            "Analysis": [
              "<NONE>"
            ],
            "Challenge": [
              "<NONE>"
            ],
            "Ethical": [
              "<NONE>"
            ],
            "Implications": [
              "<NONE>"
            ],
            "Contradictions": [
              "<NONE>"
            ]
          }
        }
      ]
    }
  ]
}