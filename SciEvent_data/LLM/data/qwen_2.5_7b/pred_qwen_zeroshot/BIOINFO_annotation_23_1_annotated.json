{
  "papers": [
    {
      "paper_code": "bioinfo_23_P_499",
      "abstract": "Synthetic lethality (SL) is a promising strategy for anticancer therapy, as inhibiting SL partners of genes with cancer-specific mutations can selectively kill the cancer cells without harming the normal cells. Wet-lab techniques for SL screening have issues like high cost and off-target effects. Computational methods can help address these issues. Previous machine learning methods leverage known SL pairs, and the use of knowledge graphs (KGs) can significantly enhance the prediction performance. However, the subgraph structures of KG have not been fully explored. Besides, most machine learning methods lack interpretability, which is an obstacle for wide applications of machine learning to SL identification. We present a model named KR4SL to predict SL partners for a given primary gene. It captures the structural semantics of a KG by efficiently constructing and learning from relational digraphs in the KG. To encode the semantic information of the relational digraphs, we fuse textual semantics of entities into propagated messages and enhance the sequential semantics of paths using a recurrent neural network. Moreover, we design an attentive aggregator to identify critical subgraph structures that contribute the most to the SL prediction as explanations. Extensive experiments under different settings show that KR4SL significantly outperforms all the baselines. The explanatory subgraphs for the predicted gene pairs can unveil prediction process and mechanisms underlying synthetic lethality. The improved predictive power and interpretability indicate that deep learning is practically useful for SL-based cancer drug target discovery.",
      "events": [
        {
          "Background/Introduction": "",
          "Text": "Synthetic lethality (SL) is a promising strategy for anticancer therapy, as inhibiting SL partners of genes with cancer-specific mutations can selectively kill the cancer cells without harming the normal cells. Wet-lab techniques for SL screening have issues like high cost and off-target effects. Computational methods can help address these issues. Previous machine learning methods leverage known SL pairs, and the use of knowledge graphs (KGs) can significantly enhance the prediction performance. However, the subgraph structures of KG have not been fully explored. Besides, most machine learning methods lack interpretability, which is an obstacle for wide applications of machine learning to SL identification.",
          "Main Action": "<NONE>",
          "Arguments": {
            "Agent": [
              "Previous machine learning methods",
              "most machine learning methods"
            ],
            "Object": {
              "Primary Object": [
                "knowledge graphs",
                "interpretability"
              ],
              "Primary Modifier": [
                "<NONE>"
              ],
              "Secondary Object": [
                "subgraph structures of KG",
                "wide applications of machine learning to SL identification"
              ],
              "Secondary Modifier": [
                "<NONE>"
              ]
            },
            "Context": [
              "Wet-lab techniques for SL screening have issues like high cost and off-target effects.",
              "Computational methods can help address these issues."
            ],
            "Purpose": [
              "enhance the prediction performance",
              "an obstacle for wide applications of machine learning to SL identification"
            ],
            "Method": [
              "leverage known SL pairs",
              "lack interpretability"
            ],
            "Results": [
              "significantly enhance the prediction performance"
            ],
            "Analysis": [
              "<NONE>"
            ],
            "Challenge": [
              "the subgraph structures of KG have not been fully explored.",
              "Most machine learning methods lack interpretability."
            ],
            "Ethical": [
              "<NONE>"
            ],
            "Implications": [
              "potential for wider application of computational methods in identifying synthetic lethal interactions"
            ],
            "Contradictions": [
              "<NONE>"
            ]
          }
        },
        {
          "Methods/Approach": "",
          "Text": "We present a model named KR4SL to predict SL partners for a given primary gene. It captures the structural semantics of a KG by efficiently constructing and learning from relational digraphs in the KG. To encode the semantic information of the relational digraphs, we fuse textual semantics of entities into propagated messages and enhance the sequential semantics of paths using a recurrent neural network. Moreover, we design an attentive aggregator to identify critical subgraph structures that contribute the most to the SL prediction as explanations.",
          "Main Action": "present",
          "Arguments": {
            "Agent": [
              "we"
            ],
            "Object": {
              "Primary Object": [
                "a model named KR4SL"
              ],
              "Primary Modifier": [
                "<NONE>"
              ],
              "Secondary Object": [
                "<NONE>"
              ],
              "Secondary Modifier": [
                "<NONE>"
              ]
            },
            "Context": [
              "predict SL partners for a given primary gene"
            ],
            "Purpose": [
              "capture the structural semantics of a KG by efficiently constructing and learning from relational digraphs in the KG"
            ],
            "Method": [
              "fuse textual semantics of entities into propagated messages",
              "enhance the sequential semantics of paths using a recurrent neural network",
              "design an attentive aggregator"
            ],
            "Results": [
              "identify critical subgraph structures that contribute the most to the SL prediction as explanations"
            ],
            "Analysis": [
              "<NONE>"
            ],
            "Challenge": [
              "<NONE>"
            ],
            "Ethical": [
              "<NONE>"
            ],
            "Implications": [
              "<NONE>"
            ],
            "Contradictions": [
              "<NONE>"
            ]
          }
        },
        {
          "Results/Findings": "",
          "Text": "Extensive experiments under different settings show that KR4SL significantly outperforms all the baselines. The explanatory subgraphs for the predicted gene pairs can unveil prediction process and mechanisms underlying synthetic lethality.",
          "Main Action": "show",
          "Arguments": {
            "Agent": [
              "Extensive experiments under different settings"
            ],
            "Object": {
              "Primary Object": [
                "KR4SL"
              ],
              "Primary Modifier": [
                "<NONE>"
              ],
              "Secondary Object": [
                "all the baselines"
              ],
              "Secondary Modifier": [
                "<NONE>"
              ]
            },
            "Context": [
              "under different settings"
            ],
            "Purpose": [
              "significantly outperforms"
            ],
            "Method": [
              "extensive experiments"
            ],
            "Results": [
              "outperforms all the baselines"
            ],
            "Analysis": [
              "unveil prediction process and mechanisms underlying synthetic lethality"
            ],
            "Challenge": [
              "<NONE>"
            ],
            "Ethical": [
              "<NONE>"
            ],
            "Implications": [
              "<NONE>"
            ],
            "Contradictions": [
              "<NONE>"
            ]
          }
        },
        {
          "Conclusions/Implications": "",
          "Text": "The improved predictive power and interpretability indicate that deep learning is practically useful for SL-based cancer drug target discovery.",
          "Main Action": "<NONE>",
          "Arguments": {
            "Agent": [
              "deep learning"
            ],
            "Object": {
              "Primary Object": [
                "SL-based cancer drug target discovery"
              ],
              "Primary Modifier": [
                "<NONE>"
              ],
              "Secondary Object": [
                "<NONE>"
              ],
              "Secondary Modifier": [
                "<NONE>"
              ]
            },
            "Context": [
              "improved predictive power and interpretability"
            ],
            "Purpose": [
              "practically useful"
            ],
            "Method": [
              "<NONE>"
            ],
            "Results": [
              "improved predictive power and interpretability"
            ],
            "Analysis": [
              "indicating practical usefulness"
            ],
            "Challenge": [
              "<NONE>"
            ],
            "Ethical": [
              "<NONE>"
            ],
            "Implications": [
              "broader significance or potential for future applications/research"
            ],
            "Contradictions": [
              "<NONE>"
            ]
          }
        }
      ]
    },
    {
      "paper_code": "bioinfo_23_P_110",
      "abstract": "We present a multi-sequence generalization of Variational Information Bottleneck and call the resulting model Attentive Variational Information Bottleneck (AVIB). Our AVIB model leverages multi-head self-attention to implicitly approximate a posterior distribution over latent encodings conditioned on multiple input sequences. We apply AVIB to a fundamental immuno-oncology problem: predicting the interactions between T-cell receptors (TCRs) and peptides. Experimental results on various datasets show that AVIB significantly outperforms state-of-the-art methods for TCR-peptide interaction prediction. Additionally, we show that the latent posterior distribution learned by AVIB is particularly effective for the unsupervised detection of out-of-distribution amino acid sequences.",
      "events": [
        {
          "Background/Introduction": "",
          "Text": "We present a multi-sequence generalization of Variational Information Bottleneck and call the resulting model Attentive Variational Information Bottleneck (AVIB).",
          "Main Action": "present",
          "Arguments": {
            "Agent": [
              "we"
            ],
            "Object": {
              "Primary Object": [
                "a multi-sequence generalization of Variational Information Bottleneck"
              ],
              "Primary Modifier": [
                "<NONE>"
              ],
              "Secondary Object": [
                "Attentive Variational Information Bottleneck (AVIB)"
              ],
              "Secondary Modifier": [
                "<NONE>"
              ]
            },
            "Context": [
              "<NONE>"
            ],
            "Purpose": [
              "<NONE>"
            ],
            "Method": [
              "<NONE>"
            ],
            "Results": [
              "<NONE>"
            ],
            "Analysis": [
              "<NONE>"
            ],
            "Challenge": [
              "<NONE>"
            ],
            "Ethical": [
              "<NONE>"
            ],
            "Implications": [
              "<NONE>"
            ],
            "Contradictions": [
              "<NONE>"
            ]
          }
        },
        {
          "Methods/Approach": "",
          "Text": "Our AVIB model leverages multi-head self-attention to implicitly approximate a posterior distribution over latent encodings conditioned on multiple input sequences. We apply AVIB to a fundamental immuno-oncology problem: predicting the interactions between T-cell receptors (TCRs) and peptides.",
          "Main Action": "<NONE>",
          "Arguments": {
            "Agent": [
              "Our AVIB model"
            ],
            "Object": {
              "Primary Object": [
                "a posterior distribution over latent encodings"
              ],
              "Primary Modifier": [
                "<NONE>"
              ],
              "Secondary Object": [
                "multiple input sequences"
              ],
              "Secondary Modifier": [
                "<NONE>"
              ]
            },
            "Context": [
              "leverages multi-head self-attention"
            ],
            "Purpose": [
              "predicting the interactions between T-cell receptors (TCRs) and peptides"
            ],
            "Method": [
              "applying AVIB"
            ],
            "Results": [
              "<NONE>"
            ],
            "Analysis": [
              "<NONE>"
            ],
            "Challenge": [
              "<NONE>"
            ],
            "Ethical": [
              "<NONE>"
            ],
            "Implications": [
              "<NONE>"
            ],
            "Contradictions": [
              "<NONE>"
            ]
          }
        },
        {
          "Results/Findings": "",
          "Text": "Experimental results on various datasets show that AVIB significantly outperforms state-of-the-art methods for TCR-peptide interaction prediction. Additionally, we show that the latent posterior distribution learned by AVIB is particularly effective for the unsupervised detection of out-of-distribution amino acid sequences.",
          "Main Action": "show",
          "Arguments": {
            "Agent": [
              "AVIB",
              "we"
            ],
            "Object": {
              "Primary Object": [
                "experimental results",
                "state-of-the-art methods",
                "latent posterior distribution"
              ],
              "Primary Modifier": [
                "<NONE>"
              ],
              "Secondary Object": [
                "various datasets",
                "unsupervised detection of out-of-distribution amino acid sequences"
              ],
              "Secondary Modifier": [
                "<NONE>"
              ]
            },
            "Context": [
              "on various datasets"
            ],
            "Purpose": [
              "significantly outperforms"
            ],
            "Method": [
              "learned by AVIB"
            ],
            "Results": [
              "outperform state-of-the-art methods",
              "effective for the unsupervised detection of out-of-distribution amino acid sequences"
            ],
            "Analysis": [
              "particularly effective"
            ],
            "Challenge": [
              "<NONE>"
            ],
            "Ethical": [
              "<NONE>"
            ],
            "Implications": [
              "<NONE>"
            ],
            "Contradictions": [
              "<NONE>"
            ]
          }
        }
      ]
    }
  ]
}