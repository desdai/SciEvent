{
  "papers": [
    {
      "paper_code": "ACL_23_P_657",
      "abstract": "Second language acquisition (SLA) research has extensively studied cross-linguistic transfer, the influence of linguistic structure of a speaker’s native language [L1] on the successful acquisition of a foreign language [L2]. Effects of such transfer can be positive (facilitating acquisition) or negative (impeding acquisition). We find that NLP literature has not given enough attention to the phenomenon of negative transfer. To understand patterns of both positive and negative transfer between L1 and L2, we model sequential second language acquisition in LMs. Further, we build a Multilingual Age Ordered CHILDES (MAO-CHILDES)—a dataset consisting of 5 typologically diverse languages, i.e., German, French, Polish, Indonesian, and Japanese—to understand the degree to which native Child-Directed Speech (CDS) [L1] can help or conflict with English language acquisition [L2]. To examine the impact of native CDS, we use the TILT-based cross lingual transfer learning approach established by Papadimitriou and Jurafsky (2020) and find that, as in human SLA, language family distance predicts more negative transfer. Additionally, we find that conversational speech data shows greater facilitation for language acquisition than scripted speech data. Our findings call for further research using our novel Transformer-based SLA models and we would like to encourage it by releasing our code, data, and models.",
      "events": [
        {
          "Background/Introduction": "",
          "Text": "Second language acquisition (SLA) research has extensively studied cross-linguistic transfer, the influence of linguistic structure of a speaker’s native language [L1] on the successful acquisition of a foreign language [L2]. Effects of such transfer can be positive (facilitating acquisition) or negative (impeding acquisition). We find that NLP literature has not given enough attention to the phenomenon of negative transfer.",
          "Main Action": "<NONE>",
          "Arguments": {
            "Agent": [
              "We"
            ],
            "Object": {
              "Primary Object": [
                "NLP literature"
              ],
              "Primary Modifier": [
                "<NONE>"
              ],
              "Secondary Object": [
                "negative transfer phenomenon"
              ],
              "Secondary Modifier": [
                "<NONE>"
              ]
            },
            "Context": [
              "cross-linguistic transfer",
              "influence of L1 on SLA"
            ],
            "Purpose": [
              "give enough attention"
            ],
            "Method": [
              "<NONE>"
            ],
            "Results": [
              "not given enough attention"
            ],
            "Analysis": [
              "<NONE>"
            ],
            "Challenge": [
              "<NONE>"
            ],
            "Ethical": [
              "<NONE>"
            ],
            "Implications": [
              "broad significance or potential for future applications/research"
            ],
            "Contradictions": [
              "<NONE>"
            ]
          }
        },
        {
          "Methods/Approach": "",
          "Text": "To understand patterns of both positive and negative transfer between L1 and L2, we model sequential second language acquisition in LMs. Further, we build a Multilingual Age Ordered CHILDES (MAO-CHILDES)—a dataset consisting of 5 typologically diverse languages, i.e., German, French, Polish, Indonesian, and Japanese—to understand the degree to which native Child-Directed Speech (CDS) [L1] can help or conflict with English language acquisition [L2].",
          "Main Action": "model",
          "Arguments": {
            "Agent": [
              "we"
            ],
            "Object": {
              "Primary Object": [
                "sequential second language acquisition"
              ],
              "Primary Modifier": [
                "<NONE>"
              ],
              "Secondary Object": [
                "LMs"
              ],
              "Secondary Modifier": [
                "<NONE>"
              ]
            },
            "Context": [
              "to understand patterns of both positive and negative transfer between L1 and L2"
            ],
            "Purpose": [
              "<NONE>"
            ],
            "Method": [
              "build a Multilingual Age Ordered CHILDES (MAO-CHILDES) — a dataset consisting of 5 typologically diverse languages, i.e., German, French, Polish, Indonesian, and Japanese"
            ],
            "Results": [
              "understand the degree to which native Child-Directed Speech (CDS) [L1] can help or conflict with English language acquisition [L2]"
            ],
            "Analysis": [
              "<NONE>"
            ],
            "Challenge": [
              "<NONE>"
            ],
            "Ethical": [
              "<NONE>"
            ],
            "Implications": [
              "<NONE>"
            ],
            "Contradictions": [
              "<NONE>"
            ]
          }
        },
        {
          "Results/Findings": "",
          "Text": "To examine the impact of native CDS, we use the TILT-based cross lingual transfer learning approach established by Papadimitriou and Jurafsky (2020) and find that, as in human SLA, language family distance predicts more negative transfer. Additionally, we find that conversational speech data shows greater facilitation for language acquisition than scripted speech data.",
          "Main Action": "use",
          "Arguments": {
            "Agent": [
              "we"
            ],
            "Object": {
              "Primary Object": [
                "TILT-based cross lingual transfer learning approach"
              ],
              "Primary Modifier": [
                "<NONE>"
              ],
              "Secondary Object": [
                "<NONE>"
              ],
              "Secondary Modifier": [
                "<NONE>"
              ]
            },
            "Context": [
              "to examine the impact of native CDS"
            ],
            "Purpose": [
              "<NONE>"
            ],
            "Method": [
              "established by Papadimitriou and Jurafsky (2020)"
            ],
            "Results": [
              "find that, as in human SLA, language family distance predicts more negative transfer",
              "conversational speech data shows greater facilitation for language acquisition than scripted speech data"
            ],
            "Analysis": [
              "<NONE>"
            ],
            "Challenge": [
              "<NONE>"
            ],
            "Ethical": [
              "<NONE>"
            ],
            "Implications": [
              "<NONE>"
            ],
            "Contradictions": [
              "<NONE>"
            ]
          }
        },
        {
          "Conclusions/Implications": "",
          "Text": "Our findings call for further research using our novel Transformer-based SLA models and we would like to encourage it by releasing our code, data, and models.",
          "Main Action": "call for",
          "Arguments": {
            "Agent": [
              "our findings"
            ],
            "Object": {
              "Primary Object": [
                "further research"
              ],
              "Primary Modifier": [
                "<NONE>"
              ],
              "Secondary Object": [
                "using our novel Transformer-based SLA models"
              ],
              "Secondary Modifier": [
                "<NONE>"
              ]
            },
            "Context": [
              "releasing our code, data, and models"
            ],
            "Purpose": [
              "encourage it"
            ],
            "Method": [
              "<NONE>"
            ],
            "Results": [
              "<NONE>"
            ],
            "Analysis": [
              "<NONE>"
            ],
            "Challenge": [
              "<NONE>"
            ],
            "Ethical": [
              "<NONE>"
            ],
            "Implications": [
              "<NONE>"
            ],
            "Contradictions": [
              "<NONE>"
            ]
          }
        }
      ]
    },
    {
      "paper_code": "ACL_23_P_334",
      "abstract": "Despite significant progress having been made in question answering on tabular data (Table QA), it’s unclear whether, and to what extent existing Table QA models are robust to task-specific perturbations, e.g., replacing key question entities or shuffling table columns. To systematically study the robustness of Table QA models, we propose a benchmark called RobuT, which builds upon existing Table QA datasets (WTQ, WikiSQL-Weak, and SQA) and includes human-annotated adversarial perturbations in terms of table header, table content, and question. Our results indicate that both state-of-the-art Table QA models and large language models (e.g., GPT-3) with few-shot learning falter in these adversarial sets. We propose to address this problem by using large language models to generate adversarial examples to enhance training, which significantly improves the robustness of Table QA models.",
      "events": [
        {
          "Background/Introduction": "",
          "Text": "Despite significant progress having been made in question answering on tabular data (Table QA), it’s unclear whether, and to what extent existing Table QA models are robust to task-specific perturbations, e.g., replacing key question entities or shuffling table columns.",
          "Main Action": "<NONE>",
          "Arguments": {
            "Agent": [
              "existing Table QA models"
            ],
            "Object": {
              "Primary Object": [
                "robustness"
              ],
              "Primary Modifier": [
                "<NONE>"
              ],
              "Secondary Object": [
                "task-specific perturbations"
              ],
              "Secondary Modifier": [
                "<NONE>"
              ]
            },
            "Context": [
              "significant progress has been made",
              "question answering on tabular data"
            ],
            "Purpose": [
              "understanding"
            ],
            "Method": [
              "replacing key question entities or shuffling table columns"
            ],
            "Results": [
              "unclear whether...are robust to task-specific perturbations"
            ],
            "Analysis": [
              "<NONE>"
            ],
            "Challenge": [
              "<NONE>"
            ],
            "Ethical": [
              "<NONE>"
            ],
            "Implications": [
              "broader significance or potential for future applications/research"
            ],
            "Contradictions": [
              "<NONE>"
            ]
          }
        },
        {
          "Methods/Approach": "",
          "Text": "To systematically study the robustness of Table QA models, we propose a benchmark called RobuT, which builds upon existing Table QA datasets (WTQ, WikiSQL-Weak, and SQA) and includes human-annotated adversarial perturbations in terms of table header, table content, and question.",
          "Main Action": "propose",
          "Arguments": {
            "Agent": [
              "we"
            ],
            "Object": {
              "Primary Object": [
                "a benchmark called RobuT"
              ],
              "Primary Modifier": [
                "<NONE>"
              ],
              "Secondary Object": [
                "existing Table QA datasets (WTQ, WikiSQL-Weak, and SQA)",
                "human-annotated adversarial perturbations"
              ],
              "Secondary Modifier": [
                "<NONE>"
              ]
            },
            "Context": [
              "systematically study the robustness of Table QA models"
            ],
            "Purpose": [
              "to build upon existing Table QA datasets and include human-annotated adversarial perturbations in terms of table header, table content, and question"
            ],
            "Method": [
              "builds upon existing Table QA datasets (WTQ, WikiSQL-Weak, and SQA), including human-annotated adversarial perturbations in terms of table header, table content, and question"
            ],
            "Results": [
              "<NONE>"
            ],
            "Analysis": [
              "<NONE>"
            ],
            "Challenge": [
              "<NONE>"
            ],
            "Ethical": [
              "<NONE>"
            ],
            "Implications": [
              "<NONE>"
            ],
            "Contradictions": [
              "<NONE>"
            ]
          }
        },
        {
          "Results/Findings": "",
          "Text": "Our results indicate that both state-of-the-art Table QA models and large language models (e.g., GPT-3) with few-shot learning falter in these adversarial sets.",
          "Main Action": "<NONE>",
          "Arguments": {
            "Agent": [
              "our results"
            ],
            "Object": {
              "Primary Object": [
                "state-of-the-art Table QA models",
                "large language models (e.g., GPT-3)"
              ],
              "Primary Modifier": [
                "<NONE>"
              ],
              "Secondary Object": [
                "these adversarial sets"
              ],
              "Secondary Modifier": [
                "<NONE>"
              ]
            },
            "Context": [
              "indicate that both...falter"
            ],
            "Purpose": [
              "<NONE>"
            ],
            "Method": [
              "with few-shot learning"
            ],
            "Results": [
              "both state-of-the-art Table QA models and large language models (e.g., GPT-3)...falter in these adversarial sets"
            ],
            "Analysis": [
              "<NONE>"
            ],
            "Challenge": [
              "<NONE>"
            ],
            "Ethical": [
              "<NONE>"
            ],
            "Implications": [
              "<NONE>"
            ],
            "Contradictions": [
              "<NONE>"
            ]
          }
        },
        {
          "Conclusions/Implications": "",
          "Text": "We propose to address this problem by using large language models to generate adversarial examples to enhance training, which significantly improves the robustness of Table QA models.",
          "Main Action": "propose",
          "Arguments": {
            "Agent": [
              "we"
            ],
            "Object": {
              "Primary Object": [
                "to address this problem"
              ],
              "Primary Modifier": [
                "<NONE>"
              ],
              "Secondary Object": [
                "using large language models to generate adversarial examples to enhance training"
              ],
              "Secondary Modifier": [
                "<NONE>"
              ]
            },
            "Context": [
              "enhance training"
            ],
            "Purpose": [
              "significantly improves the robustness of Table QA models"
            ],
            "Method": [
              "using large language models to generate adversarial examples"
            ],
            "Results": [
              "significantly improves the robustness of Table QA models"
            ],
            "Analysis": [
              "<NONE>"
            ],
            "Challenge": [
              "<NONE>"
            ],
            "Ethical": [
              "<NONE>"
            ],
            "Implications": [
              "<NONE>"
            ],
            "Contradictions": [
              "<NONE>"
            ]
          }
        }
      ]
    }
  ]
}