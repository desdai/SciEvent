{
  "papers": [
    {
      "paper_code": "ACL_23_P_725",
      "abstract": "Backdoor attacks have become an emerging threat to NLP systems. By providing poisoned training data, the adversary can embed a “backdoor” into the victim model, which allows input instances satisfying certain textual patterns (e.g., containing a keyword) to be predicted as a target label of the adversary’s choice. In this paper, we demonstrate that it is possible to design a backdoor attack that is both stealthy (i.e., hard to notice) and effective (i.e., has a high attack success rate). We propose BITE, a backdoor attack that poisons the training data to establish strong correlations between the target label and a set of “trigger words”. These trigger words are iteratively identified and injected into the target-label instances through natural word-level perturbations. The poisoned training data instruct the victim model to predict the target label on inputs containing trigger words, forming the backdoor. Experiments on four text classification datasets show that our proposed attack is significantly more effective than baseline methods while maintaining decent stealthiness, raising alarm on the usage of untrusted training data. We further propose a defense method named DeBITE based on potential trigger word removal, which outperforms existing methods in defending against BITE and generalizes well to handling other backdoor attacks.",
      "events": [
        {
          "Background/Introduction": "",
          "Text": "Backdoor attacks have become an emerging threat to NLP systems. By providing poisoned training data, the adversary can embed a “backdoor” into the victim model, which allows input instances satisfying certain textual patterns (e.g., containing a keyword) to be predicted as a target label of the adversary’s choice.",
          "Main Action": "have become",
          "Arguments": {
            "Agent": [
              "backdoor attacks"
            ],
            "Object": {
              "Primary Object": [
                "an emerging threat to NLP systems"
              ],
              "Primary Modifier": [
                "<NONE>"
              ],
              "Secondary Object": [
                "poisoned training data"
              ],
              "Secondary Modifier": [
                "<NONE>"
              ]
            },
            "Context": [
              "By providing poisoned training data, the adversary can embed a backdoor into the victim model,"
            ],
            "Purpose": [
              "<NONE>"
            ],
            "Method": [
              "<NONE>"
            ],
            "Results": [
              "which allows input instances satisfying certain textual patterns (e.g., containing a keyword) to be predicted as a target label of the adversary's choice."
            ],
            "Analysis": [
              "<NONE>"
            ],
            "Challenge": [
              "<NONE>"
            ],
            "Ethical": [
              "<NONE>"
            ],
            "Implications": [
              "<NONE>"
            ],
            "Contradictions": [
              "<NONE>"
            ]
          }
        },
        {
          "Methods/Approach": "",
          "Text": "In this paper, we demonstrate that it is possible to design a backdoor attack that is both stealthy (i.e., hard to notice) and effective (i.e., has a high attack success rate). We propose BITE, a backdoor attack that poisons the training data to establish strong correlations between the target label and a set of “trigger words”. These trigger words are iteratively identified and injected into the target-label instances through natural word-level perturbations. The poisoned training data instruct the victim model to predict the target label on inputs containing trigger words, forming the backdoor.",
          "Main Action": "design",
          "Arguments": {
            "Agent": [
              "we"
            ],
            "Object": {
              "Primary Object": [
                "backdoor attack"
              ],
              "Primary Modifier": [
                "<NONE>"
              ],
              "Secondary Object": [
                "training data"
              ],
              "Secondary Modifier": [
                "<NONE>"
              ]
            },
            "Context": [
              "it is possible to design a backdoor attack that is both stealthy (i.e., hard to notice) and effective (i.e., has a high attack success rate)"
            ],
            "Purpose": [
              "to establish strong correlations between the target label and a set of 'trigger words'"
            ],
            "Method": [
              "poisoning the training data to inject 'trigger words' into the target-label instances through natural word-level perturbations"
            ],
            "Results": [
              "The poisoned training data instructs the victim model to predict the target label on inputs containing trigger words, forming the backdoor"
            ],
            "Analysis": [
              "<NONE>"
            ],
            "Challenge": [
              "<NONE>"
            ],
            "Ethical": [
              "<NONE>"
            ],
            "Implications": [
              "<NONE>"
            ],
            "Contradictions": [
              "<NONE>"
            ]
          }
        },
        {
          "Results/Findings": "",
          "Text": "Experiments on four text classification datasets show that our proposed attack is significantly more effective than baseline methods while maintaining decent stealthiness, raising alarm on the usage of untrusted training data.",
          "Main Action": "show",
          "Arguments": {
            "Agent": [
              "experiments"
            ],
            "Object": {
              "Primary Object": [
                "our proposed attack is significantly more effective than baseline methods while maintaining decent stealthiness"
              ],
              "Primary Modifier": [
                "<NONE>"
              ],
              "Secondary Object": [
                "usage of untrusted training data"
              ],
              "Secondary Modifier": [
                "<NONE>"
              ]
            },
            "Context": [
              "on four text classification datasets"
            ],
            "Purpose": [
              "raising alarm"
            ],
            "Method": [
              "<NONE>"
            ],
            "Results": [
              "our proposed attack is significantly more effective than baseline methods while maintaining decent stealthiness"
            ],
            "Analysis": [
              "<NONE>"
            ],
            "Challenge": [
              "<NONE>"
            ],
            "Ethical": [
              "<NONE>"
            ],
            "Implications": [
              "raising alarm on the usage of untrusted training data"
            ],
            "Contradictions": [
              "<NONE>"
            ]
          }
        },
        {
          "Conclusions/Implications": "",
          "Text": "We further propose a defense method named DeBITE based on potential trigger word removal, which outperforms existing methods in defending against BITE and generalizes well to handling other backdoor attacks.",
          "Main Action": "further propose",
          "Arguments": {
            "Agent": [
              "We"
            ],
            "Object": {
              "Primary Object": [
                "a defense method named DeBITE based on potential trigger word removal"
              ],
              "Primary Modifier": [
                "<NONE>"
              ],
              "Secondary Object": [
                "existing methods"
              ],
              "Secondary Modifier": [
                "<NONE>"
              ]
            },
            "Context": [
              "outperforms existing methods in defending against BITE and generalizes well to handling other backdoor attacks"
            ],
            "Purpose": [
              "defending against BITE and generalizing well to handling other backdoor attacks"
            ],
            "Method": [
              "based on potential trigger word removal"
            ],
            "Results": [
              "outperforms existing methods in defending against BITE and generalizes well to handling other backdoor attacks"
            ],
            "Analysis": [
              "<NONE>"
            ],
            "Challenge": [
              "<NONE>"
            ],
            "Ethical": [
              "<NONE>"
            ],
            "Implications": [
              "<NONE>"
            ],
            "Contradictions": [
              "<NONE>"
            ]
          }
        }
      ]
    },
    {
      "paper_code": "ACL_23_P_702",
      "abstract": "Similes play an imperative role in creative writing such as story and dialogue generation. Proper evaluation metrics are like a beacon guiding the research of simile generation (SG). However, it remains under-explored as to what criteria should be considered, how to quantify each criterion into metrics, and whether the metrics are effective for comprehensive, efficient, and reliable SG evaluation. To address the issues, we establish HAUSER, a holistic and automatic evaluation system for the SG task, which consists of five criteria from three perspectives and automatic metrics for each criterion. Through extensive experiments, we verify that our metrics are significantly more correlated with human ratings from each perspective compared with prior automatic metrics.",
      "events": [
        {
          "Background/Introduction": "",
          "Text": "Similes play an imperative role in creative writing such as story and dialogue generation. Proper evaluation metrics are like a beacon guiding the research of simile generation (SG). However, it remains under-explored as to what criteria should be considered, how to quantify each criterion into metrics, and whether the metrics are effective for comprehensive, efficient, and reliable SG evaluation.",
          "Main Action": "remains under-explored",
          "Arguments": {
            "Agent": [
              "what criteria should be considered, how to quantify each criterion into metrics, and whether the metrics are effective for comprehensive, efficient, and reliable SG evaluation"
            ],
            "Object": {
              "Primary Object": [
                "<NONE>"
              ],
              "Primary Modifier": [
                "<NONE>"
              ],
              "Secondary Object": [
                "simile generation"
              ],
              "Secondary Modifier": [
                "<NONE>"
              ]
            },
            "Context": [
              "Proper evaluation metrics are like a beacon guiding the research of simile generation (SG). However,"
            ],
            "Purpose": [
              "What is the purpose or aim of the event?"
            ],
            "Method": [
              "<NONE>"
            ],
            "Results": [
              "<NONE>"
            ],
            "Analysis": [
              "Whether the metrics are effective for comprehensive, efficient, and reliable SG evaluation"
            ],
            "Challenge": [
              "Under-exploration of proper evaluation metrics for simile generation"
            ],
            "Ethical": [
              "<NONE>"
            ],
            "Implications": [
              "The importance of developing appropriate evaluation metrics for simile generation"
            ],
            "Contradictions": [
              "<NONE>"
            ]
          }
        },
        {
          "Methods/Approach": "",
          "Text": "To address the issues, we establish HAUSER, a holistic and automatic evaluation system for the SG task, which consists of five criteria from three perspectives and automatic metrics for each criterion.",
          "Main Action": "establish",
          "Arguments": {
            "Agent": [
              "we"
            ],
            "Object": {
              "Primary Object": [
                "HAUSER, a holistic and automatic evaluation system for the SG task"
              ],
              "Primary Modifier": [
                "<NONE>"
              ],
              "Secondary Object": [
                "five criteria from three perspectives and automatic metrics for each criterion"
              ],
              "Secondary Modifier": [
                "<NONE>"
              ]
            },
            "Context": [
              "to address the issues"
            ],
            "Purpose": [
              "<NONE>"
            ],
            "Method": [
              "<NONE>"
            ],
            "Results": [
              "<NONE>"
            ],
            "Analysis": [
              "<NONE>"
            ],
            "Challenge": [
              "<NONE>"
            ],
            "Ethical": [
              "<NONE>"
            ],
            "Implications": [
              "<NONE>"
            ],
            "Contradictions": [
              "<NONE>"
            ]
          }
        },
        {
          "Results/Findings": "",
          "Text": "Through extensive experiments, we verify that our metrics are significantly more correlated with human ratings from each perspective compared with prior automatic metrics.",
          "Main Action": "verify",
          "Arguments": {
            "Agent": [
              "we"
            ],
            "Object": {
              "Primary Object": [
                "our metrics"
              ],
              "Primary Modifier": [
                "<NONE>"
              ],
              "Secondary Object": [
                "prior automatic metrics"
              ],
              "Secondary Modifier": [
                "<NONE>"
              ]
            },
            "Context": [
              "through extensive experiments"
            ],
            "Purpose": [
              "<NONE>"
            ],
            "Method": [
              "<NONE>"
            ],
            "Results": [
              "are significantly more correlated with human ratings from each perspective compared with prior automatic metrics"
            ],
            "Analysis": [
              "<NONE>"
            ],
            "Challenge": [
              "<NONE>"
            ],
            "Ethical": [
              "<NONE>"
            ],
            "Implications": [
              "<NONE>"
            ],
            "Contradictions": [
              "<NONE>"
            ]
          }
        }
      ]
    }
  ]
}