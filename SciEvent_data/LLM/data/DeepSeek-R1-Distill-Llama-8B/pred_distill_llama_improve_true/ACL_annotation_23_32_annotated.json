{
  "papers": [
    {
      "paper_code": "ACL_23_P_634",
      "abstract": "Many text generation applications require the generated text to be factually consistent with input information. Automatic evaluation of factual consistency is challenging. Previous work has developed various metrics that often depend on specific functions, such as natural language inference (NLI) or question answering (QA), trained on limited data. Those metrics thus can hardly assess diverse factual inconsistencies (e.g., contradictions, hallucinations) that occur in varying inputs/outputs (e.g., sentences, documents) from different tasks. In this paper, we propose AlignScore, a new holistic metric that applies to a variety of factual inconsistency scenarios as above. AlignScore is based on a general function of information alignment between two arbitrary text pieces. Crucially, we develop a unified training framework of the alignment function by integrating a large diversity of data sources, resulting in 4.7M training examples from 7 well-established tasks (NLI, QA, paraphrasing, fact verification, information retrieval, semantic similarity, and summarization). We conduct extensive experiments on large-scale benchmarks including 22 evaluation datasets, where 19 of the datasets were never seen in the alignment training. AlignScore achieves substantial improvement over a wide range of previous metrics. Moreover, AlignScore (355M parameters) matches or even outperforms metrics based on ChatGPT and GPT-4 that are orders of magnitude larger.",
      "events": [
        {
          "Background/Introduction": "",
          "Text": "Many text generation applications require the generated text to be factually consistent with input information. Automatic evaluation of factual consistency is challenging. Previous work has developed various metrics that often depend on specific functions, such as natural language inference (NLI) or question answering (QA), trained on limited data. Those metrics thus can hardly assess diverse factual inconsistencies (e.g., contradictions, hallucinations) that occur in varying inputs/outputs (e.g., sentences, documents) from different tasks.",
          "Main Action": "Automatic evaluation of factual consistency is challenging",
          "Arguments": {
            "Agent": [
              "<NONE>"
            ],
            "Object": {
              "Primary Object": [
                "Many text generation applications"
              ],
              "Secondary Object": [
                "<NONE>"
              ]
            },
            "Context": [
              "Text generation applications require the generated text to be factually consistent with input information.",
              "Previous work has developed various metrics that often depend on specific functions, such as natural language inference (NLI) or question answering (QA), trained on limited data."
            ],
            "Purpose": [
              "To address the challenge of automatically evaluating factual consistency"
            ],
            "Method": [
              "Metrics that often depend on specific functions, such as natural language inference (NLI) or question answering (QA), trained on limited data"
            ],
            "Results": [
              "Those metrics thus can hardly assess diverse factual inconsistencies (e.g., contradictions, hallucinations) that occur in varying inputs/outputs (e.g., sentences, documents) from different tasks"
            ],
            "Analysis": [
              "Notable challenges include the inability of existing metrics to handle diverse inconsistencies across different tasks"
            ],
            "Challenge": [
              "Difficulty in reliably measuring factual consistency across various tasks"
            ],
            "Ethical": [
              "<NONE>"
            ],
            "Implications": [
              "Potential improvements needed in evaluation metrics for better understanding and assessment of factual consistency"
            ],
            "Contradictions": [
              "Disagreements between existing metrics and real-world inconsistencies"
            ]
          }
        },
        {
          "Methods/Approach": "",
          "Text": "In this paper, we propose AlignScore, a new holistic metric that applies to a variety of factual inconsistency scenarios as above. AlignScore is based on a general function of information alignment between two arbitrary text pieces. Crucially, we develop a unified training framework of the alignment function by integrating a large diversity of data sources, resulting in 4.7M training examples from 7 well-established tasks (NLI, QA, paraphrasing, fact verification, information retrieval, semantic similarity, and summarization).",
          "Main Action": "Develop a unified training framework",
          "Arguments": {
            "Agent": [
              "we"
            ],
            "Object": {
              "Primary Object": [
                "training framework"
              ],
              "Secondary Object": [
                "<NONE>"
              ]
            },
            "Context": [
              "AlignScore, a new holistic metric that applies to a variety of factual inconsistency scenarios as above"
            ],
            "Purpose": [
              "to apply to a variety of factual inconsistency scenarios"
            ],
            "Method": [
              "integrating a large diversity of data sources, resulting in 4.7M training examples from 7 well-established tasks"
            ],
            "Results": [
              "resulting in 4.7M training examples"
            ],
            "Analysis": [
              "<NONE>"
            ],
            "Challenge": [
              "<NONE>"
            ],
            "Ethical": [
              "<NONE>"
            ],
            "Implications": [
              "potential for future applications/research"
            ],
            "Contradictions": [
              "<NONE>"
            ]
          }
        },
        {
          "Results/Findings": "",
          "Text": "We conduct extensive experiments on large-scale benchmarks including 22 evaluation datasets, where 19 of the datasets were never seen in the alignment training. AlignScore achieves substantial improvement over a wide range of previous metrics. Moreover, AlignScore (355M parameters) matches or even outperforms metrics based on ChatGPT and GPT-4 that are orders of magnitude larger.",
          "Main Action": "conduct extensive experiments",
          "Arguments": {
            "Agent": [
              "we"
            ],
            "Object": {
              "Primary Object": [
                "large-scale benchmarks including 22 evaluation datasets"
              ],
              "Secondary Object": [
                "<NONE>"
              ]
            },
            "Context": [
              "<NONE>"
            ],
            "Purpose": [
              "to achieve substantial improvement over a wide range of previous metrics"
            ],
            "Method": [
              "evaluation datasets"
            ],
            "Results": [
              "AlignScore achieves substantial improvement over a wide range of previous metrics",
              "matches or even outperforms metrics based on ChatGPT and GPT-4"
            ],
            "Analysis": [
              "<NONE>"
            ],
            "Challenge": [
              "<NONE>"
            ],
            "Ethical": [
              "<NONE>"
            ],
            "Implications": [
              "<NONE>"
            ],
            "Contradictions": [
              "<NONE>"
            ]
          }
        }
      ]
    },
    {
      "paper_code": "ACL_23_P_859",
      "abstract": "Large language models (LLMs) that have been trained on multilingual but not parallel text exhibit a remarkable ability to translate between languages. We probe this ability in an in-depth study of the pathways language model (PaLM), which has demonstrated the strongest machine translation (MT) performance among similarly-trained LLMs to date. We investigate various strategies for choosing translation examples for few-shot prompting, concluding that example quality is the most important factor. Using optimized prompts, we revisit previous assessments of PaLM’s MT capabilities with more recent test sets, modern MT metrics, and human evaluation, and find that its performance, while impressive, still lags that of state-of-the-art supervised systems. We conclude by providing an analysis of PaLM’s MT output which reveals some interesting properties and prospects for future work.",
      "events": [
        {
          "Background/Introduction": "",
          "Text": "Large language models (LLMs) that have been trained on multilingual but not parallel text exhibit a remarkable ability to translate between languages.",
          "Main Action": "exhibit",
          "Arguments": {
            "Agent": [
              "Large language models (LLMs)"
            ],
            "Object": {
              "Primary Object": [
                "languages"
              ],
              "Secondary Object": [
                "<NONE>"
              ]
            },
            "Context": [
              "<NONE>"
            ],
            "Purpose": [
              "<NONE>"
            ],
            "Method": [
              "<NONE>"
            ],
            "Results": [
              "a remarkable ability to translate between languages"
            ],
            "Analysis": [
              "<NONE>"
            ],
            "Challenge": [
              "<NONE>"
            ],
            "Ethical": [
              "<NONE>"
            ],
            "Implications": [
              "<NONE>"
            ],
            "Contradictions": [
              "<NONE>"
            ]
          }
        },
        {
          "Methods/Approach": "",
          "Text": "We probe this ability in an in-depth study of the pathways language model (PaLM), which has demonstrated the strongest machine translation (MT) performance among similarly-trained LLMs to date. We investigate various strategies for choosing translation examples for few-shot prompting, concluding that example quality is the most important factor. Using optimized prompts, we revisit previous assessments of PaLM’s MT capabilities with more recent test sets, modern MT metrics, and human evaluation, and find that its performance, while impressive, still lags that of state-of-the-art supervised systems.",
          "Main Action": "We probe this ability",
          "Arguments": {
            "Agent": [
              "we"
            ],
            "Object": {
              "Primary Object": [
                "this ability"
              ],
              "Secondary Object": [
                "<NONE>"
              ]
            },
            "Context": [
              "which has demonstrated the strongest machine translation (MT) performance among similarly-trained LLMs to date",
              "We investigate various strategies for choosing translation examples for few-shot prompting",
              "Using optimized prompts, we revisit previous assessments of PaLM’s MT capabilities with more recent test sets",
              "modern MT metrics, and human evaluation"
            ],
            "Purpose": [
              "to assess and compare PaLM’s capabilities",
              "aiming to fill gaps identified in prior studies"
            ],
            "Method": [
              "optimizing prompts",
              "using more recent test sets",
              "modern MT metrics",
              "human evaluation"
            ],
            "Results": [
              "find that its performance, while impressive, still lags that of state-of-the-art supervised systems"
            ],
            "Analysis": [
              "concluding that example quality is the most important factor",
              "discussing the implications of their findings regarding PaLM’s limitations"
            ],
            "Challenge": [
              "One challenge noted is that PaLM's performance, though strong, doesn’t match current benchmarks"
            ],
            "Ethical": [
              "<NONE>"
            ],
            "Implications": [
              "Their findings suggest areas where improvements can be made and provide insights into developing better models"
            ],
            "Contradictions": [
              "Finding that PaLM underperforms despite initial strengths contradicts earlier positive assessments"
            ]
          }
        },
        {
          "Conclusions/Implications": "",
          "Text": "We conclude by providing an analysis of PaLM’s MT output which reveals some interesting properties and prospects for future work.",
          "Main Action": "We conclude",
          "Arguments": {
            "Agent": [
              "<NONE>"
            ],
            "Object": {
              "Primary Object": [
                "PaLM’s MT output"
              ],
              "Secondary Object": [
                "<NONE>"
              ]
            },
            "Context": [
              "<NONE>"
            ],
            "Purpose": [
              "<NONE>"
            ],
            "Method": [
              "<NONE>"
            ],
            "Results": [
              "some interesting properties"
            ],
            "Analysis": [
              "<NONE>"
            ],
            "Challenge": [
              "<NONE>"
            ],
            "Ethical": [
              "<NONE>"
            ],
            "Implications": [
              "prospects for future work"
            ],
            "Contradictions": [
              "<NONE>"
            ]
          }
        }
      ]
    }
  ]
}