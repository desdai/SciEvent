{
  "papers": [
    {
      "paper_code": "dh_23_P_36",
      "abstract": "The premise of this article is that a basic understanding of the composition and functioning of large language models is critically urgent. To that end, we extract a representational map of OpenAI's GPT-2 with what we articulate as two classes of deep learning code, that which pertains to the model and that which underwrites applications built around the model. We then verify this map through case studies of two popular GPT-2 applications: the text adventure game, AI Dungeon, and the language art project, This Word Does Not Exist. Such an exercise allows us to test the potential of Critical Code Studies when the object of study is deep learning code and to demonstrate the validity of code as an analytical focus for researchers in the subfields of Critical Artificial Intelligence and Critical Machine Learning Studies. More broadly, however, our work draws attention to the means by which ordinary users might interact with, and even direct, the behavior of deep learning systems, and by extension works toward demystifying some of the auratic mystery of “AI.” What is at stake is the possibility of achieving an informed sociotechnical consensus about the responsible applications of large language models, as well as a more expansive sense of their creative capabilities — indeed, understanding how and where engagement occurs allows all of us to become more active participants in the development of machine learning systems.",
      "events": [
        {
          "Background/Introduction": "",
          "Text": "The premise of this article is that a basic understanding of the composition and functioning of large language models is critically urgent. To that end, we extract a representational map of OpenAI's GPT-2 with what we articulate as two classes of deep learning code, that which pertains to the model and that which underwrites applications built around the model.",
          "Main Action": "Extracting a representational map",
          "Arguments": {
            "Agent": [
              "We"
            ],
            "Object": {
              "Primary Object": [
                "OpenAI's GPT-2",
                "applications built around the model"
              ],
              "Secondary Object": [
                "<NONE>"
              ]
            },
            "Context": [
              "The urgency of understanding the composition and functioning of large language models",
              "Focus on GPT-2"
            ],
            "Purpose": [
              "To build a comprehensive understanding of how large language models function"
            ],
            "Method": [
              "Creating a representational map using two classes of deep learning code"
            ],
            "Results": [
              "Creation of a representational map"
            ],
            "Analysis": [
              "<NONE>"
            ],
            "Challenge": [
              "<NONE>"
            ],
            "Ethical": [
              "<NONE>"
            ],
            "Implications": [
              "Advancing understanding of large language model capabilities"
            ],
            "Contradictions": [
              "<NONE>"
            ]
          }
        },
        {
          "Methods/Approach": "",
          "Text": "We then verify this map through case studies of two popular GPT-2 applications: the text adventure game, AI Dungeon, and the language art project, This Word Does Not Exist. Such an exercise allows us to test the potential of Critical Code Studies when the object of study is deep learning code and to demonstrate the validity of code as an analytical focus for researchers in the subfields of Critical Artificial Intelligence and Critical Machine Learning Studies.",
          "Main Action": "ThisWordDoesNotExist",
          "Arguments": {
            "Agent": [
              "researchers in the subfields of Critical Artificial Intelligence and Critical Machine Learning Studies"
            ],
            "Object": {
              "Primary Object": [
                "Critical Code Studies"
              ],
              "Secondary Object": [
                "code"
              ]
            },
            "Context": [
              "AI Dungeon",
              "This Word Does Not Exist"
            ],
            "Purpose": [
              "validating code as an analytical focus"
            ],
            "Method": [
              "case studies"
            ],
            "Results": [
              "successful validation of code as an analytical focus"
            ],
            "Analysis": [
              "suggesting that code can serve as an analytical focus"
            ],
            "Challenge": [
              "<NONE>"
            ],
            "Ethical": [
              "<NONE>"
            ],
            "Implications": [
              "opening new avenues for analyzing code in various contexts"
            ],
            "Contradictions": [
              "<NONE>"
            ]
          }
        },
        {
          "Conclusions/Implications": "",
          "Text": "More broadly, however, our work draws attention to the means by which ordinary users might interact with, and even direct, the behavior of deep learning systems, and by extension works toward demystifying some of the auratic mystery of “AI.” What is at stake is the possibility of achieving an informed sociotechnical consensus about the responsible applications of large language models, as well as a more expansive sense of their creative capabilities — indeed, understanding how and where engagement occurs allows all of us to become more active participants in the development of machine learning systems.",
          "Main Action": "More broadly, however, our work draws attention to the means by which ordinary users might interact with, and even direct, the behavior of deep learning systems",
          "Arguments": {
            "Agent": [
              "our work"
            ],
            "Object": {
              "Primary Object": [
                "the means by which ordinary users might interact with, and even direct, the behavior of deep learning systems"
              ],
              "Secondary Object": [
                "<NONE>"
              ]
            },
            "Context": [
              "What is at stake is the possibility of achieving an informed sociotechnical consensus about the responsible applications of large language models, as well as a more expansive sense of their creative capabilities"
            ],
            "Purpose": [
              "Understanding how and where engagement occurs allows all of us to become more active participants in the development of machine learning systems"
            ],
            "Method": [
              "demystifying some of the auratic mystery of 'AI'"
            ],
            "Results": [
              "achieving an informed sociotechnical consensus about the responsible applications of large language models"
            ],
            "Analysis": [
              "interpreting the data on user interactions and behaviors relative to AI system responses"
            ],
            "Challenge": [
              "<NONE>"
            ],
            "Ethical": [
              "ensuring responsible applications of large language models"
            ],
            "Implications": [
              "fostering greater participation in AI development and ensuring responsible usage"
            ],
            "Contradictions": [
              "<NONE>"
            ]
          }
        }
      ]
    },
    {
      "paper_code": "dh_23_P_18",
      "abstract": "This article examines the technical development and afterlives of two projects, the CURSUS project (2000-2003) and the William Godwin's Diary project (2007-2010) to undertake case studies in problems relating to hosting and storage of digital humanities projects. In both cases, a combination of outside events or project decisions negatively impacted the project. This was discussed as part of a symposium for the Endings Principles for Digital Longevity and reflects on whether following these principles would have benefited these projects. Overall, the case is made that we should always be planning for events that could affect the sustainability of digital research projects.",
      "events": [
        {
          "Background/Introduction": "",
          "Text": "This article examines the technical development and afterlives of two projects, the CURSUS project (2000-2003) and the William Godwin's Diary project (2007-2010) to undertake case studies in problems relating to hosting and storage of digital humanities projects.",
          "Main Action": "This article examines",
          "Arguments": {
            "Agent": [
              "This article"
            ],
            "Object": {
              "Primary Object": [
                "the CURSUS project (2000-2003)",
                "William Godwin's Diary project (2007-2010)"
              ],
              "Secondary Object": [
                "<NONE>"
              ]
            },
            "Context": [
              "digital humanities projects",
              "hosting and storage"
            ],
            "Purpose": [
              "to undertake case studies in problems relating to hosting and storage of digital humanities projects"
            ],
            "Method": [
              "using the CURSUS project (2000-2003) and the William Godwin's Diary project (2007-2010) as case studies"
            ],
            "Results": [
              "<NONE>"
            ],
            "Analysis": [
              "<NONE>"
            ],
            "Challenge": [
              "<NONE>"
            ],
            "Ethical": [
              "<NONE>"
            ],
            "Implications": [
              "understanding the challenges and opportunities in hosting and storage of digital humanities projects"
            ],
            "Contradictions": [
              "<NONE>"
            ]
          }
        },
        {
          "Methods/Approach": "",
          "Text": "In both cases, a combination of outside events or project decisions negatively impacted the project. This was discussed as part of a symposium for the Endings Principles for Digital Longevity and reflects on whether following these principles would have benefited these projects.",
          "Main Action": "discussed",
          "Arguments": {
            "Agent": [
              "outside events",
              "project decisions"
            ],
            "Object": {
              "Primary Object": [
                "the project"
              ],
              "Secondary Object": [
                "<NONE>"
              ]
            },
            "Context": [
              "a symposium for the Endings Principles for Digital Longevity"
            ],
            "Purpose": [
              "reflecting on whether following these principles would have benefited these projects"
            ],
            "Method": [
              "<NONE>"
            ],
            "Results": [
              "<NONE>"
            ],
            "Analysis": [
              "<NONE>"
            ],
            "Challenge": [
              "negative impacts"
            ],
            "Ethical": [
              "<NONE>"
            ],
            "Implications": [
              "importance",
              "impact",
              "applications",
              "future work"
            ],
            "Contradictions": [
              "<NONE>"
            ]
          }
        },
        {
          "Conclusions/Implications": "",
          "Text": "Overall, the case is made that we should always be planning for events that could affect the sustainability of digital research projects.",
          "Main Action": "we should always be planning",
          "Arguments": {
            "Agent": [
              "researchers"
            ],
            "Object": {
              "Primary Object": [
                "digital research projects"
              ],
              "Secondary Object": [
                "<NONE>"
              ]
            },
            "Context": [
              "events that could affect the sustainability"
            ],
            "Purpose": [
              "preparing for possible challenges"
            ],
            "Method": [
              "<NONE>"
            ],
            "Results": [
              "<NONE>"
            ],
            "Analysis": [
              "<NONE>"
            ],
            "Challenge": [
              "<NONE>"
            ],
            "Ethical": [
              "<NONE>"
            ],
            "Implications": [
              "importance for maintaining sustainability"
            ],
            "Contradictions": [
              "<NONE>"
            ]
          }
        }
      ]
    }
  ]
}