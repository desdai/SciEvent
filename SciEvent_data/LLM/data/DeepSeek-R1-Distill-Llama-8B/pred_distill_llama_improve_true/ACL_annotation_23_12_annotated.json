{
  "papers": [
    {
      "paper_code": "ACL_23_P_844",
      "abstract": "Despite the recent progress in language generation models, their outputs may not always meet user expectations. In this work, we study whether informational feedback in natural language can be leveraged to improve generation quality and user preference alignment. To this end, we consider factual consistency in summarization, the quality that the summary should only contain information supported by the input documents, as the user-expected preference. We collect a high-quality dataset, DeFacto, containing human demonstrations and informational natural language feedback consisting of corrective instructions, edited summaries, and explanations with respect to the factual consistency of the summary. Using our dataset, we study three natural language generation tasks: (1) editing a summary by following the human feedback, (2) generating human feedback for editing the original summary, and (3) revising the initial summary to correct factual errors by generating both the human feedback and edited summary. We show that DeFacto can provide factually consistent human-edited summaries and further insights into summarization factual consistency thanks to its informational natural language feedback. We further demonstrate that fine-tuned language models can leverage our dataset to improve the summary factual consistency, while large language models lack the zero-shot learning ability in our proposed tasks that require controllable text generation.",
      "events": [
        {
          "Background/Introduction": "",
          "Text": "Despite the recent progress in language generation models, their outputs may not always meet user expectations. In this work, we study whether informational feedback in natural language can be leveraged to improve generation quality and user preference alignment. To this end, we consider factual consistency in summarization, the quality that the summary should only contain information supported by the input documents, as the user-expected preference.",
          "Main Action": "we study whether informational feedback...",
          "Arguments": {
            "Agent": [
              "we"
            ],
            "Object": {
              "Primary Object": [
                "improving generation quality and user preference alignment"
              ],
              "Secondary Object": [
                "<NONE>"
              ]
            },
            "Context": [
              "Despite the recent progress...",
              "their outputs may not always meet user expectations"
            ],
            "Purpose": [
              "To this end, we consider..."
            ],
            "Method": [
              "<NONE>"
            ],
            "Results": [
              "<NONE>"
            ],
            "Analysis": [
              "<NONE>"
            ],
            "Challenge": [
              "<NONE>"
            ],
            "Ethical": [
              "<NONE>"
            ],
            "Implications": [
              "<NONE>"
            ],
            "Contradictions": [
              "<NONE>"
            ]
          }
        },
        {
          "Methods/Approach": "",
          "Text": "We collect a high-quality dataset, DeFacto, containing human demonstrations and informational natural language feedback consisting of corrective instructions, edited summaries, and explanations with respect to the factual consistency of the summary. Using our dataset, we study three natural language generation tasks: (1) editing a summary by following the human feedback, (2) generating human feedback for editing the original summary, and (3) revising the initial summary to correct factual errors by generating both the human feedback and edited summary.",
          "Main Action": "Collect",
          "Arguments": {
            "Agent": [
              "We"
            ],
            "Object": {
              "Primary Object": [
                "DeFacto"
              ],
              "Secondary Object": [
                "<NONE>"
              ]
            },
            "Context": [
              "human demonstrations and informational natural language feedback consisting of corrective instructions, edited summaries, and explanations with respect to the factual consistency of the summary"
            ],
            "Purpose": [
              "studying three natural language generation tasks"
            ],
            "Method": [
              "using our dataset",
              "editing a summary by following human feedback",
              "generating human feedback for editing the original summary",
              "revising the initial summary to correct factual errors by generating both the human feedback and edited summary"
            ],
            "Results": [
              "successful creation and utilization of the dataset implying positive outcomes"
            ],
            "Analysis": [
              "<NONE>"
            ],
            "Challenge": [
              "<NONE>"
            ],
            "Ethical": [
              "<NONE>"
            ],
            "Implications": [
              "<NONE>"
            ],
            "Contradictions": [
              "<NONE>"
            ]
          }
        },
        {
          "Results/Findings": "",
          "Text": "We show that DeFacto can provide factually consistent human-edited summaries and further insights into summarization factual consistency thanks to its informational natural language feedback. We further demonstrate that fine-tuned language models can leverage our dataset to improve the summary factual consistency, while large language models lack the zero-shot learning ability in our proposed tasks that require controllable text generation.",
          "Main Action": "Further demonstrate",
          "Arguments": {
            "Agent": [
              "We"
            ],
            "Object": {
              "Primary Object": [
                "Defacto",
                "Summarization factual consistency"
              ],
              "Secondary Object": [
                "Large language models"
              ]
            },
            "Context": [
              "Human-edited summaries",
              "Informational natural language feedback"
            ],
            "Purpose": [
              "Improve the summary factual consistency"
            ],
            "Method": [
              "Fine-tuned language models",
              "Dataset",
              "Zero-shot learning ability"
            ],
            "Results": [
              "Fine-tuned language models can leverage our dataset to improve the summary factual consistency"
            ],
            "Analysis": [
              "Large language models lack the zero-shot learning ability in our proposed tasks that require controllable text generation"
            ],
            "Challenge": [
              "<NONE>"
            ],
            "Ethical": [
              "<NONE>"
            ],
            "Implications": [
              "This advancement could lead to more accurate and reliable AI-generated content across various domains"
            ],
            "Contradictions": [
              "<NONE>"
            ]
          }
        }
      ]
    },
    {
      "paper_code": "ACL_23_P_700",
      "abstract": "State-of-the-art techniques common to low resource Machine Translation (MT) are applied to improve MT of spoken language text to Sign Language (SL) glosses. In our experiments, we improve the performance of the transformer-based models via (1) data augmentation, (2) semi-supervised Neural Machine Translation (NMT), (3) transfer learning and (4) multilingual NMT. The proposed methods are implemented progressively on two German SL corpora containing gloss annotations. Multilingual NMT combined with data augmentation appear to be the most successful setting, yielding statistically significant improvements as measured by three automatic metrics (up to over 6 points BLEU), and confirmed via human evaluation. Our best setting outperforms all previous work that report on the same test-set and is also confirmed on a corpus of the American Sign Language (ASL).",
      "events": [
        {
          "Background/Introduction": "",
          "Text": "State-of-the-art techniques common to low-resource Machine Translation (MT) are applied to improve MT of spoken language text to Sign Language (SL) glosses.",
          "Main Action": "are applied",
          "Arguments": {
            "Agent": [
              "<NONE>"
            ],
            "Object": {
              "Primary Object": [
                "spoken language text"
              ],
              "Secondary Object": [
                "Sign Language (SL) glosses"
              ]
            },
            "Context": [
              "low-resource Machine Translation (MT)",
              "State-of-the-art techniques"
            ],
            "Purpose": [
              "improve MT of spoken language text to Sign Language (SL) glosses"
            ],
            "Method": [
              "state-of-the-art techniques common to low-resource Machine Translation (MT)"
            ],
            "Results": [
              "improving MT of spoken language text to Sign Language (SL) glosses"
            ],
            "Analysis": [
              "<NONE>"
            ],
            "Challenge": [
              "<NONE>"
            ],
            "Ethical": [
              "<NONE>"
            ],
            "Implications": [
              "bridging gaps between spoken and signed languages through improved Machine Translation systems"
            ],
            "Contradictions": [
              "<NONE>"
            ]
          }
        },
        {
          "Methods/Approach": "",
          "Text": "In our experiments, we improve the performance of the transformer-based models via (1) data augmentation, (2) semi-supervised Neural Machine Translation (NMT), (3) transfer learning and (4) multilingual NMT. The proposed methods are implemented progressively on two German SL corpora containing gloss annotations.",
          "Main Action": "Implement",
          "Arguments": {
            "Agent": [
              "We"
            ],
            "Object": {
              "Primary Object": [
                "Transformer-based models"
              ],
              "Secondary Object": [
                "Two German SL corpora"
              ]
            },
            "Context": [
              "Our experiments",
              "Transformers-based models"
            ],
            "Purpose": [
              "<NONE>"
            ],
            "Method": [
              "Data augmentation",
              "Semi-supervised Neural Machine Translation (NMT)",
              "Transfer learning",
              "Multilingual NMT"
            ],
            "Results": [
              "<NONE>"
            ],
            "Analysis": [
              "<NONE>"
            ],
            "Challenge": [
              "<NONE>"
            ],
            "Ethical": [
              "<NONE>"
            ],
            "Implications": [
              "<NONE>"
            ],
            "Contradictions": [
              "<NONE>"
            ]
          }
        },
        {
          "Results/Findings": "",
          "Text": "Multilingual NMT combined with data augmentation appear to be the most successful setting, yielding statistically significant improvements as measured by three automatic metrics (up to over 6 points BLEU), and confirmed via human evaluation. Our best setting outperforms all previous work that report on the same test-set and is also confirmed on a corpus of the American Sign Language (ASL).",
          "Main Action": "Multilingual NMT combined with data augmentation appear to be the most successful setting",
          "Arguments": {
            "Agent": [
              "Our best setting"
            ],
            "Object": {
              "Primary Object": [
                "the model"
              ],
              "Secondary Object": [
                "the test-set"
              ]
            },
            "Context": [
              "This finding closes a critical gap in understanding the limitations of monolingual NMT systems"
            ],
            "Purpose": [
              "To demonstrate the effectiveness of our proposed approach"
            ],
            "Method": [
              "Combining multilingual neural machine translation with data augmentation"
            ],
            "Results": [
              "yielding statistically significant improvements as measured by three automatic metrics (up to over 6 points BLEU)"
            ],
            "Analysis": [
              "These results suggest that the integration of multilingual NMT with data augmentation significantly improves translation quality"
            ],
            "Challenge": [
              "<NONE>"
            ],
            "Ethical": [
              "<NONE>"
            ],
            "Implications": [
              "This advancement opens new possibilities for cross-lingual communication in scenarios with limited resources"
            ],
            "Contradictions": [
              "<NONE>"
            ]
          }
        }
      ]
    }
  ]
}