{
  "papers": [
    {
      "paper_code": "ACL_23_P_844",
      "abstract": "Despite the recent progress in language generation models, their outputs may not always meet user expectations. In this work, we study whether informational feedback in natural language can be leveraged to improve generation quality and user preference alignment. To this end, we consider factual consistency in summarization, the quality that the summary should only contain information supported by the input documents, as the user-expected preference. We collect a high-quality dataset, DeFacto, containing human demonstrations and informational natural language feedback consisting of corrective instructions, edited summaries, and explanations with respect to the factual consistency of the summary. Using our dataset, we study three natural language generation tasks: (1) editing a summary by following the human feedback, (2) generating human feedback for editing the original summary, and (3) revising the initial summary to correct factual errors by generating both the human feedback and edited summary. We show that DeFacto can provide factually consistent human-edited summaries and further insights into summarization factual consistency thanks to its informational natural language feedback. We further demonstrate that fine-tuned language models can leverage our dataset to improve the summary factual consistency, while large language models lack the zero-shot learning ability in our proposed tasks that require controllable text generation.",
      "events": [
        {
          "Background/Introduction": "",
          "Text": "Despite the recent progress in language generation models, their outputs may not always meet user expectations. In this work, we study whether informational feedback in natural language can be leveraged to improve generation quality and user preference alignment. To this end, we consider factual consistency in summarization, the quality that the summary should only contain information supported by the input documents, as the user-expected preference.",
          "Main Action": "study",
          "Arguments": {
            "Agent": [
              "we"
            ],
            "Object": {
              "Primary Object": [
                "informational feedback in natural language"
              ],
              "Secondary Object": [
                "generation quality and user preference alignment"
              ]
            },
            "Context": [
              "<NONE>"
            ],
            "Purpose": [
              "improve generation quality and user preference alignment"
            ],
            "Method": [
              "consider factual consistency in summarization"
            ],
            "Results": [
              "<NONE>"
            ],
            "Analysis": [
              "<NONE>"
            ],
            "Challenge": [
              "<NONE>"
            ],
            "Ethical": [
              "<NONE>"
            ],
            "Implications": [
              "<NONE>"
            ],
            "Contradictions": [
              "<NONE>"
            ]
          }
        },
        {
          "Methods/Approach": "",
          "Text": "We collect a high-quality dataset, DeFacto, containing human demonstrations and informational natural language feedback consisting of corrective instructions, edited summaries, and explanations with respect to the factual consistency of the summary. Using our dataset, we study three natural language generation tasks: (1) editing a summary by following the human feedback, (2) generating human feedback for editing the original summary, and (3) revising the initial summary to correct factual errors by generating both the human feedback and edited summary.",
          "Main Action": "collect",
          "Arguments": {
            "Agent": [
              "we"
            ],
            "Object": {
              "Primary Object": [
                "a high-quality dataset"
              ],
              "Secondary Object": [
                "<NONE>"
              ]
            },
            "Context": [
              "human demonstrations and informational natural language feedback consisting of corrective instructions, edited summaries, and explanations with respect to the factual consistency of the summary"
            ],
            "Purpose": [
              "to study three natural language generation tasks"
            ],
            "Method": [
              "using our dataset"
            ],
            "Results": [
              "<NONE>"
            ],
            "Analysis": [
              "<NONE>"
            ],
            "Challenge": [
              "<NONE>"
            ],
            "Ethical": [
              "<NONE>"
            ],
            "Implications": [
              "<NONE>"
            ],
            "Contradictions": [
              "<NONE>"
            ]
          }
        },
        {
          "Results/Findings": "",
          "Text": "We show that DeFacto can provide factually consistent human-edited summaries and further insights into summarization factual consistency thanks to its informational natural language feedback. We further demonstrate that fine-tuned language models can leverage our dataset to improve the summary factual consistency, while large language models lack the zero-shot learning ability in our proposed tasks that require controllable text generation.",
          "Main Action": "We show that",
          "Arguments": {
            "Agent": [
              "We"
            ],
            "Object": {
              "Primary Object": [
                "DeFacto"
              ],
              "Secondary Object": [
                "summarization factual consistency"
              ]
            },
            "Context": [
              "Thanks to its informational natural language feedback"
            ],
            "Purpose": [
              "To evaluate the effectiveness of DeFacto in improving summarization factual consistency"
            ],
            "Method": [
              "Using fine-tuned language models to leverage the dataset for improved factual consistency"
            ],
            "Results": [
              "Fine-tuned language models perform better than large language models in maintaining factual consistency due to their controllable text generation capability"
            ],
            "Analysis": [
              "This suggests that model size affects performance, with smaller models excelling in tasks needing precise output control"
            ],
            "Challenge": [
              "Large language models' inability to learn new tasks without fine-tuning limits their applicability to specialized requirements"
            ],
            "Ethical": [
              "<NONE>"
            ],
            "Implications": [
              "Future research may focus more on creating adaptable models suited to particular domains instead of generic ones"
            ],
            "Contradictions": [
              "<NONE>"
            ]
          }
        }
      ]
    },
    {
      "paper_code": "ACL_23_P_700",
      "abstract": "State-of-the-art techniques common to low resource Machine Translation (MT) are applied to improve MT of spoken language text to Sign Language (SL) glosses. In our experiments, we improve the performance of the transformer-based models via (1) data augmentation, (2) semi-supervised Neural Machine Translation (NMT), (3) transfer learning and (4) multilingual NMT. The proposed methods are implemented progressively on two German SL corpora containing gloss annotations. Multilingual NMT combined with data augmentation appear to be the most successful setting, yielding statistically significant improvements as measured by three automatic metrics (up to over 6 points BLEU), and confirmed via human evaluation. Our best setting outperforms all previous work that report on the same test-set and is also confirmed on a corpus of the American Sign Language (ASL).",
      "events": [
        {
          "Background/Introduction": "",
          "Text": "State-of-the-art techniques common to low-resource Machine Translation (MT) are applied to improve MT of spoken language text to Sign Language (SL) glosses.",
          "Main Action": "are applied",
          "Arguments": {
            "Agent": [
              "State-of-the-art techniques"
            ],
            "Object": {
              "Primary Object": [
                "spoken language text to Sign Language (SL) glosses"
              ],
              "Secondary Object": [
                "<NONE>"
              ]
            },
            "Context": [
              "Low-resource Machine Translation (MT)"
            ],
            "Purpose": [
              "to improve MT of spoken language text to Sign Language (SL) glosses"
            ],
            "Method": [
              "State-of-the-art techniques common to low-resource Machine Translation (MT)"
            ],
            "Results": [
              "<NONE>"
            ],
            "Analysis": [
              "<NONE>"
            ],
            "Challenge": [
              "<NONE>"
            ],
            "Ethical": [
              "<NONE>"
            ],
            "Implications": [
              "<NONE>"
            ],
            "Contradictions": [
              "<NONE>"
            ]
          }
        },
        {
          "Methods/Approach": "",
          "Text": "In our experiments, we improve the performance of the transformer-based models via (1) data augmentation, (2) semi-supervised Neural Machine Translation (NMT), (3) transfer learning and (4) multilingual NMT. The proposed methods are implemented progressively on two German SL corpora containing gloss annotations.",
          "Main Action": "we improve the performance of the transformer-based models",
          "Arguments": {
            "Agent": [
              "we"
            ],
            "Object": {
              "Primary Object": [
                "the performance of the transformer-based models"
              ],
              "Secondary Object": [
                "<NONE>"
              ]
            },
            "Context": [
              "our experiments",
              "transformer-based models",
              "German SL corpora containing gloss annotations"
            ],
            "Purpose": [
              "to improve the performance"
            ],
            "Method": [
              "data augmentation",
              "semi-supervised Neural Machine Translation (NMT)",
              "transfer learning",
              "multilingual NMT"
            ],
            "Results": [
              "improved performance"
            ],
            "Analysis": [
              "<NONE>"
            ],
            "Challenge": [
              "<NONE>"
            ],
            "Ethical": [
              "<NONE>"
            ],
            "Implications": [
              "<NONE>"
            ],
            "Contradictions": [
              "<NONE>"
            ]
          }
        },
        {
          "Results/Findings": "",
          "Text": "Multilingual NMT combined with data augmentation appear to be the most successful setting, yielding statistically significant improvements as measured by three automatic metrics (up to over 6 points BLEU), and confirmed via human evaluation. Our best setting outperforms all previous work that report on the same test-set and is also confirmed on a corpus of the American Sign Language (ASL).",
          "Main Action": "yielding statistically significant improvements as measured by three automatic metrics (up to over 6 points BLEU)",
          "Arguments": {
            "Agent": [
              "<NONE>"
            ],
            "Object": {
              "Primary Object": [
                "Our best setting"
              ],
              "Secondary Object": [
                "American Sign Language (ASL)"
              ]
            },
            "Context": [
              "Multilingual NMT combined with data augmentation appear to be the most successful setting"
            ],
            "Purpose": [
              "To evaluate or improve translation systems"
            ],
            "Method": [
              "Combining multilingual NMT with data augmentation"
            ],
            "Results": [
              "Statistically significant improvements up to 6 points BLEU, confirmed via human evaluation"
            ],
            "Analysis": [
              "Interpretation of these results compared to prior work"
            ],
            "Challenge": [
              "Overcoming limitations of previous work"
            ],
            "Ethical": [
              "<NONE>"
            ],
            "Implications": [
              "Broader impact on machine translation"
            ],
            "Contradictions": [
              "<NONE>"
            ]
          }
        }
      ]
    }
  ]
}