{
  "papers": [
    {
      "paper_code": "cscw_23_P_267",
      "abstract": "Past work has explored various ways for online platforms to leverage crowd wisdom for misinformation detection and moderation. Yet, platforms often relegate governance to their communities, and limited research has been done from the perspective of these communities and their moderators. How is misinformation currently moderated in online communities that are heavily self-governed? What role does the crowd play in this process, and how can this process be improved? In this study, we answer these questions through semi-structured interviews with Reddit moderators. We focus on a case study of COVID-19 misinformation. First, our analysis identifies a general moderation workflow model encompassing various processes participants use for handling COVID-19 misinformation. Further, we show that the moderation workflow revolves around three elements: content facticity, user intent, and perceived harm. Next, our interviews reveal that Reddit moderators rely on two types of crowd wisdom for misinformation detection. Almost all participants are heavily reliant on reports from crowds of ordinary users to identify potential misinformation. A second crowd--participants' own moderation teams and expert moderators of other communities--provide support when participants encounter difficult, ambiguous cases. Finally, we use design probes to better understand how different types of crowd signals---from ordinary users and moderators---readily available on Reddit can assist moderators with identifying misinformation. We observe that nearly half of all participants preferred these cues over labels from expert fact-checkers because these cues can help them discern user intent. Additionally, a quarter of the participants distrust professional fact-checkers, raising important concerns about misinformation moderation.",
      "events": [
        {
          "Background/Introduction": "",
          "Text": "Past work has explored various ways for online platforms to leverage crowd wisdom for misinformation detection and moderation. Yet, platforms often relegate governance to their communities, and limited research has been done from the perspective of these communities and their moderators. How is misinformation currently moderated in online communities that are heavily self-governed? What role does the crowd play in this process, and how can this process be improved?",
          "Main Action": "How misinformation is currently moderated",
          "Arguments": {
            "Agent": [
              "online communities"
            ],
            "Object": {
              "Primary Object": [
                "misinformation"
              ],
              "Secondary Object": [
                "<NONE>"
              ]
            },
            "Context": [
              "Platforms often relegate governance to their communities"
            ],
            "Purpose": [
              "To detect and moderate misinformation"
            ],
            "Method": [
              "relying on the crowd for moderation"
            ],
            "Results": [
              "<NONE>"
            ],
            "Analysis": [
              "Current methods may lack effectiveness"
            ],
            "Challenge": [
              "Limited research has been done from the perspective of these communities and their moderators"
            ],
            "Ethical": [
              "Potential ethical concerns regarding privacy and fairness"
            ],
            "Implications": [
              "Improving community engagement and system effectiveness"
            ],
            "Contradictions": [
              "Existing solutions may not fully address community-driven needs"
            ]
          }
        },
        {
          "Methods/Approach": "",
          "Text": "In this study, we answer these questions through semi-structured interviews with Reddit moderators. We focus on a case study of COVID-19 misinformation. First, our analysis identifies a general moderation workflow model encompassing various processes participants use for handling COVID-19 misinformation. Further, we show that the moderation workflow revolves around three elements: content facticity, user intent, and perceived harm.",
          "Main Action": "conducting semi-structured interviews",
          "Arguments": {
            "Agent": [
              "we"
            ],
            "Object": {
              "Primary Object": [
                "Reddit moderators"
              ],
              "Secondary Object": [
                "<NONE>"
              ]
            },
            "Context": [
              "case study of COVID-19 misinformation"
            ],
            "Purpose": [
              "understanding how participants use various processes for handling COVID-19 misinformation"
            ],
            "Method": [
              "semi-structured interviews"
            ],
            "Results": [
              "analysis identifies a general moderation workflow model",
              "show that the moderation workflow revolves around three elements: content facticity, user intent, and perceived harm"
            ],
            "Analysis": [
              "interpretations or explanations of other arguments"
            ],
            "Challenge": [
              "<NONE>"
            ],
            "Ethical": [
              "<NONE>"
            ],
            "Implications": [
              "broader significance or potential for future applications/research"
            ],
            "Contradictions": [
              "<NONE>"
            ]
          }
        },
        {
          "Results/Findings": "",
          "Text": "Next, our interviews reveal that Reddit moderators rely on two types of crowd wisdom for misinformation detection. Almost all participants are heavily reliant on reports from crowds of ordinary users to identify potential misinformation. A second crowd--participants' own moderation teams and expert moderators of other communities--provide support when participants encounter difficult, ambiguous cases. Finally, we use design probes to better understand how different types of crowd signals---from ordinary users and moderators---readily available on Reddit can assist moderators with identifying misinformation. We observe that nearly half of all participants preferred these cues over labels from expert fact-checkers because these cues can help them discern user intent. Additionally, a quarter of the participants distrust professional fact-checkers, raising important concerns about misinformation moderation.",
          "Main Action": "We observe",
          "Arguments": {
            "Agent": [
              "Participants"
            ],
            "Object": {
              "Primary Object": [
                "these cues"
              ],
              "Secondary Object": [
                "expert fact-checkers"
              ]
            },
            "Context": [
              "Reddit moderators rely on two types of crowd wisdom for misinformation detection.",
              "Almost all participants are heavily reliant on reports from crowds of ordinary users to identify potential misinformation.",
              "A second crowd--participants' own moderation teams and expert moderators of other communities--provide support when participants encounter difficult, ambiguous cases."
            ],
            "Purpose": [
              "to better understand how different types of crowd signals---from ordinary users and moderators---readily available on Reddit can assist moderators with identifying misinformation"
            ],
            "Method": [
              "design probes",
              "comparing cues against expert labels"
            ],
            "Results": [
              "nearly half of all participants preferred these cues over labels from expert fact-checkers",
              "a quarter of the participants distrust professional fact-checkers"
            ],
            "Analysis": [
              "These cues can help them discern user intent",
              "There are important concerns about misinformation moderation due to distrust in professional fact-checkers."
            ],
            "Challenge": [
              "distrust in professional fact-checkers raises important concerns about misinformation moderation",
              "moderation efforts may be hindered by lack of trust in external sources"
            ],
            "Ethical": [
              "Potential issues with misinformation moderation",
              "Concerns about the reliability of community-based versus expert-based solutions"
            ],
            "Implications": [
              "Broader implications for misinformation handling practices",
              "Highlighting the importance of community-based systems in detecting misinformation"
            ],
            "Contradictions": [
              "Disagreements between community-based and expert-based approaches",
              "Tensions between trusting laypeople's judgment vs. expert authority"
            ]
          }
        }
      ]
    },
    {
      "paper_code": "cscw_23_P_206",
      "abstract": "Traditional wall-sized displays mostly only support side-by-side co-located collaboration, while transparent displays naturally support face-to-face interaction. Many previous works assume transparent displays support collaboration. Yet it is unknown how exactly its afforded face-to-face interaction can support loose or close collaboration, especially compared to the side-by-side configuration offered by traditional large displays. In this paper, we used an established experimental task that operationalizes different collaboration coupling and layout locality, to compare pairs of participants collaborating side-by-side versus face-to-face in each collaborative situation. We compared quantitative measures and collected interview and observation data to further illustrate and explain our observed user behavior patterns. The results showed that the unique face-to-face collaboration brought by transparent display can result in more efficient task performance, different territorial behavior, and both positive and negative collaborative factors. Our findings provided empirical understanding about the collaborative experience supported by wall-sized transparent displays and shed light on its future design.",
      "events": [
        {
          "Background/Introduction": "",
          "Text": "Traditional wall-sized displays mostly only support side-by-side co-located collaboration, while transparent displays naturally support face-to-face interaction. Many previous works assume transparent displays support collaboration. Yet it is unknown how exactly its afforded face-to-face interaction can support loose or close collaboration, especially compared to the side-by-side configuration offered by traditional large displays.",
          "Main Action": "<NONE>",
          "Arguments": {
            "Agent": [
              "<NONE>"
            ],
            "Object": {
              "Primary Object": [
                "<NONE>"
              ],
              "Secondary Object": [
                "<NONE>"
              ]
            },
            "Context": [
              "<NONE>"
            ],
            "Purpose": [
              "<NONE>"
            ],
            "Method": [
              "<NONE>"
            ],
            "Results": [
              "<NONE>"
            ],
            "Analysis": [
              "<NONE>"
            ],
            "Challenge": [
              "<NONE>"
            ],
            "Ethical": [
              "<NONE>"
            ],
            "Implications": [
              "<NONE>"
            ],
            "Contradictions": [
              "<NONE>"
            ]
          }
        },
        {
          "Methods/Approach": "",
          "Text": "In this paper, we used an established experimental task that operationalizes different collaboration coupling and layout locality, to compare pairs of participants collaborating side-by-side versus face-to-face in each collaborative situation. We compared quantitative measures and collected interview and observation data to further illustrate and explain our observed user behavior patterns.",
          "Main Action": "<NONE>",
          "Arguments": {
            "Agent": [
              "<NONE>"
            ],
            "Object": {
              "Primary Object": [
                "<NONE>"
              ],
              "Secondary Object": [
                "<NONE>"
              ]
            },
            "Context": [
              "<NONE>"
            ],
            "Purpose": [
              "<NONE>"
            ],
            "Method": [
              "used"
            ],
            "Results": [
              "collected"
            ],
            "Analysis": [
              "further illustrated",
              "explained"
            ],
            "Challenge": [
              "<NONE>"
            ],
            "Ethical": [
              "<NONE>"
            ],
            "Implications": [
              "<NONE>"
            ],
            "Contradictions": [
              "<NONE>"
            ]
          }
        },
        {
          "Results/Findings": "",
          "Text": "The results showed that the unique face-to-face collaboration brought by transparent display can result in more efficient task performance, different territorial behavior, and both positive and negative collaborative factors.",
          "Main Action": "<NONE>",
          "Arguments": {
            "Agent": [
              "<NONE>"
            ],
            "Object": {
              "Primary Object": [
                "<NONE>"
              ],
              "Secondary Object": [
                "<NONE>"
              ]
            },
            "Context": [
              "<NONE>"
            ],
            "Purpose": [
              "<NONE>"
            ],
            "Method": [
              "<NONE>"
            ],
            "Results": [
              "<NONE>"
            ],
            "Analysis": [
              "<NONE>"
            ],
            "Challenge": [
              "<NONE>"
            ],
            "Ethical": [
              "<NONE>"
            ],
            "Implications": [
              "<NONE>"
            ],
            "Contradictions": [
              "<NONE>"
            ]
          }
        },
        {
          "Conclusions/Implications": "",
          "Text": "Our findings provided empirical understanding about the collaborative experience supported by wall-sized transparent displays and shed light on its future design.",
          "Main Action": "<NONE>",
          "Arguments": {
            "Agent": [
              "<NONE>"
            ],
            "Object": {
              "Primary Object": [
                "<NONE>"
              ],
              "Secondary Object": [
                "<NONE>"
              ]
            },
            "Context": [
              "<NONE>"
            ],
            "Purpose": [
              "<NONE>"
            ],
            "Method": [
              "<NONE>"
            ],
            "Results": [
              "<NONE>"
            ],
            "Analysis": [
              "<NONE>"
            ],
            "Challenge": [
              "<NONE>"
            ],
            "Ethical": [
              "<NONE>"
            ],
            "Implications": [
              "<NONE>"
            ],
            "Contradictions": [
              "<NONE>"
            ]
          }
        }
      ]
    }
  ]
}