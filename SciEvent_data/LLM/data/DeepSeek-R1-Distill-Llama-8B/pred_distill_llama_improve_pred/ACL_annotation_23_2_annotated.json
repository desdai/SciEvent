{
  "papers": [
    {
      "paper_code": "ACL_23_P_420",
      "abstract": "Weir has defined a hierarchy of language classes whose second member (L2) is generated by tree-adjoining grammars (TAG), linear indexed grammars (LIG), combinatory categorial grammars, and head grammars. The hierarchy is obtained using the mechanism of control, and L2 is obtained using a context-free grammar (CFG) whose derivations are controlled by another CFG. We adapt Weir’s definition of a controllable CFG (called a labeled distinguished CFG) to give a definition of controllable pushdown automata (PDAs), called labeled distinguished PDAs. This yields three new characterizations of L2 as the class of languages generated by PDAs controlling PDAs, PDAs controlling CFGs, and CFGs controlling PDAs. We show that these four formalisms are not only weakly equivalent but equivalent in a stricter sense that we call d-weak equivalence. Furthermore, using an even stricter notion of equivalence called d-strong equivalence, we make precise the intuition that a CFG controlling a CFG is a TAG, a PDA controlling a PDA is an embedded PDA, and a PDA controlling a CFG is a LIG. The fourth member of this family, a CFG controlling a PDA, does not correspond to any kind of automaton we know of, so we invent one and call it a Pushdown Adjoining Automaton (PAA).",
      "events": [
        {
          "Background/Introduction": "",
          "Text": "Weir has defined a hierarchy of language classes whose second member (L2) is generated by tree-adjoining grammars (TAG), linear indexed grammars (LIG), combinatory categorial grammars, and head grammars. The hierarchy is obtained using the mechanism of control, and L2 is obtained using a context-free grammar (CFG) whose derivations are controlled by another CFG.",
          "Main Action": "has defined",
          "Arguments": {
            "Agent": [
              "Weir"
            ],
            "Object": {
              "Primary Object": [
                "a hierarchy of language classes"
              ],
              "Secondary Object": [
                "<NONE>"
              ]
            },
            "Context": [
              "<NONE>"
            ],
            "Purpose": [
              "<NONE>"
            ],
            "Method": [
              "<NONE>"
            ],
            "Results": [
              "<NONE>"
            ],
            "Analysis": [
              "<NONE>"
            ],
            "Challenge": [
              "<NONE>"
            ],
            "Ethical": [
              "<NONE>"
            ],
            "Implications": [
              "<NONE>"
            ],
            "Contradictions": [
              "<NONE>"
            ]
          }
        },
        {
          "Methods/Approach": "",
          "Text": "We adapt Weir’s definition of a controllable CFG (called a labeled distinguished CFG) to give a definition of controllable pushdown automata (PDAs), called labeled distinguished PDAs. This yields three new characterizations of L2 as the class of languages generated by PDAs controlling PDAs, PDAs controlling CFGs, and CFGs controlling PDAs.",
          "Main Action": "Define",
          "Arguments": {
            "Agent": [
              "We"
            ],
            "Object": {
              "Primary Object": [
                "Controllable pushdown automata (PDAs)"
              ],
              "Secondary Object": [
                "<NONE>"
              ]
            },
            "Context": [
              "Weir’s definition of a controllable CFG"
            ],
            "Purpose": [
              "To provide a new characterization of PDAs"
            ],
            "Method": [
              "Adapting Weir’s definition of a controllable CFG"
            ],
            "Results": [
              "Labeled distinguished PDAs"
            ],
            "Analysis": [
              "<NONE>"
            ],
            "Challenge": [
              "<NONE>"
            ],
            "Ethical": [
              "<NONE>"
            ],
            "Implications": [
              "Clarifying the definition and classification of pushdown automata"
            ],
            "Contradictions": [
              "<NONE>"
            ]
          }
        },
        {
          "Results/Findings": "",
          "Text": "We show that these four formalisms are not only weakly equivalent but equivalent in a stricter sense that we call d-weak equivalence. Furthermore, using an even stricter notion of equivalence called d-strong equivalence, we make precise the intuition that a CFG controlling a CFG is a TAG, a PDA controlling a PDA is an embedded PDA, and a PDA controlling a CFG is a LIG. The fourth member of this family, a CFG controlling a PDA, does not correspond to any kind of automaton we know of, so we invent one and call it a Pushdown Adjoining Automaton (PAA).",
          "Main Action": "We show that these four formalisms are not only weakly equivalent but equivalent in a stricter sense that we call d-weak equivalence",
          "Arguments": {
            "Agent": [
              "We"
            ],
            "Object": {
              "Primary Object": [
                "these four formalisms"
              ],
              "Secondary Object": [
                "<NONE>"
              ]
            },
            "Context": [
              "a CFG controlling a CFG is a TAG, a PDA controlling a PDA is an embedded PDA, and a PDA controlling a CFG is a LIG"
            ],
            "Purpose": [
              "to make precise the intuition that a CFG controlling a CFG is a TAG, a PDA controlling a PDA is an embedded PDA, and a PDA controlling a CFG is a LIG"
            ],
            "Method": [
              "using an even stricter notion of equivalence called d-strong equivalence",
              "introducing a new concept called Pushdown Adjoining Automaton (PAA)"
            ],
            "Results": [
              "d-weak equivalence",
              "d-strong equivalence",
              "Pushdown Adjoining Automaton (PAA)"
            ],
            "Analysis": [
              "making precise the intuition that a CFG controlling a CFG is a TAG, a PDA controlling a PDA is an embedded PDA, and a PDA controlling a CFG is a LIG"
            ],
            "Challenge": [
              "recognizing these equivalences initially"
            ],
            "Ethical": [
              "<NONE>"
            ],
            "Implications": [
              "opening up new areas in theoretical computer science concerning controlled systems"
            ],
            "Contradictions": [
              "<NONE>"
            ]
          }
        }
      ]
    },
    {
      "paper_code": "ACL_23_P_216",
      "abstract": "End-to-end Speech Translation (E2E ST) aims to directly translate source speech into target text. Existing ST methods perform poorly when only extremely small speech-text data are available for training. We observe that an ST model’s performance closely correlates with its embedding similarity between speech and source transcript. In this paper, we propose Word-Aligned COntrastive learning (WACO), a simple and effective method for extremely low-resource speech-to-text translation. Our key idea is bridging word-level representations for both speech and text modalities via contrastive learning. We evaluate WACO and other methods on the MuST-C dataset, a widely used ST benchmark, and on a low-resource direction Maltese-English from IWSLT 2023. Our experiments demonstrate that WACO outperforms the best baseline by 9+ BLEU points with only 1-hour parallel ST data.",
      "events": [
        {
          "Background/Introduction": "",
          "Text": "End-to-end Speech Translation (E2E ST) aims to directly translate source speech into target text. Existing ST methods perform poorly when only extremely small speech-text data are available for training. We observe that an ST model’s performance closely correlates with its embedding similarity between speech and source transcript.",
          "Main Action": "Analyze",
          "Arguments": {
            "Agent": [
              "We"
            ],
            "Object": {
              "Primary Object": [
                "ST model's performance"
              ],
              "Secondary Object": [
                "embedding similarity between speech and source transcript"
              ]
            },
            "Context": [
              "Existing ST methods perform poorly..."
            ],
            "Purpose": [
              "To understand the factors affecting ST model performance"
            ],
            "Method": [
              "Comparing speech and source transcript embeddings"
            ],
            "Results": [
              "Performance closely correlates with embedding similarity"
            ],
            "Analysis": [
              "This suggests that improving embedding similarity may enhance performance"
            ],
            "Challenge": [
              "<NONE>"
            ],
            "Ethical": [
              "<NONE>"
            ],
            "Implications": [
              "Better data leads to improved models and translations"
            ],
            "Contradictions": [
              "<NONE>"
            ]
          }
        },
        {
          "Methods/Approach": "",
          "Text": "In this paper, we propose Word-Aligned COntrastive learning (WACO), a simple and effective method for extremely low-resource speech-to-text translation. Our key idea is bridging word-level representations for both speech and text modalities via contrastive learning.",
          "Main Action": "Propose Word-Aligned Contrastive Learning (WACO)",
          "Arguments": {
            "Agent": [
              "We"
            ],
            "Object": {
              "Primary Object": [
                "Word-Aligned Contrastive Learning (WACO)"
              ],
              "Secondary Object": [
                "Extremely low-resource speech-to-text translation"
              ]
            },
            "Context": [
              "This paper",
              "speech and text modalities",
              "existing methods"
            ],
            "Purpose": [
              "Addressing the challenge of speech-to-text translation in resource-constrained environments"
            ],
            "Method": [
              "Contrastive learning framework",
              "Bridging word-level representations"
            ],
            "Results": [
              "Simple and effective method"
            ],
            "Analysis": [
              "Novelty of the approach",
              "Comparison with existing methods"
            ],
            "Challenge": [
              "Extreme low-resource setting",
              "Limited computational resources"
            ],
            "Ethical": [
              "<NONE>"
            ],
            "Implications": [
              "Broader applicability in resource-constrained areas",
              "Future research directions"
            ],
            "Contradictions": [
              "<NONE>"
            ]
          }
        },
        {
          "Results/Findings": "",
          "Text": "We evaluate WACO and other methods on the MuST-C dataset, a widely used ST benchmark, and on a low-resource direction Maltese-English from IWSLT 2023. Our experiments demonstrate that WACO outperforms the best baseline by 9+ BLEU points with only 1-hour parallel ST data.",
          "Main Action": "Evaluate",
          "Arguments": {
            "Agent": [
              "We"
            ],
            "Object": {
              "Primary Object": [
                "WACO"
              ],
              "Secondary Object": [
                "other methods"
              ]
            },
            "Context": [
              "MuST-C dataset",
              "a widely used ST benchmark",
              "low-resource direction Maltese-English from IWSLT 2023"
            ],
            "Purpose": [
              "Compare performance of WACO and other methods on specified datasets"
            ],
            "Method": [
              "Use of MuST-C dataset",
              "Use of Maltese-English from IWSLT 2023"
            ],
            "Results": [
              "Outperform the best baseline by 9+ BLEU points"
            ],
            "Analysis": [
              "Improvement demonstrated by WACO compared to baseline"
            ],
            "Challenge": [
              "<NONE>"
            ],
            "Ethical": [
              "<NONE>"
            ],
            "Implications": [
              "Potential for future applications and further research"
            ],
            "Contradictions": [
              "<NONE>"
            ]
          }
        }
      ]
    }
  ]
}