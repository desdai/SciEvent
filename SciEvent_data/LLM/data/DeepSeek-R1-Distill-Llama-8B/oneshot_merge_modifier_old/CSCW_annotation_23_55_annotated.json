{
  "papers": [
    {
      "paper_code": "cscw_23_P_101",
      "abstract": "Live streaming has become a popular activity world-wide that has warranted research attention on its privacy related issues. For instance, bystanders' privacy, or the privacy of third-parties captured by streamers, has been increasingly studied as live streaming has become almost ubiquitous in both public and private spaces in many countries. While prior work has studied bystanders' privacy concerns, a gap exists in understanding how streamers consider bystanders' privacy and the steps they take (or do not take) to preserve it. Understanding streamers' considerations towards bystanders' privacy is vital because streamers are the ones who have direct control over whether and how bystanders' information is disclosed. To address this gap, we conducted an interview study with 25 Chinese streamers to understand their considerations and practices regarding bystanders' privacy in live streaming. We found that streamers cared about bystanders' privacy and evaluated possible privacy violations to bystanders from several perspectives. To protect bystanders from privacy violations, streamers primarily relied on technical, behavioral, and collaborative strategies. Our results also indicated that current streaming platforms lacked features that helped streamers seamlessly manage bystanders' privacy and involved bystanders into their privacy decision-making. Applying the theoretical lens of collective privacy management, we discuss implications for the design of live streaming systems to support streamers in protecting bystanders' privacy.",
      "events": [
        {
          "Background/Introduction": "",
          "Text": "Live streaming has become a popular activity world-wide that has warranted research attention on its privacy related issues. For instance, bystanders' privacy, or the privacy of third-parties captured by streamers, has been increasingly studied as live streaming has become almost ubiquitous in both public and private spaces in many countries. While prior work has studied bystanders' privacy concerns, a gap exists in understanding how streamers consider bystanders' privacy and the steps they take (or do not take) to preserve it. Understanding streamers' considerations towards bystanders' privacy is vital because streamers are the ones who have direct control over whether and how bystanders' information is disclosed.",
          "Main Action": "has long been recognized",
          "Arguments": {
            "Agent": [
              "the problem of hallucinations in neural machine translation"
            ],
            "Object": {
              "Primary Object": [
                "<NONE>"
              ],
              "Secondary Object": [
                "<NONE>"
              ]
            },
            "Context": [
              "so far the progress on its alleviation is very little."
            ],
            "Purpose": [
              "<NONE>"
            ],
            "Method": [
              "<NONE>"
            ],
            "Results": [
              "Indeed, recently it turned out that without artificially encouraging models to hallucinate, previously existing methods fall short and even the standard sequence log-probability is more informative"
            ],
            "Analysis": [
              "It means that internal characteristics of the model can give much more information than we expect"
            ],
            "Challenge": [
              "<NONE>"
            ],
            "Ethical": [
              "<NONE>"
            ],
            "Implications": [
              "<NONE>"
            ],
            "Contradictions": [
              "before using external models and measures, we first need to ask: how far can we go if we use nothing but the translation model itself?"
            ]
          }
        },
        {
          "Methods/Approach": "",
          "Text": "To address this gap, we conducted an interview study with 25 Chinese streamers to understand their considerations and practices regarding bystanders' privacy in live streaming.",
          "Main Action": "conducted an interview study",
          "Arguments": {
            "Agent": [
              "we"
            ],
            "Object": {
              "Primary Object": [
                "to understand their considerations and practices regarding bystanders' privacy in live streaming"
              ],
              "Secondary Object": [
                "<NONE>"
              ]
            },
            "Context": [
              "<NONE>"
            ],
            "Purpose": [
              "<NONE>"
            ],
            "Method": [
              "<NONE>"
            ],
            "Results": [
              "<NONE>"
            ],
            "Analysis": [
              "<NONE>"
            ],
            "Challenge": [
              "<NONE>"
            ],
            "Ethical": [
              "<NONE>"
            ],
            "Implications": [
              "<NONE>"
            ],
            "Contradictions": [
              "<NONE>"
            ]
          }
        },
        {
          "Results/Findings": "",
          "Text": "We found that streamers cared about bystanders' privacy and evaluated possible privacy violations to bystanders from several perspectives. To protect bystanders from privacy violations, streamers primarily relied on technical, behavioral, and collaborative strategies. Our results also indicated that current streaming platforms lacked features that helped streamers seamlessly manage bystanders' privacy and involved bystanders into their privacy decision-making.",
          "Main Action": "found that streamers cared about bystanders' privacy and evaluated possible privacy violations to bystanders from several perspectives.",
          "Arguments": {
            "Agent": [
              "We"
            ],
            "Object": {
              "Primary Object": [
                "streamers"
              ],
              "Secondary Object": [
                "bystanders' privacy"
              ]
            },
            "Context": [
              "To protect bystanders from privacy violations, streamers primarily relied on technical, behavioral, and collaborative strategies."
            ],
            "Purpose": [
              "<NONE>"
            ],
            "Method": [
              "<NONE>"
            ],
            "Results": [
              "Our results also indicated that current streaming platforms lacked features that helped streamers seamlessly manage bystanders' privacy and involved bystanders into their privacy decision-making."
            ],
            "Analysis": [
              "The fact that streamers had to rely on various strategies suggests there was a gap in existing solutions."
            ],
            "Challenge": [
              "The lack of seamless management features on current platforms posed a significant challenge for streamers."
            ],
            "Ethical": [
              "Ensuring bystanders' privacy while balancing content creation and engagement raises ethical considerations."
            ],
            "Implications": [
              "These findings highlight the importance of developing better privacy management tools for live-streaming platforms."
            ],
            "Contradictions": [
              "Previous assumptions about self-regulation may have underestimated the complexity of managing privacy in real-time."
            ]
          }
        },
        {
          "Conclusions/Implications": "",
          "Text": "Applying the theoretical lens of collective privacy management, we discuss implications for the design of live streaming systems to support streamers in protecting bystanders' privacy.",
          "Main Action": "discuss implications",
          "Arguments": {
            "Agent": [
              "collective privacy management"
            ],
            "Object": {
              "Primary Object": [
                "<NONE>"
              ],
              "Secondary Object": [
                "<NONE>"
              ]
            },
            "Context": [
              "to support streamers in protecting bystanders' privacy."
            ],
            "Purpose": [
              "<NONE>"
            ],
            "Method": [
              "<NONE>"
            ],
            "Results": [
              "<NONE>"
            ],
            "Analysis": [
              "<NONE>"
            ],
            "Challenge": [
              "<NONE>"
            ],
            "Ethical": [
              "<NONE>"
            ],
            "Implications": [
              "<NONE>"
            ],
            "Contradictions": [
              "<NONE>"
            ]
          }
        }
      ]
    },
    {
      "paper_code": "cscw_23_P_201",
      "abstract": "Numerous toolkits have been developed to support ethical AI development. However, toolkits, like all tools, encode assumptions in their design about what work should be done and how. In this paper, we conduct a qualitative analysis of 27 AI ethics toolkits to critically examine how the work of ethics is imagined and how it is supported by these toolkits. Specifically, we examine the discourses toolkits rely on when talking about ethical issues, who they imagine should do the work of ethics, and how they envision the work practices involved in addressing ethics. Among the toolkits, we identify a mismatch between the imagined work of ethics and the support the toolkits provide for doing that work. In particular, we identify a lack of guidance around how to navigate labor, organizational, and institutional power dynamics as they relate to performing ethical work. We use these omissions to chart future work for researchers and designers of AI ethics toolkits.",
      "events": [
        {
          "Background/Introduction": "",
          "Text": "Numerous toolkits have been developed to support ethical AI development. However, toolkits, like all tools, encode assumptions in their design about what work should be done and how.",
          "Main Action": "have been developed",
          "Arguments": {
            "Agent": [
              "Numerous toolkits"
            ],
            "Object": {
              "Primary Object": [
                "<NONE>"
              ],
              "Secondary Object": [
                "<NONE>"
              ]
            },
            "Context": [
              "However, toolkits, like all tools, encode assumptions in their design about what work should be done and how."
            ],
            "Purpose": [
              "<NONE>"
            ],
            "Method": [
              "<NONE>"
            ],
            "Results": [
              "<NONE>"
            ],
            "Analysis": [
              "<NONE>"
            ],
            "Challenge": [
              "<NONE>"
            ],
            "Ethical": [
              "<NONE>"
            ],
            "Implications": [
              "<NONE>"
            ],
            "Contradictions": [
              "<NONE>"
            ]
          }
        },
        {
          "Methods/Approach": "",
          "Text": "In this paper, we conduct a qualitative analysis of 27 AI ethics toolkits to critically examine how the work of ethics is imagined and how it is supported by these toolkits. Specifically, we examine the discourses toolkits rely on when talking about ethical issues, who they imagine should do the work of ethics, and how they envision the work practices involved in addressing ethics.",
          "Main Action": "conduct",
          "Arguments": {
            "Agent": [
              "we"
            ],
            "Object": {
              "Primary Object": [
                "27 AI ethics toolkits"
              ],
              "Secondary Object": [
                "<NONE>"
              ]
            },
            "Context": [
              "to critically examine how the work of ethics is imagined"
            ],
            "Purpose": [
              "<NONE>"
            ],
            "Method": [
              "examining the discourses toolkits rely on when talking about ethical issues, who they imagine should do the work of ethics, and how they envision the work practices involved in addressing ethics"
            ],
            "Results": [
              "<NONE>"
            ],
            "Analysis": [
              "how it is supported by these toolkits"
            ],
            "Challenge": [
              "<NONE>"
            ],
            "Ethical": [
              "<NONE>"
            ],
            "Implications": [
              "<NONE>"
            ],
            "Contradictions": [
              "<NONE>"
            ]
          }
        },
        {
          "Results/Findings": "",
          "Text": "Among the toolkits, we identify a mismatch between the imagined work of ethics and the support the toolkits provide for doing that work. In particular, we identify a lack of guidance around how to navigate labor, organizational, and institutional power dynamics as they relate to performing ethical work.",
          "Main Action": "identify",
          "Arguments": {
            "Agent": [
              "we"
            ],
            "Object": {
              "Primary Object": [
                "a mismatch between the imagined work of ethics and the support the toolkits provide for doing that work."
              ],
              "Secondary Object": [
                "<NONE>"
              ]
            },
            "Context": [
              "among the toolkits"
            ],
            "Purpose": [
              "<NONE>"
            ],
            "Method": [
              "<NONE>"
            ],
            "Results": [
              "In particular, we identify a lack of guidance around how to navigate labor, organizational, and institutional power dynamics as they relate to performing ethical work."
            ],
            "Analysis": [
              "<NONE>"
            ],
            "Challenge": [
              "<NONE>"
            ],
            "Ethical": [
              "<NONE>"
            ],
            "Implications": [
              "<NONE>"
            ],
            "Contradictions": [
              "<NONE>"
            ]
          }
        },
        {
          "Conclusions/Implications": "",
          "Text": "We use these omissions to chart future work for researchers and designers of AI ethics toolkits.",
          "Main Action": "<NONE>",
          "Arguments": {
            "Agent": [
              "<NONE>"
            ],
            "Object": {
              "Primary Object": [
                "<NONE>"
              ],
              "Secondary Object": [
                "<NONE>"
              ]
            },
            "Context": [
              "<NONE>"
            ],
            "Purpose": [
              "<NONE>"
            ],
            "Method": [
              "<NONE>"
            ],
            "Results": [
              "<NONE>"
            ],
            "Analysis": [
              "<NONE>"
            ],
            "Challenge": [
              "<NONE>"
            ],
            "Ethical": [
              "<NONE>"
            ],
            "Implications": [
              "<NONE>"
            ],
            "Contradictions": [
              "<NONE>"
            ]
          }
        }
      ]
    }
  ]
}