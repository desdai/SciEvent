{
  "papers": [
    {
      "paper_code": "cscw_23_P_257",
      "abstract": "AI explanations are often mentioned as a way to improve human-AI decision-making, but empirical studies have not found consistent evidence of explanations' effectiveness and, on the contrary, suggest that they can increase overreliance when the AI system is wrong. While many factors may affect reliance on AI support, one important factor is how decision-makers reconcile their own intuition — beliefs or heuristics, based on prior knowledge, experience, or pattern recognition, used to make judgments — with the information provided by the AI system to determine when to override AI predictions. We conduct a think-aloud, mixed-methods study with two explanation types (feature- and example-based) for two prediction tasks to explore how decision-makers' intuition affects their use of AI predictions and explanations, and ultimately their choice of when to rely on AI. Our results identify three types of intuition involved in reasoning about AI predictions and explanations: intuition about the task outcome, features, and AI limitations. Building on these, we summarize three observed pathways for decision-makers to apply their own intuition and override AI predictions. We use these pathways to explain why (1) the feature-based explanations we used did not improve participants' decision outcomes and increased their overreliance on AI, and (2) the example-based explanations we used improved decision-makers' performance over feature-based explanations and helped achieve complementary human-AI performance. Overall, our work identifies directions for further development of AI decision-support systems and explanation methods that help decision-makers effectively apply their intuition to achieve appropriate reliance on AI.",
      "events": [
        {
          "Background/Introduction": "",
          "Text": "AI explanations are often mentioned as a way to improve human-AI decision-making, but empirical studies have not found consistent evidence of explanations' effectiveness and, on the contrary, suggest that they can increase overreliance when the AI system is wrong. While many factors may affect reliance on AI support, one important factor is how decision-makers reconcile their own intuition — beliefs or heuristics, based on prior knowledge, experience, or pattern recognition, used to make judgments — with the information provided by the AI system to determine when to override AI predictions.",
          "Main Action": "mention",
          "Arguments": {
            "Agent": [
              "many factors"
            ],
            "Object": {
              "Primary Object": [
                "how decision-makers reconcile their own intuition"
              ],
              "Secondary Object": [
                "with the information provided by the AI system"
              ]
            },
            "Context": [
              "While many factors may affect reliance on AI support"
            ],
            "Purpose": [
              "to determine when to override AI predictions"
            ],
            "Method": [
              "based on prior knowledge, experience, or pattern recognition"
            ],
            "Results": [
              "<NONE>"
            ],
            "Analysis": [
              "<NONE>"
            ],
            "Challenge": [
              "one important factor is how decision-makers reconcile their own intuition"
            ],
            "Ethical": [
              "<NONE>"
            ],
            "Implications": [
              "<NONE>"
            ],
            "Contradictions": [
              "<NONE>"
            ]
          }
        },
        {
          "Methods/Approach": "",
          "Text": "We conduct a think-aloud, mixed-methods study with two explanation types (feature- and example-based) for two prediction tasks to explore how decision-makers' intuition affects their use of AI predictions and explanations, and ultimately their choice of when to rely on AI.",
          "Main Action": "conduct",
          "Arguments": {
            "Agent": [
              "We"
            ],
            "Object": {
              "Primary Object": [
                "think-aloud, mixed-methods study"
              ],
              "Secondary Object": [
                "two explanation types",
                "two prediction tasks"
              ]
            },
            "Context": [
              "for two prediction tasks to explore how decision-makers' intuition affects their use of AI predictions and explanations, and ultimately their choice of when to rely on AI."
            ],
            "Purpose": [
              "to explore how decision-makers' intuition affects their use of AI predictions and explanations, and ultimately their choice of when to rely on AI."
            ],
            "Method": [
              "with two explanation types (feature- and example-based)"
            ],
            "Results": [
              "<NONE>"
            ],
            "Analysis": [
              "<NONE>"
            ],
            "Challenge": [
              "and ultimately their choice of when to rely on AI."
            ],
            "Ethical": [
              "<NONE>"
            ],
            "Implications": [
              "<NONE>"
            ],
            "Contradictions": [
              "<NONE>"
            ]
          }
        },
        {
          "Results/Findings": "",
          "Text": "Our results identify three types of intuition involved in reasoning about AI predictions and explanations: intuition about the task outcome, features, and AI limitations. Building on these, we summarize three observed pathways for decision-makers to apply their own intuition and override AI predictions. We use these pathways to explain why (1) the feature-based explanations we used did not improve participants' decision outcomes and increased their overreliance on AI, and (2) the example-based explanations we used improved decision-makers' performance over feature-based explanations and helped achieve complementary human-AI performance.",
          "Main Action": "",
          "Arguments": {
            "Agent": [
              "<NONE>"
            ],
            "Object": {
              "Primary Object": [
                "<NONE>"
              ],
              "Secondary Object": [
                "<NONE>"
              ]
            },
            "Context": [
              "<NONE>"
            ],
            "Purpose": [
              "<NONE>"
            ],
            "Method": [
              "<NONE>"
            ],
            "Results": [
              "<NONE>"
            ],
            "Analysis": [
              "<NONE>"
            ],
            "Challenge": [
              "<NONE>"
            ],
            "Ethical": [
              "<NONE>"
            ],
            "Implications": [
              "<NONE>"
            ],
            "Contradictions": [
              "<NONE>"
            ]
          }
        },
        {
          "Conclusions/Implications": "",
          "Text": "Overall, our work identifies directions for further development of AI decision-support systems and explanation methods that help decision-makers effectively apply their intuition to achieve appropriate reliance on AI.",
          "Main Action": "identifies",
          "Arguments": {
            "Agent": [
              "our work"
            ],
            "Object": {
              "Primary Object": [
                "directions for further development of AI decision-support systems and explanation methods"
              ],
              "Secondary Object": [
                "<NONE>"
              ]
            },
            "Context": [
              "that help decision-makers effectively apply their intuition to achieve appropriate reliance on AI"
            ],
            "Purpose": [
              "<NONE>"
            ],
            "Method": [
              "<NONE>"
            ],
            "Results": [
              "<NONE>"
            ],
            "Analysis": [
              "<NONE>"
            ],
            "Challenge": [
              "What is the SINGLE most representative trigger (verb or verb phrase) in the segment?"
            ],
            "Ethical": [
              "<NONE>"
            ],
            "Implications": [
              "what is the broader significance or potential for future applications/research?"
            ],
            "Contradictions": [
              "<NONE>"
            ]
          }
        }
      ]
    },
    {
      "paper_code": "cscw_23_P_182",
      "abstract": "With the shift to hybrid meetings in work spaces, there is an increasing need to create a more inclusive hybrid meeting experience where people meeting together in a room interact with those joining remotely. This paper describes a design exploration, implementation, and evaluation of Perspectives, a novel hybrid meeting system that aimed to create an inclusive and equitable space for hybrid meetings. Perspectives digitally composites everyone into a virtual room so that each person has a unique but spatially consistent viewpoint into the meeting. The user study compared Perspectives with three commercially available UX designs for hybrid meetings: Gallery, Together Mode, and Front Row. Results from this study revealed key benefits of Perspectives, including supporting natural interactions, creating a strong sense of co-presence, and reducing cognitive load. Results from the study also helped iterate on the design principles of Perspectives, which offer important insights on supporting hybrid meetings.",
      "events": [
        {
          "Background/Introduction": "",
          "Text": "With the shift to hybrid meetings in work spaces, there is an increasing need to create a more inclusive hybrid meeting experience where people meeting together in a room interact with those joining remotely.",
          "Main Action": "create a more inclusive hybrid meeting experience",
          "Arguments": {
            "Agent": [
              "people meeting together in a room"
            ],
            "Object": {
              "Primary Object": [
                "those joining remotely"
              ],
              "Secondary Object": [
                "<NONE>"
              ]
            },
            "Context": [
              "With the shift to hybrid meetings in work spaces"
            ],
            "Purpose": [
              "<NONE>"
            ],
            "Method": [
              "<NONE>"
            ],
            "Results": [
              "<NONE>"
            ],
            "Analysis": [
              "<NONE>"
            ],
            "Challenge": [
              "there is an increasing need"
            ],
            "Ethical": [
              "<NONE>"
            ],
            "Implications": [
              "what is the broader significance or potential for future applications/research?"
            ],
            "Contradictions": [
              "<NONE>"
            ]
          }
        },
        {
          "Methods/Approach": "",
          "Text": "This paper describes a design exploration, implementation, and evaluation of Perspectives, a novel hybrid meeting system that aimed to create an inclusive and equitable space for hybrid meetings. Perspectives digitally composites everyone into a virtual room so that each person has a unique but spatially consistent viewpoint into the meeting. The user study compared Perspectives with three commercially available UX designs for hybrid meetings: Gallery, Together Mode, and Front Row.",
          "Main Action": "describes",
          "Arguments": {
            "Agent": [
              "this paper"
            ],
            "Object": {
              "Primary Object": [
                "design exploration, implementation, and evaluation of Perspectives"
              ],
              "Secondary Object": [
                "<NONE>"
              ]
            },
            "Context": [
              "Perspectives digitally composites everyone into a virtual room so that each person has a unique but spatially consistent viewpoint into the meeting"
            ],
            "Purpose": [
              "to create an inclusive and equitable space for hybrid meetings"
            ],
            "Method": [
              "implementation"
            ],
            "Results": [
              "The user study compared Perspectives with three commercially available UX designs for hybrid meetings"
            ],
            "Analysis": [
              "<NONE>"
            ],
            "Challenge": [
              "<NONE>"
            ],
            "Ethical": [
              "<NONE>"
            ],
            "Implications": [
              "what is the broader significance or potential for future applications/research?"
            ],
            "Contradictions": [
              "<NONE>"
            ]
          }
        },
        {
          "Results/Findings": "",
          "Text": "Results from this study revealed key benefits of Perspectives, including supporting natural interactions, creating a strong sense of co-presence, and reducing cognitive load. Results from the study also helped iterate on the design principles of Perspectives, which offer important insights on supporting hybrid meetings.",
          "Main Action": "revealed",
          "Arguments": {
            "Agent": [
              "this study"
            ],
            "Object": {
              "Primary Object": [
                "key benefits of Perspectives"
              ],
              "Secondary Object": [
                "<NONE>"
              ]
            },
            "Context": [
              "including supporting natural interactions, creating a strong sense of co-presence, and reducing cognitive load"
            ],
            "Purpose": [
              "<NONE>"
            ],
            "Method": [
              "<NONE>"
            ],
            "Results": [
              "Results from the study"
            ],
            "Analysis": [
              "<NONE>"
            ],
            "Challenge": [
              "which offer important insights on supporting hybrid meetings"
            ],
            "Ethical": [
              "<NONE>"
            ],
            "Implications": [
              "<NONE>"
            ],
            "Contradictions": [
              "<NONE>"
            ]
          }
        }
      ]
    }
  ]
}