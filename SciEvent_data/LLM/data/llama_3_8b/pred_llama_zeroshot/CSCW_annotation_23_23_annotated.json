{
  "papers": [
    {
      "paper_code": "cscw_23_P_256",
      "abstract": "Artificial intelligence (AI) is increasingly being considered to assist human decision-making in high-stake domains (e.g., health). However, researchers have discussed an issue that humans can over-rely on wrong suggestions of the AI model instead of achieving human-AI complementary performance. In this work, we utilized salient feature explanations along with what-if, counterfactual explanations to make humans review AI suggestions more analytically to reduce overreliance on AI and explored the effect of these explanations on trust and reliance on AI during clinical decision-making. We conducted an experiment with seven therapists and ten laypersons on the task of assessing post-stroke survivors' quality of motion, and analyzed their performance, agreement level on the task, and reliance on AI without and with two types of AI explanations. Our results showed that the AI model with both salient features and counterfactual explanations assisted therapists and laypersons to improve their performance and agreement level on the task when 'right' AI outputs are presented. While both therapists and laypersons over-relied on 'wrong' AI outputs, counterfactual explanations assisted both therapists and laypersons to reduce their over-reliance on 'wrong' AI outputs by 21% compared to salient feature explanations. Specifically, laypersons had higher performance degrades by 18.0 f1-score with salient feature explanations and 14.0 f1-score with counterfactual explanations than therapists with performance degrades of 8.6 and 2.8 f1-scores respectively. Our work discusses the potential of counterfactual explanations to better estimate the accuracy of an AI model and reduce over-reliance on 'wrong' AI outputs and implications for improving human-AI collaborative decision-making.",
      "events": [
        {
          "Background/Introduction": "",
          "Text": "Artificial intelligence (AI) is increasingly being considered to assist human decision-making in high-stake domains (e.g., health). However, researchers have discussed an issue that humans can over-rely on wrong suggestions of the AI model instead of achieving human-AI complementary performance.",
          "Main Action": "have discussed",
          "Arguments": {
            "Agent": [
              "researchers"
            ],
            "Object": {
              "Primary Object": [
                "an issue"
              ],
              "Primary Modifier": [
                "<NONE>"
              ],
              "Secondary Object": [
                "<NONE>"
              ],
              "Secondary Modifier": [
                "<NONE>"
              ]
            },
            "Context": [
              "humans can over-rely on wrong suggestions of the AI model instead of achieving human-AI complementary performance"
            ],
            "Purpose": [
              "<NONE>"
            ],
            "Method": [
              "<NONE>"
            ],
            "Results": [
              "<NONE>"
            ],
            "Analysis": [
              "<NONE>"
            ],
            "Challenge": [
              "over-reliance on wrong suggestions"
            ],
            "Ethical": [
              "<NONE>"
            ],
            "Implications": [
              "<NONE>"
            ],
            "Contradictions": [
              "<NONE>"
            ]
          }
        },
        {
          "Methods/Approach": "",
          "Text": "In this work, we utilized salient feature explanations along with what-if, counterfactual explanations to make humans review AI suggestions more analytically to reduce overreliance on AI and explored the effect of these explanations on trust and reliance on AI during clinical decision-making. We conducted an experiment with seven therapists and ten laypersons on the task of assessing post-stroke survivors' quality of motion, and analyzed their performance, agreement level on the task, and reliance on AI without and with two types of AI explanations.",
          "Main Action": "utilized",
          "Arguments": {
            "Agent": [
              "we"
            ],
            "Object": {
              "Primary Object": [
                "salient feature explanations along with what-if, counterfactual explanations"
              ],
              "Primary Modifier": [
                "<NONE>"
              ],
              "Secondary Object": [
                "AI suggestions"
              ],
              "Secondary Modifier": [
                "<NONE>"
              ]
            },
            "Context": [
              "to make humans review AI suggestions more analytically to reduce overreliance on AI and explored the effect of these explanations on trust and reliance on AI during clinical decision-making"
            ],
            "Purpose": [
              "reduce overreliance on AI"
            ],
            "Method": [
              "conducted an experiment with seven therapists and ten laypersons on the task of assessing post-stroke survivors' quality of motion"
            ],
            "Results": [
              "analyzed their performance, agreement level on the task, and reliance on AI without and with two types of AI explanations"
            ],
            "Analysis": [
              "<NONE>"
            ],
            "Challenge": [
              "<NONE>"
            ],
            "Ethical": [
              "<NONE>"
            ],
            "Implications": [
              "during clinical decision-making"
            ],
            "Contradictions": [
              "<NONE>"
            ]
          }
        },
        {
          "Results/Findings": "",
          "Text": "Our results showed that the AI model with both salient features and counterfactual explanations assisted therapists and laypersons to improve their performance and agreement level on the task when 'right' AI outputs are presented. While both therapists and laypersons over-relied on 'wrong' AI outputs, counterfactual explanations assisted both therapists and laypersons to reduce their over-reliance on 'wrong' AI outputs by 21% compared to salient feature explanations. Specifically, laypersons had higher performance degrades by 18.0 F1-score with salient feature explanations and 14.0 F1-score with counterfactual explanations than therapists with performance degrades of 8.6 and 2.8 F1-scores respectively.",
          "Main Action": "'assisted'",
          "Arguments": {
            "Agent": [
              "therapists and laypersons"
            ],
            "Object": {
              "Primary Object": [
                "to improve their performance and agreement level on the task"
              ],
              "Primary Modifier": [
                "<NONE>"
              ],
              "Secondary Object": [
                "when right AI outputs are presented"
              ],
              "Secondary Modifier": [
                "<NONE>"
              ]
            },
            "Context": [
              "The AI model with both salient features and counterfactual explanations"
            ],
            "Purpose": [
              "improve their performance and agreement level on the task"
            ],
            "Method": [
              "salient feature explanations and counterfactual explanations"
            ],
            "Results": [
              "reduce their over-reliance on wrong AI outputs by 21%"
            ],
            "Analysis": [
              "counterfactual explanations assisted both therapists and laypersons"
            ],
            "Challenge": [
              "over-reliance on wrong AI outputs"
            ],
            "Ethical": [
              "<NONE>"
            ],
            "Implications": [
              "higher performance degrade"
            ],
            "Contradictions": [
              "<NONE>"
            ]
          }
        },
        {
          "Conclusions/Implications": "",
          "Text": "Our work discusses the potential of counterfactual explanations to better estimate the accuracy of an AI model and reduce over-reliance on 'wrong' AI outputs and implications for improving human-AI collaborative decision-making.",
          "Main Action": "discusses",
          "Arguments": {
            "Agent": [
              "our work"
            ],
            "Object": {
              "Primary Object": [
                "potential of counterfactual explanations"
              ],
              "Primary Modifier": [
                "<NONE>"
              ],
              "Secondary Object": [
                "better estimate the accuracy of an AI model"
              ],
              "Secondary Modifier": [
                "<NONE>"
              ]
            },
            "Context": [
              "to better estimate the accuracy of an AI model and reduce over-reliance on 'wrong' AI outputs and implications for improving human-AI collaborative decision-making."
            ],
            "Purpose": [
              "improving human-AI collaborative decision-making"
            ],
            "Method": [
              "<NONE>"
            ],
            "Results": [
              "<NONE>"
            ],
            "Analysis": [
              "<NONE>"
            ],
            "Challenge": [
              "<NONE>"
            ],
            "Ethical": [
              "<NONE>"
            ],
            "Implications": [
              "for improving human-AI collaborative decision-making"
            ],
            "Contradictions": [
              "<NONE>"
            ]
          }
        }
      ]
    },
    {
      "paper_code": "cscw_23_P_229",
      "abstract": "Prison and police abolition has become a major political philosophy in North American discourse following the 2020 George Floyd protests. The philosophy remains divisive, and North American abolitionists seeking to coalition-build, provide resources for vulnerable populations, and garner public support continue to experience challenges. We explore current usage of digital tools among abolitionists and the potential of a digital mapping tool to address these challenges. We conduct an interview study with 15 abolitionist organizations to understand activists' perspectives on the value of digital tools for organizing and a content analysis of 25 existing digital tools that convey abolitionist ideas to the public. Our findings together reveal (1) opportunities for digital mapping and HCI to support abolitionist activism and grassroots activism more broadly and (2) the challenges of digitally and spatially representing a movement that is intentionally grassroots, clandestine, and often involves organizers working in disparate locations.",
      "events": [
        {
          "Background/Introduction": "",
          "Text": "Prison and police abolition has become a major political philosophy in North American discourse following the 2020 George Floyd protests. The philosophy remains divisive, and North American abolitionists seeking to coalition-build, provide resources for vulnerable populations, and garner public support continue to experience challenges.",
          "Main Action": "continue",
          "Arguments": {
            "Agent": [
              "North American abolitionists"
            ],
            "Object": {
              "Primary Object": [
                "coalition-building"
              ],
              "Primary Modifier": [
                "<NONE>"
              ],
              "Secondary Object": [
                "provide resources for vulnerable populations",
                "garner public support"
              ],
              "Secondary Modifier": [
                "<NONE>"
              ]
            },
            "Context": [
              "The philosophy remains divisive, and..."
            ],
            "Purpose": [
              "seeking to...",
              "provide resources for vulnerable populations",
              "garner public support"
            ],
            "Method": [
              "<NONE>"
            ],
            "Results": [
              "<NONE>"
            ],
            "Analysis": [
              "<NONE>"
            ],
            "Challenge": [
              "experience challenges"
            ],
            "Ethical": [
              "<NONE>"
            ],
            "Implications": [
              "<NONE>"
            ],
            "Contradictions": [
              "<NONE>"
            ]
          }
        },
        {
          "Methods/Approach": "",
          "Text": "We explore current usage of digital tools among abolitionists and the potential of a digital mapping tool to address these challenges. We conduct an interview study with 15 abolitionist organizations to understand activists' perspectives on the value of digital tools for organizing and a content analysis of 25 existing digital tools that convey abolitionist ideas to the public.",
          "Main Action": "conduct",
          "Arguments": {
            "Agent": [
              "we"
            ],
            "Object": {
              "Primary Object": [
                "an interview study"
              ],
              "Primary Modifier": [
                "<NONE>"
              ],
              "Secondary Object": [
                "with 15 abolitionist organizations"
              ],
              "Secondary Modifier": [
                "<NONE>"
              ]
            },
            "Context": [
              "to understand activists' perspectives on the value of digital tools for organizing and a content analysis of 25 existing digital tools that convey abolitionist ideas to the public."
            ],
            "Purpose": [
              "to understand activists' perspectives on the value of digital tools for organizing"
            ],
            "Method": [
              "interview study",
              "content analysis"
            ],
            "Results": [
              "<NONE>"
            ],
            "Analysis": [
              "<NONE>"
            ],
            "Challenge": [
              "<NONE>"
            ],
            "Ethical": [
              "<NONE>"
            ],
            "Implications": [
              "addressing challenges"
            ],
            "Contradictions": [
              "<NONE>"
            ]
          }
        },
        {
          "Results/Findings": "",
          "Text": "Our findings together reveal (1) opportunities for digital mapping and HCI to support abolitionist activism and grassroots activism more broadly and (2) the challenges of digitally and spatially representing a movement that is intentionally grassroots, clandestine, and often involves organizers working in disparate locations.",
          "Main Action": "reveal",
          "Arguments": {
            "Agent": [
              "findings"
            ],
            "Object": {
              "Primary Object": [
                "opportunities for digital mapping and HCI to support abolitionist activism and grassroots activism more broadly"
              ],
              "Primary Modifier": [
                "<NONE>"
              ],
              "Secondary Object": [
                "challenges of digitally and spatially representing a movement"
              ],
              "Secondary Modifier": [
                "<NONE>"
              ]
            },
            "Context": [
              "a movement that is intentionally grassroots, clandestine, and often involves organizers working in disparate locations"
            ],
            "Purpose": [
              "supporting abolitionist activism and grassroots activism more broadly"
            ],
            "Method": [
              "<NONE>"
            ],
            "Results": [
              "(1) opportunities...and (2) the challenges..."
            ],
            "Analysis": [
              "<NONE>"
            ],
            "Challenge": [
              "the challenges"
            ],
            "Ethical": [
              "<NONE>"
            ],
            "Implications": [
              "for supporting abolitionist activism and grassroots activism more broadly"
            ],
            "Contradictions": [
              "<NONE>"
            ]
          }
        }
      ]
    }
  ]
}