{
  "papers": [
    {
      "paper_code": "ACL_23_P_160",
      "abstract": "Methods to generate text from structured data have advanced significantly in recent years, primarily due to fine-tuning of pre-trained language models on large datasets. However, such models can fail to produce output faithful to the input data, particularly on out-of-domain data. Sufficient annotated data is often not available for specific domains, leading us to seek an unsupervised approach to improve the faithfulness of output text. Since the problem is fundamentally one of consistency between the representations of the structured data and text, we evaluate the effectiveness of cycle training in this work. Cycle training uses two models which are inverses of each other: one that generates text from structured data, and one which generates the structured data from natural language text. We show that cycle training, when initialized with a small amount of supervised data (100 samples in our case), achieves nearly the same performance as fully supervised approaches for the data-to-text generation task on the WebNLG, E2E, WTQ, and WSQL datasets. We perform extensive empirical analysis with automated evaluation metrics and a newly designed human evaluation schema to reveal different cycle training strategies’ effectiveness of reducing various types of generation errors.",
      "events": [
        {
          "Background/Introduction": "",
          "Text": "Methods to generate text from structured data have advanced significantly in recent years, primarily due to fine-tuning of pre-trained language models on large datasets. However, such models can fail to produce output faithful to the input data, particularly on out-of-domain data. Sufficient annotated data is often not available for specific domains, leading us to seek an unsupervised approach to improve the faithfulness of output text.",
          "Main Action": "seek",
          "Arguments": {
            "Agent": [
              "us"
            ],
            "Object": {
              "Primary Object": [
                "an unsupervised approach"
              ],
              "Primary Modifier": [
                "<NONE>"
              ],
              "Secondary Object": [
                "to improve the faithfulness of output text"
              ],
              "Secondary Modifier": [
                "<NONE>"
              ]
            },
            "Context": [
              "However, such models can fail to produce output faithful to the input data, particularly on out-of-domain data."
            ],
            "Purpose": [
              "improve the faithfulness of output text"
            ],
            "Method": [
              "unsupervised approach"
            ],
            "Results": [
              "<NONE>"
            ],
            "Analysis": [
              "<NONE>"
            ],
            "Challenge": [
              "sufficient annotated data is often not available for specific domains"
            ],
            "Ethical": [
              "<NONE>"
            ],
            "Implications": [
              "leading to seek an unsupervised approach"
            ],
            "Contradictions": [
              "<NONE>"
            ]
          }
        },
        {
          "Methods/Approach": "",
          "Text": "Since the problem is fundamentally one of consistency between the representations of the structured data and text, we evaluate the effectiveness of cycle training in this work. Cycle training uses two models which are inverses of each other: one that generates text from structured data, and one which generates the structured data from natural language text.",
          "Main Action": "evaluate",
          "Arguments": {
            "Agent": [
              "we"
            ],
            "Object": {
              "Primary Object": [
                "effectiveness of cycle training"
              ],
              "Primary Modifier": [
                "<NONE>"
              ],
              "Secondary Object": [
                "<NONE>"
              ],
              "Secondary Modifier": [
                "<NONE>"
              ]
            },
            "Context": [
              "problem of consistency between the representations of the structured data and text"
            ],
            "Purpose": [
              "to evaluate the effectiveness of cycle training"
            ],
            "Method": [
              "cycle training using two models which are inverses of each other"
            ],
            "Results": [
              "<NONE>"
            ],
            "Analysis": [
              "<NONE>"
            ],
            "Challenge": [
              "<NONE>"
            ],
            "Ethical": [
              "<NONE>"
            ],
            "Implications": [
              "<NONE>"
            ],
            "Contradictions": [
              "<NONE>"
            ]
          }
        },
        {
          "Results/Findings": "",
          "Text": "We show that cycle training, when initialized with a small amount of supervised data (100 samples in our case), achieves nearly the same performance as fully supervised approaches for the data-to-text generation task on the WebNLG, E2E, WTQ, and WSQL datasets. We perform extensive empirical analysis with automated evaluation metrics and a newly designed human evaluation schema to reveal different cycle training strategies’ effectiveness of reducing various types of generation errors.",
          "Main Action": "show",
          "Arguments": {
            "Agent": [
              "we"
            ],
            "Object": {
              "Primary Object": [
                "cycle training"
              ],
              "Primary Modifier": [
                "<NONE>"
              ],
              "Secondary Object": [
                "supervised data",
                "datasets"
              ],
              "Secondary Modifier": [
                "<NONE>"
              ]
            },
            "Context": [
              "with automated evaluation metrics",
              "a newly designed human evaluation schema"
            ],
            "Purpose": [
              "to reveal different cycle training strategies' effectiveness"
            ],
            "Method": [
              "extensive empirical analysis"
            ],
            "Results": [
              "nearly the same performance as fully supervised approaches"
            ],
            "Analysis": [
              "reducing various types of generation errors"
            ],
            "Challenge": [
              "<NONE>"
            ],
            "Ethical": [
              "<NONE>"
            ],
            "Implications": [
              "for the data-to-text generation task"
            ],
            "Contradictions": [
              "<NONE>"
            ]
          }
        }
      ]
    },
    {
      "paper_code": "ACL_23_P_668",
      "abstract": "Health-related speech datasets are often small and varied in focus. This makes it difficult to leverage them to effectively support healthcare goals. Robust transfer of linguistic features across different datasets orbiting the same goal carries potential to address this concern. To test this hypothesis, we experiment with domain adaptation (DA) techniques on heterogeneous spoken language data to evaluate generalizability across diverse datasets for a common task: dementia detection. We find that adapted models exhibit better performance across conversational and task-oriented datasets. The feature-augmented DA method achieves a 22% increase in accuracy adapting from a conversational to task-specific dataset compared to a jointly trained baseline. This suggests promising capacity of these techniques to allow for productive use of disparate data for a complex spoken language healthcare task.",
      "events": [
        {
          "Background/Introduction": "",
          "Text": "Health-related speech datasets are often small and varied in focus. This makes it difficult to leverage them to effectively support healthcare goals. Robust transfer of linguistic features across different datasets orbiting the same goal carries potential to address this concern.",
          "Main Action": "carries",
          "Arguments": {
            "Agent": [
              "Robust transfer"
            ],
            "Object": {
              "Primary Object": [
                "linguistic features"
              ],
              "Primary Modifier": [
                "<NONE>"
              ],
              "Secondary Object": [
                "different datasets"
              ],
              "Secondary Modifier": [
                "<NONE>"
              ]
            },
            "Context": [
              "This makes it difficult to leverage them to effectively support healthcare goals."
            ],
            "Purpose": [
              "address this concern"
            ],
            "Method": [
              "<NONE>"
            ],
            "Results": [
              "<NONE>"
            ],
            "Analysis": [
              "<NONE>"
            ],
            "Challenge": [
              "<NONE>"
            ],
            "Ethical": [
              "<NONE>"
            ],
            "Implications": [
              "to address this concern"
            ],
            "Contradictions": [
              "<NONE>"
            ]
          }
        },
        {
          "Methods/Approach": "",
          "Text": "To test this hypothesis, we experiment with domain adaptation (DA) techniques on heterogeneous spoken language data to evaluate generalizability across diverse datasets for a common task: dementia detection.",
          "Main Action": "experiment",
          "Arguments": {
            "Agent": [
              "we"
            ],
            "Object": {
              "Primary Object": [
                "domain adaptation (DA) techniques"
              ],
              "Primary Modifier": [
                "<NONE>"
              ],
              "Secondary Object": [
                "heterogeneous spoken language data"
              ],
              "Secondary Modifier": [
                "<NONE>"
              ]
            },
            "Context": [
              "to evaluate generalizability across diverse datasets for a common task"
            ],
            "Purpose": [
              "dementia detection"
            ],
            "Method": [
              "domain adaptation (DA) techniques"
            ],
            "Results": [
              "<NONE>"
            ],
            "Analysis": [
              "<NONE>"
            ],
            "Challenge": [
              "<NONE>"
            ],
            "Ethical": [
              "<NONE>"
            ],
            "Implications": [
              "for a common task"
            ],
            "Contradictions": [
              "<NONE>"
            ]
          }
        },
        {
          "Results/Findings": "",
          "Text": "We find that adapted models exhibit better performance across conversational and task-oriented datasets. The feature-augmented DA method achieves a 22% increase in accuracy adapting from a conversational to task-specific dataset compared to a jointly trained baseline.",
          "Main Action": "achieves",
          "Arguments": {
            "Agent": [
              "The feature-augmented DA method"
            ],
            "Object": {
              "Primary Object": [
                "a 22% increase in accuracy"
              ],
              "Primary Modifier": [
                "<NONE>"
              ],
              "Secondary Object": [
                "adaptating from a conversational to task-specific dataset"
              ],
              "Secondary Modifier": [
                "<NONE>"
              ]
            },
            "Context": [
              "compared to a jointly trained baseline"
            ],
            "Purpose": [
              "to adapt from a conversational to task-specific dataset"
            ],
            "Method": [
              "feature-augmented DA method"
            ],
            "Results": [
              "a 22% increase in accuracy"
            ],
            "Analysis": [
              "<NONE>"
            ],
            "Challenge": [
              "<NONE>"
            ],
            "Ethical": [
              "<NONE>"
            ],
            "Implications": [
              "for future applications/research"
            ],
            "Contradictions": [
              "<NONE>"
            ]
          }
        },
        {
          "Conclusions/Implications": "",
          "Text": "This suggests promising capacity of these techniques to allow for productive use of disparate data for a complex spoken language healthcare task.",
          "Main Action": "allow",
          "Arguments": {
            "Agent": [
              "these techniques"
            ],
            "Object": {
              "Primary Object": [
                "productive use of disparate data"
              ],
              "Primary Modifier": [
                "<NONE>"
              ],
              "Secondary Object": [
                "a complex spoken language healthcare task"
              ],
              "Secondary Modifier": [
                "<NONE>"
              ]
            },
            "Context": [
              "for a complex spoken language healthcare task"
            ],
            "Purpose": [
              "to allow for productive use"
            ],
            "Method": [
              "these techniques"
            ],
            "Results": [
              "promising capacity"
            ],
            "Analysis": [
              "<NONE>"
            ],
            "Challenge": [
              "<NONE>"
            ],
            "Ethical": [
              "<NONE>"
            ],
            "Implications": [
              "future use"
            ],
            "Contradictions": [
              "<NONE>"
            ]
          }
        }
      ]
    }
  ]
}