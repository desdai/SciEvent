{
  "papers": [
    {
      "paper_code": "ACL_23_P_34",
      "abstract": "Large language models (LLMs) can be used to generate text data for training and evaluating other models. However, creating high-quality datasets with LLMs can be challenging. In this work, we explore human-AI partnerships to facilitate high diversity and accuracy in LLM-based text data generation. We first examine two approaches to diversify text generation: 1) logit suppression, which minimizes the generation of languages that have already been frequently generated, and 2) temperature sampling, which flattens the token sampling probability. We found that diversification approaches can increase data diversity but often at the cost of data accuracy (i.e., text and labels being appropriate for the target domain). To address this issue, we examined two human interventions, 1) label replacement (LR), correcting misaligned labels, and 2) out-of-scope filtering (OOSF), removing instances that are out of the user’s domain of interest or to which no considered label applies. With oracle studies, we found that LR increases the absolute accuracy of models trained with diversified datasets by 14.4%. Moreover, we found that some models trained with data generated with LR interventions outperformed LLM-based few-shot classification. In contrast, OOSF was not effective in increasing model accuracy, implying the need for future work in human-in-the-loop text data generation.",
      "events": [
        {
          "Background/Introduction": "",
          "Text": "Large language models (LLMs) can be used to generate text data for training and evaluating other models. However, creating high-quality datasets with LLMs can be challenging.",
          "Main Action": "<NONE>",
          "Arguments": {
            "Agent": [
              "<NONE>"
            ],
            "Object": {
              "Primary Object": [
                "<NONE>"
              ],
              "Secondary Object": [
                "<NONE>"
              ]
            },
            "Context": [
              "However,",
              "creating"
            ],
            "Purpose": [
              "can be challenging."
            ],
            "Method": [
              "using Large language models (LLMs)",
              "to generate text data"
            ],
            "Results": [
              "<NONE>"
            ],
            "Analysis": [
              "<NONE>"
            ],
            "Challenge": [
              "High-quality datasets"
            ],
            "Ethical": [
              "<NONE>"
            ],
            "Implications": [
              "<NONE>"
            ],
            "Contradictions": [
              "<NONE>"
            ]
          }
        },
        {
          "Methods/Approach": "",
          "Text": "In this work, we explore human-AI partnerships to facilitate high diversity and accuracy in LLM-based text data generation. We first examine two approaches to diversify text generation: 1) logit suppression, which minimizes the generation of languages that have already been frequently generated, and 2) temperature sampling, which flattens the token sampling probability. We found that diversification approaches can increase data diversity but often at the cost of data accuracy (i.e., text and labels being appropriate for the target domain). To address this issue, we examined two human interventions, 1) label replacement (LR), correcting misaligned labels, and 2) out-of-scope filtering (OOSF), removing instances that are out of the user’s domain of interest or to which no considered label applies.",
          "Main Action": "We",
          "Arguments": {
            "Agent": [
              "<NAME>"
            ],
            "Object": {
              "Primary Object": [
                "<NONE>"
              ],
              "Secondary Object": [
                "<NONE>"
              ]
            },
            "Context": [
              "human-AI",
              "partnerships",
              "to",
              "facilitate",
              "high",
              "diversity",
              "and",
              "accuracy",
              "in",
              "LLM-based",
              "text",
              "data",
              "generation."
            ],
            "Purpose": [
              "To",
              "address",
              "this",
              "issue,"
            ],
            "Method": [
              "logit",
              "suppression",
              "which",
              "minimizes",
              "the",
              "generation",
              "of",
              "languages",
              "that",
              "have",
              "already",
              "been",
              "frequently",
              "generated,"
            ],
            "Results": [
              "we",
              "found",
              "that",
              "diversification",
              "approaches",
              "can",
              "increase",
              "data",
              "diversity",
              "but",
              "often",
              "at",
              "the",
              "cost",
              "of",
              "data",
              "accuracy"
            ],
            "Analysis": [
              "(i.e.,",
              "text",
              "and",
              "labels",
              "being",
              "appropriate",
              "for",
              "the",
              "target",
              "domain)"
            ],
            "Challenge": [
              "increasing",
              "data",
              "diversity",
              "while",
              "maintaining",
              "data",
              "accuracy"
            ],
            "Ethical": [
              "<NONE>"
            ],
            "Implications": [
              "This",
              "study",
              "has",
              "implications",
              "for",
              "future",
              "research",
              "on",
              "AI-assisted",
              "content",
              "creation.",
              "It",
              "also",
              "suggests",
              "ways",
              "to",
              "evaluate",
              "the",
              "quality",
              "of",
              "machine-generated",
              "content."
            ],
            "Contradictions": [
              "<NONE>"
            ]
          }
        },
        {
          "Results/Findings": "",
          "Text": "With oracle studies, we found that LR increases the absolute accuracy of models trained with diversified datasets by 14.4%. Moreover, we found that some models trained with data generated with LR interventions outperformed LLM-based few-shot classification. In contrast, OOSF was not effective in increasing model accuracy, implying the need for future work in human-in-the-loop text data generation.",
          "Main Action": "found",
          "Arguments": {
            "Agent": [
              "we"
            ],
            "Object": {
              "Primary Object": [
                "<NONE>"
              ],
              "Secondary Object": [
                "<NONE>"
              ]
            },
            "Context": [
              "oracle studies",
              "LR increases the absolute accuracy of models trained with diversified datasets by 14.4%"
            ],
            "Purpose": [
              "<NONE>"
            ],
            "Method": [
              "diversified datasets",
              "data generated with LR interventions"
            ],
            "Results": [
              "some models trained with data generated with LR interventions outperformed LLM-based few-shot classification"
            ],
            "Analysis": [
              "<NONE>"
            ],
            "Challenge": [
              "OOSF was not effective in increasing model accuracy"
            ],
            "Ethical": [
              "<NONE>"
            ],
            "Implications": [
              "implying the need for future work in human-in-the-loop text data generation"
            ],
            "Contradictions": [
              "<NONE>"
            ]
          }
        }
      ]
    },
    {
      "paper_code": "ACL_23_P_823",
      "abstract": "Existing research on multimodal relation extraction (MRE) faces two co-existing challenges, internal-information over-utilization and external-information under-exploitation. To combat that, we propose a novel framework that simultaneously implements the idea of internal-information screening and external-information exploiting. First, we represent the fine-grained semantic structures of the input image and text with the visual and textual scene graphs, which are further fused into a unified cross-modal graph (CMG). Based on CMG, we perform structure refinement with the guidance of the graph information bottleneck principle, actively denoising the less-informative features. Next, we perform topic modeling over the input image and text, incorporating latent multimodal topic features to enrich the contexts. On the benchmark MRE dataset, our system outperforms the current best model significantly. With further in-depth analyses, we reveal the great potential of our method for the MRE task.",
      "events": [
        {
          "Background/Introduction": "",
          "Text": "Existing research on multimodal relation extraction (MRE) faces two co-existing challenges, internal-information over-utilization and external-information under-exploitation.",
          "Main Action": "<NONE>",
          "Arguments": {
            "Agent": [
              "<NONE>"
            ],
            "Object": {
              "Primary Object": [
                "<NONE>"
              ],
              "Secondary Object": [
                "<NONE>"
              ]
            },
            "Context": [
              "existing research on multimodal relation extraction (MRE) faces two co-existing challenges,"
            ],
            "Purpose": [
              "to address these challenges"
            ],
            "Method": [
              "<NONE>"
            ],
            "Results": [
              "<NONE>"
            ],
            "Analysis": [
              "<NONE>"
            ],
            "Challenge": [
              "internal-information over-utilization and external-information under-exploitation"
            ],
            "Ethical": [
              "<NONE>"
            ],
            "Implications": [
              "<NONE>"
            ],
            "Contradictions": [
              "<NONE>"
            ]
          }
        },
        {
          "Methods/Approach": "",
          "Text": "To combat that, we propose a novel framework that simultaneously implements the idea of internal-information screening and external-information exploiting. First, we represent the fine-grained semantic structures of the input image and text with the visual and textual scene graphs, which are further fused into a unified cross-modal graph (CMG). Based on CMG, we perform structure refinement with the guidance of the graph information bottleneck principle, actively denoising the less-informative features. Next, we perform topic modeling over the input image and text, incorporating latent multimodal topic features to enrich the contexts.",
          "Main Action": "propose",
          "Arguments": {
            "Agent": [
              "we"
            ],
            "Object": {
              "Primary Object": [
                "<NONE>"
              ],
              "Secondary Object": [
                "<NONE>"
              ]
            },
            "Context": [
              "combat that"
            ],
            "Purpose": [
              "novel framework that simultaneously implements the idea of internal-information screening and external-information exploiting."
            ],
            "Method": [
              "representing the fine-grained semantic structures of the input image and text with the visual and textual scene graphs,"
            ],
            "Results": [
              "<NONE>"
            ],
            "Analysis": [
              "<NONE>"
            ],
            "Challenge": [
              "<NONE>"
            ],
            "Ethical": [
              "<NONE>"
            ],
            "Implications": [
              "<NONE>"
            ],
            "Contradictions": [
              "<NONE>"
            ]
          }
        },
        {
          "Results/Findings": "",
          "Text": "On the benchmark MRE dataset, our system outperforms the current best model significantly. With further in-depth analyses, we reveal the great potential of our method for the MRE task.",
          "Main Action": "reveal",
          "Arguments": {
            "Agent": [
              "we"
            ],
            "Object": {
              "Primary Object": [
                "<NONE>"
              ],
              "Secondary Object": [
                "<NONE>"
              ]
            },
            "Context": [
              "great potential",
              "MRE task"
            ],
            "Purpose": [
              "<NONE>"
            ],
            "Method": [
              "<NONE>"
            ],
            "Results": [
              "the great potential of our method for the MRE task"
            ],
            "Analysis": [
              "<NONE>"
            ],
            "Challenge": [
              "<NONE>"
            ],
            "Ethical": [
              "<NONE>"
            ],
            "Implications": [
              "<NONE>"
            ],
            "Contradictions": [
              "<NONE>"
            ]
          }
        }
      ]
    }
  ]
}