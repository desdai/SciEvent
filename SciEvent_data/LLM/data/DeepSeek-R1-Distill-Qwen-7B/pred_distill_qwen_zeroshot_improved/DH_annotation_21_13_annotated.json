{
  "papers": [
    {
      "paper_code": "dh_21_P_34",
      "abstract": "Over the past decade, podcasting has grown into one of the most important media forms in the world. This article argues that podcasting’s unique technical affordances — particularly RSS feeds and user-entered metadata — open up productive methods for exploring the cultural practices and meanings of the medium. We share three different methods for studying RSS feeds and podcast metadata: 1) visualizing how topics and keywords trend over time; 2) visualizing networks of commonly associated keywords entered by podcasters; and 3) analyzing norms and common practices for the duration of podcasts (as a time-based media format, podcasting is unusual in that it is not bound by the programming schedules and technical limitations that provide strict parameters for most audiovisual forms). The methods and preliminary results reveal how metadata can function as a surrogate for studying large collections of time-based media objects. Yet our study also shows that, when it comes to born digital media, the metadata are never fully separate from the objects they describe. We argue that future work in AV in DH needs to delineate between methods best suited for digitized media collections compared to those most appropriate for born digital media collections.",
      "events": [
        {
          "Background/Introduction": "",
          "Text": "Over the past decade, podcasting has grown into one of the most important media forms in the world. This article argues that podcasting’s unique technical affordances — particularly RSS feeds and user-entered metadata — open up productive methods for exploring the cultural practices and meanings of the medium.",
          "Main Action": "Argues",
          "Arguments": {
            "Agent": [
              "<NONE>"
            ],
            "Object": {
              "Primary Object": [
                "Podcasting's technical affordances"
              ],
              "Secondary Object": [
                "user-entered metadata"
              ]
            },
            "Context": [
              "Over the past decade, podcasting has grown into one of the most important media forms in the world.",
              "This article argues that podcasting’s unique technical affordances — particularly RSS feeds and user-entered metadata — open up productive methods for exploring the cultural practices and meanings of the medium."
            ],
            "Purpose": [
              "Demonstrates how podcasting's technical features enable meaningful cultural insights"
            ],
            "Method": [
              "Analyzes cultural practices through available data sources"
            ],
            "Results": [
              "Such exploratory processes yield new understandings of podcasting's role in shaping cultural narratives"
            ],
            "Analysis": [
              "Explores the intersection between technological advancements and cultural expression through podcasting"
            ],
            "Challenge": [
              "None specifically identified in this excerpt"
            ],
            "Ethical": [
              "Not addressed in this context"
            ],
            "Implications": [
              "Has the potential to influence interdisciplinary research linking technology and culture"
            ],
            "Contradictions": [
              "None presented in this discussion"
            ]
          }
        },
        {
          "Methods/Approach": "ERROR",
          "Text": "We share three different methods for studying RSS feeds and podcast metadata: 1) visualizing how topics and keywords trend over time; 2) visualizing networks of commonly associated keywords entered by podcasters; and 3) analyzing norms and common practices for the duration of podcasts (as a time-based media format, podcasting is unusual in that it is not bound by the programming schedules and technical limitations that provide strict parameters for most audiovisual forms).",
          "Main Action": "ERROR",
          "Arguments": {
            "Agent": [
              "ERROR"
            ],
            "Object": {
              "Primary Object": [
                "ERROR"
              ],
              "Secondary Object": [
                "ERROR"
              ]
            },
            "Context": [
              "ERROR"
            ],
            "Purpose": [
              "ERROR"
            ],
            "Method": [
              "ERROR"
            ],
            "Results": [
              "ERROR"
            ],
            "Analysis": [
              "ERROR"
            ],
            "Challenge": [
              "ERROR"
            ],
            "Ethical": [
              "ERROR"
            ],
            "Implications": [
              "ERROR"
            ],
            "Contradictions": [
              "ERROR"
            ]
          },
          "Error_Type": "NO_JSON_FOUND"
        },
        {
          "Results/Findings": "",
          "Text": "The methods and preliminary results reveal how metadata can function as a surrogate for studying large collections of time-based media objects. Yet our study also shows that, when it comes to born digital media, the metadata are never fully separate from the objects they describe.",
          "Main Action": "<NONE>",
          "Arguments": {
            "Agent": [
              "<NONE>"
            ],
            "Object": {
              "Primary Object": [
                "<NONE>"
              ],
              "Secondary Object": [
                "<NONE>"
              ]
            },
            "Context": [
              "This abstract segment analyzes how metadata functions",
              "as a surrogate for studying large collections of time-based media objects"
            ],
            "Purpose": [
              "To establish the role of metadata in representing born digital media",
              "To highlight the relationship between metadata and the objects they describe"
            ],
            "Method": [
              "Revealing how metadata can function as a surrogate",
              "Conducting preliminary studies on metadata characteristics"
            ],
            "Results": [
              "Our study reveals how metadata can function as a surrogate for studying large collections of time-based media objects.",
              "Yet our study also shows that, when it comes to born digital media, the metadata are never fully separate from the objects they describe."
            ],
            "Analysis": [
              "Interpreting the data leads us to conclude that metadata play dual roles in media representation.",
              "Analyzing the findings emphasizes the complexity inherent in metadata dependency structures."
            ],
            "Challenge": [
              "Identifying cases where metadata cannot disentangle themselves from represented objects presents difficulties.",
              "Ensuring robustness against such interdependencies requires innovative methodological approaches."
            ],
            "Ethical": [
              "No direct ethical concerns were addressed within this segment.",
              "Potential misinterpretation risks necessitate careful methodology review."
            ],
            "Implications": [
              "Understanding metadata roles opens doors to improved data handling practices.",
              "Recognizing metadata-over object links paves way for enhanced analytical frameworks."
            ],
            "Contradictions": [
              "None evident within this segment."
            ]
          }
        },
        {
          "Conclusions/Implications": "",
          "Text": "We argue that future work in AV in DH needs to delineate between methods best suited for digitized media collections compared to those most appropriate for born digital media collections.",
          "Main Action": "<NONE>",
          "Arguments": {
            "Agent": [
              "<NONE>"
            ],
            "Object": {
              "Primary Object": [
                "<NONE>"
              ],
              "Secondary Object": [
                "<NONE>"
              ]
            },
            "Context": [
              "We argue",
              "future work in AV in DH"
            ],
            "Purpose": [
              "advancing methodological understanding in AV/DH"
            ],
            "Method": [
              "various analytical techniques"
            ],
            "Results": [
              "distinguishing methods applicable to digitized versus born-digital media"
            ],
            "Analysis": [
              "argumentative position suggests a necessary task ahead"
            ],
            "Challenge": [
              "no challenges specified"
            ],
            "Ethical": [
              "ethical considerations such as representativeness across media formats haven't been touched upon in this excerpt"
            ],
            "Implications": [
              "broader impact potentially resulting from effective handling of diverse data sources"
            ],
            "Contradictions": [
              "none specified"
            ]
          }
        }
      ]
    },
    {
      "paper_code": "dh_21_P_36",
      "abstract": "This paper introduces Coleto, an automatic collation tool for the comparison of variant texts in English, German, or French, which separates edits from variant texts so that textual changes can be classified and contextualized. Coleto’s proposed methodology for the classification of edits in variants includes: major/minor expansion, major/minor condensation, changes to numbers and whitespace, and common orthographic features. From this classification schema, Coleto generates: an aligned table of edits in the variants, visualizations of the frequency of classified edits, and a visualization of edit density across the progression of the texts. As a sample use case, we present mixed-method analyses of Andy Weir’s science fiction bestseller, The Martian, aided by Coleto’s functions and generated outputs.",
      "events": [
        {
          "Background/Introduction": "ERROR",
          "Text": "This paper introduces Coleto, an automatic collation tool for the comparison of variant texts in English, German, or French, which separates edits from variant texts so that textual changes can be classified and contextualized.",
          "Main Action": "ERROR",
          "Arguments": {
            "Agent": [
              "ERROR"
            ],
            "Object": {
              "Primary Object": [
                "ERROR"
              ],
              "Secondary Object": [
                "ERROR"
              ]
            },
            "Context": [
              "ERROR"
            ],
            "Purpose": [
              "ERROR"
            ],
            "Method": [
              "ERROR"
            ],
            "Results": [
              "ERROR"
            ],
            "Analysis": [
              "ERROR"
            ],
            "Challenge": [
              "ERROR"
            ],
            "Ethical": [
              "ERROR"
            ],
            "Implications": [
              "ERROR"
            ],
            "Contradictions": [
              "ERROR"
            ]
          },
          "Error_Type": "NO_JSON_FOUND"
        },
        {
          "Methods/Approach": "",
          "Text": "Coleto’s proposed methodology for the classification of edits in variants includes: major/minor expansion, major/minor condensation, changes to numbers and whitespace, and common orthographic features. From this classification schema, Coleto generates: an aligned table of edits in the variants, visualizations of the frequency of classified edits, and a visualization of edit density across the progression of the texts. As a sample use case, we present mixed-method analyses of Andy Weir’s science fiction bestseller, The Martian, aided by Coleto’s functions and generated outputs.",
          "Main Action": "Coleto’s proposed methodology for the classification of edits in variants",
          "Arguments": {
            "Agent": [
              "Coleto’s methodology",
              "methods"
            ],
            "Object": {
              "Primary Object": [
                "classifies edits in variants",
                "various types"
              ],
              "Secondary Object": [
                "changes to numbers and whitespace",
                "common orthographic features"
              ]
            },
            "Context": [
              "From this classification schema, Coleto generates an aligned table of edits in the variants, visualizations of the frequency of classified edits, and a visualization of edit density across the progression of the texts."
            ],
            "Purpose": [
              "To develop a systematic way to analyze and compare textual variations across different versions of a text, providing insights into the nature and extent of editorial changes over time."
            ],
            "Method": [
              "Various computational techniques, tools, and frameworks such as categorization algorithms, visualization libraries, statistical measures, integration platforms, and modeling systems"
            ],
            "Results": [
              "An aligned table of edited variants, visual representations showing the frequency distribution of categorized edits, and graphical displays illustrating the spatial variation of edits across text progressions."
            ],
            "Analysis": [
              "Insights into patterns of change, identification of significant shifts in writing style or narrative focus, assessment of consistency in editorial practices across sections of the text."
            ],
            "Challenge": [
              "Potential limitations regarding scalability for very large corpora, complexity of interpreting high-dimensional data visualizations, reliance on domain-specific expertise for contextual understanding of the textual material."
            ],
            "Ethical": [
              "None reported"
            ],
            "Implications": [
              "Advances in computational literary studies, enhanced capabilities for digital humanities projects examining textual evolution, improved methodologies for authorship attribution and stylistic analysis."
            ],
            "Contradictions": [
              "None identified"
            ]
          }
        }
      ]
    }
  ]
}