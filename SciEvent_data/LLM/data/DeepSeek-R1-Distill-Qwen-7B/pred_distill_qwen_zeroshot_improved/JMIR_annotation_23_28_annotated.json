{
  "papers": [
    {
      "paper_code": "jmir_23_P_165",
      "abstract": "Digital mindfulness-based interventions (MBIs) are a promising approach to deliver accessible and scalable mindfulness training and have been shown to improve a range of health outcomes. However, the success of digital MBIs is reliant on adequate engagement, which remains a crucial challenge. Understanding people’s experiences of using digital MBIs and identifying the core factors that facilitate or act as barriers to engagement is essential to inform intervention development and maximize engagement and outcomes. This study aims to systematically map the literature on people’s experiences of using digital MBIs that target psychosocial variables (e.g., anxiety, depression, distress, and well-being) and identify key barriers to and facilitators of engagement. We conducted a scoping review to synthesize empirical qualitative research on people’s experiences of using digital MBIs. We adopted a streamlined approach to ensure that the evidence could be incorporated into the early stages of intervention development. The search strategy identified articles with at least one keyword related to mindfulness, digital, user experience, and psychosocial variables in their title or abstract. Inclusion criteria specified that articles must have a qualitative component, report on participants’ experiences of using a digital MBI designed to improve psychosocial variables, and have a sample age range that at least partially overlapped with 16 to 35 years. Qualitative data on user experience were charted and analyzed using inductive thematic synthesis to generate understandings that go beyond the content of the original studies. We used the Quality of Reporting Tool to critically appraise the included sources of evidence. The search identified 530 studies, 22 (4.2%) of which met the inclusion criteria. Overall, the samples were approximately 78% female and 79% White; participants were aged between 16 and 69 years; and the most used measures in intervention studies were mindfulness, psychological flexibility, and variables related to mental health (including depression, anxiety, stress, and well-being). All studies were judged to be adequately reported. We identified 3 themes characterizing barriers to and facilitators of engagement: responses to own practice (i.e., negative reactions to one’s own practice are common and can deplete motivation), making mindfulness a habit (i.e., creating a consistent training routine is essential yet challenging), and leaning on others (i.e., those engaging depend on someone else for support). The themes identified in this review provide crucial insights as to why people frequently stop engaging with digital MBIs. Researchers and developers should consider using person-based coparticipatory methods to improve acceptability of and engagement with digital MBIs, increase their effectiveness, and support their translation to real-world use. Such strategies must be grounded in relevant literature and meet the priorities and needs of the individuals who will use the interventions.",
      "events": [
        {
          "Background/Introduction": "",
          "Text": "Digital mindfulness-based interventions (MBIs) are a promising approach to deliver accessible and scalable mindfulness training and have been shown to improve a range of health outcomes. However, the success of digital MBIs is reliant on adequate engagement, which remains a crucial challenge. Understanding people’s experiences of using digital MBIs and identifying the core factors that facilitate or act as barriers to engagement is essential to inform intervention development and maximize engagement and outcomes.",
          "Main Action": "Understanding people’s experiences",
          "Arguments": {
            "Agent": [
              "people’s experiences"
            ],
            "Object": {
              "Primary Object": [
                "understanding factors that facilitate or act as barriers to engagement"
              ],
              "Secondary Object": [
                "engagement itself"
              ]
            },
            "Context": [
              "using digital MBIs"
            ],
            "Purpose": [
              "to inform intervention development"
            ],
            "Method": [
              "identifying core factors"
            ],
            "Results": [
              "<NONE>"
            ],
            "Analysis": [
              "<NONE>"
            ],
            "Challenge": [
              "<NONE>"
            ],
            "Ethical": [
              "<NONE>"
            ],
            "Implications": [
              "<NONE>"
            ],
            "Contradictions": [
              "<NONE>"
            ]
          }
        },
        {
          "Methods/Approach": "ERROR",
          "Text": "This study aims to systematically map the literature on people’s experiences of using digital MBIs that target psychosocial variables (e.g., anxiety, depression, distress, and well-being) and identify key barriers to and facilitators of engagement. We conducted a scoping review to synthesize empirical qualitative research on people’s experiences of using digital MBIs. We adopted a streamlined approach to ensure that the evidence could be incorporated into the early stages of intervention development. The search strategy identified articles with at least one keyword related to mindfulness, digital, user experience, and psychosocial variables in their title or abstract. Inclusion criteria specified that articles must have a qualitative component, report on participants’ experiences of using a digital MBI designed to improve psychosocial variables, and have a sample age range that at least partially overlapped with 16 to 35 years. Qualitative data on user experience were charted and analyzed using inductive thematic synthesis to generate understandings that go beyond the content of the original studies. We used the Quality of Reporting Tool to critically appraise the included sources of evidence.",
          "Main Action": "ERROR",
          "Arguments": {
            "Agent": [
              "ERROR"
            ],
            "Object": {
              "Primary Object": [
                "ERROR"
              ],
              "Secondary Object": [
                "ERROR"
              ]
            },
            "Context": [
              "ERROR"
            ],
            "Purpose": [
              "ERROR"
            ],
            "Method": [
              "ERROR"
            ],
            "Results": [
              "ERROR"
            ],
            "Analysis": [
              "ERROR"
            ],
            "Challenge": [
              "ERROR"
            ],
            "Ethical": [
              "ERROR"
            ],
            "Implications": [
              "ERROR"
            ],
            "Contradictions": [
              "ERROR"
            ]
          },
          "Error_Type": "RECONSTRUCTION_ERROR"
        },
        {
          "Results/Findings": "",
          "Text": "The search identified 530 studies, 22 (4.2%) of which met the inclusion criteria. Overall, the samples were approximately 78% female and 79% White; participants were aged between 16 and 69 years; and the most used measures in intervention studies were mindfulness, psychological flexibility, and variables related to mental health (including depression, anxiety, stress, and well-being). All studies were judged to be adequately reported. We identified 3 themes characterizing barriers to and facilitators of engagement: responses to own practice (i.e., negative reactions to one’s own practice are common and can deplete motivation), making mindfulness a habit (i.e., creating a consistent training routine is essential yet challenging), and leaning on others (i.e., those engaging depend on someone else for support).",
          "Main Action": "Judged to be adequately reported",
          "Arguments": {
            "Agent": [
              "researchers"
            ],
            "Object": {
              "Primary Object": [
                "studies"
              ],
              "Secondary Object": [
                "adequately reported"
              ]
            },
            "Context": [
              "All studies underwent thorough evaluation to ensure reliable and valid data collection.",
              "Quality checks were implemented throughout the analysis process to maintain consistency and accuracy."
            ],
            "Purpose": [
              "To validate the integrity and applicability of the included studies for meaningful thematic analysis."
            ],
            "Method": [
              "Review protocols such as eligibility criteria adherence, sample demographics verification, outcome measurement validation, and statistical methodologies application."
            ],
            "Results": [
              "Studies consistently demonstrated high-quality reporting across demographic profiles and measurement scales used.",
              "Thematic analysis proceeded confidently due to uniform evaluation criteria across all examined works."
            ],
            "Analysis": [
              "Evaluations confirmed alignment with predefined inclusion/exclusion parameters, enhancing credibility of meta-analysis results.",
              "Insights derived from systematic assessments informed robust thematic characterization of barriers and facilitators.",
              "Ensured unbiased processing of evidence contributing to comprehensive understanding of participant experiences and mental health metrics."
            ],
            "Challenge": [
              "Potential variability in subjective evaluations could impact generalizability of exclusion/inclusion decisions.",
              "Subjective judgements necessitate transparent documentation to minimize bias in final thematic synthesis."
            ],
            "Ethical": [
              "Adherence to rigorous peer-review ensured accountability and transparency in study selection and analysis.",
              "Transparent methodology upholds ethical standards in literature synthesis and thematic exploration."
            ],
            "Implications": [
              "Established framework for critical appraisal enhances confidence in synthesised body of work.",
              "Validated procedures provide solid foundation for replicating and extending current investigation efforts.",
              "Robust evaluation systems facilitate accurate comparisons across diverse populations and settings."
            ],
            "Contradictions": [
              "Discrepancies in reporting styles could affect comparability unless standardized formats are enforced.",
              "Variation in operational definitions complicates cross-study comparison despite best efforts to standardise inclusion criteria."
            ]
          }
        },
        {
          "Conclusions/Implications": "",
          "Text": "The themes identified in this review provide crucial insights as to why people frequently stop engaging with digital MBIs. Researchers and developers should consider using person-based coparticipatory methods to improve acceptability of and engagement with digital MBIs, increase their effectiveness, and support their translation to real-world use. Such strategies must be grounded in relevant literature and meet the priorities and needs of the individuals who will use the interventions.",
          "Main Action": "researchers and developers should",
          "Arguments": {
            "Agent": [
              "researchers",
              "developers"
            ],
            "Object": {
              "Primary Object": [
                "person-based coparticipatory methods"
              ],
              "Secondary Object": [
                "digital MBIs"
              ]
            },
            "Context": [
              "identifying themes in this review provide crucial insights as to why people frequently stop engaging with digital MBIs."
            ],
            "Purpose": [
              "improve acceptability of and engagement with digital MBIs",
              "increase their effectiveness",
              "support their translation to real-world use"
            ],
            "Method": [
              "grounded in relevant literature",
              "meet the priorities and needs of the individuals who will use the interventions"
            ],
            "Results": [
              "increased acceptance",
              "greater effectiveness",
              "successful translation to real-world use"
            ],
            "Analysis": [
              "prioritizing literature alignment and individual needs drives strategic decisions"
            ],
            "Challenge": [
              "balancing theoretical considerations with practical implementations",
              "addressing diverse user needs across varied contexts"
            ],
            "Ethical": [
              "respecting user autonomy",
              "ensuring transparency"
            ],
            "Implications": [
              "applying similar principles to other health technologies",
              "enabling scalable improvements"
            ],
            "Contradictions": [
              "<NONE>"
            ]
          }
        }
      ]
    },
    {
      "paper_code": "jmir_23_P_975",
      "abstract": "Large language model (LLM)–based artificial intelligence chatbots direct the power of large training data sets toward successive, related tasks as opposed to single-ask tasks, for which artificial intelligence already achieves impressive performance. The capacity of LLMs to assist in the full scope of iterative clinical reasoning via successive prompting, in effect acting as artificial physicians, has not yet been evaluated. This study aimed to evaluate ChatGPT’s capacity for ongoing clinical decision support via its performance on standardized clinical vignettes. We inputted all 36 published clinical vignettes from the Merck Sharpe & Dohme (MSD) Clinical Manual into ChatGPT and compared its accuracy on differential diagnoses, diagnostic testing, final diagnosis, and management based on patient age, gender, and case acuity. Accuracy was measured by the proportion of correct responses to the questions posed within the clinical vignettes tested, as calculated by human scorers. We further conducted linear regression to assess the contributing factors toward ChatGPT’s performance on clinical tasks. ChatGPT achieved an overall accuracy of 71.7% (95% CI 69.3%-74.1%) across all 36 clinical vignettes. The LLM demonstrated the highest performance in making a final diagnosis with an accuracy of 76.9% (95% CI 67.8%-86.1%) and the lowest performance in generating an initial differential diagnosis with an accuracy of 60.3% (95% CI 54.2%-66.6%). Compared to answering questions about general medical knowledge, ChatGPT demonstrated inferior performance on differential diagnosis (β=–15.8%; P<.001) and clinical management (β=–7.4%; P=.02) question types. ChatGPT achieves impressive accuracy in clinical decision-making, with increasing strength as it gains more clinical information at its disposal. In particular, ChatGPT demonstrates the greatest accuracy in tasks of final diagnosis as compared to initial diagnosis. Limitations include possible model hallucinations and the unclear composition of ChatGPT’s training data set.",
      "events": [
        {
          "Background/Introduction": "",
          "Text": "Large language model (LLM)–based artificial intelligence chatbots direct the power of large training data sets toward successive, related tasks as opposed to single-ask tasks, for which artificial intelligence already achieves impressive performance. The capacity of LLMs to assist in the full scope of iterative clinical reasoning via successive prompting, in effect acting as artificial physicians, has not yet been evaluated.",
          "Main Action": "LLMs have demonstrated impressive performance in handling successive, related tasks as compared to single-ask tasks.",
          "Arguments": {
            "Agent": [
              "artificial intelligence chatbots",
              [
                "<NONE>"
              ]
            ],
            "Object": {
              "Primary Object": [
                "large training data sets",
                [
                  "<NONE>"
                ]
              ],
              "Secondary Object": [
                "iterative clinical reasoning",
                [
                  "<NONE>"
                ]
              ]
            },
            "Context": [
              "<NONE>"
            ],
            "Purpose": [
              "<NONE>"
            ],
            "Method": [
              "<NONE>"
            ],
            "Results": [
              "<NONE>"
            ],
            "Analysis": [
              "<NONE>"
            ],
            "Challenge": [
              "<NONE>"
            ],
            "Ethical": [
              "<NONE>"
            ],
            "Implications": [
              "<NONE>"
            ],
            "Contradictions": [
              "<NONE>"
            ]
          }
        },
        {
          "Methods/Approach": "",
          "Text": "This study aimed to evaluate ChatGPT’s capacity for ongoing clinical decision support via its performance on standardized clinical vignettes. We inputted all 36 published clinical vignettes from the Merck Sharpe & Dohme (MSD) Clinical Manual into ChatGPT and compared its accuracy on differential diagnoses, diagnostic testing, final diagnosis, and management based on patient age, gender, and case acuity. Accuracy was measured by the proportion of correct responses to the questions posed within the clinical vignettes tested, as calculated by human scorers. We further conducted linear regression to assess the contributing factors toward ChatGPT’s performance on clinical tasks.",
          "Main Action": "Evaluate",
          "Arguments": {
            "Agent": [
              "All 36 published clinical vignettes from MSD's Clinical Manual",
              "ChatGPT"
            ],
            "Object": {
              "Primary Object": [
                "Standardized clinical vignettes"
              ],
              "Secondary Object": [
                "Machine learning-based approach used in GPT models"
              ]
            },
            "Context": [
              "We inputted all 36 published clinical vignettes [...] into ChatGPT",
              "Comparisons were made across various metrics [...]",
              "Human scorers [...] calculated accuracy"
            ],
            "Purpose": [
              "To validate whether AI models like ChatGPT can perform ongoing clinical decision support",
              "Beyond theoretical contexts"
            ],
            "Method": [
              "Used machine learning algorithms inherent to GPT models",
              "Involved standard practices [...]",
              "Applied statistical modeling techniques including linear regression"
            ],
            "Results": [
              "Reported findings about ChatGPT's performance relative to expected standards",
              "[accuracy percentage] determined by human scorers"
            ],
            "Analysis": [
              "Discussion on alignment with clinical practice expectations",
              "Strengths and limitations observed during evaluations"
            ],
            "Challenge": [
              "Variability among healthcare professionals’ decision-making styles",
              "Computational resources for processing large datasets",
              "Ensuring fair comparisons between AI systems"
            ],
            "Ethical": [
              "Fairness",
              "Bias mitigation",
              "Transparency in decision-making"
            ],
            "Implications": [
              "Enhancing understanding of AI capabilities in clinical settings",
              "Scalability and generalizability across diverse populations"
            ],
            "Contradictions": [
              "<NONE>"
            ]
          }
        },
        {
          "Results/Findings": "",
          "Text": "ChatGPT achieved an overall accuracy of 71.7% (95% CI 69.3%-74.1%) across all 36 clinical vignettes. The LLM demonstrated the highest performance in making a final diagnosis with an accuracy of 76.9% (95% CI 67.8%-86.1%) and the lowest performance in generating an initial differential diagnosis with an accuracy of 60.3% (95% CI 54.2%-66.6%). Compared to answering questions about general medical knowledge, ChatGPT demonstrated inferior performance on differential diagnosis (β=–15.8%; P<.001) and clinical management (β=–7.4%; P=.02) question types.",
          "Main Action": "Compare performance",
          "Arguments": {
            "Agent": [
              "ChatGPT"
            ],
            "Object": {
              "Primary Object": [
                "performance of ChatGPT",
                "overall accuracy of 71.7%",
                "final diagnosis accuracy of 76.9%",
                "initial differential diagnosis accuracy of 60.3%"
              ],
              "Secondary Object": [
                "<NONE>"
              ]
            },
            "Context": [
              "Across all 36 clinical vignettes",
              "demonstrated the highest performance",
              "lowest performance",
              "compared to answering questions about general medical knowledge",
              "differential diagnosis",
              "clinical management"
            ],
            "Purpose": [
              "<NONE>"
            ],
            "Method": [
              "statistical measurements",
              "beta coefficients",
              "p-values",
              "effect size",
              "significance testing"
            ],
            "Results": [
              "accuracy of 71.7%",
              "diagnosis accuracy of 76.9%",
              "differential diagnosis accuracy of 60.3%",
              "superior performance",
              "inferior performance",
              "beta = –15.8%",
              "P < .001",
              "beta = –7.4%",
              "P = .02"
            ],
            "Analysis": [
              "<NONE>"
            ],
            "Challenge": [
              "<NONE>"
            ],
            "Ethical": [
              "<NONE>"
            ],
            "Implications": [
              "<NONE>"
            ],
            "Contradictions": [
              "<NONE>"
            ]
          }
        },
        {
          "Conclusions/Implications": "",
          "Text": "ChatGPT achieves impressive accuracy in clinical decision-making, with increasing strength as it gains more clinical information at its disposal. In particular, ChatGPT demonstrates the greatest accuracy in tasks of final diagnosis as compared to initial diagnosis. Limitations include possible model hallucinations and the unclear composition of ChatGPT’s training data set.",
          "Main Action": "achieves impressive accuracy",
          "Arguments": {
            "Agent": [
              "ChatGPT"
            ],
            "Object": {
              "Primary Object": [
                "increasing clinical information"
              ],
              "Secondary Object": [
                "accession to more clinical information"
              ]
            },
            "Context": [
              "in clinical decision-making",
              "with increasing strength as it gains more clinical information at its disposal"
            ],
            "Purpose": [
              "improving diagnostic capabilities"
            ],
            "Method": [
              "comparing performance metrics across different phases of diagnosis using datasets reflecting varied clinical inputs"
            ],
            "Results": [
              "impressive accuracy in tasks of final diagnosis",
              "greater accuracy than initial diagnosis"
            ],
            "Analysis": [
              "how having more clinical information affects decision-making processes"
            ],
            "Challenge": [
              "possible model hallucinations",
              "unclear composition of ChatGPT’s training data set"
            ],
            "Ethical": [
              "responsible deployment considerations including patient safety",
              "avoiding biased outputs"
            ],
            "Implications": [
              "potential for widespread improvements in healthcare diagnostics",
              "revolutionization of the field"
            ],
            "Contradictions": [
              "no contradictions mentioned in the text"
            ]
          }
        }
      ]
    }
  ]
}