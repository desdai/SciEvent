{
  "papers": [
    {
      "paper_code": "dh_23_P_29",
      "abstract": "This paper describes a collaborative project designed to meet the needs of communities interested in Gə'əz language texts - and other under-resourced manuscript traditions - by developing an easy-to-use open-source tool that converts images of manuscript pages into a transcription using optical character recognition (OCR). Our computational tool incorporates a custom data curation process to address the language-specific facets of Gə'əz coupled with a Convolutional Recurrent Neural Network to perform the transcription. An open-source OCR transcription tool for digitized Gə'əz manuscripts can be used by students and scholars of Ethiopian manuscripts to create a substantial and computer-searchable corpus of transcribed and digitized Gə'əz texts, opening access to vital resources for sustaining the history and living culture of Ethiopia and its people. With suitable ground-truth, our open-source OCR transcription tool can also be retrained to read other under-resourced scripts. The tool we developed can be run without a graphics processing unit (GPU), meaning that it requires much less computing power than most other modern AI systems. It can be run offline from a personal computer, or accessed via a web client and potentially in the web browser of a smartphone. The paper describes our team's collaborative development of this first open-source tool for Gə'əz manuscript transcription that is both highly accurate and accessible to communities interested in Gə'əz books and the texts they contain.",
      "events": [
        {
          "Background/Introduction": "",
          "Text": "This paper describes a collaborative project designed to meet the needs of communities interested in Gə'əz language texts - and other under-resourced manuscript traditions - by developing an easy-to-use open-source tool that converts images of manuscript pages into a transcription using optical character recognition (OCR).",
          "Main Action": "development",
          "Arguments": {
            "Agent": [
              "a collaborative project"
            ],
            "Object": {
              "Primary Object": [
                "an easy-to-use open-source tool"
              ],
              "Secondary Object": [
                "communities interested in Gə'əz language texts and other under-resourced manuscript traditions"
              ]
            },
            "Context": [
              "to meet the needs of communities interested in Gə'əz language texts - and other under-resourced manuscript traditions"
            ],
            "Purpose": [
              "helping these communities create accessible versions of their texts",
              "aiding preservation efforts"
            ],
            "Method": [
              "using optical character recognition (OCR), focusing on ease of use and accessibility"
            ],
            "Results": [
              "<NONE>"
            ],
            "Analysis": [
              "<NONE>"
            ],
            "Challenge": [
              "overcoming resource limitations such as funding or expertise"
            ],
            "Ethical": [
              "<NONE>"
            ],
            "Implications": [
              "potentially improving accessibility and preserving linguistic heritage"
            ],
            "Contradictions": [
              "<NONE>"
            ]
          }
        },
        {
          "Methods/Approach": "",
          "Text": "Our computational tool incorporates a custom data curation process to address the language-specific facets of Gə'əz coupled with a Convolutional Recurrent Neural Network to perform the transcription. An open-source OCR transcription tool for digitized Gə'əz manuscripts can be used by students and scholars of Ethiopian manuscripts to create a substantial and computer-searchable corpus of transcribed and digitized Gə'əz texts, opening access to vital resources for sustaining the history and living culture of Ethiopia and its people.",
          "Main Action": "incorporates",
          "Arguments": {
            "Agent": [
              "custom data curation process",
              "Convolutional Recurrent Neural Network"
            ],
            "Object": {
              "Primary Object": [
                "Gə'əz language specifics",
                "transcription outputs"
              ],
              "Secondary Object": [
                "digitized Gə'əz manuscripts",
                "domain expertise"
              ]
            },
            "Context": [
              "digitized Gə'əz manuscripts exist",
              "students and scholars utilize them"
            ],
            "Purpose": [
              "create a substantial and computer searchable corpus",
              "access vital resources sustain history and culture"
            ],
            "Method": [
              "custom data curation process combined with Convolutional Recurrent Neural Network",
              "OCR technology application"
            ],
            "Results": [
              "vital resources become accessible",
              "history and culture preserved effectively"
            ],
            "Analysis": [
              "evaluation of transcription model performance",
              "effectiveness measured across various manuscript types"
            ],
            "Challenge": [
              "maintaining linguistic nuance during translation",
              "balancing technical accuracy with cultural fidelity"
            ],
            "Ethical": [
              "preserving original intent",
              "balance between modernization and tradition"
            ],
            "Implications": [
              "enhanced education and cultural programs",
              "broader global understanding of Ethiopia's contribution"
            ],
            "Contradictions": [
              "<NONE>"
            ]
          }
        },
        {
          "Results/Findings": "",
          "Text": "With suitable ground-truth, our open-source OCR transcription tool can also be retrained to read other under-resourced scripts. The tool we developed can be run without a graphics processing unit (GPU), meaning that it requires much less computing power than most other modern AI systems. It can be run offline from a personal computer, or accessed via a web client and potentially in the web browser of a smartphone.",
          "Main Action": "retrain",
          "Arguments": {
            "Agent": [
              "we"
            ],
            "Object": {
              "Primary Object": [
                "other under-resourced scripts"
              ],
              "Secondary Object": [
                "<NONE>"
              ]
            },
            "Context": [
              "Our open-source OCR transcription tool"
            ],
            "Purpose": [
              "enhance applicability across diverse scenarios"
            ],
            "Method": [
              "lightweight AI solutions requiring minimal GPU usage"
            ],
            "Results": [
              "successful application leads to efficient processing"
            ],
            "Analysis": [
              "balancing accuracy despite lower computational requirements"
            ],
            "Challenge": [
              "consideration arises regarding balance between speed and precision"
            ],
            "Ethical": [
              "ethics concerning equitable access to OCR capabilities"
            ],
            "Implications": [
              "broader impact opening doors for similar innovations"
            ],
            "Contradictions": [
              "<NONE>"
            ]
          }
        },
        {
          "Conclusions/Implications": "ERROR",
          "Text": "The paper describes our team's collaborative development of this first open-source tool for Gə'əz manuscript transcription that is both highly accurate and accessible to communities interested in Gə'əz books and the texts they contain.",
          "Main Action": "ERROR",
          "Arguments": {
            "Agent": [
              "ERROR"
            ],
            "Object": {
              "Primary Object": [
                "ERROR"
              ],
              "Secondary Object": [
                "ERROR"
              ]
            },
            "Context": [
              "ERROR"
            ],
            "Purpose": [
              "ERROR"
            ],
            "Method": [
              "ERROR"
            ],
            "Results": [
              "ERROR"
            ],
            "Analysis": [
              "ERROR"
            ],
            "Challenge": [
              "ERROR"
            ],
            "Ethical": [
              "ERROR"
            ],
            "Implications": [
              "ERROR"
            ],
            "Contradictions": [
              "ERROR"
            ]
          },
          "Error_Type": "NO_JSON_FOUND"
        }
      ]
    },
    {
      "paper_code": "dh_23_P_50",
      "abstract": "The article sets up a critique of Sentiment Analysis (SA) tools in literary studies, both from a theoretical and a computational point of view. In the first section, a possible use of SA in narratology and reader response studies is discussed, highlighting the gaps between literary theories and computational models, and suggesting possible solutions to fill them. In the second section, a stratified taxonomy of SA tools is proposed, which distinguishes: (1) the emotion theory adopted by the tool; (2) the method used to build the emotion resources; (3) the technique adopted to accomplish the analysis. A critical survey of six representative SA tools for literary studies (Syuzhet, Vader, SentiArt, SEANCE, Stanford SA, and Transformers Pipelines) closes the article.",
      "events": [
        {
          "Background/Introduction": "",
          "Text": "The article sets up a critique of Sentiment Analysis (SA) tools in literary studies, both from a theoretical and a computational point of view.",
          "Main Action": "Sets up",
          "Arguments": {
            "Agent": [
              "article"
            ],
            "Object": {
              "Primary Object": [
                "Sentiment Analysis (SA) tools"
              ],
              "Secondary Object": [
                "from a theoretical and a computational point of view"
              ]
            },
            "Context": [
              "The article is critiquing Sentiment Analysis (SA) tools in literary studies"
            ],
            "Purpose": [
              "Evaluates the functionality of SA tools from theoretical and computational angles"
            ],
            "Method": [
              "<NONE>"
            ],
            "Results": [
              "<NONE>"
            ],
            "Analysis": [
              "<NONE>"
            ],
            "Challenge": [
              "Potential contradictions arise from combining theoretical and computational approaches"
            ],
            "Ethical": [
              "Ongoing discussions concern ethical considerations in sentiment analysis"
            ],
            "Implications": [
              "Paves the way for improved evaluation methodologies in literary studies"
            ],
            "Contradictions": [
              "<NONE>"
            ]
          }
        },
        {
          "Methods/Approach": "",
          "Text": "In the first section, a possible use of SA in narratology and reader response studies is discussed, highlighting the gaps between literary theories and computational models, and suggesting possible solutions to fill them. In the second section, a stratified taxonomy of SA tools is proposed, which distinguishes: (1) the emotion theory adopted by the tool; (2) the method used to build the emotion resources; (3) the technique adopted to accomplish the analysis.",
          "Main Action": "<NONE>",
          "Arguments": {
            "Agent": [
              "<NONE>"
            ],
            "Object": {
              "Primary Object": [
                "<NONE>"
              ],
              "Secondary Object": [
                "<NONE>"
              ]
            },
            "Context": [
              "<NONE>"
            ],
            "Purpose": [
              "<NONE>"
            ],
            "Method": [
              "<NONE>"
            ],
            "Results": [
              "<NONE>"
            ],
            "Analysis": [
              "<NONE>"
            ],
            "Challenge": [
              "<NONE>"
            ],
            "Ethical": [
              "<NONE>"
            ],
            "Implications": [
              "<NONE>"
            ],
            "Contradictions": [
              "<NONE>"
            ]
          }
        },
        {
          "Results/Findings": "ERROR",
          "Text": "A critical survey of six representative SA tools for literary studies (Syuzhet, Vader, SentiArt, SEANCE, Stanford SA, and Transformers Pipelines) closes the article.",
          "Main Action": "ERROR",
          "Arguments": {
            "Agent": [
              "ERROR"
            ],
            "Object": {
              "Primary Object": [
                "ERROR"
              ],
              "Secondary Object": [
                "ERROR"
              ]
            },
            "Context": [
              "ERROR"
            ],
            "Purpose": [
              "ERROR"
            ],
            "Method": [
              "ERROR"
            ],
            "Results": [
              "ERROR"
            ],
            "Analysis": [
              "ERROR"
            ],
            "Challenge": [
              "ERROR"
            ],
            "Ethical": [
              "ERROR"
            ],
            "Implications": [
              "ERROR"
            ],
            "Contradictions": [
              "ERROR"
            ]
          },
          "Error_Type": "NO_JSON_FOUND"
        }
      ]
    }
  ]
}