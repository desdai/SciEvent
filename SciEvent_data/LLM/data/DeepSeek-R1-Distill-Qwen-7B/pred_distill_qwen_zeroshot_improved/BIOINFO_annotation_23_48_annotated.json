{
  "papers": [
    {
      "paper_code": "bioinfo_23_P_432",
      "abstract": "Interpretable deep learning (DL) models that can provide biological insights, in addition to accurate predictions, are of great interest to the biomedical community. Recently, interpretable DL models that incorporate signaling pathways have been proposed for drug response prediction (DRP). While these models improve interpretability, it is unclear whether this comes at the cost of less accurate DRPs, or a prediction improvement can also be obtained. We comprehensively and systematically assessed four state-of-the-art interpretable DL models using three pathway collections to assess their ability in making accurate predictions on unseen samples from the same dataset, as well as their generalizability to an independent dataset. Our results showed that models that explicitly incorporate pathway information in the form of a latent layer perform worse compared to models that incorporate this information implicitly. However, in most evaluation setups, the best performance was achieved using a black-box multilayer perceptron, and the performance of a random forests baseline was comparable to those of the interpretable models. Replacing the signaling pathways with randomly generated pathways showed a comparable performance for the majority of the models. Finally, the performance of all models deteriorated when applied to an independent dataset. These results highlight the importance of systematic evaluation of newly proposed models using carefully selected baselines. We provide different evaluation setups and baseline models that can be used to achieve this goal.",
      "events": [
        {
          "Background/Introduction": "ERROR",
          "Text": "Interpretable deep learning (DL) models that can provide biological insights, in addition to accurate predictions, are of great interest to the biomedical community. Recently, interpretable DL models that incorporate signaling pathways have been proposed for drug response prediction (DRP). While these models improve interpretability, it is unclear whether this comes at the cost of less accurate DRPs, or a prediction improvement can also be obtained.",
          "Main Action": "ERROR",
          "Arguments": {
            "Agent": [
              "ERROR"
            ],
            "Object": {
              "Primary Object": [
                "ERROR"
              ],
              "Secondary Object": [
                "ERROR"
              ]
            },
            "Context": [
              "ERROR"
            ],
            "Purpose": [
              "ERROR"
            ],
            "Method": [
              "ERROR"
            ],
            "Results": [
              "ERROR"
            ],
            "Analysis": [
              "ERROR"
            ],
            "Challenge": [
              "ERROR"
            ],
            "Ethical": [
              "ERROR"
            ],
            "Implications": [
              "ERROR"
            ],
            "Contradictions": [
              "ERROR"
            ]
          },
          "Error_Type": "NO_JSON_FOUND"
        },
        {
          "Methods/Approach": "",
          "Text": "We comprehensively and systematically assessed four state-of-the-art interpretable DL models using three pathway collections to assess their ability in making accurate predictions on unseen samples from the same dataset, as well as their generalizability to an independent dataset.",
          "Main Action": "<NONE>",
          "Arguments": {
            "Agent": [
              "<NONE>"
            ],
            "Object": {
              "Primary Object": [
                "<NONE>"
              ],
              "Secondary Object": [
                "<NONE>"
              ]
            },
            "Context": [
              "<NONE>"
            ],
            "Purpose": [
              "<NONE>"
            ],
            "Method": [
              "<NONE>"
            ],
            "Results": [
              "<NONE>"
            ],
            "Analysis": [
              "<NONE>"
            ],
            "Challenge": [
              "<NONE>"
            ],
            "Ethical": [
              "<NONE>"
            ],
            "Implications": [
              "<NONE>"
            ],
            "Contradictions": [
              "<NONE>"
            ]
          }
        },
        {
          "Results/Findings": "",
          "Text": "Our results showed that models that explicitly incorporate pathway information in the form of a latent layer perform worse compared to models that incorporate this information implicitly. However, in most evaluation setups, the best performance was achieved using a black-box multilayer perceptron, and the performance of a random forests baseline was comparable to those of the interpretable models. Replacing the signaling pathways with randomly generated pathways showed a comparable performance for the majority of the models. Finally, the performance of all models deteriorated when applied to an independent dataset.",
          "Main Action": "Comparing model performances",
          "Arguments": {
            "Agent": [
              "we"
            ],
            "Object": {
              "Primary Object": [
                "models"
              ],
              "Secondary Object": [
                "different ways of integrating pathway info"
              ]
            },
            "Context": [
              "improving understanding of effective modeling strategies, particularly in healthcare domains"
            ],
            "Purpose": [
              "understanding the effects of integrating pathway information on model performance"
            ],
            "Method": [
              "employing different model architectures and experimenting with manipulated pathway inputs"
            ],
            "Results": [
              "mixed performance depending on pathway integration strategy; decline in performance on independent datasets"
            ],
            "Analysis": [
              "challenges faced included interpreting trade-offs between performance and interpretability; importance of replicable experimental designs"
            ],
            "Challenge": [
              "small sample size leading to noisy estimates; high cost of developing accurate prediction systems; lack of standardized benchmarks for model evaluation"
            ],
            "Ethical": [
              "balance between model accuracy and interpretability needed; transparent reporting essential for public trust; careful consideration of clinical utility versus technical precision"
            ],
            "Implications": [
              "prioritize development of simple, interpretable models unless higher accuracy demands outweigh benefits; guide future research efforts toward clearer distinction between explainability and predictiveness"
            ],
            "Contradictions": [
              "<NONE>"
            ]
          }
        },
        {
          "Conclusions/Implications": "",
          "Text": "These results highlight the importance of systematic evaluation of newly proposed models using carefully selected baselines. We provide different evaluation setups and baseline models that can be used to achieve this goal.",
          "Main Action": "Provide",
          "Arguments": {
            "Agent": [
              "These results"
            ],
            "Object": {
              "Primary Object": [
                "Different evaluation setups and baseline models"
              ],
              "Secondary Object": [
                "<NONE>"
              ]
            },
            "Context": [
              "<NONE>"
            ],
            "Purpose": [
              "<NONE>"
            ],
            "Method": [
              "<NONE>"
            ],
            "Results": [
              "<NONE>"
            ],
            "Analysis": [
              "<NONE>"
            ],
            "Challenge": [
              "<NONE>"
            ],
            "Ethical": [
              "<NONE>"
            ],
            "Implications": [
              "<NONE>"
            ],
            "Contradictions": [
              "<NONE>"
            ]
          }
        }
      ]
    },
    {
      "paper_code": "bioinfo_23_P_838",
      "abstract": "In whole genome sequencing data, polymerase chain reaction amplification results in duplicate DNA fragments coming from the same location in the genome. The process of preparing a whole genome bisulfite sequencing (WGBS) library, on the other hand, can create two DNA fragments from the same location that should not be considered duplicates. Currently, only one WGBS-aware duplicate marking tool exists. However, it only works with the output from a single tool, does not accept streaming input or output, and requires a substantial amount of memory relative to the input size. Dupsifter provides an aligner-agnostic duplicate marking tool that is lightweight, has streaming capabilities, and is memory efficient.",
      "events": [
        {
          "Background/Introduction": "",
          "Text": "In whole genome sequencing data, polymerase chain reaction amplification results in duplicate DNA fragments coming from the same location in the genome. The process of preparing a whole genome bisulfite sequencing (WGBS) library, on the other hand, can create two DNA fragments from the same location that should not be considered duplicates. Currently, only one WGBS-aware duplicate marking tool exists. However, it only works with the output from a single tool, does not accept streaming input or output, and requires a substantial amount of memory relative to the input size.",
          "Main Action": "Introducing",
          "Arguments": {
            "Agent": [
              "a novel computational method"
            ],
            "Object": {
              "Primary Object": [
                "an automated solution for detecting PCR-based sequence duplications in WGBS libraries"
              ],
              "Secondary Object": [
                "a tool capable of processing large-scale genomic datasets efficiently"
              ]
            },
            "Context": [
              "Currently, only one WGBS-aware duplicate marking tool exists.",
              "However, it only works with the output from a single tool, does not accept streaming input or output, and requires a substantial amount of memory relative to the input size."
            ],
            "Purpose": [
              "To address the limitation of relying solely on individual tool compatibility and scalability issues"
            ],
            "Method": [
              "Developing a comprehensive framework integrating real-time PCR detection capabilities with scalable big data algorithms optimized for genomics"
            ],
            "Results": [
              "A prototype implementation demonstrates improved accuracy up to X times faster than conventional methods."
            ],
            "Analysis": [
              "This advancement paves the way for more efficient workflow integration and reduces dependency on labor-intensive post-processing steps."
            ],
            "Challenge": [
              "Balancing speed improvements with resource efficiency remains a critical hurdle due to inherent trade-offs in algorithmic complexity."
            ],
            "Ethical": [
              "Potential clinical misdiagnosis risks necessitate rigorous validation against gold-standard benchmarks."
            ],
            "Implications": [
              "Enables seamless integration into next-generation pipelines enhancing reproducibility and accessibility for researchers worldwide."
            ],
            "Contradictions": [
              "<NONE>"
            ]
          }
        },
        {
          "Methods/Approach": "",
          "Text": "Dupsifter provides an aligner-agnostic duplicate marking tool that is lightweight, has streaming capabilities, and is memory efficient.",
          "Main Action": "provides",
          "Arguments": {
            "Agent": [
              "DupSifter"
            ],
            "Object": {
              "Primary Object": [
                "<NONE>"
              ],
              "Secondary Object": [
                "<NONE>"
              ]
            },
            "Context": [
              "lightweight",
              "streaming capabilities",
              "memory efficient"
            ],
            "Purpose": [
              "aligner-agnostic duplicate marking tool"
            ],
            "Method": [
              "streaming capabilities",
              "low memory consumption"
            ],
            "Results": [
              "<NONE>"
            ],
            "Analysis": [
              "<NONE>"
            ],
            "Challenge": [
              "<NONE>"
            ],
            "Ethical": [
              "<NONE>"
            ],
            "Implications": [
              "aligner-agnostic solution",
              "wider application areas",
              "minimal resources required"
            ],
            "Contradictions": [
              "<NONE>"
            ]
          }
        }
      ]
    }
  ]
}