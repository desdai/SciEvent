{
  "papers": [
    {
      "paper_code": "cscw_23_P_101",
      "abstract": "Live streaming has become a popular activity world-wide that has warranted research attention on its privacy related issues. For instance, bystanders' privacy, or the privacy of third-parties captured by streamers, has been increasingly studied as live streaming has become almost ubiquitous in both public and private spaces in many countries. While prior work has studied bystanders' privacy concerns, a gap exists in understanding how streamers consider bystanders' privacy and the steps they take (or do not take) to preserve it. Understanding streamers' considerations towards bystanders' privacy is vital because streamers are the ones who have direct control over whether and how bystanders' information is disclosed. To address this gap, we conducted an interview study with 25 Chinese streamers to understand their considerations and practices regarding bystanders' privacy in live streaming. We found that streamers cared about bystanders' privacy and evaluated possible privacy violations to bystanders from several perspectives. To protect bystanders from privacy violations, streamers primarily relied on technical, behavioral, and collaborative strategies. Our results also indicated that current streaming platforms lacked features that helped streamers seamlessly manage bystanders' privacy and involved bystanders into their privacy decision-making. Applying the theoretical lens of collective privacy management, we discuss implications for the design of live streaming systems to support streamers in protecting bystanders' privacy.",
      "events": [
        {
          "Background/Introduction": "",
          "Text": "Live streaming has become a popular activity world-wide that has warranted research attention on its privacy related issues. For instance, bystanders' privacy, or the privacy of third-parties captured by streamers, has been increasingly studied as live streaming has become almost ubiquitous in both public and private spaces in many countries. While prior work has studied bystanders' privacy concerns, a gap exists in understanding how streamers consider bystanders' privacy and the steps they take (or do not take) to preserve it. Understanding streamers' considerations towards bystanders' privacy is vital because streamers are the ones who have direct control over whether and how bystanders' information is disclosed.",
          "Main Action": "live streaming",
          "Arguments": {
            "Agent": [
              "researchers"
            ],
            "Object": {
              "Primary Object": [
                "bystanders' privacy concerns"
              ],
              "Secondary Object": [
                "third-parties captured by streamers"
              ]
            },
            "Context": [
              "Live streaming has become a popular activity worldwide that has warranted research attention on its privacy-related issues."
            ],
            "Purpose": [
              "Understanding streamers' considerations towards bystanders' privacy"
            ],
            "Method": [
              "general observation"
            ],
            "Results": [
              "<NONE>"
            ],
            "Analysis": [
              "<NONE>"
            ],
            "Challenge": [
              "<NONE>"
            ],
            "Ethical": [
              "<NONE>"
            ],
            "Implications": [
              "Expanding research areas focused on both platform policies and end-user awareness"
            ],
            "Contradictions": [
              "<NONE>"
            ]
          }
        },
        {
          "Methods/Approach": "",
          "Text": "To address this gap, we conducted an interview study with 25 Chinese streamers to understand their considerations and practices regarding bystanders' privacy in live streaming.",
          "Main Action": "conducted an interview study",
          "Arguments": {
            "Agent": [
              "we",
              "25 Chinese streamers"
            ],
            "Object": {
              "Primary Object": [
                "their considerations and practices"
              ],
              "Secondary Object": [
                "bystanders' privacy in live streaming"
              ]
            },
            "Context": [
              "to address this gap"
            ],
            "Purpose": [
              "to understand their considerations and practices"
            ],
            "Method": [
              "interview study with 25 Chinese streamers"
            ],
            "Results": [
              "<NONE>"
            ],
            "Analysis": [
              "<NONE>"
            ],
            "Challenge": [
              "<NONE>"
            ],
            "Ethical": [
              "<NONE>"
            ],
            "Implications": [
              "<NONE>"
            ],
            "Contradictions": [
              "<NONE>"
            ]
          }
        },
        {
          "Results/Findings": "",
          "Text": "We found that streamers cared about bystanders' privacy and evaluated possible privacy violations to bystanders from several perspectives. To protect bystanders from privacy violations, streamers primarily relied on technical, behavioral, and collaborative strategies. Our results also indicated that current streaming platforms lacked features that helped streamers seamlessly manage bystanders' privacy and involved bystanders into their privacy decision-making.",
          "Main Action": "To protect bystanders from privacy violations",
          "Arguments": {
            "Agent": [
              "Streamers"
            ],
            "Object": {
              "Primary Object": [
                "Bystanders' privacy"
              ],
              "Secondary Object": [
                "Potential privacy violations"
              ]
            },
            "Context": [
              "Our results also indicated that current streaming platforms lacked features that helped streamers seamlessly manage bystanders' privacy and involved bystanders into their privacy decision-making."
            ],
            "Purpose": [
              "What is the purpose or aim of the event?"
            ],
            "Method": [
              "How did the researchers conduct their investigation?",
              "Techniques, tools, approaches were employed including categorization of privacy violation evaluations."
            ],
            "Results": [
              "Results indicated that current streaming platforms lacked features that enabled seamless management of bystanders' privacy and active involvement in decision-making."
            ],
            "Analysis": [
              "Further analysis revealed challenges faced by streamers in balancing privacy protections with content moderation needs.",
              "This suggests room for improvement in integrating privacy support systems tailored to community dynamics."
            ],
            "Challenge": [
              "Current streaming platforms fell short in providing necessary features for effective privacy management and integration of bystander participation."
            ],
            "Ethical": [
              "Ensuring informed consent and transparency remains critical in designing privacy protection measures aimed at safeguarding individual rights."
            ],
            "Implications": [
              "These findings imply opportunities for enhancing streaming platforms with robust privacy management tools that facilitate proactive discussions involving users.",
              "Such developments could foster trust between broadcasters and viewers, potentially leading to more inclusive online environments."
            ],
            "Contradictions": [
              "No explicit contradictions identified in the text."
            ]
          }
        },
        {
          "Conclusions/Implications": "",
          "Text": "Applying the theoretical lens of collective privacy management, we discuss implications for the design of live streaming systems to support streamers in protecting bystanders' privacy.",
          "Main Action": "Protecting",
          "Arguments": {
            "Agent": [
              "Streamers"
            ],
            "Object": {
              "Primary Object": [
                "Bystanders' privacy"
              ],
              "Secondary Object": [
                "None"
              ]
            },
            "Context": [
              "<NONE>"
            ],
            "Purpose": [
              "<NONE>"
            ],
            "Method": [
              "<NONE>"
            ],
            "Results": [
              "<NONE>"
            ],
            "Analysis": [
              "<NONE>"
            ],
            "Challenge": [
              "<NONE>"
            ],
            "Ethical": [
              "<NONE>"
            ],
            "Implications": [
              "<NONE>"
            ],
            "Contradictions": [
              "<NONE>"
            ]
          }
        }
      ]
    },
    {
      "paper_code": "cscw_23_P_201",
      "abstract": "Numerous toolkits have been developed to support ethical AI development. However, toolkits, like all tools, encode assumptions in their design about what work should be done and how. In this paper, we conduct a qualitative analysis of 27 AI ethics toolkits to critically examine how the work of ethics is imagined and how it is supported by these toolkits. Specifically, we examine the discourses toolkits rely on when talking about ethical issues, who they imagine should do the work of ethics, and how they envision the work practices involved in addressing ethics. Among the toolkits, we identify a mismatch between the imagined work of ethics and the support the toolkits provide for doing that work. In particular, we identify a lack of guidance around how to navigate labor, organizational, and institutional power dynamics as they relate to performing ethical work. We use these omissions to chart future work for researchers and designers of AI ethics toolkits.",
      "events": [
        {
          "Background/Introduction": "",
          "Text": "Numerous toolkits have been developed to support ethical AI development. However, toolkits, like all tools, encode assumptions in their design about what work should be done and how.",
          "Main Action": "Encode assumptions in their design about what work should be done and how",
          "Arguments": {
            "Agent": [
              "Numerous toolkits"
            ],
            "Object": {
              "Primary Object": [
                "All tools"
              ],
              "Secondary Object": [
                "<NONE>"
              ]
            },
            "Context": [
              "Providing foundational information about the nature of toolkits and their role in ethical AI practice"
            ],
            "Purpose": [
              "<NONE>"
            ],
            "Method": [
              "Analyzing the toolkit structures or examining their underlying principles"
            ],
            "Results": [
              "<NONE>"
            ],
            "Analysis": [
              "<NONE>"
            ],
            "Challenge": [
              "Over-reliance on external frameworks leads to issues akin to over-relying on heuristics in decision-making processes"
            ],
            "Ethical": [
              "Discussions surround autonomy vs intervention in sensitive domains like military or public safety"
            ],
            "Implications": [
              "<NONE>"
            ],
            "Contradictions": [
              "Some argue against the rigidity implying inherent bias building into these systems"
            ]
          }
        },
        {
          "Methods/Approach": "",
          "Text": "In this paper, we conduct a qualitative analysis of 27 AI ethics toolkits to critically examine how the work of ethics is imagined and how it is supported by these toolkits. Specifically, we examine the discourses toolkits rely on when talking about ethical issues, who they imagine should do the work of ethics, and how they envision the work practices involved in addressing ethics.",
          "Main Action": "Conducting",
          "Arguments": {
            "Agent": [
              "We"
            ],
            "Object": {
              "Primary Object": [
                "Qualitative analysis of 27 AI ethics toolkits"
              ],
              "Secondary Object": [
                "<NONE>"
              ]
            },
            "Context": [
              "<NONE>"
            ],
            "Purpose": [
              "<NONE>"
            ],
            "Method": [
              "<NONE>"
            ],
            "Results": [
              "<NONE>"
            ],
            "Analysis": [
              "<NONE>"
            ],
            "Challenge": [
              "<NONE>"
            ],
            "Ethical": [
              "<NONE>"
            ],
            "Implications": [
              "<NONE>"
            ],
            "Contradictions": [
              "<NONE>"
            ]
          }
        },
        {
          "Results/Findings": "",
          "Text": "Among the toolkits, we identify a mismatch between the imagined work of ethics and the support the toolkits provide for doing that work. In particular, we identify a lack of guidance around how to navigate labor, organizational, and institutional power dynamics as they relate to performing ethical work.",
          "Main Action": "Identify",
          "Arguments": {
            "Agent": [
              "researchers"
            ],
            "Object": {
              "Primary Object": [
                "a lack of guidance"
              ],
              "Secondary Object": [
                "how to navigate labor, organizational, and institutional power dynamics"
              ]
            },
            "Context": [
              "Among the toolkits"
            ],
            "Purpose": [
              "to address the identified mismatch"
            ],
            "Method": [
              "<NONE>"
            ],
            "Results": [
              "Foundations were uncovered"
            ],
            "Analysis": [
              "<NONE>"
            ],
            "Challenge": [
              "<NONE>"
            ],
            "Ethical": [
              "<NONE>"
            ],
            "Implications": [
              "Potential for future application/research"
            ],
            "Contradictions": [
              "<NONE>"
            ]
          }
        },
        {
          "Conclusions/Implications": "",
          "Text": "We use these omissions to chart future work for researchers and designers of AI ethics toolkits.",
          "Main Action": "Use",
          "Arguments": {
            "Agent": [
              "researchers and designers"
            ],
            "Object": {
              "Primary Object": [
                "these omissions"
              ],
              "Secondary Object": [
                "<NONE>"
              ]
            },
            "Context": [
              "charting future work for researchers and designers of AI ethics toolkits"
            ],
            "Purpose": [
              "to chart future work for researchers and designers of AI ethics toolkits"
            ],
            "Method": [
              "<NONE>"
            ],
            "Results": [
              "<NONE>"
            ],
            "Analysis": [
              "<NONE>"
            ],
            "Challenge": [
              "<NONE>"
            ],
            "Ethical": [
              "ethical concerns relate to responsible AI development"
            ],
            "Implications": [
              "advancing robust regulatory measures across diverse sectors relying on AI technologies"
            ],
            "Contradictions": [
              "<NONE>"
            ]
          }
        }
      ]
    }
  ]
}