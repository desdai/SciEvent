{
  "papers": [
    {
      "paper_code": "cscw_23_P_256",
      "abstract": "Artificial intelligence (AI) is increasingly being considered to assist human decision-making in high-stake domains (e.g., health). However, researchers have discussed an issue that humans can over-rely on wrong suggestions of the AI model instead of achieving human-AI complementary performance. In this work, we utilized salient feature explanations along with what-if, counterfactual explanations to make humans review AI suggestions more analytically to reduce overreliance on AI and explored the effect of these explanations on trust and reliance on AI during clinical decision-making. We conducted an experiment with seven therapists and ten laypersons on the task of assessing post-stroke survivors' quality of motion, and analyzed their performance, agreement level on the task, and reliance on AI without and with two types of AI explanations. Our results showed that the AI model with both salient features and counterfactual explanations assisted therapists and laypersons to improve their performance and agreement level on the task when 'right' AI outputs are presented. While both therapists and laypersons over-relied on 'wrong' AI outputs, counterfactual explanations assisted both therapists and laypersons to reduce their over-reliance on 'wrong' AI outputs by 21% compared to salient feature explanations. Specifically, laypersons had higher performance degrades by 18.0 f1-score with salient feature explanations and 14.0 f1-score with counterfactual explanations than therapists with performance degrades of 8.6 and 2.8 f1-scores respectively. Our work discusses the potential of counterfactual explanations to better estimate the accuracy of an AI model and reduce over-reliance on 'wrong' AI outputs and implications for improving human-AI collaborative decision-making.",
      "events": [
        {
          "Background/Introduction": "ERROR",
          "Text": "Artificial intelligence (AI) is increasingly being considered to assist human decision-making in high-stake domains (e.g., health). However, researchers have discussed an issue that humans can over-rely on wrong suggestions of the AI model instead of achieving human-AI complementary performance.",
          "Main Action": "ERROR",
          "Arguments": {
            "Agent": [
              "ERROR"
            ],
            "Object": {
              "Primary Object": [
                "ERROR"
              ],
              "Secondary Object": [
                "ERROR"
              ]
            },
            "Context": [
              "ERROR"
            ],
            "Purpose": [
              "ERROR"
            ],
            "Method": [
              "ERROR"
            ],
            "Results": [
              "ERROR"
            ],
            "Analysis": [
              "ERROR"
            ],
            "Challenge": [
              "ERROR"
            ],
            "Ethical": [
              "ERROR"
            ],
            "Implications": [
              "ERROR"
            ],
            "Contradictions": [
              "ERROR"
            ]
          },
          "Error_Type": "NO_JSON_FOUND"
        },
        {
          "Methods/Approach": "",
          "Text": "In this work, we utilized salient feature explanations along with what-if, counterfactual explanations to make humans review AI suggestions more analytically to reduce overreliance on AI and explored the effect of these explanations on trust and reliance on AI during clinical decision-making. We conducted an experiment with seven therapists and ten laypersons on the task of assessing post-stroke survivors' quality of motion, and analyzed their performance, agreement level on the task, and reliance on AI without and with two types of AI explanations.",
          "Main Action": "utilized salient feature explanations along with what-if, counterfactual explanations",
          "Arguments": {
            "Agent": [
              "seven therapists",
              "ten laypersons"
            ],
            "Object": {
              "Primary Object": [
                "the task of assessing post-stroke survivors' quality of motion"
              ],
              "Secondary Object": [
                "performance, agreement level on the task, and reliance on AI"
              ]
            },
            "Context": [
              "we conducted an experiment with seven therapists and ten laypersons on the task of assessing post-stroke survivors' quality of motion"
            ],
            "Purpose": [
              "to explore the effect of these explanations on trust and reliance on AI during clinical decision-making."
            ],
            "Method": [
              "We utilized salient feature explanations along with what-if, counterfactual explanations to make humans review AI suggestions more analytically.",
              "We conducted an experiment with seven therapists and ten laypersons on the task of assessing post-stroke survivors' quality of motion."
            ],
            "Results": [
              "We analyzed their performance, agreement level on the task, and reliance on AI without and with two types of AI explanations."
            ],
            "Analysis": [
              "We explored the effect of these explanations on trust and reliance on AI during clinical decision-making."
            ],
            "Challenge": [
              "<NONE>"
            ],
            "Ethical": [
              "<NONE>"
            ],
            "Implications": [
              "This suggests the broader significance or potential for future applications/research in improving AI integration in healthcare training programs."
            ],
            "Contradictions": [
              "<NONE>"
            ]
          }
        },
        {
          "Results/Findings": "",
          "Text": "Our results showed that the AI model with both salient features and counterfactual explanations assisted therapists and laypersons to improve their performance and agreement level on the task when 'right' AI outputs are presented. While both therapists and laypersons over-relied on 'wrong' AI outputs, counterfactual explanations assisted both therapists and laypersons to reduce their over-reliance on 'wrong' AI outputs by 21% compared to salient feature explanations. Specifically, laypersons had higher performance degrades by 18.0 F1-score with salient feature explanations and 14.0 F1-score with counterfactual explanations than therapists with performance degrades of 8.6 and 2.8 F1-scores respectively.",
          "Main Action": "AI model",
          "Arguments": {
            "Agent": [
              "AI model"
            ],
            "Object": {
              "Primary Object": [
                "therapists and laypersons"
              ],
              "Secondary Object": [
                "<NONE>"
              ]
            },
            "Context": [
              "Our results showed that the AI model with both salient features and counterfactual explanations assisted therapists and laypersons"
            ],
            "Purpose": [
              "Evaluate how AI models assist therapists and laypeople differently depending on the nature of AI output (salient feature explanations versus counterfactual explanations)"
            ],
            "Method": [
              "Used both types of AI explanations (salient features and counterfactual explanations), measure performance metrics including F1-scores."
            ],
            "Results": [
              "Assisted therapists and laypersons to improve their performance and agreement level on the task when 'right' AI outputs are presented.",
              "While both therapists and laypersons over-relied on 'wrong' AI outputs, counterfactual explanations assisted both therapists and laypersons to reduce their over-reliance on 'wrong' AI outputs by 21% compared to salient feature explanations.",
              "Specifically, laypersons had higher performance degradation by 18.0 F1-score with salient feature explanations and 14.0 F1-score with counterfactual explanations than therapists with performance degradation of 8.6 and 2.8 F1-scores respectively."
            ],
            "Analysis": [
              "Interpretations or explanations of other arguments include quantification of improvement in accuracy and reduction in cognitive bias."
            ],
            "Challenge": [
              "Limitations included small sample size restricting statistical power and variation in participant baseline proficiency potentially limiting generalizability."
            ],
            "Ethical": [
              "Promotes transparency through counterfactual explanations addressing user trust goals clarify decision-making processes particularly relevant for sensitive areas like mental health treatment adherence."
            ],
            "Implications": [
              "Future application expansion possibilities include testing diverse populations integration of ML algorithms development of causal reasoning support systems aligned with clinical guidelines."
            ],
            "Contradictions": [
              "<NONE>"
            ]
          }
        },
        {
          "Conclusions/Implications": "ERROR",
          "Text": "Our work discusses the potential of counterfactual explanations to better estimate the accuracy of an AI model and reduce over-reliance on 'wrong' AI outputs and implications for improving human-AI collaborative decision-making.",
          "Main Action": "ERROR",
          "Arguments": {
            "Agent": [
              "ERROR"
            ],
            "Object": {
              "Primary Object": [
                "ERROR"
              ],
              "Secondary Object": [
                "ERROR"
              ]
            },
            "Context": [
              "ERROR"
            ],
            "Purpose": [
              "ERROR"
            ],
            "Method": [
              "ERROR"
            ],
            "Results": [
              "ERROR"
            ],
            "Analysis": [
              "ERROR"
            ],
            "Challenge": [
              "ERROR"
            ],
            "Ethical": [
              "ERROR"
            ],
            "Implications": [
              "ERROR"
            ],
            "Contradictions": [
              "ERROR"
            ]
          },
          "Error_Type": "NO_JSON_FOUND"
        }
      ]
    },
    {
      "paper_code": "cscw_23_P_229",
      "abstract": "Prison and police abolition has become a major political philosophy in North American discourse following the 2020 George Floyd protests. The philosophy remains divisive, and North American abolitionists seeking to coalition-build, provide resources for vulnerable populations, and garner public support continue to experience challenges. We explore current usage of digital tools among abolitionists and the potential of a digital mapping tool to address these challenges. We conduct an interview study with 15 abolitionist organizations to understand activists' perspectives on the value of digital tools for organizing and a content analysis of 25 existing digital tools that convey abolitionist ideas to the public. Our findings together reveal (1) opportunities for digital mapping and HCI to support abolitionist activism and grassroots activism more broadly and (2) the challenges of digitally and spatially representing a movement that is intentionally grassroots, clandestine, and often involves organizers working in disparate locations.",
      "events": [
        {
          "Background/Introduction": "",
          "Text": "Prison and police abolition has become a major political philosophy in North American discourse following the 2020 George Floyd protests. The philosophy remains divisive, and North American abolitionists seeking to coalition-build, provide resources for vulnerable populations, and garner public support continue to experience challenges.",
          "Main Action": "seeking to coalition-build, provide resources for vulnerable populations, and garner public support",
          "Arguments": {
            "Agent": [
              "North American Abolitionists"
            ],
            "Object": {
              "Primary Object": [
                "vulnerable populations"
              ],
              "Secondary Object": [
                "general public",
                "other organizations"
              ]
            },
            "Context": [
              "<NONE>"
            ],
            "Purpose": [
              "<NONE>"
            ],
            "Method": [
              "<NONE>"
            ],
            "Results": [
              "<NONE>"
            ],
            "Analysis": [
              "<NONE>"
            ],
            "Challenge": [
              "<NONE>"
            ],
            "Ethical": [
              "<NONE>"
            ],
            "Implications": [
              "<NONE>"
            ],
            "Contradictions": [
              "<NONE>"
            ]
          }
        },
        {
          "Methods/Approach": "ERROR",
          "Text": "We explore current usage of digital tools among abolitionists and the potential of a digital mapping tool to address these challenges. We conduct an interview study with 15 abolitionist organizations to understand activists' perspectives on the value of digital tools for organizing and a content analysis of 25 existing digital tools that convey abolitionist ideas to the public.",
          "Main Action": "ERROR",
          "Arguments": {
            "Agent": [
              "ERROR"
            ],
            "Object": {
              "Primary Object": [
                "ERROR"
              ],
              "Secondary Object": [
                "ERROR"
              ]
            },
            "Context": [
              "ERROR"
            ],
            "Purpose": [
              "ERROR"
            ],
            "Method": [
              "ERROR"
            ],
            "Results": [
              "ERROR"
            ],
            "Analysis": [
              "ERROR"
            ],
            "Challenge": [
              "ERROR"
            ],
            "Ethical": [
              "ERROR"
            ],
            "Implications": [
              "ERROR"
            ],
            "Contradictions": [
              "ERROR"
            ]
          },
          "Error_Type": "NO_JSON_FOUND"
        },
        {
          "Results/Findings": "",
          "Text": "Our findings together reveal (1) opportunities for digital mapping and HCI to support abolitionist activism and grassroots activism more broadly and (2) the challenges of digitally and spatially representing a movement that is intentionally grassroots, clandestine, and often involves organizers working in disparate locations.",
          "Main Action": "<NONE>",
          "Arguments": {
            "Agent": [
              "Digital Mapping",
              "Human-Centered Interaction"
            ],
            "Object": {
              "Primary Object": [
                "Abolitionist Activism",
                "Grassroots Activism"
              ],
              "Secondary Object": [
                "Technologies like Digital Mapping",
                "Human-Centered Interaction Tools"
              ]
            },
            "Context": [
              "How digital representations affect grassroots movements",
              "Challenges in digitally representing movements operating in diverse locations"
            ],
            "Purpose": [
              "To understand how technology enhances grassroots organization",
              "To highlight challenges in tech-based activism"
            ],
            "Method": [
              "Case studies examining data from various regions",
              "Data analysis focusing on fragmented locations"
            ],
            "Results": [
              "Positive impacts of digital tools on global grassroots efforts",
              "Technical hurdles despite spatial mapping attempts"
            ],
            "Analysis": [
              "Potential expansion via integrated digital engagement models",
              "Systemic issue requirements for improvement"
            ],
            "Challenge": [
              "Balancing technological advancements with community-driven initiatives",
              "Addressing privacy and security concerns in tech use"
            ],
            "Ethical": [
              "Concerns about empowering vs controlling individual autonomy",
              "Privacy and security risks associated with tech use"
            ],
            "Implications": [
              "New avenues for inclusive tech integration in grassroots",
              "Necessity of adapting tech strategies to match movement dynamics"
            ],
            "Contradictions": [
              "Focusing purely on digital mapping neglects broader grassroots needs",
              "Over-reliance on tech may overshadow community-led efforts"
            ]
          }
        }
      ]
    }
  ]
}