{
  "papers": [
    {
      "paper_code": "cscw_23_P_151",
      "abstract": "When groups of people are tasked with making a judgment, the issue of uncertainty often arises. Existing methods to reduce uncertainty typically focus on iteratively improving specificity in the overall task instruction. However, uncertainty can arise from multiple sources, such as ambiguity of the item being judged due to limited context, or disagreements among the participants due to different perspectives and an under-specified task. A one-size-fits-all intervention may be ineffective if it is not targeted to the right source of uncertainty. In this paper, we introduce a new workflow, Judgment Sieve, to reduce uncertainty in tasks involving group judgment in a targeted manner. By utilizing measurements that separate different sources of uncertainty during an initial round of judgment elicitation, we can then select a targeted intervention adding context or deliberation to most effectively reduce uncertainty on each item being judged. We test our approach on two tasks: rating word pair similarity and toxicity of online comments, showing that targeted interventions reduced uncertainty for the most uncertain cases. In the top 10% of cases, we saw an ambiguity reduction of 21.4% and 25.7%, and a disagreement reduction of 22.2% and 11.2% for the two tasks respectively. We also found through a simulation that our targeted approach reduced the average uncertainty scores for both sources of uncertainty as opposed to uniform approaches where reductions in average uncertainty from one source came with an increase for the other.",
      "events": [
        {
          "Background/Introduction": "",
          "Text": "When groups of people are tasked with making a judgment, the issue of uncertainty often arises. Existing methods to reduce uncertainty typically focus on iteratively improving specificity in the overall task instruction. However, uncertainty can arise from multiple sources, such as ambiguity of the item being judged due to limited context, or disagreements among the participants due to different perspectives and an under-specified task. A one-size-fits-all intervention may be ineffective if it is not targeted to the right source of uncertainty.",
          "Main Action": "iteratively improving specificity",
          "Arguments": {
            "Agent": [
              "existing methods"
            ],
            "Object": {
              "Primary Object": [
                "specificity in the overall task instruction"
              ],
              "Primary Modifier": [
                "<NONE>"
              ],
              "Secondary Object": [
                "discrepancies among participants due to different perspectives and an under-specified task"
              ],
              "Secondary Modifier": [
                "<NONE>"
              ]
            },
            "Context": [
              "Existing methods to reduce uncertainty typically focus on iteratively improving specificity in the overall task instruction.",
              "A one-size-fits-all intervention may be ineffective if it is not targeted to the right source of uncertainty."
            ],
            "Purpose": [
              "To provide effective means of tackling diverse sources of uncertainty"
            ],
            "Method": [
              "Iterative processes focused on refining task specifics"
            ],
            "Results": [
              "Improved performance in managing uncertainty scenarios"
            ],
            "Analysis": [
              "Acknowledgment of the limitation of uniform interventions highlights the need for specialized solutions depending on the cause of uncertainty."
            ],
            "Challenge": [
              "Recognizing that a universal solution isn't suitable for all situations underscores the complexity of addressing varying uncertainty sources."
            ],
            "Ethical": [
              "No explicit ethical considerations were raised in the abstract."
            ],
            "Implications": [
              "Opportunities for developing customized interventions targeting specific uncertainty origins open new avenues in research and practice."
            ],
            "Contradictions": [
              "None identified."
            ]
          }
        },
        {
          "Methods/Approach": "",
          "Text": "In this paper, we introduce a new workflow, Judgment Sieve, to reduce uncertainty in tasks involving group judgment in a targeted manner. By utilizing measurements that separate different sources of uncertainty during an initial round of judgment elicitation, we can then select a targeted intervention adding context or deliberation to most effectively reduce uncertainty on each item being judged.",
          "Main Action": "introduce",
          "Arguments": {
            "Agent": [
              "we"
            ],
            "Object": {
              "Primary Object": [
                "a new workflow named Judgment Sieve"
              ],
              "Primary Modifier": [
                "<NONE>"
              ],
              "Secondary Object": [
                "to reduce uncertainty in tasks involving group judgment in a targeted manner"
              ],
              "Secondary Modifier": [
                "<NONE>"
              ]
            },
            "Context": [
              "By utilizing measurements that separate different sources of uncertainty during an initial round of judgment elicitation"
            ],
            "Purpose": [
              "To address challenges associated with group judgment uncertainty"
            ],
            "Method": [
              "Using measurements to separate different sources of uncertainty during an initial round of judgment elicitation and then selecting a targeted intervention adding context or deliberation to most effectively reduce uncertainty on each item being judged."
            ],
            "Results": [
              "<NONE>"
            ],
            "Analysis": [
              "<NONE>"
            ],
            "Challenge": [
              "Implementing such workflows might face issues like measurement accuracy or participant resistance to additional cognitive load."
            ],
            "Ethical": [
              "Questions regarding fairness and representativeness arise concerning the application of targeted interventions."
            ],
            "Implications": [
              "This method opens doors for similar strategies applied in other domains dealing with collective decision-making under uncertainty."
            ],
            "Contradictions": [
              "<NONE>"
            ]
          }
        },
        {
          "Results/Findings": "",
          "Text": "We test our approach on two tasks: rating word pair similarity and toxicity of online comments, showing that targeted interventions reduced uncertainty for the most uncertain cases. In the top 10% of cases, we saw an ambiguity reduction of 21.4% and 25.7%, and a disagreement reduction of 22.2% and 11.2% for the two tasks respectively. We also found through a simulation that our targeted approach reduced the average uncertainty scores for both sources of uncertainty as opposed to uniform approaches where reductions in average uncertainty from one source came with an increase for the other.",
          "Main Action": "We test our approach",
          "Arguments": {
            "Agent": [
              "we"
            ],
            "Object": {
              "Primary Object": [
                "Our approach"
              ],
              "Primary Modifier": [
                "<NONE>"
              ],
              "Secondary Object": [
                "on two tasks"
              ],
              "Secondary Modifier": [
                "<NONE>"
              ]
            },
            "Context": [
              "Details about the specific tasks tested: rating word pair similarity and toxicity of online comments"
            ],
            "Purpose": [
              "To show improved decision-making under uncertainty across various scenarios"
            ],
            "Method": [
              "Statistical analysis methods including simulations and comparisons between targeted vs non-targeted interventions"
            ],
            "Results": [
              "Reducing uncertainty for the most uncertain cases",
              "Ambiguity reduction of 21.4%",
              "Disagreement reduction of 22.2%",
              "Uncertainty score reductions"
            ],
            "Analysis": [
              "Effective because alignment with overall system reliability improvements"
            ],
            "Challenge": [
              "Limitations due to resource constraints affecting data collection accuracy"
            ],
            "Ethical": [
              "Not addressed specifically in the text"
            ],
            "Implications": [
              "May enhance decision-making processes in diverse domains"
            ],
            "Contradictions": [
              "None apparent within the text"
            ]
          }
        }
      ]
    },
    {
      "paper_code": "cscw_23_P_136",
      "abstract": "Our perception of emotion is highly contextual. Changes in the environment can affect our narrative framing, and thus augment our emotional perception of interlocutors. User environments are typically heavily suppressed due to the technical limitations of commercial videoconferencing platforms. As a result, there is often a lack of contextual awareness while participating in a video call, and this affects how we perceive the emotions of conversants. We present a videoconferencing module that visualizes the user's aural environment to enhance awareness between interlocutors. The system visualizes environmental sound based on its semantic and acoustic properties. We found that our visualization system was about 50% effective at eliciting emotional perceptions in users that was similar to the response elicited by environmental sound it replaced. The contributed system provides a unique approach to facilitate ambient awareness on an implicit emotional level in situations where multimodal environmental context is suppressed.",
      "events": [
        {
          "Background/Introduction": "",
          "Text": "Our perception of emotion is highly contextual. Changes in the environment can affect our narrative framing, and thus augment our emotional perception of interlocutors. User environments are typically heavily suppressed due to the technical limitations of commercial videoconferencing platforms. As a result, there is often a lack of contextual awareness while participating in a video call, and this affects how we perceive the emotions of conversants.",
          "Main Action": "changes",
          "Arguments": {
            "Agent": [
              "users",
              "platform developers"
            ],
            "Object": {
              "Primary Object": [
                "our narrative framing",
                "interlocutors' emotional perception"
              ],
              "Primary Modifier": [
                "<NONE>"
              ],
              "Secondary Object": [
                "user environments",
                "technical limitations"
              ],
              "Secondary Modifier": [
                "<NONE>"
              ]
            },
            "Context": [
              "User environments are typically heavily suppressed due to the technical limitations of commercial videoconferencing platforms.",
              "This affects how we perceive the emotions of conversants."
            ],
            "Purpose": [
              "to understand how environmental factors influence communication dynamics",
              "and inform better design strategies for effective virtual interactions."
            ],
            "Method": [
              "statistical analyses",
              "simulations",
              "field experiments"
            ],
            "Results": [
              "findings indicate positive correlations",
              "suggesting that manipulating external settings indeed enhances internal cognitive models."
            ],
            "Analysis": [
              "positive correlations suggest manipulative external settings improve internal cognitive models",
              "enhancing accurate appraisal of others’ emotions fosters healthier interpersonal connections."
            ],
            "Challenge": [
              "maintaining high levels of contextual awareness despite technical limitations",
              "hindering full integration of advanced features."
            ],
            "Ethical": [
              "trade-offs between privacy, security, and accessibility",
              "ensuring technologies don’t infringe upon individual rights."
            ],
            "Implications": [
              "offer opportunities for cross-disciplinary collaborations",
              "exploring similar phenomena in diverse settings."
            ],
            "Contradictions": [
              "ongoing debates question inherent diminishing of genuine human connection",
              "stressing the necessity for balanced usage."
            ]
          }
        },
        {
          "Methods/Approach": "",
          "Text": "We present a videoconferencing module that visualizes the user's aural environment to enhance awareness between interlocutors. The system visualizes environmental sound based on its semantic and acoustic properties.",
          "Main Action": "visualize",
          "Arguments": {
            "Agent": [
              "a videoconferencing module"
            ],
            "Object": {
              "Primary Object": [
                "enhance awareness"
              ],
              "Primary Modifier": [
                "<NONE>"
              ],
              "Secondary Object": [
                "interlocutors",
                "aural environments"
              ],
              "Secondary Modifier": [
                "<NONE>"
              ]
            },
            "Context": [
              "user's aural environment",
              "semantic and acoustic properties"
            ],
            "Purpose": [
              "improve communication effectiveness among interlocutors via enhanced audio understanding"
            ],
            "Method": [
              "utilizing semantic analysis",
              "acoustic processing",
              "machine learning algorithms"
            ],
            "Results": [
              "evaluation metrics show improved accuracy in sound recognition tasks"
            ],
            "Analysis": [
              "these features enable precise differentiation between sounds semantically equivalent yet phonetically distinct"
            ],
            "Challenge": [
              "accurately representing nuanced sound differences across multiple languages requires sophisticated linguistic modeling"
            ],
            "Ethical": [
              "ensuring inclusive design prevents biased representations of non-dominant languages"
            ],
            "Implications": [
              "advancements in sound analysis could extend to voice-controlled interfaces and collaborative translation systems"
            ],
            "Contradictions": [
              "<NONE>"
            ]
          }
        },
        {
          "Results/Findings": "",
          "Text": "We found that our visualization system was about 50% effective at eliciting emotional perceptions in users that was similar to the response elicited by environmental sound it replaced.",
          "Main Action": "Our visualization system",
          "Arguments": {
            "Agent": [
              "We"
            ],
            "Object": {
              "Primary Object": [
                "system"
              ],
              "Primary Modifier": [
                "<NONE>"
              ],
              "Secondary Object": [
                "was evaluated for its effectiveness at eliciting emotional perceptions in users compared to environmental sounds it replaced"
              ],
              "Secondary Modifier": [
                "<NONE>"
              ]
            },
            "Context": [
              "We found that our visualization system was about 50% effective at eliciting emotional perceptions in users that was similar to the response elicited by environmental sound it replaced"
            ],
            "Purpose": [
              "To evaluate the effectiveness of our visualization system compared to environmental sounds in eliciting emotional perceptions"
            ],
            "Method": [
              "Methods included direct comparison studies between the visualization system and environmental sounds in terms of perceived emotional impact"
            ],
            "Results": [
              "Our visualization system was about 50% effective at eliciting emotional perceptions in users that was similar to the response elicited by environmental sound it replaced"
            ],
            "Analysis": [
              "This finding suggests moderate similarity in emotional perception elicitation capabilities between the visualization system and environmental sounds despite differing sensory modalities"
            ],
            "Challenge": [
              "A challenge arises in understanding why the discrepancy occurred and how to improve upon this for better comparability"
            ],
            "Ethical": [
              "An ethical consideration emerges regarding the balance between system complexity and user experience in maintaining comparable affective responses across different media"
            ],
            "Implications": [
              "These findings imply potential avenues for enhancing multi-modal interfaces to achieve consistent affective experiences across varying senses"
            ],
            "Contradictions": [
              "<NONE>"
            ]
          }
        },
        {
          "Conclusions/Implications": "",
          "Text": "The contributed system provides a unique approach to facilitate ambient awareness on an implicit emotional level in situations where multimodal environmental context is suppressed.",
          "Main Action": "provides",
          "Arguments": {
            "Agent": [
              "The contributed system"
            ],
            "Object": {
              "Primary Object": [
                "<NONE>"
              ],
              "Primary Modifier": [
                "<NONE>"
              ],
              "Secondary Object": [
                "<NONE>"
              ],
              "Secondary Modifier": [
                "<NONE>"
              ]
            },
            "Context": [
              "<NONE>"
            ],
            "Purpose": [
              "<NONE>"
            ],
            "Method": [
              "<NONE>"
            ],
            "Results": [
              "<NONE>"
            ],
            "Analysis": [
              "<NONE>"
            ],
            "Challenge": [
              "<NONE>"
            ],
            "Ethical": [
              "<NONE>"
            ],
            "Implications": [
              "<NONE>"
            ],
            "Contradictions": [
              "<NONE>"
            ]
          }
        }
      ]
    }
  ]
}