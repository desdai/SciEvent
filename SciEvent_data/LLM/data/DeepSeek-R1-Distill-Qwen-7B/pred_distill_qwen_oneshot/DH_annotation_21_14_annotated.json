{
  "papers": [
    {
      "paper_code": "dh_21_P_67",
      "abstract": "This essay details the development and current NEH-funded research goals of The Media Ecology Project (MEP), directed by Prof. Mark Williams and designed by Dr. John Bell at Dartmouth. The virtuous cycle of access, research, and preservation that MEP realizes is built upon a foundation of technological advance (software development) plus large-scale partnership networks with scholars, students, and institutions of historical memory such as moving image archives. The development of our Onomy vocabulary tool and NEH-funded Semantic Annotation Tool (SAT) are detailed, including their application in two advancement grants from the NEH regarding 1) early cinema history, and 2) television newsfilm that covered the civil rights movement in the U.S. MEP is fundamentally 1) a sustainability project that 2) develops literacies of moving image and visual culture history, and 3) functions as a collaborative incubator that fosters new research questions and methods ranging from traditional Arts and Humanities close-textual analysis to computational distant reading. New research questions in relation to these workflows will literally transform the value of media archives and support the development of interdisciplinary research and pedagogy/curricular goals (e.g., media literacy) regarding the study of visual culture history and its legacies in the 21st century.",
      "events": [
        {
          "Background/Introduction": "",
          "Text": "This essay details the development and current NEH-funded research goals of The Media Ecology Project (MEP), directed by Prof. Mark Williams and designed by Dr. John Bell at Dartmouth. The virtuous cycle of access, research, and preservation that MEP realizes is built upon a foundation of technological advance (software development) plus large-scale partnership networks with scholars, students, and institutions of historical memory such as moving image archives.",
          "Main Action": "The virtuous cycle of access, research, and preservation that MEP realizes is built upon",
          "Arguments": {
            "Agent": [
              "Dartmouth"
            ],
            "Object": {
              "Primary Object": [
                "a foundation of technological advance (software development) plus large-scale partnership networks with scholars, students, and institutions of historical memory such as moving image archives"
              ],
              "Primary Modifier": [
                "<NONE>"
              ],
              "Secondary Object": [
                "<NONE>"
              ],
              "Secondary Modifier": [
                "<NONE>"
              ]
            },
            "Context": [
              "This essay details the development and current NEH-funded research goals of The Media Ecology Project (MEP), directed by Prof. Mark Williams and designed by Dr. John Bell at Dartmouth."
            ],
            "Purpose": [
              "<NONE>"
            ],
            "Method": [
              "<NONE>"
            ],
            "Results": [
              "<NONE>"
            ],
            "Analysis": [
              "<NONE>"
            ],
            "Challenge": [
              "<NONE>"
            ],
            "Ethical": [
              "<NONE>"
            ],
            "Implications": [
              "<NONE>"
            ],
            "Contradictions": [
              "<NONE>"
            ]
          }
        },
        {
          "Methods/Approach": "",
          "Text": "The development of our Onomy vocabulary tool and NEH-funded Semantic Annotation Tool (SAT) are detailed, including their application in two advancement grants from the NEH regarding 1) early cinema history, and 2) television newsfilm that covered the civil rights movement in the U.S. MEP is fundamentally 1) a sustainability project that 2) develops literacies of moving image and visual culture history, and 3) functions as a collaborative incubator that fosters new research questions and methods ranging from traditional Arts and Humanities close-textual analysis to computational distant reading.",
          "Main Action": "developed",
          "Arguments": {
            "Agent": [
              "MEP"
            ],
            "Object": {
              "Primary Object": [
                "Semantic Annotation Tool (SAT)"
              ],
              "Primary Modifier": [
                "<NONE>"
              ],
              "Secondary Object": [
                "<NONE>"
              ],
              "Secondary Modifier": [
                "<NONE>"
              ]
            },
            "Context": [
              "NEH-funded Semantic Annotation Tool (SAT)"
            ],
            "Purpose": [
              "Advancing understanding through semantic annotations applied to films and news"
            ],
            "Method": [
              "Working closely with experts in arts and humanities and computational linguistics; employ manual annotation and AI-based classification algorithms"
            ],
            "Results": [
              "Applying SAT under two advancement grants from NEH regarding 1) early cinema history, and 2) television newsfilm that covered the civil rights movement in the U.S."
            ],
            "Analysis": [
              "MEP is fundamentally focused on advancing cultural heritage preservation via media content during critical periods"
            ],
            "Challenge": [
              "Challenges arising from integrating diverse methodologies due to varying expertise levels and domain-specific terminologies"
            ],
            "Ethical": [
              "Concerns raised about bias inherent in human labeling practices; ensuring fairness and representativeness"
            ],
            "Implications": [
              "Broadens scope for future interdisciplinary research combining qualitative textual analysis with computational methods"
            ],
            "Contradictions": [
              "<NONE>"
            ]
          }
        },
        {
          "Conclusions/Implications": "",
          "Text": "New research questions in relation to these workflows will literally transform the value of media archives and support the development of interdisciplinary research and pedagogy/curricular goals (e.g., media literacy) regarding the study of visual culture history and its legacies in the 21st century.",
          "Main Action": "<NONE>",
          "Arguments": {
            "Agent": [
              "<NONE>"
            ],
            "Object": {
              "Primary Object": [
                "<NONE>"
              ],
              "Primary Modifier": [
                "<NONE>"
              ],
              "Secondary Object": [
                "<NONE>"
              ],
              "Secondary Modifier": [
                "<NONE>"
              ]
            },
            "Context": [
              "<NONE>"
            ],
            "Purpose": [
              "<NONE>"
            ],
            "Method": [
              "<NONE>"
            ],
            "Results": [
              "<NONE>"
            ],
            "Analysis": [
              "<NONE>"
            ],
            "Challenge": [
              "<NONE>"
            ],
            "Ethical": [
              "<NONE>"
            ],
            "Implications": [
              "<NONE>"
            ],
            "Contradictions": [
              "<NONE>"
            ]
          }
        }
      ]
    },
    {
      "paper_code": "dh_21_P_47",
      "abstract": "This paper examines musical artificial intelligence (AI) algorithms that can not only learn from big data, but learn in ways that would be familiar to a musician or music theorist. This paper aims to find more effective links between music-related big data and artificial intelligence algorithms by incorporating principles with a strong grounding in music theory. We show that it is possible to increase the accuracy of two common algorithms (mode prediction and key prediction) by using music-theory-based techniques during the data preparation process. We offer methods to alter often-used Krumhansl Kessler profiles [Krumhansl and Kessler 1982], and the manner in which they are employed during preprocessing, to aid the connection of musical big data and mode or key predicting algorithms.",
      "events": [
        {
          "Background/Introduction": "",
          "Text": "This paper examines musical artificial intelligence (AI) algorithms that can not only learn from big data, but learn in ways that would be familiar to a musician or music theorist. This paper aims to find more effective links between music-related big data and artificial intelligence algorithms by incorporating principles with a strong grounding in music theory.",
          "Main Action": "examines",
          "Arguments": {
            "Agent": [
              "this paper"
            ],
            "Object": {
              "Primary Object": [
                "musical AI algorithms that can learn from big data in ways familiar to musicians or music theorists"
              ],
              "Primary Modifier": [
                "<NONE>"
              ],
              "Secondary Object": [
                "<NONE>"
              ],
              "Secondary Modifier": [
                "<NONE>"
              ]
            },
            "Context": [
              "This paper examines musical AI algorithms that can not only learn from big data, but learn in ways that would be familiar to a musician or music theorist.",
              "This paper aims to find more effective links between music-related big data and artificial intelligence algorithms by incorporating principles with a strong grounding in music theory."
            ],
            "Purpose": [
              "<NONE>"
            ],
            "Method": [
              "<NONE>"
            ],
            "Results": [
              "<NONE>"
            ],
            "Analysis": [
              "<NONE>"
            ],
            "Challenge": [
              "<NONE>"
            ],
            "Ethical": [
              "<NONE>"
            ],
            "Implications": [
              "<NONE>"
            ],
            "Contradictions": [
              "<NONE>"
            ]
          }
        },
        {
          "Methods/Approach": "",
          "Text": "We show that it is possible to increase the accuracy of two common algorithms (mode prediction and key prediction) by using music-theory-based techniques during the data preparation process. We offer methods to alter often-used Krumhansl Kessler profiles [Krumhansl and Kessler 1982], and the manner in which they are employed during preprocessing, to aid the connection of musical big data and mode or key predicting algorithms.",
          "Main Action": "show that",
          "Arguments": {
            "Agent": [
              "We"
            ],
            "Object": {
              "Primary Object": [
                "it is possible to increase the accuracy of two common algorithms (mode prediction and key prediction)"
              ],
              "Primary Modifier": [
                "<NONE>"
              ],
              "Secondary Object": [
                "by using music-theory-based techniques during the data preparation process"
              ],
              "Secondary Modifier": [
                "<NONE>"
              ]
            },
            "Context": [
              "<NONE>"
            ],
            "Purpose": [
              "<NONE>"
            ],
            "Method": [
              "offer methods to alter often-used Krumhansl Kessler profiles [... ] and the manner in which they are employed during preprocessing"
            ],
            "Results": [
              "<NONE>"
            ],
            "Analysis": [
              "<NONE>"
            ],
            "Challenge": [
              "<NONE>"
            ],
            "Ethical": [
              "<NONE>"
            ],
            "Implications": [
              "<NONE>"
            ],
            "Contradictions": [
              "<NONE>"
            ]
          }
        }
      ]
    }
  ]
}