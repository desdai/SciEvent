{
  "papers": [
    {
      "paper_code": "cscw_23_P_107",
      "abstract": "In recent years, industry leaders and researchers have proposed to use technical provenance standards to address visual misinformation spread through digitally altered media. By adding immutable and secure provenance information such as authorship and edit date to media metadata, social media users could potentially better assess the validity of the media they encounter. However, it is unclear how end users would respond to provenance information, or how to best design provenance indicators to be understandable to laypeople. We conducted an online experiment with 595 participants from the US and UK to investigate how provenance information altered users' accuracy perceptions and trust in visual content shared on social media. We found that provenance information often lowered trust and caused users to doubt deceptive media, particularly when it revealed that the media was composited. We additionally tested conditions where the provenance information itself was shown to be incomplete or invalid, and found that these states have a significant impact on participants' accuracy perceptions and trust in media, leading them, in some cases, to disbelieve honest media. Our findings show that provenance, although enlightening, is still not a concept well-understood by users, who confuse media credibility with the orthogonal (albeit related) concept of provenance credibility. We discuss how design choices may contribute to provenance (mis)understanding, and conclude with implications for usable provenance systems, including clearer interfaces and user education.",
      "events": [
        {
          "Background/Introduction": "",
          "Text": "In recent years, industry leaders and researchers have proposed to use technical provenance standards to address visual misinformation spread through digitally altered media. By adding immutable and secure provenance information such as authorship and edit date to media metadata, social media users could potentially better assess the validity of the media they encounter. However, it is unclear how end users would respond to provenance information, or how to best design provenance indicators to be understandable to laypeople.",
          "Main Action": "adding",
          "Arguments": {
            "Agent": [
              "by adding"
            ],
            "Object": {
              "Primary Object": [
                "immutable and secure provenance information such as authorship and edit date to media metadata"
              ],
              "Primary Modifier": [
                "<NONE>"
              ],
              "Secondary Object": [
                "<NONE>"
              ],
              "Secondary Modifier": [
                "<NONE>"
              ]
            },
            "Context": [
              "By adding immutable and secure provenance information such as authorship and edit date to media metadata"
            ],
            "Purpose": [
              "<NONE>"
            ],
            "Method": [
              "<NONE>"
            ],
            "Results": [
              "However, it is unclear how end users would respond to provenance information, or how to best design provenance indicators to be understandable to laypeople."
            ],
            "Analysis": [
              "Despite efforts to make provenance information robust against adversarial tampering, the lack of standardized formats complicates adoption by non-experts."
            ],
            "Challenge": [
              "<NONE>"
            ],
            "Ethical": [
              "<NONE>"
            ],
            "Implications": [
              "Adding provenance information aims to mitigate visual misinformation risks but faces hurdles due to varying levels of user comprehension and system complexity."
            ],
            "Contradictions": [
              "<NONE>"
            ]
          }
        },
        {
          "Methods/Approach": "",
          "Text": "We conducted an online experiment with 595 participants from the US and UK to investigate how provenance information altered users' accuracy perceptions and trust in visual content shared on social media.",
          "Main Action": "conducted",
          "Arguments": {
            "Agent": [
              "We"
            ],
            "Object": {
              "Primary Object": [
                "an online experiment with 595 participants from the US and UK"
              ],
              "Primary Modifier": [
                "<NONE>"
              ],
              "Secondary Object": [
                "<NONE>"
              ],
              "Secondary Modifier": [
                "<NONE>"
              ]
            },
            "Context": [
              "to investigate how provenance information altered users' accuracy perceptions and trust in visual content shared on social media."
            ],
            "Purpose": [
              "<NONE>"
            ],
            "Method": [
              "<NONE>"
            ],
            "Results": [
              "<NONE>"
            ],
            "Analysis": [
              "<NONE>"
            ],
            "Challenge": [
              "<NONE>"
            ],
            "Ethical": [
              "<NONE>"
            ],
            "Implications": [
              "<NONE>"
            ],
            "Contradictions": [
              "<NONE>"
            ]
          }
        },
        {
          "Results/Findings": "",
          "Text": "We found that provenance information often lowered trust and caused users to doubt deceptive media, particularly when it revealed that the media was composited. We additionally tested conditions where the provenance information itself was shown to be incomplete or invalid, and found that these states have a significant impact on participants' accuracy perceptions and trust in media, leading them, in some cases, to disbelieve honest media.",
          "Main Action": "found that",
          "Arguments": {
            "Agent": [
              "We"
            ],
            "Object": {
              "Primary Object": [
                "provenance information often lowered trust and caused users to doubt deceptive media"
              ],
              "Primary Modifier": [
                "<NONE>"
              ],
              "Secondary Object": [
                "particularly when it revealed that the media was composited"
              ],
              "Secondary Modifier": [
                "<NONE>"
              ]
            },
            "Context": [
              "We additionally tested conditions where the provenance information itself was shown to be incomplete or invalid, and found that these states have a significant impact on participants' accuracy perceptions and trust in media"
            ],
            "Purpose": [
              "<NONE>"
            ],
            "Method": [
              "<NONE>"
            ],
            "Results": [
              "and led them, in some cases, to disbelieve honest media"
            ],
            "Analysis": [
              "<NONE>"
            ],
            "Challenge": [
              "<NONE>"
            ],
            "Ethical": [
              "<NONE>"
            ],
            "Implications": [
              "<NONE>"
            ],
            "Contradictions": [
              "<NONE>"
            ]
          }
        },
        {
          "Conclusions/Implications": "",
          "Text": "Our findings show that provenance, although enlightening, is still not a concept well-understood by users, who confuse media credibility with the orthogonal (albeit related) concept of provenance credibility. We discuss how design choices may contribute to provenance (mis)understanding, and conclude with implications for usable provenance systems, including clearer interfaces and user education.",
          "Main Action": "showed",
          "Arguments": {
            "Agent": [
              "We"
            ],
            "Object": {
              "Primary Object": [
                "despite significant advances in understanding their behavior over the years, despite significant advances in understanding their behavior over the years, despite significant advances in understanding their behavior over the years, despite significant advances in understanding their behavior over the years"
              ],
              "Primary Modifier": [
                "<NONE>"
              ],
              "Secondary Object": [
                "<NONE>"
              ],
              "Secondary Modifier": [
                "<NONE>"
              ]
            },
            "Context": [
              "Despite significant advances in understanding their behavior over the years.",
              "Despite significant advances in understanding their behavior over the years.",
              "Despite significant advances in understanding their behavior over the years.",
              "Despite significant advances in understanding their behavior over the years."
            ],
            "Purpose": [
              "<NONE>"
            ],
            "Method": [
              "<NONE>"
            ],
            "Results": [
              "<NONE>"
            ],
            "Analysis": [
              "<NONE>"
            ],
            "Challenge": [
              "<NONE>"
            ],
            "Ethical": [
              "<NONE>"
            ],
            "Implications": [
              "<NONE>"
            ],
            "Contradictions": [
              "<NONE>"
            ]
          }
        }
      ]
    },
    {
      "paper_code": "cscw_23_P_15",
      "abstract": "While commercial conversational agents (CA) (i.e. Google assistant, Siri, Alexa) are widely used, these systems have limitations in error-handling, flexibility, personalization, and overall dialogue management that are amplified in care coordination settings. In this paper, we synthesize and articulate these limitations through quantitative and qualitative analysis of 56 older adults interacting with a commercial CA deployed in their home for a 10-week period. We look at the CA as a compensatory technology in an older adult's care network. We argue that the CA limitations are rooted in the rigid cue-and-response style of task-oriented interactions common in CAs. We then propose a redesign for CA conversation flow to favor flexibility and personalization that is nonetheless viable within the limitations of current AI and machine learning technologies. We explore design tradeoffs to better support the usability needs of older adults compared to current design optimizations driven by efficiency and privacy goals.",
      "events": [
        {
          "Background/Introduction": "",
          "Text": "While commercial conversational agents (CA) (i.e. Google Assistant, Siri, Alexa) are widely used, these systems have limitations in error-handling, flexibility, personalization, and overall dialogue management that are amplified in care coordination settings.",
          "Main Action": "<NONE>",
          "Arguments": {
            "Agent": [
              "While commercial conversational agents (CA) (i.e. Google Assistant, Siri, Alexa) are widely used"
            ],
            "Object": {
              "Primary Object": [
                "these systems have limitations in error-handling, flexibility, personalization, and overall dialogue management"
              ],
              "Primary Modifier": [
                "<NONE>"
              ],
              "Secondary Object": [
                "in care coordination settings"
              ],
              "Secondary Modifier": [
                "<NONE>"
              ]
            },
            "Context": [
              "<NONE>"
            ],
            "Purpose": [
              "<NONE>"
            ],
            "Method": [
              "<NONE>"
            ],
            "Results": [
              "<NONE>"
            ],
            "Analysis": [
              "<NONE>"
            ],
            "Challenge": [
              "<NONE>"
            ],
            "Ethical": [
              "<NONE>"
            ],
            "Implications": [
              "<NONE>"
            ],
            "Contradictions": [
              "<NONE>"
            ]
          }
        },
        {
          "Methods/Approach": "",
          "Text": "In this paper, we synthesize and articulate these limitations through quantitative and qualitative analysis of 56 older adults interacting with a commercial CA deployed in their home for a 10-week period. We look at the CA as a compensatory technology in an older adult's care network. We argue that the CA limitations are rooted in the rigid cue-and-response style of task-oriented interactions common in CAs. We then propose a redesign for CA conversation flow to favor flexibility and personalization that is nonetheless viable within the limitations of current AI and machine learning technologies. We explore design tradeoffs to better support the usability needs of older adults compared to current design optimizations driven by efficiency and privacy goals.",
          "Main Action": "synthesize and articulate",
          "Arguments": {
            "Agent": [
              "In this paper"
            ],
            "Object": {
              "Primary Object": [
                "these limitations through quantitative and qualitative analysis of 56 older adults interacting with a commercial CA deployed in their home for a 10-week period"
              ],
              "Primary Modifier": [
                "<NONE>"
              ],
              "Secondary Object": [
                "the CA as a compensatory technology in an older adult's care network"
              ],
              "Secondary Modifier": [
                "<NONE>"
              ]
            },
            "Context": [
              "we look at the CA as a compensatory technology in an older adult's care network"
            ],
            "Purpose": [
              "to examine and explain the underlying reasons behind the CA's limitations"
            ],
            "Method": [
              "quantitative and qualitative analysis of 56 older adults over a 10-week period"
            ],
            "Results": [
              "<NONE>"
            ],
            "Analysis": [
              "The CA limitations are rooted in the rigid cue-and-response style of task-oriented interactions common in CAs"
            ],
            "Challenge": [
              "We then propose a redesign for CA conversation flow to favor flexibility and personalization that is Nonetheless viable within the limitations of current AI and machine learning technologies"
            ],
            "Ethical": [
              "<NONE>"
            ],
            "Implications": [
              "We explore design tradeoffs to better support the usability needs of older adults compared to current design optimizations driven by efficiency and privacy goals"
            ],
            "Contradictions": [
              "<NONE>"
            ]
          }
        }
      ]
    }
  ]
}