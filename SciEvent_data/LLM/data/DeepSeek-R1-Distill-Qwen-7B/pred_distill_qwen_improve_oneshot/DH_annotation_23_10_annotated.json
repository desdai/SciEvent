{
  "papers": [
    {
      "paper_code": "dh_23_P_29",
      "abstract": "This paper describes a collaborative project designed to meet the needs of communities interested in Gə'əz language texts - and other under-resourced manuscript traditions - by developing an easy-to-use open-source tool that converts images of manuscript pages into a transcription using optical character recognition (OCR). Our computational tool incorporates a custom data curation process to address the language-specific facets of Gə'əz coupled with a Convolutional Recurrent Neural Network to perform the transcription. An open-source OCR transcription tool for digitized Gə'əz manuscripts can be used by students and scholars of Ethiopian manuscripts to create a substantial and computer-searchable corpus of transcribed and digitized Gə'əz texts, opening access to vital resources for sustaining the history and living culture of Ethiopia and its people. With suitable ground-truth, our open-source OCR transcription tool can also be retrained to read other under-resourced scripts. The tool we developed can be run without a graphics processing unit (GPU), meaning that it requires much less computing power than most other modern AI systems. It can be run offline from a personal computer, or accessed via a web client and potentially in the web browser of a smartphone. The paper describes our team's collaborative development of this first open-source tool for Gə'əz manuscript transcription that is both highly accurate and accessible to communities interested in Gə'əz books and the texts they contain.",
      "events": [
        {
          "Background/Introduction": "",
          "Text": "This paper describes a collaborative project designed to meet the needs of communities interested in Gə'əz language texts - and other under-resourced manuscript traditions - by developing an easy-to-use open-source tool that converts images of manuscript pages into a transcription using optical character recognition (OCR).",
          "Main Action": "converts",
          "Arguments": {
            "Agent": [
              "This paper"
            ],
            "Object": {
              "Primary Object": [
                "images of manuscript pages"
              ],
              "Secondary Object": [
                "<NONE>"
              ]
            },
            "Context": [
              "This paper describes a collaborative project designed to meet the needs of communities interested in Gə'əz language texts - and other under-resitized manuscript traditions - by developing an easy-to-use open-source tool that converts images of manuscript pages into a transcription using optical character recognition (OCR)."
            ],
            "Purpose": [
              "<NONE>"
            ],
            "Method": [
              "<NONE>"
            ],
            "Results": [
              "<NONE>"
            ],
            "Analysis": [
              "<NONE>"
            ],
            "Challenge": [
              "<NONE>"
            ],
            "Ethical": [
              "<NONE>"
            ],
            "Implications": [
              "<NONE>"
            ],
            "Contradictions": [
              "<NONE>"
            ]
          }
        },
        {
          "Methods/Approach": "",
          "Text": "Our computational tool incorporates a custom data curation process to address the language-specific facets of Gə'əz coupled with a Convolutional Recurrent Neural Network to perform the transcription. An open-source OCR transcription tool for digitized Gə'əz manuscripts can be used by students and scholars of Ethiopian manuscripts to create a substantial and computer-searchable corpus of transcribed and digitized Gə'əz texts, opening access to vital resources for sustaining the history and living culture of Ethiopia and its people.",
          "Main Action": "can be used",
          "Arguments": {
            "Agent": [
              "students and scholars of Ethiopian manuscripts"
            ],
            "Object": {
              "Primary Object": [
                "an open-source OCR transcription tool for digitized Gə'əz manuscripts can be used by students and scholars of Ethiopian manuscripts to create a substantial and computer-searchable corpus of transcribed and digitized Gə'əz texts"
              ],
              "Secondary Object": [
                "to gain access to vital resources for sustaining the history and living culture of Ethiopia and its people"
              ]
            },
            "Context": [
              "An open-source OCR transcription tool for digitized Gə'əz manuscripts can be used by students and scholars of Ethiopian manuscripts to create a substantial and computer-searchable corpus of transcribed and digitized Gə'əz texts, opening access to vital resources for sustaining the history and living culture of Ethiopia and its people."
            ],
            "Purpose": [
              "To provide students and scholars with direct access to comprehensive and structured digital versions of Gə'əz texts, thereby aiding in linguistic research and cultural preservation efforts."
            ],
            "Method": [
              "Students and scholars utilize an open-source OCR transcription tool alongside a Convolutional Recurrent Neural Network-based transcription system to convert physical manuscripts into digital formats for systematic study."
            ],
            "Results": [
              "Using this method creates a vast repository of transcribed and digitized Gə'əz texts, which expands the accessibility of these rare linguistic records and supports ongoing linguistic research initiatives."
            ],
            "Analysis": [
              "The integration of advanced AI techniques with traditional OCR tools represents a significant advancement in handling minority language literatures."
            ],
            "Challenge": [
              "There may be limitations regarding the scalability of current OCR tools specifically tailored for unique scripts like Gə'əz."
            ],
            "Ethical": [
              "The availability of such resources promotes equitable access to linguistic materials, potentially fostering greater understanding among diverse communities."
            ],
            "Implications": [
              "This development opens doors for multidisciplinary research focused on minority languages, offering new opportunities for linguistic preservation and cultural heritage documentation."
            ],
            "Contradictions": [
              "None mentioned."
            ]
          }
        },
        {
          "Results/Findings": "",
          "Text": "With suitable ground-truth, our open-source OCR transcription tool can also be retrained to read other under-resourced scripts. The tool we developed can be run without a graphics processing unit (GPU), meaning that it requires much less computing power than most other modern AI systems. It can be run offline from a personal computer, or accessed via a web client and potentially in the web browser of a smartphone.",
          "Main Action": "can be retrained",
          "Arguments": {
            "Agent": [
              "our open-source OCR transcription tool"
            ],
            "Object": {
              "Primary Object": [
                "other under-resourced scripts"
              ],
              "Secondary Object": [
                "<NONE>"
              ]
            },
            "Context": [
              "With suitable ground-truth"
            ],
            "Purpose": [
              "<NONE>"
            ],
            "Method": [
              "<NONE>"
            ],
            "Results": [
              "<NONE>"
            ],
            "Analysis": [
              "<NONE>"
            ],
            "Challenge": [
              "<NONE>"
            ],
            "Ethical": [
              "<NONE>"
            ],
            "Implications": [
              "<NONE>"
            ],
            "Contradictions": [
              "<NONE>"
            ]
          }
        },
        {
          "Conclusions/Implications": "ERROR",
          "Text": "The paper describes our team's collaborative development of this first open-source tool for Gə'əz manuscript transcription that is both highly accurate and accessible to communities interested in Gə'əz books and the texts they contain.",
          "Main Action": "ERROR",
          "Arguments": {
            "Agent": [
              "ERROR"
            ],
            "Object": {
              "Primary Object": [
                "ERROR"
              ],
              "Secondary Object": [
                "ERROR"
              ]
            },
            "Context": [
              "ERROR"
            ],
            "Purpose": [
              "ERROR"
            ],
            "Method": [
              "ERROR"
            ],
            "Results": [
              "ERROR"
            ],
            "Analysis": [
              "ERROR"
            ],
            "Challenge": [
              "ERROR"
            ],
            "Ethical": [
              "ERROR"
            ],
            "Implications": [
              "ERROR"
            ],
            "Contradictions": [
              "ERROR"
            ]
          },
          "Error_Type": "NO_JSON_FOUND"
        }
      ]
    },
    {
      "paper_code": "dh_23_P_50",
      "abstract": "The article sets up a critique of Sentiment Analysis (SA) tools in literary studies, both from a theoretical and a computational point of view. In the first section, a possible use of SA in narratology and reader response studies is discussed, highlighting the gaps between literary theories and computational models, and suggesting possible solutions to fill them. In the second section, a stratified taxonomy of SA tools is proposed, which distinguishes: (1) the emotion theory adopted by the tool; (2) the method used to build the emotion resources; (3) the technique adopted to accomplish the analysis. A critical survey of six representative SA tools for literary studies (Syuzhet, Vader, SentiArt, SEANCE, Stanford SA, and Transformers Pipelines) closes the article.",
      "events": [
        {
          "Background/Introduction": "ERROR",
          "Text": "The article sets up a critique of Sentiment Analysis (SA) tools in literary studies, both from a theoretical and a computational point of view.",
          "Main Action": "ERROR",
          "Arguments": {
            "Agent": [
              "ERROR"
            ],
            "Object": {
              "Primary Object": [
                "ERROR"
              ],
              "Secondary Object": [
                "ERROR"
              ]
            },
            "Context": [
              "ERROR"
            ],
            "Purpose": [
              "ERROR"
            ],
            "Method": [
              "ERROR"
            ],
            "Results": [
              "ERROR"
            ],
            "Analysis": [
              "ERROR"
            ],
            "Challenge": [
              "ERROR"
            ],
            "Ethical": [
              "ERROR"
            ],
            "Implications": [
              "ERROR"
            ],
            "Contradictions": [
              "ERROR"
            ]
          },
          "Error_Type": "RECONSTRUCTION_ERROR"
        },
        {
          "Methods/Approach": "",
          "Text": "In the first section, a possible use of SA in narratology and reader response studies is discussed, highlighting the gaps between literary theories and computational models, and suggesting possible solutions to fill them. In the second section, a stratified taxonomy of SA tools is proposed, which distinguishes: (1) the emotion theory adopted by the tool; (2) the method used to build the emotion resources; (3) the technique adopted to accomplish the analysis.",
          "Main Action": "discussing",
          "Arguments": {
            "Agent": [
              "researchers"
            ],
            "Object": {
              "Primary Object": [
                "a possible use of SA in narratology and reader response studies"
              ],
              "Secondary Object": [
                "the gaps between literary theories and computational models"
              ]
            },
            "Context": [
              "highlighting the gaps between literary theories and computational models",
              "and suggesting possible solutions to fill them"
            ],
            "Purpose": [
              "to explore and address discrepancies between traditional literary theories and modern computational modeling approaches in the application of speech analysis (SA)",
              "and to propose innovative strategies or methodologies that bridge these divides"
            ],
            "Method": [
              "proposing a stratified taxonomy of SA tools",
              "which distinguishes three main dimensions: the emotion theory adopted by the tool, the method used to build emotion resources, and the technique employed to perform analysis."
            ],
            "Results": [
              "highlighting the gaps between literary theories and computational models",
              "and suggesting possible solutions to fill them"
            ],
            "Analysis": [
              "proposing a stratified taxonomy of SA tools",
              "which distinguishes three main dimensions: the emotion theory adopted by the tool, the method used to build emotion resources, and the technique employed to perform analysis."
            ],
            "Challenge": [
              "addressing the gap between theoretical frameworks and practical computational implementations",
              "and proposing a unified framework that integrates diverse analytical approaches under a common methodology"
            ],
            "Ethical": [
              "exploring the ethical implications of integrating speech analysis tools into literary studies",
              "considering cultural sensitivity and representativeness in computational models"
            ],
            "Implications": [
              "potentially enhancing interdisciplinary collaboration between linguists, computer scientists, and literary scholars",
              "thereby advancing our understanding of linguistic structures and their expression in written form"
            ],
            "Contradictions": [
              "<NONE>"
            ]
          }
        },
        {
          "Results/Findings": "",
          "Text": "A critical survey of six representative SA tools for literary studies (Syuzhet, Vader, SentiArt, SEANCE, Stanford SA, and Transformers Pipelines) closes the article.",
          "Main Action": "closes the article",
          "Arguments": {
            "Agent": [
              "six representative SA tools"
            ],
            "Object": {
              "Primary Object": [
                "<NONE>"
              ],
              "Secondary Object": [
                "<NONE>"
              ]
            },
            "Context": [
              "A critical survey of six representative SA tools ... recent advances in neural machine translation"
            ],
            "Purpose": [
              "To compare and evaluate the effectiveness of these tools against a baseline method"
            ],
            "Method": [
              "<NONE>"
            ],
            "Results": [
              "<NONE>"
            ],
            "Analysis": [
              "<NONE>"
            ],
            "Challenge": [
              "<NONE>"
            ],
            "Ethical": [
              "<NONE>"
            ],
            "Implications": [
              "<NONE>"
            ],
            "Contradictions": [
              "<NONE>"
            ]
          }
        }
      ]
    }
  ]
}