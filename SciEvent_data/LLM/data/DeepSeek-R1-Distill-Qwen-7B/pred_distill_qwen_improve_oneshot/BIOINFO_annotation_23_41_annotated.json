{
  "papers": [
    {
      "paper_code": "bioinfo_23_P_742",
      "abstract": "There is a growing number of available protein sequences, but only a limited amount has been manually annotated. For example, only 0.25% of all entries of UniProtKB are reviewed by human annotators. Further developing automatic tools to infer protein function from sequence alone can alleviate part of this gap. In this article, we investigate the potential of Transformer deep neural networks on a specific case of functional sequence annotation: the prediction of enzymatic classes. We show that our EnzBert transformer models, trained to predict Enzyme Commission (EC) numbers by specialization of a protein language model, outperforms state-of-the-art tools for monofunctional enzyme class prediction based on sequences only. Accuracy is improved from 84% to 95% on the prediction of EC numbers at level two on the EC40 benchmark. To evaluate the prediction quality at level four, the most detailed level of EC numbers, we built two new time-based benchmarks for comparison with state-of-the-art methods ECPred and DeepEC: the macro-F1 score is respectively improved from 41% to 54% and from 20% to 26%. Finally, we also show that using a simple combination of attention maps is on par with, or better than, other classical interpretability methods on the EC prediction task. More specifically, important residues identified by attention maps tend to correspond to known catalytic sites. Quantitatively, we report a max F-Gain score of 96.05%, while classical interpretability methods reach 91.44% at best.",
      "events": [
        {
          "Background/Introduction": "",
          "Text": "There is a growing number of available protein sequences, but only a limited amount has been manually annotated. For example, only 0.25% of all entries of UniProtKB are reviewed by human annotators. Further developing automatic tools to infer protein function from sequence alone can alleviate part of this gap.",
          "Main Action": "grows",
          "Arguments": {
            "Agent": [
              "A large number of protein sequences"
            ],
            "Object": {
              "Primary Object": [
                "have grown substantially over recent years"
              ],
              "Secondary Object": [
                "<NONE>"
              ]
            },
            "Context": [
              "Only 0.25% of all entries inUniProtKB are reviewed by human annotators."
            ],
            "Purpose": [
              "To highlight the urgent need for improved automated tools to infer protein function from sequence data alone to address the gap caused by inadequate manual annotation."
            ],
            "Method": [
              "<NONE>"
            ],
            "Results": [
              "Further developments in automatic tools to infer protein function from sequence data alone can alleviate part of this gap"
            ],
            "Analysis": [
              "The scale of the problem underscores the importance of efficient computational methods in molecular biology."
            ],
            "Challenge": [
              "The fundamental difficulty in reliably predicting protein function purely from sequence data without substantial contextual information."
            ],
            "Ethical": [
              "<NONE>"
            ],
            "Implications": [
              "Improved automated tools could lead to more accurate functional predictions and facilitate comparative analyses across diverse biological systems."
            ],
            "Contradictions": [
              "<NONE>"
            ]
          }
        },
        {
          "Methods/Approach": "",
          "Text": "In this article, we investigate the potential of Transformer deep neural networks on a specific case of functional sequence annotation: the prediction of enzymatic classes. We show that our EnzBert transformer models, trained to predict Enzyme Commission (EC) numbers by specialization of a protein language model, outperforms state-of-the-art tools for monofunctional enzyme class prediction based on sequences only.",
          "Main Action": "compare",
          "Arguments": {
            "Agent": [
              "we evaluate"
            ],
            "Object": {
              "Primary Object": [
                "our EnzBert models ... performance against state-of-the-art tools"
              ],
              "Secondary Object": [
                "<NONE>"
              ]
            },
            "Context": [
              "<NONE>"
            ],
            "Purpose": [
              "<NONE>"
            ],
            "Method": [
              "<NONE>"
            ],
            "Results": [
              "Our EnzBert models, trained to predict enzymic ECs via specialized protein language modeling, achieve superior performance compared to BLAST+ baseline searches for monofunctional enzymes."
            ],
            "Analysis": [
              "<NONE>"
            ],
            "Challenge": [
              "<NONE>"
            ],
            "Ethical": [
              "<NONE>"
            ],
            "Implications": [
              "<NONE>"
            ],
            "Contradictions": [
              "<NONE>"
            ]
          }
        },
        {
          "Results/Findings": "",
          "Text": "Accuracy is improved from 84% to 95% on the prediction of EC numbers at level two on the EC40 benchmark. To evaluate the prediction quality at level four, the most detailed level of EC numbers, we built two new time-based benchmarks for comparison with state-of-the-art methods ECPred and DeepEC: the macro-F1 score is respectively improved from 41% to 54% and from 20% to 26%. Finally, we also show that using a simple combination of attention maps is on par with, or better than, other classical interpretability methods on the EC prediction task. More specifically, important residues identified by attention maps tend to correspond to known catalytic sites. Quantitatively, we report a max F-Gain score of 96.05%, while classical interpretability methods reach 91.44% at best.",
          "Main Action": "reporting",
          "Arguments": {
            "Agent": [
              "researchers"
            ],
            "Object": {
              "Primary Object": [
                "quantitatively, we report a max f-gain score of 96.05%",
                "important residues identified by attention maps tend to correspond to known catalytic sites"
              ],
              "Secondary Object": [
                "<NONE>"
              ]
            },
            "Context": [
              "while the prediction quality was evaluated at level two initially"
            ],
            "Purpose": [
              "to demonstrate the effectiveness of a simple combination of attention maps over traditional interpretability methods in ec number prediction tasks"
            ],
            "Method": [
              "building two new time-based benchmarks for comparison with state-of-the-art methods ecpred and deepec"
            ],
            "Results": [
              "we achieve a max f-gain score of 96.05% using our novel approach with attention maps"
            ],
            "Analysis": [
              "important residues identified by attention maps correlate well with known catalytic sites"
            ],
            "Challenge": [
              "none"
            ],
            "Ethical": [
              "none"
            ],
            "Implications": [
              "our findings suggest that leveraging advanced interpretability techniques like attention maps can significantly boost predictive accuracy in enzyme-related studies"
            ],
            "Contradictions": [
              "none"
            ]
          }
        }
      ]
    },
    {
      "paper_code": "bioinfo_23_P_277",
      "abstract": "Sequence alignment is a memory bound computation whose performance in modern systems is limited by the memory bandwidth bottleneck. Processing-in-memory (PIM) architectures alleviate this bottleneck by providing the memory with computing competencies. We propose Alignment-in-Memory (AIM), a framework for high-throughput sequence alignment using PIM, and evaluate it on UPMEM, the first publicly available general-purpose programmable PIM system. Our evaluation shows that a real PIM system can substantially outperform server-grade multi-threaded CPU systems running at full-scale when performing sequence alignment for a variety of algorithms, read lengths, and edit distance thresholds. We hope that our findings inspire more work on creating and accelerating bioinformatics algorithms for such real PIM systems.",
      "events": [
        {
          "Background/Introduction": "",
          "Text": "Sequence alignment is a memory bound computation whose performance in modern systems is limited by the memory bandwidth bottleneck. Processing-in-memory (PIM) architectures alleviate this bottleneck by providing the memory with computing competencies.",
          "Main Action": "whose performance ... is limited by the memory bandwidth bottleneck.",
          "Arguments": {
            "Agent": [
              "Processing-in-memory (PIM) architectures"
            ],
            "Object": {
              "Primary Object": [
                "memory bandwidth bottleneck"
              ],
              "Secondary Object": [
                "<NONE>"
              ]
            },
            "Context": [
              "Sequence alignment is a memory bound computation whose performance in modern systems is limited by the memory bandwidth bottleneck."
            ],
            "Purpose": [
              "<NONE>"
            ],
            "Method": [
              "<NONE>"
            ],
            "Results": [
              "<NONE>"
            ],
            "Analysis": [
              "<NONE>"
            ],
            "Challenge": [
              "<NONE>"
            ],
            "Ethical": [
              "<NONE>"
            ],
            "Implications": [
              "The introduction of PIM architectures represents a significant advancement toward mitigating memory-bound computations, potentially revolutionizing areas reliant on efficient memory utilization."
            ],
            "Contradictions": [
              "<NONE>"
            ]
          }
        },
        {
          "Methods/Approach": "",
          "Text": "We propose Alignment-in-Memory (AIM), a framework for high-throughput sequence alignment using PIM, and evaluate it on UPMEM, the first publicly available general-purpose programmable PIM system",
          "Main Action": "evaluate",
          "Arguments": {
            "Agent": [
              "We"
            ],
            "Object": {
              "Primary Object": [
                "Alignment-in-Memory (AIM)"
              ],
              "Secondary Object": [
                "UP_MEM"
              ]
            },
            "Context": [
              "<NONE>"
            ],
            "Purpose": [
              "<NONE>"
            ],
            "Method": [
              "<NONE>"
            ],
            "Results": [
              "<NONE>"
            ],
            "Analysis": [
              "<NONE>"
            ],
            "Challenge": [
              "<NONE>"
            ],
            "Ethical": [
              "<NONE>"
            ],
            "Implications": [
              "<NONE>"
            ],
            "Contradictions": [
              "<NONE>"
            ]
          }
        },
        {
          "Results/Findings": "",
          "Text": "Our evaluation shows that a real PIM system can substantially outperform server-grade multi-threaded CPU systems running at full-scale when performing sequence alignment for a variety of algorithms, read lengths, and edit distance thresholds.",
          "Main Action": "shows",
          "Arguments": {
            "Agent": [
              "Our evaluation"
            ],
            "Object": {
              "Primary Object": [
                "server-grade multi-threaded CPU systems running at full-scale"
              ],
              "Secondary Object": [
                "when performing sequence alignment for a variety of algorithms, read lengths, and edit distance thresholds"
              ]
            },
            "Context": [
              "high-throughput sequencing data processing and complex alignments often encountered in bioinformatics studies"
            ],
            "Purpose": [
              "<NONE>"
            ],
            "Method": [
              "<NONE>"
            ],
            "Results": [
              "Our evaluation shows that a real PIM system can substantially outperform server-grade multi-threaded CPU systems running at full-scale when performing sequence alignment for a variety of algorithms, read lengths, and edit distance thresholds."
            ],
            "Analysis": [
              "<NONE>"
            ],
            "Challenge": [
              "<NONE>"
            ],
            "Ethical": [
              "<NONE>"
            ],
            "Implications": [
              "The findings imply that PIM systems offer significant advantages in handling large-scale genomic analyses requiring efficient processing capabilities, suggesting a shift toward specialized hardware solutions in biocomputing domains."
            ],
            "Contradictions": [
              "<NONE>"
            ]
          }
        },
        {
          "Conclusions/Implications": "",
          "Text": "We hope that our findings inspire more work on creating and accelerating bioinformatics algorithms for such real PIM systems.",
          "Main Action": "We hope that our findings",
          "Arguments": {
            "Agent": [
              "We"
            ],
            "Object": {
              "Primary Object": [
                "foster more work on creating and accelerating bioinformatics algorithms for such real PIM systems"
              ],
              "Secondary Object": [
                "<NONE>"
              ]
            },
            "Context": [
              "<NONE>"
            ],
            "Purpose": [
              "<NONE>"
            ],
            "Method": [
              "<NONE>"
            ],
            "Results": [
              "<NONE>"
            ],
            "Analysis": [
              "<NONE>"
            ],
            "Challenge": [
              "<NONE>"
            ],
            "Ethical": [
              "<NONE>"
            ],
            "Implications": [
              "<NONE>"
            ],
            "Contradictions": [
              "<NONE>"
            ]
          }
        }
      ]
    }
  ]
}