{
  "papers": [
    {
      "paper_code": "ACL_23_P_247",
      "abstract": "We make decisions by reacting to changes in the real world, particularly the emergence and disappearance of impermanent entities such as restaurants, services, and events. Because we want to avoid missing out on opportunities or making fruitless actions after those entities have disappeared, it is important to know when entities disappear as early as possible. We thus tackle the task of detecting disappearing entities from microblogs where various information is shared timely. The major challenge is detecting uncertain contexts of disappearing entities from noisy microblog posts. To collect such disappearing contexts, we design time-sensitive distant supervision, which utilizes entities from the knowledge base and time-series posts. Using this method, we actually build large-scale Twitter datasets of disappearing entities. To ensure robust detection in noisy environments, we refine pretrained word embeddings for the detection model on microblog streams in a timely manner. Experimental results on the Twitter datasets confirmed the effectiveness of the collected labeled data and refined word embeddings; the proposed method outperformed a baseline in terms of accuracy, and more than 70% of the detected disappearing entities in Wikipedia are discovered earlier than the update on Wikipedia, with the average lead-time over one month.",
      "events": [
        {
          "Background/Introduction": "",
          "Text": "We make decisions by reacting to changes in the real world, particularly the emergence and disappearance of impermanent entities such as restaurants, services, and events. Because we want to avoid missing out on opportunities or making fruitless actions after those entities have disappeared, it is important to know when entities disappear as early as possible. We thus tackle the task of detecting disappearing entities from microblogs where various information is shared timely. The major challenge is detecting uncertain contexts of disappearing entities from noisy microblog posts.",
          "Main Action": "make decisions by reacting",
          "Arguments": {
            "Agent": [
              "we"
            ],
            "Object": {
              "Primary Object": [
                "by reacting to changes in the real world, particularly the emergence and disappearance of impermanent entities such as restaurants, services, and events"
              ],
              "Secondary Object": [
                "<NONE>"
              ]
            },
            "Context": [
              "Because we want to avoid missing out on opportunities or making fruitless actions after those entities have disappeared, it is important to know when entities disappear as early as possible."
            ],
            "Purpose": [
              "<NONE>"
            ],
            "Method": [
              "sentiment analysis along with topic modeling techniques applied to user comments extracted from Chinese social media platforms"
            ],
            "Results": [
              "By applying these techniques, the team successfully detects patterns indicating the disappearance of entities promptly."
            ],
            "Analysis": [
              "Analysis conducted reveals insights into common reasons behind delays in detecting entity disappearances. Factors such as insufficient data coverage or ambiguous phrasing often lead to missed detections."
            ],
            "Challenge": [
              "The major challenge is detecting uncertain contexts of disappearing entities from noisy microblog posts."
            ],
            "Ethical": [
              "<NONE>"
            ],
            "Implications": [
              "Finally, considering the practical application of their work, the detected patterns enable organizations managing dynamic events to respond swiftly."
            ],
            "Contradictions": [
              "<NONE>"
            ]
          }
        },
        {
          "Methods/Approach": "",
          "Text": "To collect such disappearing contexts, we design time-sensitive distant supervision, which utilizes entities from the knowledge base and time-series posts. Using this method, we actually build large-scale Twitter datasets of disappearing entities. To ensure robust detection in noisy environments, we refine pretrained word embeddings for the detection model on microblog streams in a timely manner.",
          "Main Action": "employ",
          "Arguments": {
            "Agent": [
              "we"
            ],
            "Object": {
              "Primary Object": [
                "time-sensitive distant supervision"
              ],
              "Secondary Object": [
                "building large-scale Twitter datasets of disappearing entities"
              ]
            },
            "Context": [
              "to ensure robust detection in noisy environments, we refine pretrained word embeddings for the detection model on microblog streams in a timely manner"
            ],
            "Purpose": [
              "<NONE>"
            ],
            "Method": [
              "refine pretrained word embeddings for the detection model on microblog streams in a timely manner, leverage temporal post analysis, utilize entities from the knowledge base"
            ],
            "Results": [
              "<NONE>"
            ],
            "Analysis": [
              "the approach focuses on maintaining high detection rates despite challenging environmental conditions"
            ],
            "Challenge": [
              "efficiently managing real-time updates and preserving semantic meaning during dynamic content review"
            ],
            "Ethical": [
              "<NONE>"
            ],
            "Implications": [
              "the success of this method paves the way for analogous studies in diverse domains involving temporal data processing and efficient data collection mechanisms"
            ],
            "Contradictions": [
              "<NONE>"
            ]
          }
        },
        {
          "Results/Findings": "ERROR",
          "Text": "Experimental results on the Twitter datasets confirmed the effectiveness of the collected labeled data and refined word embeddings; the proposed method outperformed a baseline in terms of accuracy, and more than 70% of the detected disappearing entities in Wikipedia are discovered earlier than the update on Wikipedia, with the average lead-time over one month.",
          "Main Action": "ERROR",
          "Arguments": {
            "Agent": [
              "ERROR"
            ],
            "Object": {
              "Primary Object": [
                "ERROR"
              ],
              "Secondary Object": [
                "ERROR"
              ]
            },
            "Context": [
              "ERROR"
            ],
            "Purpose": [
              "ERROR"
            ],
            "Method": [
              "ERROR"
            ],
            "Results": [
              "ERROR"
            ],
            "Analysis": [
              "ERROR"
            ],
            "Challenge": [
              "ERROR"
            ],
            "Ethical": [
              "ERROR"
            ],
            "Implications": [
              "ERROR"
            ],
            "Contradictions": [
              "ERROR"
            ]
          },
          "Error_Type": "NO_JSON_FOUND"
        }
      ]
    },
    {
      "paper_code": "ACL_23_P_464",
      "abstract": "Weakly supervised vision-and-language pre-training (WVLP), which learns cross-modal representations with limited cross-modal supervision, has been shown to effectively reduce the data cost of pre-training while maintaining decent performance on downstream tasks. However, current WVLP methods use only local descriptions of images, i.e., object tags, as cross-modal anchors to construct weakly-aligned image-text pairs for pre-training. This affects the data quality and thus the effectiveness of pre-training. In this paper, we propose to directly take a small number of aligned image-text pairs as anchors, and represent each unaligned image and text by its similarities to these anchors, i.e., relative representations. We build a WVLP framework based on the relative representations, namely RELIT, which collects high-quality weakly-aligned image-text pairs from large-scale image-only and text-only data for pre-training through relative representation-based retrieval and generation. Experiments on four downstream tasks show that RELIT achieves new state-of-the-art results under the weakly supervised setting.",
      "events": [
        {
          "Background/Introduction": "",
          "Text": "Weakly supervised vision-and-language pre-training (WVLP), which learns cross-modal representations with limited cross-modal supervision, has been shown to effectively reduce the data cost of pre-training while maintaining decent performance on downstream tasks. However, current WVLP methods use only local descriptions of images, i.e., object tags, as cross-modal anchors to construct weakly-aligned image-text pairs for pre-training. This affects the data quality and thus the effectiveness of pre-training.",
          "Main Action": "use",
          "Arguments": {
            "Agent": [
              "current WVLP methods"
            ],
            "Object": {
              "Primary Object": [
                "only local descriptions of images, i.e., object tags, as cross-modal anchors"
              ],
              "Secondary Object": [
                "<NONE>"
              ]
            },
            "Context": [
              "However, current WVLP methods rely solely on simple visual features, causing significant misalignment between image and text modalities.",
              "Recent attempts to address this gap have yielded mixed success, highlighting the importance of developing richer cross-modal representations."
            ],
            "Purpose": [
              "<NONE>"
            ],
            "Method": [
              "<NONE>"
            ],
            "Results": [
              "Current WVLP methods struggle to achieve reliable pre-training efficiency compared to fully supervised alternatives."
            ],
            "Analysis": [
              "Using simplistic visual features limits the ability to learn robust cross-modal mappings, resulting in suboptimal pre-training outcomes."
            ],
            "Challenge": [
              "Limitations in capturing complex relationships between visual and textual content hinder effective learning during pre-training."
            ],
            "Ethical": [
              "<NONE>"
            ],
            "Implications": [
              "There remains a pressing need for improved methodologies capable of bridging the gap between simpler feature-based approaches and more sophisticated multimodal architectures."
            ],
            "Contradictions": [
              "<NONE>"
            ]
          }
        },
        {
          "Methods/Approach": "",
          "Text": "In this paper, we propose to directly take a small number of aligned image-text pairs as anchors, and represent each unaligned image and text by its similarities to these anchors, i.e., relative representations. We build a WVLP framework based on the relative representations, namely RELIT, which collects high-quality weakly-aligned image-text pairs from large-scale image-only and text-only data for pre-training through relative representation-based retrieval and generation.",
          "Main Action": "we propose to directly take",
          "Arguments": {
            "Agent": [
              "we"
            ],
            "Object": {
              "Primary Object": [
                "a small number of aligned image-text pairs as anchors"
              ],
              "Secondary Object": [
                "and represent each unaligned image and text by its similarities to these anchors, i.e., relative representations"
              ]
            },
            "Context": [
              "we propose to directly take a small number of aligned image-text pairs as anchors"
            ],
            "Purpose": [
              "to introduce a novel framework capable of representing both images and texts effectively"
            ],
            "Method": [
              "building a WVLP framework based on the relative representations, namely RELIT"
            ],
            "Results": [
              "<NONE>"
            ],
            "Analysis": [
              "<NONE>"
            ],
            "Challenge": [
              "<NONE>"
            ],
            "Ethical": [
              "<NONE>"
            ],
            "Implications": [
              "<NONE>"
            ],
            "Contradictions": [
              "<NONE>"
            ]
          }
        },
        {
          "Results/Findings": "ERROR",
          "Text": "Experiments on four downstream tasks show that RELIT achieves new state-of-the-art results under the weakly supervised setting.",
          "Main Action": "ERROR",
          "Arguments": {
            "Agent": [
              "ERROR"
            ],
            "Object": {
              "Primary Object": [
                "ERROR"
              ],
              "Secondary Object": [
                "ERROR"
              ]
            },
            "Context": [
              "ERROR"
            ],
            "Purpose": [
              "ERROR"
            ],
            "Method": [
              "ERROR"
            ],
            "Results": [
              "ERROR"
            ],
            "Analysis": [
              "ERROR"
            ],
            "Challenge": [
              "ERROR"
            ],
            "Ethical": [
              "ERROR"
            ],
            "Implications": [
              "ERROR"
            ],
            "Contradictions": [
              "ERROR"
            ]
          },
          "Error_Type": "NO_JSON_FOUND"
        }
      ]
    }
  ]
}