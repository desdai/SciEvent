{
  "papers": [
    {
      "paper_code": "ACL_23_P_404",
      "abstract": "Complaining is an illocutionary act in which the speaker communicates his/her dissatisfaction with a set of circumstances and holds the hearer (the complainee) answerable, directly or indirectly. Considering breakthroughs in machine learning approaches, the complaint detection task has piqued the interest of the natural language processing (NLP) community. Most of the earlier studies failed to justify their findings, necessitating the adoption of interpretable models that can explain the model’s output in real time. We introduce an explainable complaint dataset, X-CI, the first benchmark dataset for explainable complaint detection. Each instance in the X-CI dataset is annotated with five labels: complaint label, emotion label, polarity label, complaint severity level, and rationale (explainability), i.e., the causal span explaining the reason for the complaint/non-complaint label. We address the task of explainable complaint detection and propose a commonsense-aware unified generative framework by reframing the multitask problem as a text-to-text generation task. Our framework can predict the complaint cause, severity level, emotion, and polarity of the text in addition to detecting whether it is a complaint or not. We further establish the advantages of our proposed model on various evaluation metrics over the state-of-the-art models and other baselines when applied to the X-CI dataset in both full and few-shot settings.",
      "events": [
        {
          "Background/Introduction": "",
          "Text": "Complaining is an illocutionary act in which the speaker communicates his/her dissatisfaction with a set of circumstances and holds the hearer (the complainee) answerable, directly or indirectly. Considering breakthroughs in machine learning approaches, the complaint detection task has piqued the interest of the natural language processing (NLP) community. Most of the earlier studies failed to justify their findings, necessitating the adoption of interpretable models that can explain the model’s output in real time.",
          "Main Action": "recent breakthroughs in machine learning approaches lead researchers to focus",
          "Arguments": {
            "Agent": [
              "researchers"
            ],
            "Object": {
              "Primary Object": [
                "on creating interpretable models to explain the model's output in real time"
              ],
              "Secondary Object": [
                "<NONE>"
              ]
            },
            "Context": [
              "while advances in machine learning have improved various NLP tasks including complaint detection many models remain opaque making it difficult to trust and debug them effectively"
            ],
            "Purpose": [
              "to highlight the importance of model interpretability in overcoming the limitations of existing approaches"
            ],
            "Method": [
              "early studies failed to validate their findings necessitating the development of alternative strategies"
            ],
            "Results": [
              "Indeed recent advancements demonstrate the capability of machine learning algorithms to achieve higher accuracy in detecting complaints compared to traditional methods"
            ],
            "Analysis": [
              "However despite these improvements challenges persist in providing clear explanations for complex decision-making processes inherent in automated systems"
            ],
            "Challenge": [
              "existing models often rely on intricate patterns learned automatically leaving little room for human intervention or insight"
            ],
            "Ethical": [
              "there remains concern about the potential misuse of biased or manipulated datasets affecting fairness and reliability of automated systems"
            ],
            "Implications": [
              "this underscores the urgent need for transparent trustworthy and accountable AI technologies in public services where decisions impact individuals lives extensively"
            ],
            "Contradictions": [
              "<NONE>"
            ]
          }
        },
        {
          "Methods/Approach": "ERROR",
          "Text": "We introduce an explainable complaint dataset, X-CI, the first benchmark dataset for explainable complaint detection. Each instance in the X-CI dataset is annotated with five labels: complaint label, emotion label, polarity label, complaint severity level, and rationale (explainability), i.e., the causal span explaining the reason for the complaint/non-complaint label. We address the task of explainable complaint detection and propose a commonsense-aware unified generative framework by reframing the multitask problem as a text-to-text generation task. Our framework can predict the complaint cause, severity level, emotion, and polarity of the text in addition to detecting whether it is a complaint or not.",
          "Main Action": "ERROR",
          "Arguments": {
            "Agent": [
              "ERROR"
            ],
            "Object": {
              "Primary Object": [
                "ERROR"
              ],
              "Secondary Object": [
                "ERROR"
              ]
            },
            "Context": [
              "ERROR"
            ],
            "Purpose": [
              "ERROR"
            ],
            "Method": [
              "ERROR"
            ],
            "Results": [
              "ERROR"
            ],
            "Analysis": [
              "ERROR"
            ],
            "Challenge": [
              "ERROR"
            ],
            "Ethical": [
              "ERROR"
            ],
            "Implications": [
              "ERROR"
            ],
            "Contradictions": [
              "ERROR"
            ]
          },
          "Error_Type": "RECONSTRUCTION_ERROR"
        },
        {
          "Results/Findings": "",
          "Text": "We further establish the advantages of our proposed model on various evaluation metrics over the state-of-the-art models and other baselines when applied to the X-CI dataset in both full and few-shot settings.",
          "Main Action": "further establish",
          "Arguments": {
            "Agent": [
              "We"
            ],
            "Object": {
              "Primary Object": [
                "the advantages of our proposed model on various evaluation metrics over the state-of-the-art models and other baselines when applied to the X-CI dataset in both full and few-shot settings"
              ],
              "Secondary Object": [
                "<NONE>"
              ]
            },
            "Context": [
              "<NONE>"
            ],
            "Purpose": [
              "<NONE>"
            ],
            "Method": [
              "<NONE>"
            ],
            "Results": [
              "We further establish the advantages of our proposed model on various evaluation metrics over the state-of-the-art models and other baselines when applied to the X-CI dataset in both full and few-shot settings."
            ],
            "Analysis": [
              "<NONE>"
            ],
            "Challenge": [
              "<NONE>"
            ],
            "Ethical": [
              "<NONE>"
            ],
            "Implications": [
              "<NONE>"
            ],
            "Contradictions": [
              "<NONE>"
            ]
          }
        }
      ]
    },
    {
      "paper_code": "ACL_23_P_532",
      "abstract": "Document-level event argument extraction aims to identify event arguments beyond sentence level, where a significant challenge is to model long-range dependencies. Focusing on this challenge, we present a new chain reasoning paradigm for the task, which can generate decomposable first-order logic rules for reasoning. This paradigm naturally captures long-range interdependence due to the chains’ compositional nature, which also improves interpretability by explicitly modeling the reasoning process. We introduce T-norm fuzzy logic for optimization, which permits end-to-end learning and shows promise for integrating the expressiveness of logical reasoning with the generalization of neural networks. In experiments, we show that our approach outperforms previous methods by a significant margin on two standard benchmarks (over 6 points in F1). Moreover, it is data-efficient in low-resource scenarios and robust enough to defend against adversarial attacks.",
      "events": [
        {
          "Background/Introduction": "",
          "Text": "Document-level event argument extraction aims to identify event arguments beyond sentence level, where a significant challenge is to model long-range dependencies.",
          "Main Action": "aims to identify",
          "Arguments": {
            "Agent": [
              "[Document-level event argument extraction]"
            ],
            "Object": {
              "Primary Object": [
                "<NONE>"
              ],
              "Secondary Object": [
                "<NONE>"
              ]
            },
            "Context": [
              "where a significant challenge is to model long-range dependencies"
            ],
            "Purpose": [
              "<NONE>"
            ],
            "Method": [
              "<NONE>"
            ],
            "Results": [
              "<NONE>"
            ],
            "Analysis": [
              "<NONE>"
            ],
            "Challenge": [
              "<NONE>"
            ],
            "Ethical": [
              "<NONE>"
            ],
            "Implications": [
              "<NONE>"
            ],
            "Contradictions": [
              "<NONE>"
            ]
          }
        },
        {
          "Methods/Approach": "",
          "Text": "Focusing on this challenge, we present a new chain reasoning paradigm for the task, which can generate decomposable first-order logic rules for reasoning. This paradigm naturally captures long-range interdependence due to the chains’ compositional nature, which also improves interpretability by explicitly modeling the reasoning process. We introduce T-norm fuzzy logic for optimization, which permits end-to-end learning and shows promise for integrating the expressiveness of logical reasoning with the generalization of neural networks.",
          "Main Action": "<NONE>",
          "Arguments": {
            "Agent": [
              "<NONE>"
            ],
            "Object": {
              "Primary Object": [
                "<NONE>"
              ],
              "Secondary Object": [
                "<NONE>"
              ]
            },
            "Context": [
              "<NONE>"
            ],
            "Purpose": [
              "<NONE>"
            ],
            "Method": [
              "<NONE>"
            ],
            "Results": [
              "<NONE>"
            ],
            "Analysis": [
              "<NONE>"
            ],
            "Challenge": [
              "<NONE>"
            ],
            "Ethical": [
              "<NONE>"
            ],
            "Implications": [
              "<NONE>"
            ],
            "Contradictions": [
              "<NONE>"
            ]
          }
        },
        {
          "Results/Findings": "ERROR",
          "Text": "In experiments, we show that our approach outperforms previous methods by a significant margin on two standard benchmarks (over 6 points in F1). Moreover, it is data-efficient in low-resource scenarios and robust enough to defend against adversarial attacks.",
          "Main Action": "ERROR",
          "Arguments": {
            "Agent": [
              "ERROR"
            ],
            "Object": {
              "Primary Object": [
                "ERROR"
              ],
              "Secondary Object": [
                "ERROR"
              ]
            },
            "Context": [
              "ERROR"
            ],
            "Purpose": [
              "ERROR"
            ],
            "Method": [
              "ERROR"
            ],
            "Results": [
              "ERROR"
            ],
            "Analysis": [
              "ERROR"
            ],
            "Challenge": [
              "ERROR"
            ],
            "Ethical": [
              "ERROR"
            ],
            "Implications": [
              "ERROR"
            ],
            "Contradictions": [
              "ERROR"
            ]
          },
          "Error_Type": "RECONSTRUCTION_ERROR"
        }
      ]
    }
  ]
}