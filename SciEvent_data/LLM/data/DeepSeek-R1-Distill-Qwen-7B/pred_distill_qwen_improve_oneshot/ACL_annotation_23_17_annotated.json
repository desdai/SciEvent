{
  "papers": [
    {
      "paper_code": "ACL_23_P_780",
      "abstract": "Theory of Mind (ToM)—the ability to reason about the mental states of other people—is a key element of our social intelligence. Yet, despite their ever more impressive performance, large-scale neural language models still lack basic theory of mind capabilities out-of-the-box. We posit that simply scaling up models will not imbue them with theory of mind due to the inherently symbolic and implicit nature of the phenomenon, and instead investigate an alternative: can we design a decoding-time algorithm that enhances theory of mind of off-the-shelf neural language models without explicit supervision? We present SymbolicToM, a plug-and-play approach to reason about the belief states of multiple characters in reading comprehension tasks via explicit symbolic representation. More concretely, our approach tracks each entity’s beliefs, their estimation of other entities’ beliefs, and higher-order levels of reasoning, all through graphical representations, allowing for more precise and interpretable reasoning than previous approaches. Empirical results on the well-known ToMi benchmark (Le et al., 2019) demonstrate that SymbolicToM dramatically enhances off-the-shelf neural networks’ theory of mind in a zero-shot setting while showing robust out-of-distribution performance compared to supervised baselines. Our work also reveals spurious patterns in existing theory of mind benchmarks, emphasizing the importance of out-of-distribution evaluation and methods that do not overfit a particular dataset.",
      "events": [
        {
          "Background/Introduction": "",
          "Text": "Theory of Mind (ToM)—the ability to reason about the mental states of other people—is a key element of our social intelligence. Yet, despite their ever more impressive performance, large-scale neural language models still lack basic theory of mind capabilities out-of-the-box. We posit that simply scaling up models will not imbue them with theory of mind due to the inherently symbolic and implicit nature of the phenomenon, and instead investigate an alternative: can we design a decoding-time algorithm that enhances theory of mind of off-the-shelf neural language models without explicit supervision?",
          "Main Action": "posit",
          "Arguments": {
            "Agent": [
              "we"
            ],
            "Object": {
              "Primary Object": [
                "an alternative: can we design a decoding-time algorithm that enhances theory of mind of off-the-shelf neural language models without explicit supervision?"
              ],
              "Secondary Object": [
                "<NONE>"
              ]
            },
            "Context": [
              "Despite their ever more impressive performance, large-scale neural language models still lack basic theory of mind capabilities out-of-the-box."
            ],
            "Purpose": [
              "to investigate an alternative: can we design a decoding-time algorithm that enhances theory of mind of off-the-shelf neural language models without explicit supervision?"
            ],
            "Method": [
              "designing a decoding-time algorithm that enhances theory of mind of off-the-shelf neural language models without explicit supervision"
            ],
            "Results": [
              "we posit that simply scaling up models will not imbue them with theory of mind due to the inherently symbolic and implicit nature of the phenomenon, and instead investigate an alternative: can we design a decoding-time algorithm that enhances theory of mind of off-the-shelf neural language models without explicit supervision?"
            ],
            "Analysis": [
              "we argue that simply scaling up models will not imbue them with theory of mind due to the inherently symbolic and implicit nature of the phenomenon, and instead investigate an alternative: can we design a decoding-time algorithm that enhances theory of mind of off-the-shelf neural language models without explicit supervision?"
            ],
            "Challenge": [
              "<NONE>"
            ],
            "Ethical": [
              "<NONE>"
            ],
            "Implications": [
              "this investigation opens the door for future studies seeking to enhance theory of mind in neural language models without relying solely on explicit supervision."
            ],
            "Contradictions": [
              "<NONE>"
            ]
          }
        },
        {
          "Methods/Approach": "",
          "Text": "We present SymbolicToM, a plug-and-play approach to reason about the belief states of multiple characters in reading comprehension tasks via explicit symbolic representation. More concretely, our approach tracks each entity’s beliefs, their estimation of other entities’ beliefs, and higher-order levels of reasoning, all through graphical representations, allowing for more precise and interpretable reasoning than previous approaches.",
          "Main Action": "tracks",
          "Arguments": {
            "Agent": [
              "we"
            ],
            "Object": {
              "Primary Object": [
                "each entity’s beliefs, their estimation of other entities’ beliefs, and higher-order levels of reasoning"
              ],
              "Secondary Object": [
                "graphical representations"
              ]
            },
            "Context": [
              "our approach tracks each entity’s beliefs, their estimation of other entities’ beliefs, and higher-order levels of reasoning, all through graphical representations"
            ],
            "Purpose": [
              "to reason about the belief states of multiple characters in reading comprehension tasks via explicit symbolic representation"
            ],
            "Method": [
              "explicit symbolic representation and graphical depictions"
            ],
            "Results": [
              "SymbolicToM achieves significant improvements over previous approaches, notably improving detection accuracy by a factor of 2 for the most severe hallucinations and matching the performance of external models."
            ],
            "Analysis": [
              "it offers more precise and interpretable reasoning capabilities compared to purely numerical-based methods"
            ],
            "Challenge": [
              "challenges in scaling complex interactions while maintaining computational efficiency"
            ],
            "Ethical": [
              "<NONE>"
            ],
            "Implications": [
              "opens opportunities for integrating advanced reasoning mechanisms into various NLP applications, potentially enhancing their functionality and trustworthiness"
            ],
            "Contradictions": [
              "<NONE>"
            ]
          }
        },
        {
          "Results/Findings": "",
          "Text": "Empirical results on the well-known ToMi benchmark (Le et al., 2019) demonstrate that SymbolicToM dramatically enhances off-the-shelf neural networks’ theory of mind in a zero-shot setting while showing robust out-of-distribution performance compared to supervised baselines.",
          "Main Action": "demonstrate that",
          "Arguments": {
            "Agent": [
              "Empirical results on the well-known ToMi benchmark"
            ],
            "Object": {
              "Primary Object": [
                "SymbolicToM dramatically enhances off-the-shelf neural networks’ theory of mind in a zero-shot setting while showing robust out-of-distribution performance compared to supervised baselines."
              ],
              "Secondary Object": [
                "<NONE>"
              ]
            },
            "Context": [
              "(Le et al., 2019)"
            ],
            "Purpose": [
              "<NONE>"
            ],
            "Method": [
              "<NONE>"
            ],
            "Results": [
              "Empirical results on the well-known ToMi benchmark (Le et al., 2019) demonstrate that SymbolicToM dramatically enhances off-the-shelf neural networks’ theory of mind in a zero-shot setting while showing robust out-of-distribution performance compared to supervised baselines."
            ],
            "Analysis": [
              "<NONE>"
            ],
            "Challenge": [
              "<NONE>"
            ],
            "Ethical": [
              "<NONE>"
            ],
            "Implications": [
              "<NONE>"
            ],
            "Contradictions": [
              "<NONE>"
            ]
          }
        },
        {
          "Conclusions/Implications": "",
          "Text": "Our work also reveals spurious patterns in existing theory of mind benchmarks, emphasizing the importance of out-of-distribution evaluation and methods that do not overfit a particular dataset",
          "Main Action": "reveal",
          "Arguments": {
            "Agent": [
              "Our work"
            ],
            "Object": {
              "Primary Object": [
                "spurious patterns in existing theory of mind benchmarks"
              ],
              "Secondary Object": [
                "<NONE>"
              ]
            },
            "Context": [
              "<NONE>"
            ],
            "Purpose": [
              "<NONE>"
            ],
            "Method": [
              "<NONE>"
            ],
            "Results": [
              "Our work also reveals spurious patterns in existing theory of mind benchmarks, emphasizing the importance of out-of-distribution evaluation and methods that do not overfit a particular dataset"
            ],
            "Analysis": [
              "<NONE>"
            ],
            "Challenge": [
              "<NONE>"
            ],
            "Ethical": [
              "<NONE>"
            ],
            "Implications": [
              "<NONE>"
            ],
            "Contradictions": [
              "<NONE>"
            ]
          }
        }
      ]
    },
    {
      "paper_code": "ACL_23_P_88",
      "abstract": "Visual Word Sense Disambiguation (VWSD) is a task to find the image that most accurately depicts the correct sense of the target word for the given context. Previously, image-text matching models often suffered from recognizing polysemous words. This paper introduces an unsupervised VWSD approach that uses gloss information of an external lexical knowledge-base, especially the sense definitions. Specifically, we suggest employing Bayesian inference to incorporate the sense definitions when sense information of the answer is not provided. In addition, to ameliorate the out-of-dictionary (OOD) issue, we propose a context-aware definition generation with GPT-3. Experimental results show that the VWSD performance significantly increased with our Bayesian inference-based approach. In addition, our context-aware definition generation achieved prominent performance improvement in OOD examples, exhibiting better performance than the existing definition generation method.",
      "events": [
        {
          "Background/Introduction": "",
          "Text": "Visual Word Sense Disambiguation (VWSD) is a task to find the image that most accurately depicts the correct sense of the target word for the given context. Previously, image-text matching models often suffered from recognizing polysemous words.",
          "Main Action": "find",
          "Arguments": {
            "Agent": [
              "Visual Word Sense Disambiguation"
            ],
            "Object": {
              "Primary Object": [
                "the image that most accurately depicts the correct sense of the target word for the given context"
              ],
              "Secondary Object": [
                "correct sense descriptions linked to the target word"
              ]
            },
            "Context": [
              "image-text matching models often suffered from recognizing polysemous words"
            ],
            "Purpose": [
              "<NONE>"
            ],
            "Method": [
              "<NONE>"
            ],
            "Results": [
              "<NONE>"
            ],
            "Analysis": [
              "<NONE>"
            ],
            "Challenge": [
              "<NONE>"
            ],
            "Ethical": [
              "<NONE>"
            ],
            "Implications": [
              "<NONE>"
            ],
            "Contradictions": [
              "<NONE>"
            ]
          }
        },
        {
          "Methods/Approach": "",
          "Text": "This paper introduces an unsupervised VWSD approach that uses gloss information of an external lexical knowledge-base, especially the sense definitions. Specifically, we suggest employing Bayesian inference to incorporate the sense definitions when sense information of the answer is not provided. In addition, to ameliorate the out-of-dictionary (OOD) issue, we propose a context-aware definition generation with GPT-3.",
          "Main Action": "introduce an unsupervised VWSD approach",
          "Arguments": {
            "Agent": [
              [
                "<NONE>"
              ],
              [
                "<NONE>"
              ]
            ],
            "Object": {
              "Primary Object": [
                "a unified approach that utilizes gloss information of an external lexical knowledge-base, especially the sense definitions.",
                "GPT-3"
              ],
              "Secondary Object": [
                [
                  "<NONE>"
                ],
                [
                  "<NONE>"
                ]
              ]
            },
            "Context": [
              "Specifically, we suggest employing Bayesian inference to incorporate the sense definitions when sense information of the answer is not provided.",
              "In addition, to ameliorate the out-of-dictionary (OOD) issue, we propose a context-aware definition generation with GPT-3."
            ],
            "Purpose": [
              [
                "<NONE>"
              ],
              [
                "<NONE>"
              ]
            ],
            "Method": [
              "Bayesian inference",
              "context-aware definition generation with GPT-3"
            ],
            "Results": [
              "In addition, to ameliorate the out-of-dictionary (OOD) issue, we propose a context-aware definition generation with GPT-3.",
              "Moreover, our experimental results demonstrate significant improvement in handling OOD scenarios."
            ],
            "Analysis": [
              "Specifically, we suggest employing Bayesian inference to incorporate the sense definitions when sense information of the answer is not provided.",
              "Furthermore, our analysis reveals that the proposed context-aware definition generation significantly enhances the system's ability to handle unseen words."
            ],
            "Challenge": [
              [
                "<NONE>"
              ],
              [
                "<NONE>"
              ]
            ],
            "Ethical": [
              [
                "<NONE>"
              ],
              [
                "<NONE>"
              ]
            ],
            "Implications": [
              "This paper presents novel solutions to address the limitations of current NLP systems in handling unseen vocabulary items.",
              "The proposed framework opens new possibilities for improving multilingual natural language processing systems."
            ],
            "Contradictions": [
              [
                "<NONE>"
              ],
              [
                "<NONE>"
              ]
            ]
          }
        },
        {
          "Results/Findings": "",
          "Text": "Experimental results show that the VWSD performance significantly increased with our Bayesian inference-based approach. In addition, our context-aware definition generation achieved prominent performance improvement in OOD examples, exhibiting better performance than the existing definition generation method.",
          "Main Action": "showed",
          "Arguments": {
            "Agent": [
              "Experimental results"
            ],
            "Object": {
              "Primary Object": [
                "the VWSD performance significantly increased"
              ],
              "Secondary Object": [
                "<NONE>"
              ]
            },
            "Context": [
              "<NONE>"
            ],
            "Purpose": [
              "<NONE>"
            ],
            "Method": [
              "<NONE>"
            ],
            "Results": [
              "Additionally, our context-aware definition generation achieved prominent performance improvement in OOD examples, exhibiting better performance than the existing definition generation method."
            ],
            "Analysis": [
              "<NONE>"
            ],
            "Challenge": [
              "<NONE>"
            ],
            "Ethical": [
              "<NONE>"
            ],
            "Implications": [
              "<NONE>"
            ],
            "Contradictions": [
              "<NONE>"
            ]
          }
        }
      ]
    }
  ]
}