{
  "papers": [
    {
      "paper_code": "ACL_23_P_511",
      "abstract": "Pre-trained large language models (PLMs) underly most new developments in natural language processing. They have shifted the field from application-specific model pipelines to a single model that is adapted to a wide range of tasks. Autoregressive PLMs like GPT-3 or PaLM and associated techniques like few-shot learning, have additionally shifted the output modality to generation instead of classification or regression. Despite their ubiquitous use, the generation quality of language models is rarely evaluated when these models are introduced. Additionally, it is unclear how existing generation tasks – while they can be used to compare systems at a high level – relate to the real world use cases for which people have been adopting them. In this work, we discuss how to adapt existing application-specific generation benchmarks to PLMs and provide an in-depth, empirical study of the limitations and capabilities of PLMs in natural language generation tasks along dimensions such as scale, architecture, input and output language. Our results show that PLMs differ in their applicability to different data regimes and their generalization to multiple languages. They further inform practitioners as to which PLMs to use for a given generation task setup. We share best practices to be taken into consideration when benchmarking generation capabilities during the development of upcoming PLMs.",
      "events": [
        {
          "Background/Introduction": "Pre trained models and their use cases for wide range of tasks",
          "Text": "Pre-trained large language models (PLMs) underly most new developments in natural language processing. They have shifted the field from application-specific model pipelines to a single model that is adapted to a wide range of tasks. Autoregressive PLMs like GPT-3 or PaLM and associated techniques like few-shot learning, have additionally shifted the output modality to generation instead of classification or regression. Despite their ubiquitous use, the generation quality of language models is rarely evaluated when these models are introduced. Additionally, it is unclear how existing generation tasks – while they can be used to compare systems at a high level – relate to the real-world use cases for which people have been adopting them.",
          "Main Action": "underly",
          "Arguments": {
            "Agent": [
              "Pre-trained large language models (PLMs)"
            ],
            "Object": {
              "Primary Object": [
                "most new developments"
              ],
              "Primary Modifier": [
                "in natural language processing"
              ],
              "Secondary Object": [],
              "Secondary Modifier": []
            },
            "Context": [
              "Pre-trained large language models (PLMs) underly most new developments in natural language processing",
              "shifted the field from application-specific model pipelines to a single model that is adapted to a wide range of tasks",
              "Autoregressive PLMs like GPT-3 or PaLM and associated techniques like few-shot learning, have additionally shifted the output modality to generation instead of classification or regression"
            ],
            "Purpose": [],
            "Method": [],
            "Results": [],
            "Analysis": [],
            "Challenge": [
              "the generation quality of language models is rarely evaluated when these models are introduced",
              "it is unclear how existing generation tasks – while they can be used to compare systems at a high level – relate to the real-world use cases for which people have been adopting them"
            ],
            "Ethical": [],
            "Implications": [],
            "Contradictions": []
          }
        },
        {
          "Methods/Approach": "How to adapt existing application specific benchmarks to PLM's",
          "Text": "In this work, we discuss how to adapt existing application-specific generation benchmarks to PLMs and provide an in-depth, empirical study of the limitations and capabilities of PLMs in natural language generation tasks along dimensions such as scale, architecture, input and output language.",
          "Main Action": "discuss",
          "Arguments": {
            "Agent": [
              "we"
            ],
            "Object": {
              "Primary Object": [],
              "Primary Modifier": [],
              "Secondary Object": [],
              "Secondary Modifier": []
            },
            "Context": [],
            "Purpose": [],
            "Method": [
              "how to adapt existing application-specific generation benchmarks to PLMs",
              "an in-depth, empirical study of the limitations and capabilities of PLMs in natural language generation tasks along dimensions such as scale, architecture, input and output language"
            ],
            "Results": [],
            "Analysis": [],
            "Challenge": [],
            "Ethical": [],
            "Implications": [],
            "Contradictions": []
          }
        },
        {
          "Results/Findings": "Results for findings of PLM's",
          "Text": "Our results show that PLMs differ in their applicability to different data regimes and their generalization to multiple languages. They further inform practitioners as to which PLMs to use for a given generation task setup.",
          "Main Action": "show",
          "Arguments": {
            "Agent": [
              "Our results"
            ],
            "Object": {
              "Primary Object": [
                "PLMs differ in their applicability to different data regimes and their generalization to multiple languages"
              ],
              "Primary Modifier": [],
              "Secondary Object": [],
              "Secondary Modifier": []
            },
            "Context": [],
            "Purpose": [],
            "Method": [],
            "Results": [
              "PLMs differ in their applicability to different data regimes and their generalization to multiple languages",
              "inform practitioners as to which PLMs to use for a given generation task setup"
            ],
            "Analysis": [],
            "Challenge": [],
            "Ethical": [],
            "Implications": [],
            "Contradictions": []
          }
        },
        {
          "Conclusions/Implications": "Best practices for benchmarking generation capabilities",
          "Text": "We share best practices to be taken into consideration when benchmarking generation capabilities during the development of upcoming PLMs.",
          "Main Action": "share",
          "Arguments": {
            "Agent": [
              "We"
            ],
            "Object": {
              "Primary Object": [
                "best practices"
              ],
              "Primary Modifier": [
                "to be taken into consideration when benchmarking generation capabilities"
              ],
              "Secondary Object": [],
              "Secondary Modifier": []
            },
            "Context": [],
            "Purpose": [],
            "Method": [],
            "Results": [],
            "Analysis": [],
            "Challenge": [],
            "Ethical": [],
            "Implications": [
              "best practices to be taken into consideration when benchmarking generation capabilities during the development of upcoming PLMs"
            ],
            "Contradictions": []
          }
        }
      ]
    },
    {
      "paper_code": "ACL_23_P_388",
      "abstract": "Multilingual pre-trained language models have demonstrated impressive (zero-shot) cross-lingual transfer abilities, however, their performance is hindered when the target language has distant typology from the source language or when pre-training data is limited in size. In this paper, we propose XLM-P, a method that contextually retrieves prompts as flexible guidance for encoding instances conditionally. Our space-efficient and model-agnostic XLM-P approach enables (1) lightweight modeling of language-invariant and language-specific knowledge across languages, and (2) easy integration with other multilingual pre-training methods. On the tasks of XTREME, which include text classification, sequence labeling, question answering, and sentence retrieval, both base- and large-size language models pre-trained with our proposed method exhibit consistent performance improvement. Furthermore, it provides substantial advantages for low-resource languages in unsupervised sentence retrieval and for target languages that differ greatly from the source language in cross-lingual transfer.",
      "events": [
        {
          "Background/Introduction": "Performance of multilingual pre trained language models",
          "Text": "Multilingual pre-trained language models have demonstrated impressive (zero-shot) cross-lingual transfer abilities, however, their performance is hindered when the target language has distant typology from the source language or when pre-training data is limited in size.",
          "Main Action": "demonstrated",
          "Arguments": {
            "Agent": [
              "Multilingual pre-trained language models"
            ],
            "Object": {
              "Primary Object": [
                "impressive (zero-shot) cross-lingual transfer abilities"
              ],
              "Primary Modifier": [],
              "Secondary Object": [],
              "Secondary Modifier": []
            },
            "Context": [],
            "Purpose": [],
            "Method": [],
            "Results": [],
            "Analysis": [],
            "Challenge": [
              "their performance is hindered when the target language has distant typology from the source language or when pre-training data is limited in size"
            ],
            "Ethical": [],
            "Implications": [],
            "Contradictions": []
          }
        },
        {
          "Methods/Approach": "Proposal of XLM-P to contextually retrieve prompts to encode instances",
          "Text": "In this paper, we propose XLM-P, a method that contextually retrieves prompts as flexible guidance for encoding instances conditionally. Our space-efficient and model-agnostic XLM-P approach enables (1) lightweight modeling of language-invariant and language-specific knowledge across languages, and (2) easy integration with other multilingual pre-training methods.",
          "Main Action": "propose",
          "Arguments": {
            "Agent": [
              "we"
            ],
            "Object": {
              "Primary Object": [
                "XLM-P"
              ],
              "Primary Modifier": [],
              "Secondary Object": [],
              "Secondary Modifier": []
            },
            "Context": [],
            "Purpose": [],
            "Method": [
              "contextually retrieves prompts as flexible guidance for encoding instances conditionally"
            ],
            "Results": [
              "Our space-efficient and model-agnostic XLM-P approach enables (1) lightweight modeling of language-invariant and language-specific knowledge across languages",
              "(2) easy integration with other multilingual pre-training methods"
            ],
            "Analysis": [],
            "Challenge": [],
            "Ethical": [],
            "Implications": [],
            "Contradictions": []
          }
        },
        {
          "Results/Findings": "Results of base and large size language models that use the proposed method",
          "Text": "On the tasks of XTREME, which include text classification, sequence labeling, question answering, and sentence retrieval, both base- and large-size language models pre-trained with our proposed method exhibit consistent performance improvement. Furthermore, it provides substantial advantages for low-resource languages in unsupervised sentence retrieval and for target languages that differ greatly from the source language in cross-lingual transfer.",
          "Main Action": "exhibit",
          "Arguments": {
            "Agent": [
              "base- and large-size language models"
            ],
            "Object": {
              "Primary Object": [
                "consistent performance improvement"
              ],
              "Primary Modifier": [],
              "Secondary Object": [],
              "Secondary Modifier": []
            },
            "Context": [
              "On the tasks of XTREME, which include text classification, sequence labeling, question answering, and sentence retrieval"
            ],
            "Purpose": [],
            "Method": [
              "pre-trained with our proposed method"
            ],
            "Results": [
              "it provides substantial advantages for low-resource languages in unsupervised sentence retrieval and for target languages that differ greatly from the source language in cross-lingual transfer"
            ],
            "Analysis": [],
            "Challenge": [],
            "Ethical": [],
            "Implications": [],
            "Contradictions": []
          }
        }
      ]
    }
  ]
}