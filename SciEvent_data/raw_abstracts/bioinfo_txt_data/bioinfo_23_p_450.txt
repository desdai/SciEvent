Screening new drug-target interactions (DTIs) by traditional experimental methods is costly and time-consuming. Recent advances in knowledge graphs, chemical linear notations, and genomic data enable researchers to develop computational-based-DTI models, which play a pivotal role in drug repurposing and discovery. However, there still needs to develop a multimodal fusion DTI model that integrates available heterogeneous data into a unified framework. We developed MDTips, a multimodal-data-based DTI prediction system, by fusing the knowledge graphs, gene expression profiles, and structural information of drugs/targets. MDTips yielded accurate and robust performance on DTI predictions. We found that multimodal fusion learning can fully consider the importance of each modality and incorporate information from multiple aspects, thus improving model performance. Extensive experimental results demonstrate that deep learning-based encoders (i.e. Attentive FP and Transformer) outperform traditional chemical descriptors/fingerprints, and MDTips outperforms other state-of-the-art prediction models. MDTips is designed to predict the input drugs' candidate targets, side effects, and indications with all available modalities. Via MDTips, we reverse-screened candidate targets of 6766 drugs, which can be used for drug repurposing and discovery.