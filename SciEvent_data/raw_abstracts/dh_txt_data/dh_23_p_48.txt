This article surveys the ways in which issues of race and gender bias emerge in projects involving the use of predictive analytics, big data and artificial intelligence (AI). It analyses some of the reasons biased results occur and argues for the importance of open documentation and explainability in combatting these inequities. Digital humanities can make a significant contribution in addressing these issues. This article was written in late 2020, and discussion and public debate about AI and bias has moved on enormously since the article was completed. Nevertheless, the fundamental proposition of this article has become even more important and pressing as debates around AI have progressed â€“ namely, that as a result of the development of big data and AI, it is vital to foster critical and socially aware approaches to the construction and analysis of data. The greatest threat to humanity from AI comes not from autonomous killer robots but rather from the social dislocation and injustices caused by an overreliance on poorly designed and badly documented commercial black boxes to administer everything from health care to public order and crime.