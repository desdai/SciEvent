{
  "ACL_23_P_587": {
    "abstract": "Summarization models often generate text that is poorly calibrated to quality metrics because they are trained to maximize the likelihood of a single reference (MLE). To address this, recent work has added a calibration step, which exposes a model to its own ranked outputs to improve relevance or, in a separate line of work, contrasts positive and negative sets to improve faithfulness. While effective, much of this work has focused on how to generate and optimize these sets. Less is known about why one setup is more effective than another. In this work, we uncover the underlying characteristics of effective sets. For each training instance, we form a large, diverse pool of candidates and systematically vary the subsets used for calibration fine-tuning. Each selection strategy targets distinct aspects of the sets, such as lexical diversity or the size of the gap between positive and negatives. On three diverse scientific long-form summarization datasets (spanning biomedical, clinical, and chemical domains), we find, among others, that faithfulness calibration is optimal when the negative sets are extractive and more likely to be generated, whereas for relevance calibration, the metric margin between candidates should be maximized and surprise–the disagreement between model and metric defined candidate rankings–minimized.",
    "[Background]": "Summarization models often generate text that is poorly calibrated to quality metrics because they are trained to maximize the likelihood of a single reference (MLE). To address this, recent work has added a calibration step, which exposes a model to its own ranked outputs to improve relevance or, in a separate line of work, contrasts positive and negative sets to improve faithfulness. While effective, much of this work has focused on how to generate and optimize these sets. Less is known about why one setup is more effective than another.",
    "[Method]": "For each training instance, we form a large, diverse pool of candidates and systematically vary the subsets used for calibration fine-tuning. Each selection strategy targets distinct aspects of the sets, such as lexical diversity or the size of the gap between positive and negatives.",
    "[Results]": "On three diverse scientific long-form summarization datasets (spanning biomedical, clinical, and chemical domains), we find, among others, that faithfulness calibration is optimal when the negative sets are extractive and more likely to be generated, whereas for relevance calibration, the metric margin between candidates should be maximized and surprise—the disagreement between model and metric defined candidate rankings—minimized.",
    "[Implications]": "The findings suggest that different calibration strategies may require varying approaches depending on their goals, with implications for the design of future summarization systems aiming to balance multiple evaluation metrics."
  },
  "ACL_23_P_299": {
    "abstract": "The personalized dialogue explores the consistent relationship between dialogue generation and personality. Existing personalized dialogue agents model persona profiles from three resources: sparse or dense persona descriptions and dialogue histories. However, sparse structured persona attributes are explicit but uninformative, dense persona texts contain rich persona descriptions with much noise, and dialogue history query is both noisy and uninformative for persona modeling. In this work, we combine the advantages of the three resources to obtain a richer and more accurate persona. We design a Contrastive Latent Variable-based model (CLV) that clusters the dense persona descriptions into sparse categories, which are combined with the history query to generate personalized responses. Experimental results on Chinese and English datasets demonstrate our model’s superiority in personalization.",
    "[Background]": "The existing methods for generating personalized dialogues rely solely on sparse or dense persona descriptions and dialogue histories, each presenting unique challenges such as being either too explicit yet uninformative or containing excessive noise. This motivates us to explore an alternative approach by combining these diverse sources to enhance persona modeling accuracy.",
    "[Method]": "To achieve this goal, we propose a novel framework called Contrastive Latent Variable-based model (CLV). CLV leverages dense persona descriptions by clustering them into sparse categorical representations, effectively reducing noise while preserving meaningful information. These clustered categories are then integrated with historical conversation data to guide response generation, ensuring personalized interactions.",
    "[Results]": "Our experiments across two language datasets—Chinese and English—demonstrate that the proposed CLV outperforms existing approaches in terms of personalization quality. Specifically, it achieves higher user satisfaction scores due to its ability to accurately capture nuanced user personalities and maintain coherent conversations despite varying input complexities.",
    "[Implications]": "The success of CLV suggests potential applications in various conversational AI systems, including virtual assistants and chatbots, where enhancing user experience through better understanding of individual preferences is crucial. Future work could extend this method to multilingual settings and explore its applicability in more complex scenarios."
  }
}