{
  "papers": [
    {
      "paper_code": "cscw_23_P_143",
      "abstract": "A conversational agent (CA) effectively facilitates online group discussions at scale. However, users may have expectations about how well the CA would perform that do not match with the actual performance, compromising technology acceptance. We built a facilitator CA that detects a member who has low contribution during a synchronous group chat discussion and asks the person to participate more. We designed three techniques to set end-user expectations about how accurately the CA identifies an under-contributing member: 1) information: explicitly communicating the accuracy of the detection algorithm, 2) explanation: providing an overview of the algorithm and the data used for the detection, and 3) adjustment: enabling users to gain a feeling of control over the algorithm. We conducted an online experiment with 163 crowdworkers in which each group completed a collaborative decision-making task and experienced one of the techniques. Through surveys and interviews, we found that the explanation technique was the most effective strategy overall as it reduced user embarrassment, increased the perceived intelligence of the CA, and helped users better understand the detection algorithm. In contrast, the information technique reduced members' contributions, and the adjustment technique led to a more negative perceived discussion experience. We also discovered that the interactions with other team members diluted the effects of the techniques on users' performance expectations and acceptance of the CA. We discuss implications for better designing expectation-setting techniques for AI-team collaboration such as ways to improve collaborative decision outcomes and quality of contributions.",
      "events": [
        {
          "Background/Introduction": "",
          "Text": "A conversational agent (CA) effectively facilitates online group discussions at scale. However, users may have expectations about how well the CA would perform that do not match with the actual performance, compromising technology acceptance.",
          "Main Action": "effectively facilitates",
          "Arguments": {
            "Agent": [
              "conversational agent (CA)"
            ],
            "Object": {
              "Primary Object": [
                "online group discussions"
              ],
              "Secondary Object": [
                "<NONE>"
              ]
            },
            "Context": [
              "at scale"
            ],
            "Purpose": [
              "users may have expectations [...] do not match with the actual performance"
            ],
            "Method": [
              "conversational agent in online group discussions"
            ],
            "Results": [
              "user expectations [...] do not match with the actual performance"
            ],
            "Analysis": [
              "compromising technology acceptance"
            ],
            "Challenge": [
              "<NONE>"
            ],
            "Ethical": [
              "<NONE>"
            ],
            "Implications": [
              "importance, impact, applications, or future work"
            ],
            "Contradictions": [
              "<NONE>"
            ]
          }
        },
        {
          "Methods/Approach": "",
          "Text": "We built a facilitator CA that detects a member who has low contribution during a synchronous group chat discussion and asks the person to participate more. We designed three techniques to set end-user expectations about how accurately the CA identifies an under-contributing member: 1) information: explicitly communicating the accuracy of the detection algorithm, 2) explanation: providing an overview of the algorithm and the data used for the detection, and 3) adjustment: enabling users to gain a feeling of control over the algorithm. We conducted an online experiment with 163 crowdworkers in which each group completed a collaborative decision-making task and experienced one of the techniques.",
          "Main Action": "detects",
          "Arguments": {
            "Agent": [
              "CA"
            ],
            "Object": {
              "Primary Object": [
                "member"
              ],
              "Secondary Object": [
                "person"
              ]
            },
            "Context": [
              "synchronous group chat discussion"
            ],
            "Purpose": [
              "encourage participation by identifying those contributing less"
            ],
            "Method": [
              "information",
              "explanation",
              "adjustment"
            ],
            "Results": [
              "online experiment with 163 crowdworkers"
            ],
            "Analysis": [
              "effectiveness based on the experiment"
            ],
            "Challenge": [
              "<NONE>"
            ],
            "Ethical": [
              "<NONE>"
            ],
            "Implications": [
              "improving group dynamics",
              "encouraging equal participation"
            ],
            "Contradictions": [
              "<NONE>"
            ]
          }
        },
        {
          "Results/Findings": "",
          "Text": "Through surveys and interviews, we found that the explanation technique was the most effective strategy overall as it reduced user embarrassment, increased the perceived intelligence of the CA, and helped users better understand the detection algorithm. In contrast, the information technique reduced members' contributions, and the adjustment technique led to a more negative perceived discussion experience. We also discovered that the interactions with other team members diluted the effects of the techniques on users' performance expectations and acceptance of the CA.",
          "Main Action": "we found",
          "Arguments": {
            "Agent": [
              "we"
            ],
            "Object": {
              "Primary Object": [
                "the explanation technique"
              ],
              "Secondary Object": [
                "<NONE>"
              ]
            },
            "Context": [
              "through surveys and interviews",
              "in contrast, the information technique",
              "and the adjustment technique led to a more negative perceived discussion experience",
              "interactions with other team members"
            ],
            "Purpose": [
              "<NONE>"
            ],
            "Method": [
              "<NONE>"
            ],
            "Results": [
              "reduced user embarrassment",
              "increased the perceived intelligence of the CA",
              "helped users better understand the detection algorithm"
            ],
            "Analysis": [
              "diluted the effects of the techniques on users' performance expectations and acceptance of the CA",
              "compared the effectiveness of different techniques"
            ],
            "Challenge": [
              "<NONE>"
            ],
            "Ethical": [
              "<NONE>"
            ],
            "Implications": [
              "interactions with other team members diluted the effects of the techniques on users' performance expectations and acceptance of the CA"
            ],
            "Contradictions": [
              "<NONE>"
            ]
          }
        },
        {
          "Conclusions/Implications": "",
          "Text": "We discuss implications for better designing expectation-setting techniques for AI-team collaboration such as ways to improve collaborative decision outcomes and quality of contributions.",
          "Main Action": "Discuss implications for better designing",
          "Arguments": {
            "Agent": [
              "We"
            ],
            "Object": {
              "Primary Object": [
                "Expectation-setting techniques for AI-team collaboration"
              ],
              "Secondary Object": [
                "Quality of contributions"
              ]
            },
            "Context": [
              "<NONE>"
            ],
            "Purpose": [
              "Enhancing collaborative decision outcomes"
            ],
            "Method": [
              "Ways to improve collaborative decision outcomes"
            ],
            "Results": [
              "Improved collaborative decision outcomes and quality of contributions"
            ],
            "Analysis": [
              "<NONE>"
            ],
            "Challenge": [
              "<NONE>"
            ],
            "Ethical": [
              "<NONE>"
            ],
            "Implications": [
              "Better designing expectation-setting techniques for AI-team collaboration"
            ],
            "Contradictions": [
              "<NONE>"
            ]
          }
        }
      ]
    },
    {
      "paper_code": "cscw_23_P_211",
      "abstract": "The COVID-19 pandemic transformed many aspects of health and daily life. A subset of people who were infected with the virus have ongoing chronic health issues that range in type of symptom and severity. In this study, we conducted a qualitative assessment of self-reported post-COVID symptoms from patients' electronic health records (EHR, n=564) and a randomized collection of Reddit and Twitter posts (n=500 for each). We show the inconsistencies in what types of symptoms are shared between platforms in addition to assessing the severity of the symptoms and how social media characterizations of post-COVID do not tell a complete story of this phenomenon. This research contributes to CSCW health literature by connecting digital traces of post-COVID with EHR data, critiquing the use of social media as a health proxy and points to its potential to add context to the analysis of traditional health data extracted from the EHR.",
      "events": [
        {
          "Background/Introduction": "",
          "Text": "The COVID-19 pandemic transformed many aspects of health and daily life. A subset of people who were infected with the virus have ongoing chronic health issues that range in type of symptom and severity.",
          "Main Action": "A subset of people who were infected with the virus have ongoing chronic health issues",
          "Arguments": {
            "Agent": [
              "People"
            ],
            "Object": {
              "Primary Object": [
                "Ongoing chronic health issues"
              ],
              "Secondary Object": [
                "Range in type of symptom and severity"
              ]
            },
            "Context": [
              "COVID-19 pandemic"
            ],
            "Purpose": [
              "<NONE>"
            ],
            "Method": [
              "<NONE>"
            ],
            "Results": [
              "<NONE>"
            ],
            "Analysis": [
              "<NONE>"
            ],
            "Challenge": [
              "<NONE>"
            ],
            "Ethical": [
              "<NONE>"
            ],
            "Implications": [
              "<NONE>"
            ],
            "Contradictions": [
              "<NONE>"
            ]
          }
        },
        {
          "Methods/Approach": "",
          "Text": "In this study, we conducted a qualitative assessment of self-reported post-COVID symptoms from patients' electronic health records (EHR, n=564) and a randomized collection of Reddit and Twitter posts (n=500 for each).",
          "Main Action": "Conducted",
          "Arguments": {
            "Agent": [
              "Researchers"
            ],
            "Object": {
              "Primary Object": [
                "Self-reported post-COVID symptoms",
                "Electronic Health Records (EHR)",
                "Reddit and Twitter posts"
              ],
              "Secondary Object": [
                "<NONE>"
              ]
            },
            "Context": [
              "Study",
              "Post-COVID symptoms",
              "Patients'",
              "Qualitative assessment",
              "Randomized collection",
              "Social media"
            ],
            "Purpose": [
              "Understanding symptom prevalence",
              "Comprehensive data sources",
              "Filling research gaps"
            ],
            "Method": [
              "Qualitative assessment",
              "EHR dataset (n=564)",
              "Reddit and Twitter dataset (n=500 each)"
            ],
            "Results": [
              "Symptom types",
              "Correlations between EHR and social media data",
              "Discrepancies in reporting"
            ],
            "Analysis": [
              "Comparing data sources",
              "Consistency checks",
              "Unique insights"
            ],
            "Challenge": [
              "Selection bias",
              "Data quality variability",
              "Limitations in sample representativeness"
            ],
            "Ethical": [
              "Patient privacy",
              "Informed consent",
              "Respectful data usage"
            ],
            "Implications": [
              "Enhancing future research",
              "Public health monitoring",
              "Integration of data sources"
            ],
            "Contradictions": [
              "Conflicting symptom tracking findings",
              "Previous research inconsistencies"
            ]
          }
        },
        {
          "Results/Findings": "",
          "Text": "We show the inconsistencies in what types of symptoms are shared between platforms in addition to assessing the severity of the symptoms and how social media characterizations of post-COVID do not tell a complete story of this phenomenon.",
          "Main Action": "show",
          "Arguments": {
            "Agent": [
              "we"
            ],
            "Object": {
              "Primary Object": [
                "inconsistencies in what types of symptoms are shared between platforms"
              ],
              "Secondary Object": [
                "severity of the symptoms"
              ]
            },
            "Context": [
              "post-COVID phenomenon"
            ],
            "Purpose": [
              "assessing the severity of the symptoms and understanding the nature of symptom reporting"
            ],
            "Method": [
              "analysis of data from various platforms"
            ],
            "Results": [
              "significant inconsistencies in symptom types across platforms",
              "findings indicate that social media characterizations do not provide a complete picture"
            ],
            "Analysis": [
              "these findings suggest gaps in current representations and highlight the complexity of post-COVID experiences"
            ],
            "Challenge": [
              "limited data availability and potential biases in self-reported symptoms"
            ],
            "Ethical": [
              "potential misrepresentation of health conditions through selective reporting on social media"
            ],
            "Implications": [
              "underscore the importance of comprehensive data collection methods",
              "emphasize the need for critical evaluation of source reliability"
            ],
            "Contradictions": [
              "discrepancies between professional medical assessments and layperson perceptions"
            ]
          }
        },
        {
          "Conclusions/Implications": "",
          "Text": "This research contributes to CSCW health literature by connecting digital traces of post-COVID with EHR data, critiquing the use of social media as a health proxy and points to its potential to add context to the analysis of traditional health data extracted from the EHR.",
          "Main Action": "contributes",
          "Arguments": {
            "Agent": [
              "researchers"
            ],
            "Object": {
              "Primary Object": [
                "digital traces of post-COVID"
              ],
              "Secondary Object": [
                "EHR data"
              ]
            },
            "Context": [
              "CSCW health literature"
            ],
            "Purpose": [
              "to add context to the analysis of traditional health data extracted from the EHR"
            ],
            "Method": [
              "use of social media as a health proxy"
            ],
            "Results": [
              "social media adds context to the analysis of traditional health data extracted from the EHR"
            ],
            "Analysis": [
              "critiquing the use of social media as a health proxy and points to its potential to add context"
            ],
            "Challenge": [
              "<NONE>"
            ],
            "Ethical": [
              "<NONE>"
            ],
            "Implications": [
              "enhancing understanding of health behaviors during COVID-19 pandemic",
              "informing integrative approaches combining diverse data types"
            ],
            "Contradictions": [
              "<NONE>"
            ]
          }
        }
      ]
    }
  ]
}