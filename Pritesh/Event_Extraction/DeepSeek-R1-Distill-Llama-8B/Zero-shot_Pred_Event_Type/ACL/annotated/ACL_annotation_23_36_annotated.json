{
  "papers": [
    {
      "paper_code": "ACL_23_P_211",
      "abstract": "Multilingual neural machine translation has witnessed remarkable progress in recent years. However, the long-tailed distribution of multilingual corpora poses a challenge of Pareto optimization, i.e., optimizing for some languages may come at the cost of degrading the performance of others. Existing balancing training strategies are equivalent to a series of Pareto optimal solutions, which trade off on a Pareto frontierIn Pareto optimization, Pareto optimal solutions refer to solutions in which none of the objectives can be improved without sacrificing at least one of the other objectives. The set of all Pareto optimal solutions forms a Pareto frontier. In this work, we propose a new training framework, Pareto Mutual Distillation (Pareto-MD), towards pushing the Pareto frontier outwards rather than making trade-offs. Specifically, Pareto-MD collaboratively trains two Pareto optimal solutions that favor different languages and allows them to learn from the strengths of each other via knowledge distillation. Furthermore, we introduce a novel strategy to enable stronger communication between Pareto optimal solutions and broaden the applicability of our approach. Experimental results on the widely-used WMT and TED datasets show that our method significantly pushes the Pareto frontier and outperforms baselines by up to +2.46 BLEU.",
      "events": [
        {
          "Background/Introduction": "",
          "Text": "Multilingual neural machine translation has witnessed remarkable progress in recent years. However, the long-tailed distribution of multilingual corpora poses a challenge of Pareto optimization, i.e., optimizing for some languages may come at the cost of degrading the performance of others. Existing balancing training strategies are equivalent to a series of Pareto optimal solutions, which trade off on a Pareto frontierIn Pareto optimization, Pareto optimal solutions refer to solutions in which none of the objectives can be improved without sacrificing at least one of the other objectives. The set of all Pareto optimal solutions forms a Pareto frontier.",
          "Main Action": "Identifying the challenge of Pareto optimization",
          "Arguments": {
            "Agent": [
              "Multilingual neural machine translation"
            ],
            "Object": {
              "Primary Object": [
                "Long-tailed distribution of multilingual corpora"
              ],
              "Secondary Object": [
                "Individual languages"
              ]
            },
            "Context": [
              "Advancements in neural machine translation have been remarkable"
            ],
            "Purpose": [
              "Balancing optimization across languages without negative impacts"
            ],
            "Method": [
              "Using Pareto optimization concepts and existing balancing strategies"
            ],
            "Results": [
              "<NONE>"
            ],
            "Analysis": [
              "Discussing how Pareto optimal solutions form a frontier and trade-offs involved"
            ],
            "Challenge": [
              "Poses a challenge of Pareto optimization"
            ],
            "Ethical": [
              "<NONE>"
            ],
            "Implications": [
              "Future research directions towards better balancing strategies"
            ],
            "Contradictions": [
              "<NONE>"
            ]
          }
        },
        {
          "Methods/Approach": "",
          "Text": "In this work, we propose a new training framework, Pareto Mutual Distillation (Pareto-MD), towards pushing the Pareto frontier outwards rather than making trade-offs. Specifically, Pareto-MD collaboratively trains two Pareto optimal solutions that favor different languages and allows them to learn from the strengths of each other via knowledge distillation. Furthermore, we introduce a novel strategy to enable stronger communication between Pareto optimal solutions and broaden the applicability of our approach.",
          "Main Action": "Proposing a new training framework",
          "Arguments": {
            "Agent": [
              "We"
            ],
            "Object": {
              "Primary Object": [
                "Pareto Mutual Distillation (Pareto-MD)"
              ],
              "Secondary Object": [
                "Pareto optimal solutions"
              ]
            },
            "Context": [
              "<NONE>"
            ],
            "Purpose": [
              "Pushing the Pareto frontier outwards rather than making trade-offs"
            ],
            "Method": [
              "Collaboratively training two Pareto optimal solutions that favor different languages",
              "Enabling stronger communication between Pareto optimal solutions"
            ],
            "Results": [
              "Achieving improved performance across different languages"
            ],
            "Analysis": [
              "<NONE>"
            ],
            "Challenge": [
              "<NONE>"
            ],
            "Ethical": [
              "<NONE>"
            ],
            "Implications": [
              "Enhanced language understanding",
              "Increased applicability across various tasks involving multilingualism",
              "Robustness of AI models"
            ],
            "Contradictions": [
              "<NONE>"
            ]
          }
        },
        {
          "Results/Findings": "",
          "Text": "Experimental results on the widely-used WMT and TED datasets show that our method significantly pushes the Pareto frontier and outperforms baselines by up to +2.46 BLEU.",
          "Main Action": "outperforms",
          "Arguments": {
            "Agent": [
              "our method"
            ],
            "Object": {
              "Primary Object": [
                "baselines"
              ],
              "Secondary Object": [
                "<NONE>"
              ]
            },
            "Context": [
              "widely-used WMT and TED datasets"
            ],
            "Purpose": [
              "evaluate performance against baselines"
            ],
            "Method": [
              "<NONE>"
            ],
            "Results": [
              "significantly improves performance",
              "+2.46 BLEU"
            ],
            "Analysis": [
              "<NONE>"
            ],
            "Challenge": [
              "<NONE>"
            ],
            "Ethical": [
              "<NONE>"
            ],
            "Implications": [
              "pushes the Pareto frontier",
              "new advancements in the field"
            ],
            "Contradictions": [
              "<NONE>"
            ]
          }
        }
      ]
    },
    {
      "paper_code": "ACL_23_P_367",
      "abstract": "Although pretrained language models (PLMs) can be prompted to perform a wide range of language tasks, it remains an open question how much this ability comes from generalizable linguistic understanding versus surface-level lexical patterns. To test this, we present a structured prompting approach for linguistic structured prediction tasks, allowing us to perform zero- and few-shot sequence tagging with autoregressive PLMs. We evaluate this approach on part-of-speech tagging, named entity recognition, and sentence chunking, demonstrating strong few-shot performance in all cases. We also find that while PLMs contain significant prior knowledge of task labels due to task leakage into the pretraining corpus, structured prompting can also retrieve linguistic structure with arbitrary labels. These findings indicate that the in-context learning ability and linguistic knowledge of PLMs generalizes beyond memorization of their training data.",
      "events": [
        {
          "Background/Introduction": "",
          "Text": "Although pretrained language models (PLMs) can be prompted to perform a wide range of language tasks, it remains an open question how much this ability comes from generalizable linguistic understanding versus surface-level lexical patterns.",
          "Main Action": "It remains an open question",
          "Arguments": {
            "Agent": [
              "Researchers"
            ],
            "Object": {
              "Primary Object": [
                "pretrained language models (PLMs)' ability"
              ],
              "Secondary Object": [
                "<NONE>"
              ]
            },
            "Context": [
              "<NONE>"
            ],
            "Purpose": [
              "<NONE>"
            ],
            "Method": [
              "<NONE>"
            ],
            "Results": [
              "<NONE>"
            ],
            "Analysis": [
              "<NONE>"
            ],
            "Challenge": [
              "<NONE>"
            ],
            "Ethical": [
              "<NONE>"
            ],
            "Implications": [
              "<NONE>"
            ],
            "Contradictions": [
              "<NONE>"
            ]
          }
        },
        {
          "Methods/Approach": "",
          "Text": "To test this, we present a structured prompting approach for linguistic structured prediction tasks, allowing us to perform zero- and few-shot sequence tagging with autoregressive PLMs. We evaluate this approach on part-of-speech tagging, named entity recognition, and sentence chunking, demonstrating strong few-shot performance in all cases.",
          "Main Action": "Present",
          "Arguments": {
            "Agent": [
              "We"
            ],
            "Object": {
              "Primary Object": [
                "Structured prompting approach"
              ],
              "Secondary Object": [
                "Part-of-speech tagging",
                "Named Entity Recognition",
                "Sentence chunking"
              ]
            },
            "Context": [
              "To test this"
            ],
            "Purpose": [
              "Evaluating this approach on part-of-speech tagging, named entity recognition, and sentence chunking, demonstrating strong few-shot performance in all cases"
            ],
            "Method": [
              "Using structured prompting approach",
              "Autoregressive PLMs",
              "Zero- and few-shot sequence tagging"
            ],
            "Results": [
              "Strong few-shot performance in all cases"
            ],
            "Analysis": [
              "<NONE>"
            ],
            "Challenge": [
              "<NONE>"
            ],
            "Ethical": [
              "<NONE>"
            ],
            "Implications": [
              "This approach shows promise for efficient training with limited data, potentially applicable elsewhere in language modeling tasks"
            ],
            "Contradictions": [
              "<NONE>"
            ]
          }
        },
        {
          "Results/Findings": "",
          "Text": "We also find that while PLMs contain significant prior knowledge of task labels due to task leakage into the pretraining corpus, structured prompting can also retrieve linguistic structure with arbitrary labels. These findings indicate that the in-context learning ability and linguistic knowledge of PLMs generalizes beyond memorization of their training data.",
          "Main Action": "retrieve",
          "Arguments": {
            "Agent": [
              "Structured prompting"
            ],
            "Object": {
              "Primary Object": [
                "linguistic structure with arbitrary labels"
              ],
              "Secondary Object": [
                "<NONE>"
              ]
            },
            "Context": [
              "While PLMs contain significant prior knowledge of task labels due to task leakage into the pretraining corpus"
            ],
            "Purpose": [
              "To demonstrate the in-context learning ability and linguistic knowledge of PLMs generalize beyond memorization of their training data"
            ],
            "Method": [
              "Using structured prompting"
            ],
            "Results": [
              "These findings indicate that the in-context learning ability and linguistic knowledge of PLMs generalizes beyond memorization of their training data"
            ],
            "Analysis": [
              "This implies that structured prompting effectively retrieves linguistic structure without reliance on prior knowledge"
            ],
            "Challenge": [
              "Task leakage into the pretraining corpus causes PLMs to have unintended prior knowledge"
            ],
            "Ethical": [
              "<NONE>"
            ],
            "Implications": [
              "Broader implications for understanding language model capabilities and prompt engineering strategies"
            ],
            "Contradictions": [
              "<NONE>"
            ]
          }
        }
      ]
    }
  ]
}