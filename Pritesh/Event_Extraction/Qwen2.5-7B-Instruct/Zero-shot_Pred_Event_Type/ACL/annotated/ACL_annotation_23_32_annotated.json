{
  "papers": [
    {
      "paper_code": "ACL_23_P_634",
      "abstract": "Many text generation applications require the generated text to be factually consistent with input information. Automatic evaluation of factual consistency is challenging. Previous work has developed various metrics that often depend on specific functions, such as natural language inference (NLI) or question answering (QA), trained on limited data. Those metrics thus can hardly assess diverse factual inconsistencies (e.g., contradictions, hallucinations) that occur in varying inputs/outputs (e.g., sentences, documents) from different tasks. In this paper, we propose AlignScore, a new holistic metric that applies to a variety of factual inconsistency scenarios as above. AlignScore is based on a general function of information alignment between two arbitrary text pieces. Crucially, we develop a unified training framework of the alignment function by integrating a large diversity of data sources, resulting in 4.7M training examples from 7 well-established tasks (NLI, QA, paraphrasing, fact verification, information retrieval, semantic similarity, and summarization). We conduct extensive experiments on large-scale benchmarks including 22 evaluation datasets, where 19 of the datasets were never seen in the alignment training. AlignScore achieves substantial improvement over a wide range of previous metrics. Moreover, AlignScore (355M parameters) matches or even outperforms metrics based on ChatGPT and GPT-4 that are orders of magnitude larger.",
      "events": [
        {
          "Background/Introduction": "",
          "Text": "Many text generation applications require the generated text to be factually consistent with input information. Automatic evaluation of factual consistency is challenging. Previous work has developed various metrics that often depend on specific functions, such as natural language inference (NLI) or question answering (QA), trained on limited data. Those metrics thus can hardly assess diverse factual inconsistencies (e.g., contradictions, hallucinations) that occur in varying inputs/outputs (e.g., sentences, documents) from different tasks.",
          "Main Action": "<NONE>",
          "Arguments": {
            "Agent": [
              "Previous work"
            ],
            "Object": {
              "Primary Object": [
                "various metrics"
              ],
              "Secondary Object": [
                "limited data",
                "specific functions"
              ]
            },
            "Context": [
              "Automatic evaluation of factual consistency is challenging",
              "Those metrics thus can hardly assess diverse factual inconsistencies"
            ],
            "Purpose": [
              "developed various metrics"
            ],
            "Method": [
              "trained on limited data",
              "depend on specific functions"
            ],
            "Results": [
              "can hardly assess diverse factual inconsistencies"
            ],
            "Analysis": [
              "<NONE>"
            ],
            "Challenge": [
              "challenging automatic evaluation of factual consistency",
              "hardly assess diverse factual inconsistencies"
            ],
            "Ethical": [
              "<NONE>"
            ],
            "Implications": [
              "<NONE>"
            ],
            "Contradictions": [
              "<NONE>"
            ]
          }
        },
        {
          "Methods/Approach": "",
          "Text": "In this paper, we propose AlignScore, a new holistic metric that applies to a variety of factual inconsistency scenarios as above. AlignScore is based on a general function of information alignment between two arbitrary text pieces. Crucially, we develop a unified training framework of the alignment function by integrating a large diversity of data sources, resulting in 4.7M training examples from 7 well-established tasks (NLI, QA, paraphrasing, fact verification, information retrieval, semantic similarity, and summarization).",
          "Main Action": "propose",
          "Arguments": {
            "Agent": [
              "we"
            ],
            "Object": {
              "Primary Object": [
                "AlignScore"
              ],
              "Secondary Object": [
                "a new holistic metric"
              ]
            },
            "Context": [
              "applies to a variety of factual inconsistency scenarios"
            ],
            "Purpose": [
              "to apply to a variety of factual inconsistency scenarios"
            ],
            "Method": [
              "based on a general function of information alignment between two arbitrary text pieces",
              "developing a unified training framework of the alignment function by integrating a large diversity of data sources"
            ],
            "Results": [
              "<NONE>"
            ],
            "Analysis": [
              "<NONE>"
            ],
            "Challenge": [
              "<NONE>"
            ],
            "Ethical": [
              "<NONE>"
            ],
            "Implications": [
              "<NONE>"
            ],
            "Contradictions": [
              "<NONE>"
            ]
          }
        },
        {
          "Results/Findings": "",
          "Text": "We conduct extensive experiments on large-scale benchmarks including 22 evaluation datasets, where 19 of the datasets were never seen in the alignment training. AlignScore achieves substantial improvement over a wide range of previous metrics. Moreover, AlignScore (355M parameters) matches or even outperforms metrics based on ChatGPT and GPT-4 that are orders of magnitude larger.",
          "Main Action": "conduct",
          "Arguments": {
            "Agent": [
              "we"
            ],
            "Object": {
              "Primary Object": [
                "extensive experiments"
              ],
              "Secondary Object": [
                "large-scale benchmarks",
                "evaluation datasets"
              ]
            },
            "Context": [
              "on large-scale benchmarks including 22 evaluation datasets, where 19 of the datasets were never seen in the alignment training."
            ],
            "Purpose": [
              "to achieve substantial improvement over a wide range of previous metrics"
            ],
            "Method": [
              "<NONE>"
            ],
            "Results": [
              "AlignScore achieves substantial improvement over a wide range of previous metrics.",
              "matches or even outperforms metrics based on ChatGPT and GPT-4 that are orders of magnitude larger"
            ],
            "Analysis": [
              "none"
            ],
            "Challenge": [
              "none"
            ],
            "Ethical": [
              "none"
            ],
            "Implications": [
              "none"
            ],
            "Contradictions": [
              "<NONE>"
            ]
          }
        }
      ]
    },
    {
      "paper_code": "ACL_23_P_859",
      "abstract": "Large language models (LLMs) that have been trained on multilingual but not parallel text exhibit a remarkable ability to translate between languages. We probe this ability in an in-depth study of the pathways language model (PaLM), which has demonstrated the strongest machine translation (MT) performance among similarly-trained LLMs to date. We investigate various strategies for choosing translation examples for few-shot prompting, concluding that example quality is the most important factor. Using optimized prompts, we revisit previous assessments of PaLM’s MT capabilities with more recent test sets, modern MT metrics, and human evaluation, and find that its performance, while impressive, still lags that of state-of-the-art supervised systems. We conclude by providing an analysis of PaLM’s MT output which reveals some interesting properties and prospects for future work.",
      "events": [
        {
          "Background/Introduction": "",
          "Text": "Large language models (LLMs) that have been trained on multilingual but not parallel text exhibit a remarkable ability to translate between languages.",
          "Main Action": "<NONE>",
          "Arguments": {
            "Agent": [
              "Large language models"
            ],
            "Object": {
              "Primary Object": [
                "exhibit a remarkable ability"
              ],
              "Secondary Object": [
                "to translate between languages"
              ]
            },
            "Context": [
              "that have been trained on multilingual but not parallel text"
            ],
            "Purpose": [
              "<NONE>"
            ],
            "Method": [
              "<NONE>"
            ],
            "Results": [
              "exhibit a remarkable ability to translate between languages"
            ],
            "Analysis": [
              "<NONE>"
            ],
            "Challenge": [
              "<NONE>"
            ],
            "Ethical": [
              "<NONE>"
            ],
            "Implications": [
              "<NONE>"
            ],
            "Contradictions": [
              "<NONE>"
            ]
          }
        },
        {
          "Methods/Approach": "",
          "Text": "We probe this ability in an in-depth study of the pathways language model (PaLM), which has demonstrated the strongest machine translation (MT) performance among similarly-trained LLMs to date. We investigate various strategies for choosing translation examples for few-shot prompting, concluding that example quality is the most important factor. Using optimized prompts, we revisit previous assessments of PaLM’s MT capabilities with more recent test sets, modern MT metrics, and human evaluation, and find that its performance, while impressive, still lags that of state-of-the-art supervised systems.",
          "Main Action": "investigate",
          "Arguments": {
            "Agent": [
              "we"
            ],
            "Object": {
              "Primary Object": [
                "various strategies for choosing translation examples for few-shot prompting"
              ],
              "Secondary Object": [
                "example quality"
              ]
            },
            "Context": [
              "an in-depth study of the pathways language model (PaLM), which has demonstrated the strongest machine translation (MT) performance among similarly-trained LLMs to date"
            ],
            "Purpose": [
              "concluding that example quality is the most important factor"
            ],
            "Method": [
              "using optimized prompts"
            ],
            "Results": [
              "revisit[ing] previous assessments of PaLM's MT capabilities with more recent test sets, modern MT metrics, and human evaluation, and finding that its performance, while impressive, still lags that of state-of-the-art supervised systems"
            ],
            "Analysis": [
              "none"
            ],
            "Challenge": [
              "none"
            ],
            "Ethical": [
              "none"
            ],
            "Implications": [
              "none"
            ],
            "Contradictions": [
              "none"
            ]
          }
        },
        {
          "Conclusions/Implications": "",
          "Text": "We conclude by providing an analysis of PaLM’s MT output which reveals some interesting properties and prospects for future work.",
          "Main Action": "providing",
          "Arguments": {
            "Agent": [
              "we"
            ],
            "Object": {
              "Primary Object": [
                "an analysis of PaLM's MT output"
              ],
              "Secondary Object": [
                "some interesting properties and prospects for future work"
              ]
            },
            "Context": [
              "by conclusion"
            ],
            "Purpose": [
              "revelation of certain aspects of PaLM's performance"
            ],
            "Method": [
              "<NONE>"
            ],
            "Results": [
              "some interesting properties and prospects for future work"
            ],
            "Analysis": [
              "analysis of PaLM's MT output"
            ],
            "Challenge": [
              "<NONE>"
            ],
            "Ethical": [
              "<NONE>"
            ],
            "Implications": [
              "for future work"
            ],
            "Contradictions": [
              "<NONE>"
            ]
          }
        }
      ]
    }
  ]
}